<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Regularization]]></title>
    <url>%2F2018%2F12%2F14%2FRegularization%2F</url>
    <content type="text"><![CDATA[AbstractDeep Learning models have so much flexibility and capacity that overfitting can be a serious problem, if the training dataset is not big enough. Sure it does well on the training set, but the learned network doesn’t generalize to new examples that it has never seen! This article will use regularization in our deep learning models. ImplementProblem Statement: You have just been hired as an AI expert by the French Football Corporation. They would like you to recommend positions where France’s goal keeper should kick the ball so that the French team’s players can then hit it with their head. Figure 1: Football field The goal keeper kicks the ball in the air, the players of each team are fighting to hit the ball with their head They give you the following 2D dataset from France’s past 10 games. 1train_X, train_Y, test_X, test_Y = load_2D_dataset() Each dot corresponds to a position on the football field where a football player has hit the ball with his/her head after the French goal keeper has shot the ball from the left side of the football field. If the dot is blue, it means the French player managed to hit the ball with his/her head If the dot is red, it means the other team’s player hit the ball with their head Our goal: Use a deep learning model to find the positions on the field where the goalkeeper should kick the ball. Analysis of the dataset: This dataset is a little noisy, but it looks like a diagonal line separating the upper left half (blue) from the lower right half (red) would work well. I will first try a non-regularized model. Then I will show you how to regularize it and decide which model we will choose to solve the French Football Corporation’s problem. Non-regularized modelI will use the following neural network. This model can be used: in regularization mode — by setting the lambd input to a non-zero value. We use “lambd“ instead of “lambda“ because “lambda“ is a reserved keyword in Python. in dropout mode — by setting the keep_prob to a value less than one I will first try the model without any regularization. Then, I will implement: L2 regularization — functions: “compute_cost_with_regularization()“ and “backward_propagation_with_regularization()“ Dropout — functions: “forward_propagation_with_dropout()“ and “backward_propagation_with_dropout()“ In each part, I will run this model with the correct inputs so that it calls the functions I’ve implemented: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768def model(X, Y, learning_rate = 0.3, num_iterations = 30000, print_cost = True, lambd = 0, keep_prob = 1): """ Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- input data, of shape (input size, number of examples) Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (output size, number of examples) learning_rate -- learning rate of the optimization num_iterations -- number of iterations of the optimization loop print_cost -- If True, print the cost every 10000 iterations lambd -- regularization hyperparameter, scalar keep_prob - probability of keeping a neuron active during drop-out, scalar. Returns: parameters -- parameters learned by the model. They can then be used to predict. """ grads = &#123;&#125; costs = [] # to keep track of the cost m = X.shape[1] # number of examples layers_dims = [X.shape[0], 20, 3, 1] # Initialize parameters dictionary. parameters = initialize_parameters(layers_dims) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. if keep_prob == 1: a3, cache = forward_propagation(X, parameters) elif keep_prob &lt; 1: a3, cache = forward_propagation_with_dropout(X, parameters, keep_prob) # Cost function if lambd == 0: cost = compute_cost(a3, Y) else: cost = compute_cost_with_regularization(a3, Y, parameters, lambd) # Backward propagation. assert(lambd==0 or keep_prob==1) # it is possible to use both L2 regularization and dropout, # but this assignment will only explore one at a time if lambd == 0 and keep_prob == 1: grads = backward_propagation(X, Y, cache) elif lambd != 0: grads = backward_propagation_with_regularization(X, Y, cache, lambd) elif keep_prob &lt; 1: grads = backward_propagation_with_dropout(X, Y, cache, keep_prob) # Update parameters. parameters = update_parameters(parameters, grads, learning_rate) # Print the loss every 10000 iterations if print_cost and i % 10000 == 0: print("Cost after iteration &#123;&#125;: &#123;&#125;".format(i, cost)) if print_cost and i % 1000 == 0: costs.append(cost) # plot the cost plt.plot(costs) plt.ylabel('cost') plt.xlabel('iterations (x1,000)') plt.title("Learning rate =" + str(learning_rate)) plt.show() return parameters Let’s train the model without any regularization, and observe the accuracy on the train/test sets. 1234567891011parameters = model(train_X, train_Y)print ("On the training set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)plt.title("Model without regularization")axes = plt.gca()axes.set_xlim([-0.75,0.40])axes.set_ylim([-0.75,0.65])#to plot the decision boundary of our model.plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y) Output: Cost after iteration 0: 0.6557412523481002 Cost after iteration 10000: 0.16329987525724216 Cost after iteration 20000: 0.13851642423255986 On the training set: Accuracy: 0.947867298578 On the test set: Accuracy: 0.915 The train accuracy is 94.8% while the test accuracy is 91.5%. This is the baseline model (I will observe the impact of regularization on this model). The non-regularized model is obviously overfitting the training set. It is fitting the noisy points! Lets now look at two techniques to reduce overfitting. L2 RegularizationThe standard way to avoid overfitting is called L2 regularization. It consists of appropriately modifying our cost function, from: J = -\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} \tag{1}To: J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} }_\text{cross-entropy cost} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W_{k,j}^{[l]2} }_\text{L2 regularization cost} \tag{2}Let’s modify out cost and observe the consequences. compute_cost_with_regularizationI will implement compute_cost_with_regularization() which computes the cost given by formula (2). To calculate $\sum\limitsk\sum\limits_j W{k,j}^{[l]2}$ , I will use np.sum(np.square(Wl)) 12345678910111213141516171819202122232425def compute_cost_with_regularization(A3, Y, parameters, lambd): """ Implement the cost function with L2 regularization. See formula (2) above. Arguments: A3 -- post-activation, output of forward propagation, of shape (output size, number of examples) Y -- "true" labels vector, of shape (output size, number of examples) parameters -- python dictionary containing parameters of the model Returns: cost - value of the regularized loss function (formula (2)) """ m = Y.shape[1] W1 = parameters["W1"] W2 = parameters["W2"] W3 = parameters["W3"] cross_entropy_cost = compute_cost(A3, Y) # This gives you the cross-entropy part of the cost L2_regularization_cost = (1 / m) * (lambd / 2) * (np.sum(np.square(W1))+np.sum(np.square(W2))+np.sum(np.square(W3))) cost = cross_entropy_cost + L2_regularization_cost return cost Of course, because I changed the cost, we have to change backward propagation as well! All the gradients have to be computed with respect to this new cost. I will implement the changes needed in backward propagation to take into account regularization. The changes only concern dW1, dW2 and dW3. For each, we have to add the regularization term’s gradient ($\frac{d}{dW} ( \frac{1}{2}\frac{\lambda}{m} W^2) = \frac{\lambda}{m} W$). 1234567891011121314151617181920212223242526272829303132333435363738def backward_propagation_with_regularization(X, Y, cache, lambd): """ Implements the backward propagation of our baseline model to which we added an L2 regularization. Arguments: X -- input dataset, of shape (input size, number of examples) Y -- "true" labels vector, of shape (output size, number of examples) cache -- cache output from forward_propagation() lambd -- regularization hyperparameter, scalar Returns: gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables """ m = X.shape[1] (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache dZ3 = A3 - Y dW3 = 1. / m * np.dot(dZ3, A2.T) + (lambd / m) * W3 db3 = 1. / m * np.sum(dZ3, axis=1, keepdims=True) dA2 = np.dot(W3.T, dZ3) dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0)) dW2 = 1. / m * np.dot(dZ2, A1.T) + (lambd / m) * W2 db2 = 1. / m * np.sum(dZ2, axis=1, keepdims=True) dA1 = np.dot(W2.T, dZ2) dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0)) dW1 = 1. / m * np.dot(dZ1, X.T) + (lambd / m) * W1 db1 = 1. / m * np.sum(dZ1, axis=1, keepdims=True) gradients = &#123;"dZ3": dZ3, "dW3": dW3, "db3": db3, "dA2": dA2, "dZ2": dZ2, "dW2": dW2, "db2": db2, "dA1": dA1, "dZ1": dZ1, "dW1": dW1, "db1": db1&#125; return gradients Let’s now run the model with L2 regularization $(\lambda = 0.7)$. The model() function will call: compute_cost_with_regularization instead of compute_cost backward_propagation_with_regularization instead of backward_propagation 12345678910parameters = model(train_X, train_Y, lambd = 0.7)print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)plt.title("Model with L2-regularization")axes = plt.gca()axes.set_xlim([-0.75,0.40])axes.set_ylim([-0.75,0.65])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y) Cost after iteration 0: 0.6974484493131264 Cost after iteration 10000: 0.2684918873282239 Cost after iteration 20000: 0.2680916337127301 Congrats, the test set accuracy increased to 93%. We have saved the French football team! Observations The value of $\lambda$ is a hyperparameter that we can tune using a dev set. L2 regularization makes our decision boundary smoother. If $\lambda$ is too large, it is also possible to “oversmooth”, resulting in a model with high bias. What is L2-regularization actually doing?L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes. What you should remember——the implications of L2-regularization on The cost computation: A regularization term is added to the cost The backpropagation function: There are extra terms in the gradients with respect to weight matrices Weights end up smaller (“weight decay”): Weights are pushed to smaller values. DropoutFinally, dropout is a widely used regularization technique that is specific to deep learning.It randomly shuts down some neurons in each iteration. Watch these two videos to see what this means! At each iteration, we shut down (= set to zero) each neuron of a layer with probability $1 - keep_prob$ or keep it with probability $keep_prob$ (50% here). The dropped neurons don’t contribute to the training in both the forward and backward propagations of the iteration. When we shut some neurons down, we actually modify our model. The idea behind drop-out is that at each iteration, we train a different model that uses only a subset of our neurons. With dropout, our neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time. Forward propagation with dropoutI will implement the forward propagation with dropout. I am using a 3 layer neural network, and will add dropout to the first and second hidden layers. We will not apply dropout to the input layer or output layer. Instructions:I would like to shut down some neurons in the first and second layers. To do that, I am going to carry out 4 Steps: In lecture, we dicussed creating a variable $d^{[1]}$ with the same shape as $a^{[1]}$ using np.random.rand() to randomly get numbers between 0 and 1. Here, I will use a vectorized implementation, so create a random matrix $D^{[1]} = [d^{1} d^{1} … d^{1}] $ of the same dimension as $A^{[1]}$. Set each entry of $D^{[1]}$ to be 0 with probability (1-keep_prob) or 1 with probability (keep_prob), by thresholding values in $D^{[1]}$ appropriately. Hint: to set all the entries of a matrix X to 0 (if entry is less than 0.5) or 1 (if entry is more than 0.5) I would do: X = (X &lt; 0.5). Note that 0 and 1 are respectively equivalent to False and True. Set $A^{[1]}$ to $A^{[1]} * D^{[1]}$. (I am shutting down some neurons). We can think of $D^{[1]}$ as a mask, so that when it is multiplied with another matrix, it shuts down some of the values. Divide $A^{[1]}$ by keep_prob. By doing this I am assuring that the result of the cost will still have the same expected value as without drop-out. (This technique is also called inverted dropout.) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def forward_propagation_with_dropout(X, parameters, keep_prob=0.5): """ Implements the forward propagation: LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; SIGMOID. Arguments: X -- input dataset, of shape (2, number of examples) parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3": W1 -- weight matrix of shape (20, 2) b1 -- bias vector of shape (20, 1) W2 -- weight matrix of shape (3, 20) b2 -- bias vector of shape (3, 1) W3 -- weight matrix of shape (1, 3) b3 -- bias vector of shape (1, 1) keep_prob - probability of keeping a neuron active during drop-out, scalar Returns: A3 -- last activation value, output of the forward propagation, of shape (1,1) cache -- tuple, information stored for computing the backward propagation """ np.random.seed(1) # retrieve parameters W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] W3 = parameters["W3"] b3 = parameters["b3"] # LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID Z1 = np.dot(W1, X) + b1 A1 = relu(Z1) # Steps 1-4 below correspond to the Steps 1-4 described above. D1 = np.random.rand(A1.shape[0], A1.shape[1]) # Step 1: initialize matrix D1 = np.random.rand(..., ...) D1 = D1 &lt; keep_prob # Step 2: convert entries of D1 to 0 or 1 (using keep_prob as the threshold) A1 = np.multiply(A1, D1) # Step 3: shut down some neurons of A1 A1 = A1 / keep_prob # Step 4: scale the value of neurons that haven't been shut down Z2 = np.dot(W2, A1) + b2 A2 = relu(Z2) ### (approx. 4 lines) D2 = np.random.rand(A2.shape[0], A2.shape[1]) # Step 1: initialize matrix D2 = np.random.rand(..., ...) D2 = D2 &lt;keep_prob # Step 2: convert entries of D2 to 0 or 1 (using keep_prob as the threshold) A2 = A2 * D2 # Step 3: shut down some neurons of A2 A2 = A2 / keep_prob # Step 4: scale the value of neurons that haven't been shut down Z3 = np.dot(W3, A2) + b3 A3 = sigmoid(Z3) cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) return A3, cache Backward propagation with dropoutI will implement the backward propagation with dropout. As before, I am training a 3 layer network. Add dropout to the first and second hidden layers, using the masks $D^{[1]}$ and $D^{[2]}$ stored in the cache. Instruction:Backpropagation with dropout is actually quite easy. I will have to carry out 2 Steps: I had previously shut down some neurons during forward propagation, by applying a mask $D^{[1]}$ to A1. In backpropagation, I will have to shut down the same neurons, by reapplying the same mask $D^{[1]}$ to dA1. During forward propagation, I had divided A1 by keep_prob. In backpropagation, I’ll therefore have to divide dA1 by keep_prob again (the calculus interpretation is that if $A^{[1]}$ is scaled by keep_prob, then its derivative $dA^{[1]}$ is also scaled by the same keep_prob). 12345678910111213141516171819202122232425262728293031323334353637383940414243def backward_propagation_with_dropout(X, Y, cache, keep_prob): """ Implements the backward propagation of our baseline model to which we added dropout. Arguments: X -- input dataset, of shape (2, number of examples) Y -- "true" labels vector, of shape (output size, number of examples) cache -- cache output from forward_propagation_with_dropout() keep_prob - probability of keeping a neuron active during drop-out, scalar Returns: gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables """ m = X.shape[1] (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache dZ3 = A3 - Y dW3 = 1. / m * np.dot(dZ3, A2.T) db3 = 1. / m * np.sum(dZ3, axis=1, keepdims=True) dA2 = np.dot(W3.T, dZ3) ### (≈ 2 lines of code) dA2 = dA2 * D2 # Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation dA2 = dA2 / keep_prob # Step 2: Scale the value of neurons that haven't been shut down dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0)) dW2 = 1. / m * np.dot(dZ2, A1.T) db2 = 1. / m * np.sum(dZ2, axis=1, keepdims=True) dA1 = np.dot(W2.T, dZ2) ### (≈ 2 lines of code) dA1 = dA1 * D1 # Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation dA1 = dA1 / keep_prob # Step 2: Scale the value of neurons that haven't been shut down dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0)) dW1 = 1. / m * np.dot(dZ1, X.T) db1 = 1. / m * np.sum(dZ1, axis=1, keepdims=True) gradients = &#123;"dZ3": dZ3, "dW3": dW3, "db3": db3, "dA2": dA2, "dZ2": dZ2, "dW2": dW2, "db2": db2, "dA1": dA1, "dZ1": dZ1, "dW1": dW1, "db1": db1&#125; return gradients Let’s now run the model with dropout (keep_prob = 0.86). It means at every iteration I shut down each neurons of layer 1 and 2 with 14% probability. The function model() will now call: forward_propagation_with_dropout instead of forward_propagation. backward_propagation_with_dropout instead of backward_propagation. 1234567891011parameters = model(train_X, train_Y, keep_prob = 0.86, learning_rate = 0.3)print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)plt.title("Model with dropout")axes = plt.gca()axes.set_xlim([-0.75,0.40])axes.set_ylim([-0.75,0.65])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y) Output: Cost after iteration 0: 0.6543912405149825 Cost after iteration 10000: 0.06101698657490559 Cost after iteration 20000: 0.060582435798513114 On the train set: Accuracy: 0.928909952607 On the test set: Accuracy: 0.95 Dropout works great! The test accuracy has increased again (to 95%)! Our model is not overfitting the training set and does a great job on the test set. The French football team will be forever grateful to we! Note A common mistake when using dropout is to use it both in training and testing. We should use dropout (randomly eliminate nodes) only in training. Deep learning frameworks like tensorflow, PaddlePaddle, keras or caffe come with a dropout layer implementation. Don’t stress——we will soon learn some of these frameworks.What you should remember about dropout: Dropout is a regularization technique. We only use dropout during training. Don’t use dropout (randomly eliminate nodes) during test time. Apply dropout both during forward and backward propagation. During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. We can check that this works even when keep_prob is other values than 0.5. ConclusionsHere are the results of our three models: Note that regularization hurts training set performance! This is because it limits the ability of the network to overfit to the training set. But since it ultimately gives better test accuracy, it is helping your system.What we want you to remember from this article: Regularization will help we reduce overfitting. Regularization will drive our weights to lower values. L2 regularization and Dropout are two very effective regularization techniques. Linksgithub]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradient Checking]]></title>
    <url>%2F2018%2F12%2F14%2FGradient%20Checking%2F</url>
    <content type="text"><![CDATA[AbstractGradient Checking is a important method to verify whether our backpropagation code is correct or not. In this article, I will introduce the theory of n-layer gradient checking firstly, and then i will implement a 3 layer gradient checking step by step,hope after this article,you can implement the gradient checking method to resolve your neural network’s backpropagation bugs. TheoryWe know we can use $\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}$ to estimate the grad of J in $\theta$ : \lim\limits_{\epsilon \to0}\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}\approx\frac{\alpha{J}}{\alpha{\theta}}But for the n layer neural network ,there are many parameters as $W^{[1]},b^{[1]},W^{[2]},b^{[2]},…,W^{[l]},b^{[l]}$, and $dW^{[1]},db^{[1]},dW^{[2]},db^{[2]},…,dW^{[l]},db^{[l]}$ for these parameters when we do backpropagation, we can merge these parameters to a big parameter named $\theta$ wich contains $\theta^{[1]},\theta^{[2]},..,\theta^{[l]}$and $d\theta$ contains $d\theta^{[1]},d\theta^{[2]},..,d\theta^{[l]}$. For gradient checking,we can fix the number of $l-1$ parameters and assume that $J$ is only related with one parameter $\theta^{[i]}$ ,so we can estiimate the grad of J in $\theta^{[i]}$: d\theta_{approx}^{[i]}=\lim\limits_{\epsilon \to0}\frac{J(\theta^{[i]}+\epsilon)-J(\theta^{[i]}-\epsilon)}{2\epsilon}\approx\frac{\alpha{J}}{\alpha{\theta^{[i]}}}Thus we can coculate $d\theta{approx}^{[i]}$ for every $\theta^{[i]}$ and then we should measure whether $d\theta{approx}$ is close $d\theta$ within our acceptable range by this formla : difference=\frac{||d\theta_{approx}-d\theta||_2}{||d\theta_{approx}||_2+||d\theta||_2}I will set $\epsilon=1e^{-7}$ and if $difference \le 1e^{-7}$ ,we can say our backpropagation is correct , if $1e^{-7} &lt; difference\le 1e^{-5}$ ,we should alert whether our backpropagation is correct,and if $difference&gt;1e^{-5}$ there is a great possibility that our backpropagation is incorrect. ImplementFirst of all, we need implement the dictionary_to_vector and vector_to_dictionary function to convert the parameters with parameter: dictionary_to_vector12345678910111213141516171819def dictionary_to_vector(parameters): """ Roll all our parameters dictionary into a single vector satisfying our specific required shape. """ keys = [] count = 0 for key in ["W1", "b1", "W2", "b2", "W3", "b3"]: # flatten parameter new_vector = np.reshape(parameters[key], (-1,1)) keys = keys + [key]*new_vector.shape[0] if count == 0: theta = new_vector else: theta = np.concatenate((theta, new_vector), axis=0) count = count + 1 return theta, keys vector_to_dictionary1234567891011121314def vector_to_dictionary(theta): """ Unroll all our parameters dictionary from a single vector satisfying our specific required shape. """ parameters = &#123;&#125; parameters["W1"] = theta[:20].reshape((5,4)) parameters["b1"] = theta[20:25].reshape((5,1)) parameters["W2"] = theta[25:40].reshape((3,5)) parameters["b2"] = theta[40:43].reshape((3,1)) parameters["W3"] = theta[43:46].reshape((1,3)) parameters["b3"] = theta[46:47].reshape((1,1)) return parameters Then we can implements the forward and backward propagation of neural network: forward_propagation_n123456789101112131415161718192021222324252627282930313233343536373839404142434445def forward_propagation_n(X, Y, parameters): """ Implements the forward propagation (and computes the cost) presented in Figure 3. Arguments: X -- training set for m examples Y -- labels for m examples parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3": W1 -- weight matrix of shape (5, 4) b1 -- bias vector of shape (5, 1) W2 -- weight matrix of shape (3, 5) b2 -- bias vector of shape (3, 1) W3 -- weight matrix of shape (1, 3) b3 -- bias vector of shape (1, 1) Returns: cost -- the cost function (logistic cost for one example) """ # retrieve parameters m = X.shape[1] W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] W3 = parameters["W3"] b3 = parameters["b3"] # LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID Z1 = np.dot(W1, X) + b1 A1 = relu(Z1) Z2 = np.dot(W2, A1) + b2 A2 = relu(Z2) Z3 = np.dot(W3, A2) + b3 A3 = sigmoid(Z3) # Cost logprobs = np.multiply(-np.log(A3), Y) + np.multiply(-np.log(1 - A3), 1 - Y) cost = 1. / m * np.sum(logprobs) cache = (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) return cost, cache backward_propagation_n123456789101112131415161718192021222324252627282930313233343536def backward_propagation_n(X, Y, cache): """ Implement the backward propagation presented in figure 2. Arguments: X -- input datapoint, of shape (input size, 1) Y -- true "label" cache -- cache output from forward_propagation_n() Returns: gradients -- A dictionary with the gradients of the cost with respect to each parameter, activation and pre-activation variables. """ m = X.shape[1] (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache dZ3 = A3 - Y dW3 = 1. / m * np.dot(dZ3, A2.T) db3 = 1. / m * np.sum(dZ3, axis=1, keepdims=True) dA2 = np.dot(W3.T, dZ3) dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0)) dW2 = 1. / m * np.dot(dZ2, A1.T) * 2 db2 = 1. / m * np.sum(dZ2, axis=1, keepdims=True) dA1 = np.dot(W2.T, dZ2) dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0)) dW1 = 1. / m * np.dot(dZ1, X.T) db1 = 4. / m * np.sum(dZ1, axis=1, keepdims=True) gradients = &#123;"dZ3": dZ3, "dW3": dW3, "db3": db3, "dA2": dA2, "dZ2": dZ2, "dW2": dW2, "db2": db2, "dA1": dA1, "dZ1": dZ1, "dW1": dW1, "db1": db1&#125; return gradients then we can implement the gradient_check: gradient_checkInstructionsHere is pseudo-code that will help you implement the gradient check. For each i in num_parameters: To compute J_plus[i]: Set $\theta^{+}$ to np.copy(parameters_values) Set $\theta^{+}_i$ to $\theta^{+}_i + \varepsilon$ Calculate $J^{+}_i$ using to forward_propagation_n(x, y, vector_to_dictionary($\theta^{+}$ )). To compute J_minus[i]: do the same thing with $\theta^{-}$ Compute $gradapprox[i] = \frac{J^{+}_i - J^{-}_i}{2 \varepsilon}$ Thus, we get a vector gradapprox, where gradapprox[i] is an approximation of the gradient with respect to parameter_values[i]. You can now compare this gradapprox vector to the gradients vector from backpropagation. Just like for the 1D case (Steps 1’, 2’, 3’), compute: difference = \frac {\| grad - gradapprox \|_2}{\| grad \|_2 + \| gradapprox \|_2 } \tag{3}1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859def gradient_check_n(parameters, gradients, X, Y, epsilon = 1e-7): """ Checks if backward_propagation_n computes correctly the gradient of the cost output by forward_propagation_n Arguments: parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3": grad -- output of backward_propagation_n, contains gradients of the cost with respect to the parameters. x -- input datapoint, of shape (input size, 1) y -- true "label" epsilon -- tiny shift to the input to compute approximated gradient with formula(1) Returns: difference -- difference (2) between the approximated gradient and the backward propagation gradient """ # Set-up variables parameters_values, _ = dictionary_to_vector(parameters) grad = gradients_to_vector(gradients) num_parameters = parameters_values.shape[0] J_plus = np.zeros((num_parameters, 1)) J_minus = np.zeros((num_parameters, 1)) gradapprox = np.zeros((num_parameters, 1)) # Compute gradapprox for i in range(num_parameters): # Compute J_plus[i]. Inputs: "parameters_values, epsilon". Output = "J_plus[i]". # "_" is used because the function you have to outputs two parameters but we only care about the first one thetaplus = np.copy(parameters_values) # Step 1 thetaplus[i][0] = thetaplus[i] + epsilon # Step 2 J_plus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaplus)) # Step 3 # Compute J_minus[i]. Inputs: "parameters_values, epsilon". Output = "J_minus[i]". thetaminus = np.copy(parameters_values) # Step 1 thetaminus[i][0] = thetaminus[i] - epsilon # Step 2 J_minus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus)) # Step 3 # Compute gradapprox[i] gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon) # Compare gradapprox to backward propagation gradients by computing difference. numerator = np.linalg.norm(grad - gradapprox) # Step 1' denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox) # Step 2' difference = numerator / denominator # Step 3' if difference &gt; 2e-7: print ("\033[93m" + "There is a mistake in the backward propagation! difference = " + str(difference) + "\033[0m") else: print ("\033[92m" + "Your backward propagation works perfectly fine! difference = " + str(difference) + "\033[0m") return difference test gradient checking12345X, Y, parameters = gradient_check_n_test_case()cost, cache = forward_propagation_n(X, Y, parameters)gradients = backward_propagation_n(X, Y, cache)difference = gradient_check_n(parameters, gradients, X, Y) Output: It seems that there were errors in the backward_propagation_n code we implement! Good that we’ve implemented the gradient check. Go back to backward_propagation and try to find/correct the errors : 12dW2 = 1. / m * np.dot(dZ2, A1.T) * 2db1 = 4. / m * np.sum(dZ1, axis=1, keepdims=True) It should be: 12dW2 = 1. / m * np.dot(dZ2, A1.T) db1 = 1. / m * np.sum(dZ1, axis=1, keepdims=True) then we run the test gradient cheking code: the backpagation is correct now! What you should remember from this article Gradient checking verifies closeness between the gradients from backpropagation and the numerical approximation of the gradient (computed using forward propagation). Gradient checking is slow, so we don’t run it in every iteration of training. You would usually run it only to make sure your code is correct, then turn it off and use backprop for the actual learning process. Linksgithub]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning 常用python工具包使用]]></title>
    <url>%2F2018%2F12%2F13%2Fdeeplearning%20%E5%B8%B8%E7%94%A8python%E5%B7%A5%E5%85%B7%E5%8C%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[matplotlib.plotplt.scatter()功能绘制点图 源码123def scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, edgecolors=None, hold=None, data=None, **kwargs) 主要参数解释： s表示点点的大小，c就是color，marker就是点点的形状哦o,x,*&gt;&lt;^,都可以alpha表示点点的亮度，label是标签（图例） 用法123456def testScatter(): c1=[1,2,3] c2=[1,2,3] plt.scatter(c1,c2,s=30,c='red',marker='o',alpha=0.5,label='C1') plt.show() 结果： plt.contourf()功能绘制等高线 用法contourf有三个主要参数： x：x数据 y：y数据 z：z数据，实际上z的数值决定了对应（x，y）点的颜色 此外，还可以设置将等高线分为几个部分。 12345678910111213141516171819202122232425262728# 定义等高线高度函数def f(x, y): return x-ydef testContourf(): # 数据数目 n = 256 # 定义x, y x = np.linspace(-3, 3, n) y = np.linspace(-3, 3, n) # 生成网格数据 X, Y = np.meshgrid(x, y) # 填充等高线的颜色,4是将区域分为几个部分 plt.contourf(X, Y, f(X, Y), 4,alpha=0.75, cmap=plt.cm.Spectral) # 绘制等高线 C = plt.contour(X, Y, f(X, Y), 4, colors='black', linewidth=0.5) # 绘制等高线数据 plt.clabel(C, inline=True, fontsize=10) # 去除坐标轴 plt.xticks(()) plt.yticks(()) plt.show() 结果： numpynp.squeeze()功能从数组的形状中删除单维条目，即把shape中为1的维度去掉 源码1def squeeze(a, axis=None): a时待处理的数组/矩阵，axis是待删除的维度，默认为所有维度为1的维度，注意如果要手动指定axis，则必须要求设定的axis对应的维度必须为1，否则会报错。 用法1234a=np.random.randn(1,3,1) b=np.squeeze(a) print(a.shape) print(b.shape) 输出： 可以看到当数组中含有维度1时squeeze会删除维度为1的维度。 np.power()功能计算元素的n次方 源码1def power(x1, x2, *args, **kwargs): x1是被次方对象，x2时指数，可以是数字也可以是数组，但是要保证x1和x2的列数相同。 使用12345a = np.array([1,2,3]) print(a) c=np.array([1,2,3]) b=np.power(a,c) print(b) 输出： np.meshgrid()功能用两个坐标轴上的点在平面上画网格 源码123# Based on scitools meshgriddef meshgrid(*xi, **kwargs) 使用 [X,Y]=meshgrid(x,y) [X,Y]=meshgrid(x)与[X,Y]=meshgrid(x,x)是等同的 [X,Y,Z]=meshgrid(x,y,z)生成三维数组，可用来计算三变量的函数和绘制三维立体图 以[X,Y]=meshgrid(x,y)为例，其意义是将向量x和y定义的区域转换成矩阵X和Y,其中矩阵X的行向量是向量x的简单复制，而矩阵Y的列向量是向量y的简单复制，假设x是长度为m的向量，y是长度为n的向量，则最终生成的矩阵X和Y的维度都是 (n,m) （注意不是(m,n)）。 123456789101112def testMeshgrid(): a = [1, 2, 3] b = [4, 5, 6] print(a) print(b) [x, y] = np.meshgrid(a, b) print(x) print(y) plt.figure() plt.scatter(x,y) plt.show() np.c&amp;np.r np.r_是按列连接两个矩阵，就是把两矩阵上下相加，要求列数相等，类似于pandas中的concat()。 np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等，类似于pandas中的merge()。 使用12345678910def testNumpy_r_c(): a=np.array([[1,2,3],[4,5,6]]) b=np.array([[7,8,9],[10,11,12]]) c=np.r_[a,b] d=np.c_[a,b] print(a) print(b) print(c) print(d) 输出： 注意123np.r_[a,b] 而不是np.r_(a,b)np.c_[a,b] 而不是np.c_(a,b) np.flatten()&amp;np.ravel()功能两者所要实现的功能是一致的（将多维数组降位一维），两者的区别在于返回拷贝（copy）还是返回视图（view）： numpy.flatten()返回一份拷贝，对拷贝所做的修改不会影响（reflects）原始矩阵，对原来数组做的操作也不会影响拷贝的数组。 numpy.ravel()返回的是视图（view，也颇有几分C/C++引用reference的意味），会影响（reflects）原始矩阵。 使用12345678910111213141516171819202122232425def test_ravel_flatten(): x = np.array([[1, 2], [3, 4]]) print(x) print() a=x.flatten() print(x) print(a) x[0][0] = 10 x[0][1] = 20 print(a) a[0]=-1 print(x) print() b=x.ravel() print(x) print(b) x[0][0] = 30 x[0][1] = 40 print(b) b[0]=-1 print(x) 输出： 注意看对a和b与x之间的互相影响关系。 numpy除法运算保留小数部分的除法 np.divide(x,n) np.true_divide(x,n) x/n 向下取整的除法 np.floor_divide(x,n) x//n 使用123456789101112131415x = np.array([[1, 3], [5, 7]]) print(x) d_x=np.divide(x,2) print(d_x) d_x2=x/2 print(d_x2) d_x3=np.true_divide(x,2) print(d_x3) d_x4=np.floor_divide(x,2) print(d_x4) d_x5=x//2 print(d_x5) 运行结果： np.square()功能计算矩阵中每个元素的平方 使用12345def testSquare(): x = np.arange(5, 10) print(x) y=np.square(x) print(y) 输出： randn&amp;rand功能 numpy.random.randn(d0, d1, …, dn)*是从标准正态分布中返回一个或多个样本值。* numpy.random.rand(d0, d1, …, dn)的随机样本位于[0, 1)中。 使用123456789import numpy as nparr1 = np.random.randn(1,10)print("np.random.randn结果如下:")print(arr1)print('******************************************************************')print("np.random.rand结果如下:")arr2 = np.random.rand(1,10)print(arr2) 输出： np.linalg.norm()功能linalg=linear（线性）+algebra（代数），norm则表示范数，所以就是求矩阵的范数，范数一般是对一批数据求的，比如[x1,x2,x3]具体参数如下： 1x_norm=np.linalg.norm(x, ord=None, axis=None, keepdims=False) x：表示矩阵，可以是一维的 ord表示范数的类型，具体类型如下： ord=1：列和的最大值 ord=2(默认)：|λE-ATA|=0，求特征值，然后求最大特征值的算术平方根 ord=∞：行和的最大值 axis：处理类型 axis=1：表示按行向量处理，求多个行向量的范数 axis=0：表示按列向量处理，求多个列向量的范数 axis=None（默认）：表示矩阵范数。 keepdims：是否保持矩阵的二维特性 True表示保持矩阵的二维特性，False相反 np.copy()功能copy（）用来拷贝矩阵，这个拷贝属于复制即deep copy，而直接的‘=’是numpycopy，效果来说就是通过copy拷贝的目标矩阵和原矩阵没关系，而‘=’拷贝的目标矩阵会和原矩阵有关联，修改‘=’拷贝后的值会和原来的矩阵互相有影响。 使用123456789101112131415def testCopy(): print('') a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]]) b=np.copy(a) c=a print(b) print(a) b[0][0]=100 print(a) c[0][0]=101 print(a) a[0][0]=200 print(b) print(c) 运行结果： 参考1:https://blog.csdn.net/lanchunhui/article/details/50354978 2:https://www.cnblogs.com/xieshengsen/p/6822772.html 3:https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-8-np-copy/]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The impact of different initialization strategies on neural networks]]></title>
    <url>%2F2018%2F12%2F13%2FThe%20impact%20of%20different%20initialization%20strategies%20on%20neural%20networks%2F</url>
    <content type="text"><![CDATA[AbstractAs we know, a well chosen initialization can speed up the convergence of gradient descent and increase the odds of gradient descent converging to a lower training (and generalization) error .So in this article, we will explore the impact of different parameter initialization strategies on training in deep learning. In this experience,we will try three different initialization strategies: Zeros initialization Random initialization He initialization Load datasetTo get started, we need load dataset for our experience : 1234567891011121314import numpy as npimport matplotlib.pyplot as pltimport sklearnimport sklearn.datasetsfrom init_utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagationfrom init_utils import update_parameters, predict, load_dataset, plot_decision_boundary, predict_decplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# load image dataset: blue/red dots in circlestrain_X, train_Y, test_X, test_Y = load_dataset()plt.show() What we goal is train a model toi classifier the blue dots and red dots. Neural Network modelI will use a 3-layer neural network (already implemented on init_utils). Here are the initialization methods we will experiment with: Zeros initialization — setting initialization = &quot;zeros&quot; in the input argument. Random initialization — setting initialization = &quot;random&quot; in the input argument. This initializes the weights to large random values. He initialization — setting initialization = &quot;he&quot; in the input argument. This initializes the weights to random values scaled according to a paper by He et al., 2015. The model code as follows: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859def model(X, Y, learning_rate = 0.01, num_iterations = 15000, print_cost = True, initialization = "he"): """ Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- input data, of shape (2, number of examples) Y -- true "label" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples) learning_rate -- learning rate for gradient descent num_iterations -- number of iterations to run gradient descent print_cost -- if True, print the cost every 1000 iterations initialization -- flag to choose which initialization to use ("zeros","random" or "he") Returns: parameters -- parameters learnt by the model """ grads = &#123;&#125; costs = [] # to keep track of the loss m = X.shape[1] # number of examples layers_dims = [X.shape[0], 10, 5, 1] # Initialize parameters dictionary. if initialization == "zeros": parameters = initialize_parameters_zeros(layers_dims) elif initialization == "random": parameters = initialize_parameters_random(layers_dims) elif initialization == "he": parameters = initialize_parameters_he(layers_dims) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. a3, cache = forward_propagation(X, parameters) # Loss cost = compute_loss(a3, Y) # Backward propagation. grads = backward_propagation(X, Y, cache) # Update parameters. parameters = update_parameters(parameters, grads, learning_rate) # Print the loss every 1000 iterations if print_cost and i % 1000 == 0: print("Cost after iteration &#123;&#125;: &#123;&#125;".format(i, cost)) costs.append(cost) # plot the loss plt.figure() plt.plot(costs) plt.ylabel('cost') plt.xlabel('iterations (per hundreds)') plt.title('init with'+initialization+' Learning rate =' + str(learning_rate)) plt.show() return parameters 2 - Zero initializationThere are two types of parameters to initialize in a neural network: the weight matrices $(W^{[1]}, W^{[2]}, W^{[3]}, …, W^{[L-1]}, W^{[L]})$ the bias vectors $(b^{[1]}, b^{[2]}, b^{[3]}, …, b^{[L-1]}, b^{[L]})$ Exercise: Implement the following function to initialize all parameters to zeros. You’ll see later that this does not work well since it fails to “break symmetry”, but lets try it anyway and see what happens. Use np.zeros((..,..)) with the correct shapes. 12345678910111213141516171819202122def initialize_parameters_zeros(layers_dims): """ Arguments: layer_dims -- python array (list) containing the size of each layer. Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": W1 -- weight matrix of shape (layers_dims[1], layers_dims[0]) b1 -- bias vector of shape (layers_dims[1], 1) ... WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1]) bL -- bias vector of shape (layers_dims[L], 1) """ parameters = &#123;&#125; L = len(layers_dims) # number of layers in the network for l in range(1, L): parameters['W' + str(l)] = np.zeros(shape=(layers_dims[l], layers_dims[l - 1])) parameters['b' + str(l)] = np.zeros(shape=(layers_dims[l], 1)) return parameters Run the following code to train our model on 15,000 iterations using zeros initialization: 1234567891011121314def train_with_zeros_init(): parameters = model(train_X, train_Y, initialization="zeros") print("On the train set:") predictions_train = predict(train_X, train_Y, parameters) print("On the test set:") predictions_test = predict(test_X, test_Y, parameters) print("predictions_train = " + str(predictions_train)) print("predictions_test = " + str(predictions_test)) plt.figure() plt.title("Model with Zeros initialization") axes = plt.gca() axes.set_xlim([-1.5, 1.5]) axes.set_ylim([-1.5, 1.5]) plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y) The outputs are as follows: The performance is really bad, and the cost does not really decrease, and the algorithm performs no better than random guessing. Why? From the details of the predictions and the decision boundary, we can find that the model is predicting 0 for every example. In general, initializing all the weights to zero results in the network failing to break symmetry(对称性). This means that every neuron in each layer will learn the same thing, and you might as well be training a neural network with $n^{[l]}=1$ for every layer, and the network is no more powerful than a linear classifier such as logistic regression. What we should remember The weights $W^{[l]}$ should be initialized randomly to break symmetry. It is however okay to initialize the biases $b^{[l]}$ to zeros. Symmetry is still broken so long as $W^{[l]}$ is initialized randomly. Random initializationTo break symmetry, lets intialize the weights randomly. Following random initialization, each neuron can then proceed to learn a different function of its inputs. In this exercise, you will see what happens if the weights are intialized randomly, but to very large values. 123456789101112131415161718192021222324def initialize_parameters_random(layers_dims): """ Arguments: layer_dims -- python array (list) containing the size of each layer. Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": W1 -- weight matrix of shape (layers_dims[1], layers_dims[0]) b1 -- bias vector of shape (layers_dims[1], 1) ... WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1]) bL -- bias vector of shape (layers_dims[L], 1) """ np.random.seed(3) # This seed makes sure your "random" numbers will be the as ours parameters = &#123;&#125; L = len(layers_dims) # integer representing the number of layers for l in range(1, L): parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1])*10 parameters['b' + str(l)] = np.zeros(shape=(layers_dims[l], 1)) return parameters Run the following code to train our model on 15,000 iterations using random initialization: 123456789101112131415def train_with_random_init(): parameters = model(train_X, train_Y, initialization="random") print("On the train set:") predictions_train = predict(train_X, train_Y, parameters) print("On the test set:") predictions_test = predict(test_X, test_Y, parameters) print("predictions_train = " + str(predictions_train)) print("predictions_test = " + str(predictions_test)) plt.figure() plt.title("Model with random initialization") axes = plt.gca() axes.set_xlim([-1.5, 1.5]) axes.set_ylim([-1.5, 1.5]) plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y) And the outputs are as follows: We can see “inf” as the cost after the iteration 0, this is because of numerical roundoff; a more numerically sophisticated implementation would fix this. But this isn’t worth worrying about for our purposes. Anyway, it looks like we have broken symmetry, and this gives better results. than before. The model is no longer outputting all 0s. Observations: The cost starts very high. This is because with large random-valued weights, the last activation (sigmoid) outputs results that are very close to 0 or 1 for some examples, and when it gets that example wrong it incurs a very high loss for that example. Indeed, when $\log(a^{[3]}) = \log(0)$, the loss goes to infinity. Poor initialization can lead to vanishing/exploding gradients, which also slows down the optimization algorithm. If you train this network longer you will see better results, but initializing with overly large random numbers slows down the optimization. In summary Initializing weights to very large random values does not work well. Hopefully intializing with small random values does better. The important question is: how small should be these random values be? Lets find out in the next part! He initializationFinally, try “He Initialization”; this is named for the first author of He et al., 2015. (If you have heard of “Xavier initialization”, this is similar except Xavier initialization uses a scaling factor for the weights $W^{[l]}$ of sqrt(1./layers_dims[l-1]) where He initialization would use sqrt(2./layers_dims[l-1]).): 123456789101112131415161718192021222324def initialize_parameters_he(layers_dims): """ Arguments: layer_dims -- python array (list) containing the size of each layer. Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": W1 -- weight matrix of shape (layers_dims[1], layers_dims[0]) b1 -- bias vector of shape (layers_dims[1], 1) ... WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1]) bL -- bias vector of shape (layers_dims[L], 1) """ np.random.seed(3) parameters = &#123;&#125; L = len(layers_dims) - 1 # integer representing the number of layers for l in range(1, L + 1): parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(2 / layers_dims[l - 1]) parameters['b' + str(l)] = np.zeros(shape=(layers_dims[l], 1)) return parameters And run the code as follow to train with he initialization: 123456789101112131415def train_with_he_init(): parameters = model(train_X, train_Y, initialization="he") print("On the train set:") predictions_train = predict(train_X, train_Y, parameters) print("On the test set:") predictions_test = predict(test_X, test_Y, parameters) print("predictions_train = " + str(predictions_train)) print("predictions_test = " + str(predictions_test)) plt.figure() plt.title("Model with he initialization") axes = plt.gca() axes.set_xlim([-1.5, 1.5]) axes.set_ylim([-1.5, 1.5]) plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y) The outputs are as follows: Observations: The model with He initialization separates the blue and the red dots very well in a small number of iterations. ConclusionsWe have seen three different types of initializations. For the same number of iterations and same hyperparameters the comparison is: Model Train accuracy Problem/Comment 3-layer NN with zeros initialization 50% fails to break symmetry 3-layer NN with large random initialization 83% too large weights 3-layer NN with He initialization 99% recommended method What we should remember from this blog Different initializations lead to different results Random initialization is used to break symmetry and make sure different hidden units can learn different things Don’t intialize to values that are too large He initialization works well for networks with ReLU activations. linksgithub]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何编写脚本将CSDN的博客批量导出到hexo下的md格式]]></title>
    <url>%2F2018%2F12%2F10%2F%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%B0%86CSDN%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%89%B9%E9%87%8F%E5%AF%BC%E5%87%BA%E5%88%B0hexo%E4%B8%8B%E7%9A%84md%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[最近自己搭了一个个人主页，终于可以不用忍受第三方博客平台的限制写一些自己的文章了，可是搭好了博客如何将自己原来的文章迁移到新的博客地址呢？如果手动一篇一篇导出效率太低，而且工作量太大，所以笔者写了个脚本将原来博客平台（csdn）上自己的文章批量爬取到本地并做相应的格式转换以保证可以直接发布到hexo下的博客平台。 操作环境MacBook Pro (13-inch, 2018, Four Thunderbolt 3 Ports)+pycharm+python3.6 目标将csdn下的博客批量导出并转化为hexo可以直接解析的格式，对于每一篇文章，我们重点关注以下信息： 标题（title） 正文 发表时间（date） 所属类别（categories） 对应标签（tags） 括号中的英文就是hexo下博客需要符合的格式标准，我们只需要将csdn中每一篇文章的上述属性爬取下来并以特定的格式写入文件即可，下面看实现： 文章爬取首先我们应该针对csdn的博客系统写一个通用的request函数（方法）： 12345678def request_get(url): session = requests.Session() headers = &#123; 'User-Agent': 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.118 Safari/537.36'&#125; response = requests.get(url, headers=headers, timeout=3) return response 这里的headers里面的信息是通过查看页面的审查元素信息找到的。 然后我们就可以发起请求，注意看代码注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445def start_spider(): # 把下面这个base_url换成你csdn的地址 base_url = 'https://blog.csdn.net/qq_36982160/' second_url = base_url + 'article/list/' # 从第一页开始爬取 start_url = second_url + '1' number = 1 count = 0 # 开始爬取第一个article_list，返回信息在html中 html = request_get(start_url) # 这个循环是对你博客的article_list页面的循环 while html.status_code == 200: # 获取下一页的 url selector = etree.HTML(html.text) #cur_article_list_page[0]就是当前article_list页面中的文章的list cur_article_list_page = selector.xpath('//*[@id="mainBox"]/main/div[2]') d = cur_article_list_page[0].xpath('//*[@id="mainBox"]/main/div[2]/div[2]/h4/a') l = cur_article_list_page[0].findall('data-articleid') # 这个循环是对你每一个article_list中的那些文章的循环 for elem in cur_article_list_page[0]: item_content = elem.attrib #通过对比拿到的数据和网页中的有效数据发现返回每一个article_list中的list都有一两个多余元素，每个多余元素都有style属性，利用这一特点进行过滤 if item_content.has_key('style'): continue else: if item_content.has_key('data-articleid'): #拿到文章对应的articleid articleid = item_content['data-articleid'] #用于打印进度 count += 1 print(count) #爬取单篇文章 CrawlingItemBlog(base_url, articleid) # 进行下一article_list的爬取 number += 1 next_url = second_url + str(number) html = request_get(next_url) 然后按照拿到的每一个id对单篇文章进行爬取和解析并转化为hexo可解析的markdown格式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102def CrawlingItemBlog(base_url, id): second_url = base_url + 'article/details/' url = second_url + id # 发送request请求并接受返回值 item_html = request_get(url) if item_html.status_code == 200: ''' 需要的信息： 1：标题 2：markdown内容 3：发表日期 4：标签 5：类别 ''' # 利用BeautifulSoup解析返回的html soup = BeautifulSoup(item_html.text) c = soup.find(id="content_views") # 标题 title_article = soup.find(attrs=&#123;'class': 'title-article'&#125;) # 这里是将标题作为最后存储的文件名 file_name = title_article.get_text() title_article = title_article.prettify() # 设置hexo格式博客开头的格式（title） hexo_title = 'title: ' + file_name + '\n' # 文章的categories hexo_categories = '' # 有可能出现这篇文章没有categories的情况 try: hexo_categories = soup.find(attrs=&#123;'class': 'tags-box space'&#125;).find(attrs=&#123;'class': 'tag-link'&#125;).get_text() except Exception: pass if hexo_categories == '': pass else: # 去除拿到的str中的'\t' hexo_categories = hexo_categories.replace('\t', '') hexo_categories = 'categories:\n' + '- ' + hexo_categories + '\n' # 发表时间 time = soup.find(attrs=&#123;'class': 'time'&#125;).get_text() s_time1 = time.split('年') year = s_time1[0] s_time2 = s_time1[1].split('月') month = s_time2[0] s_time3 = s_time2[1].split('日') day = s_time3[0] minite = s_time3[1].strip() hexo_date = 'date: ' + year + '-' + month + '-' + day + ' ' + minite + '\n' hexo_tags = '' # 获取tags tags = '' try: tags = soup.find(attrs=&#123;'class': 'tags-box artic-tag-box'&#125;).get_text() except Exception: pass if tags == '': pass else: tags = tags.split('\n') tags = tags[2] tags = tags.replace('\t', ' ') tags = tags.split(' ') hexo_tags = 'tags:\n' for tag in tags: if tag == '': continue else: hexo_tags = hexo_tags + '- ' + tag + '\n' # 将html转化为markdown text_maker = html2text.HTML2Text() text_maker.bypass_tables = False text = text_maker.handle(c.prettify()) # 有的文章名字特殊，会新建文件失败 try: #写入文件 f = codecs.open('./mds/' + file_name + '.md', 'w', encoding='utf-8') hexo_str = '---\n' + hexo_title + hexo_date + hexo_categories + hexo_tags + '\n---\n' f.write(hexo_str) f.write(text) f.close() except Exception: print(file_name) return True else: return False 至此就完成了csdn上博客的导出以及格式化为hexo下的博客格式，然后将导出的文章（默认在mds目录下）放在hexo博客目录的source/_post下即可。 详细代码地址github]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>博客迁移</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Neural Network]]></title>
    <url>%2F2018%2F12%2F10%2FDeep-Neural-Network%2F</url>
    <content type="text"><![CDATA[​ From Planar data classification with one hidden layer and Logistic Regression with a Neural Network mindset ,we achieved the shallow neural network, to get the higher accuracy ,we will achieve deep neural network in this paper, we will find that after a deep neural network,our network will more outstanding. initialize_parameters_deepwe set the random seed 1 to fix the result, use np.random.rand to initialize w and np.zeros to initialize b: 123456789101112131415161718192021222324252627np.random.seed(1)def initialize_parameters_deep(layer_dims): """ Arguments: layer_dims -- python array (list) containing the dimensions of each layer in our network Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1]) bl -- bias vector of shape (layer_dims[l], 1) """ np.random.seed(3) parameters = &#123;&#125; L = len(layer_dims) # number of layers in the network for l in range(1, L): # Wl should match the shape of (layer_dims[l], layer_dims[l - 1]) parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01 parameters['b' + str(l)] = np.zeros(shape=(layer_dims[l], 1)) assert (parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1])) assert (parameters['b' + str(l)].shape == (layer_dims[l], 1)) return parameters linear_forwardLet’s implement simple linear propagation first: 12345678910111213141516171819def linear_forward(A, W, b): """ Implement the linear part of a layer's forward propagation. Arguments: A -- activations from previous layer (or input data): (size of previous layer, number of examples) W -- weights matrix: numpy array of shape (size of current layer, size of previous layer) b -- bias vector, numpy array of shape (size of the current layer, 1) Returns: Z -- the input of the activation function, also called pre-activation parameter cache -- a python dictionary containing "A", "W" and "b" ; stored for computing the backward pass efficiently """ Z = np.dot(W, A) + b assert (Z.shape == (W.shape[0], A.shape[1])) cache = (A, W, b) return Z, cache linear_activation_forwardThen activate the result of forward propagation: 12345678910111213141516171819202122232425262728293031323334def linear_activation_forward(A_prev, W, b, activation): """ Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer Arguments: A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples) W -- weights matrix: numpy array of shape (size of current layer, size of previous layer) b -- bias vector, numpy array of shape (size of the current layer, 1) activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" Returns: A -- the output of the activation function, also called the post-activation value cache -- a python dictionary containing "linear_cache" and "activation_cache"; stored for computing the backward pass efficiently """ if activation == "sigmoid": # Inputs: "A_prev, W, b". Outputs: "A, activation_cache". ### START CODE HERE ### (≈ 2 lines of code) Z, linear_cache = linear_forward(A_prev, W, b) A, activation_cache = sigmoid(Z) ### END CODE HERE ### elif activation == "relu": # Inputs: "A_prev, W, b". Outputs: "A, activation_cache". ### START CODE HERE ### (≈ 2 lines of code) Z, linear_cache = linear_forward(A_prev, W, b) A, activation_cache = relu(Z) ### END CODE HERE ### assert (A.shape == (W.shape[0], A_prev.shape[1])) cache = (linear_cache, activation_cache) return A, cache L_model_forwardAfter implementing the forward propagation of a single layer, we realize the forward propagation of the multilayer network based on this: 1234567891011121314151617181920212223242526272829303132333435def L_model_forward(X, parameters): """ Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation Arguments: X -- data, numpy array of shape (input size, number of examples) parameters -- output of initialize_parameters_deep() Returns: AL -- last post-activation value caches -- list of caches containing: every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1) """ caches = [] A = X L = len(parameters) // 2 # number of layers in the neural network # Implement [LINEAR -&gt; RELU]*(L-1). Add "cache" to the "caches" list. for l in range(1, L): A_prev = A A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], "relu") caches.append(cache) # Implement LINEAR -&gt; SIGMOID. Add "cache" to the "caches" list. AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], "sigmoid") caches.append(cache) assert (AL.shape == (1, X.shape[1])) return AL, caches compute_costAfter forward propagation, we need to calculate the cost based on the results of the forward propagation and the label: 12345678910111213141516171819202122def compute_cost(AL, Y): """ Implement the cost function defined by equation (7). Arguments: AL -- probability vector corresponding to your label predictions, shape (1, number of examples) Y -- true "label" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples) Returns: cost -- cross-entropy cost """ m = Y.shape[1] # Compute loss from aL and y. cost = -np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL)) / m cost = np.squeeze(cost) # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17). assert (cost.shape == ()) return cost linear_backwardAfter completing the forward propagation, we need to implement backpropagation, which is the key to the neural network that can well learn the characteristics of the input data. First, it is the same as forward propagation to achieve a simple back-propagation of a single-layer network: 123456789101112131415161718192021222324252627def linear_backward(dZ, cache): """ Implement the linear portion of backward propagation for a single layer (layer l) Arguments: dZ -- Gradient of the cost with respect to the linear output (of current layer l) cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer Returns: dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev dW -- Gradient of the cost with respect to W (current layer l), same shape as W db -- Gradient of the cost with respect to b (current layer l), same shape as b """ A_prev, W, b = cache m = A_prev.shape[1] dW = (np.dot(dZ, A_prev.T)) / m db = np.sum(dZ, axis=1, keepdims=True) / m dA_prev = np.dot(W.T, dZ) assert (dA_prev.shape == A_prev.shape) assert (dW.shape == W.shape) assert (db.shape == b.shape) return dA_prev, dW, db linear_activation_backwardCombined with the form of different activation functions, we can calculate the inverse calculated gradient: 123456789101112131415161718192021222324252627282930def linear_activation_backward(dA, cache, activation): """ Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer. Arguments: dA -- post-activation gradient for current layer l cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" Returns: dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev dW -- Gradient of the cost with respect to W (current layer l), same shape as W db -- Gradient of the cost with respect to b (current layer l), same shape as b """ linear_cache, activation_cache = cache if activation == "relu": ### START CODE HERE ### (≈ 2 lines of code) dZ = relu_backward(dA, activation_cache) dA_prev, dW, db = linear_backward(dZ, linear_cache) ### END CODE HERE ### elif activation == "sigmoid": ### START CODE HERE ### (≈ 2 lines of code) dZ = sigmoid_backward(dA, activation_cache) dA_prev, dW, db = linear_backward(dZ, linear_cache) ### END CODE HERE ### return dA_prev, dW, db L_model_backwardAfter implementing single-layer back propagation, we implement backpropagation of multilayer neural networks based on this: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def L_model_backward(AL, Y, caches): """ Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group Arguments: AL -- probability vector, output of the forward propagation (L_model_forward()) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) caches -- list of caches containing: every cache of linear_activation_forward() with "relu" (it's caches[l], for l in range(L-1) i.e l = 0...L-2) the cache of linear_activation_forward() with "sigmoid" (it's caches[L-1]) Returns: grads -- A dictionary with the gradients grads["dA" + str(l)] = ... grads["dW" + str(l)] = ... grads["db" + str(l)] = ... """ grads = &#123;&#125; L = len(caches) # the number of layers m = AL.shape[1] Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL # Initializing the backpropagation dAL = -np.divide(Y, AL) + np.divide(1 - Y, 1 - AL) # Lth layer (SIGMOID -&gt; LINEAR) gradients. Inputs: "dAL, current_cache". Outputs: "grads["dAL-1"], grads["dWL"], grads["dbL"] current_cache = caches[L - 1] grads["dA" + str(L - 1)], grads["dW" + str(L)], grads["db" + str(L)] = linear_activation_backward(dAL, current_cache, activation='sigmoid') # Loop from l=L-2 to l=0 for l in reversed(range(L - 1)): # lth layer: (RELU -&gt; LINEAR) gradients. # Inputs: "grads["dA" + str(l + 1)], current_cache". Outputs: "grads["dA" + str(l)] , grads["dW" + str(l + 1)] , grads["db" + str(l + 1)] current_cache = caches[l] dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads["dA" + str(l + 1)], current_cache, "relu") grads["dA" + str(l)] = dA_prev_temp grads["dW" + str(l + 1)] = dW_temp grads["db" + str(l + 1)] = db_temp return grads update_parametersAfter the backpropagation is complete, we can update the parameters: 123456789101112131415161718192021222324def update_parameters(parameters, grads, learning_rate): """ Update parameters using gradient descent Arguments: parameters -- python dictionary containing your parameters grads -- python dictionary containing your gradients, output of L_model_backward Returns: parameters -- python dictionary containing your updated parameters parameters["W" + str(l)] = ... parameters["b" + str(l)] = ... """ L = len(parameters) // 2 # number of layers in the neural network # Update rule for each parameter. Use a for loop. for l in range(L): parameters["W" + str(l + 1)] = parameters["W" + str(l + 1)] - learning_rate * grads["dW" + str(l+1)] parameters["b" + str(l + 1)] = parameters["b" + str(l + 1)] - learning_rate * grads["db" + str(l+1)] return parameters L_layer_modelAfter implementing the structure of the deep neural network, we can classify the image： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False): # lr was 0.009 """ Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- data, numpy array of shape (number of examples, num_px * num_px * 3) Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) layers_dims -- list containing the input size and each layer size, of length (number of layers + 1). learning_rate -- learning rate of the gradient descent update rule num_iterations -- number of iterations of the optimization loop print_cost -- if True, it prints the cost every 100 steps Returns: parameters -- parameters learnt by the model. They can then be used to predict. """ np.random.seed(1) costs = [] # keep track of cost # Parameters initialization. (≈ 1 line of code) parameters = initialize_parameters_deep(layers_dims) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID. AL, caches = L_model_forward(X, parameters) # Compute cost. cost = compute_cost(AL, Y) # Backward propagation. grads = L_model_backward(AL, Y, caches) # Update parameters. parameters = update_parameters(parameters, grads, learning_rate) # Print the cost every 100 training example if print_cost and i % 100 == 0: print("Cost after iteration %i: %f" % (i, cost)) if print_cost and i % 100 == 0: costs.append(cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations (per tens)') plt.title("Learning rate =" + str(learning_rate)) plt.show() return parameters After running the above code, we can get the following results; and the learning rate as : Linksthe dataset and source code in :github]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Neural NetWork</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下如何安装shadowsockes GUI版]]></title>
    <url>%2F2018%2F12%2F09%2Fubuntu%E4%B8%8B%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85shadowsockes-GUI%E7%89%88%2F</url>
    <content type="text"><![CDATA[就三条命令： 123sudo add-apt-repository ppa:hzwhuang/ss-qt5 sudo apt-get update sudo apt-get install shadowsocks-qt5 安装完之后就可以按win键search到你的 shadowsocks 软件]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>Shadowsockets</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何快速搭建自己的SS服务器]]></title>
    <url>%2F2018%2F12%2F09%2F%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84SS%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[环境说明本地环境：ubuntu16.04所用服务器：Vultr本地ss客户端：Shadowsockes-qt5 服务器端配置注册账号并充值首先打开Vultr官网，进行账户注册： 注册完成后进行登录进入你的主页面并点击左边的billing进行充值： 然后进行以下三步： 这里是选择支付宝付款，当然如果你用其他支付方式也是完全没有问题的。 server创建充值完毕后我们就可以春构建创建server了，步骤如下：点击主页面的加号： 然后会进入创建页面，主要有三部分需要配置好：Server Location：建议选择Totyo，因为离的比较近，所以速度会快点 Server Type：选择你习惯的操作系统，建议选择ubuntu16.04: Server Size：建议选择25Gb的，大概5美刀一个月（如果2.5美元的有选那个最便宜，但是我搞的时候脱销了……） 后面的不用管，保持默认就可以，然后点击deploy now就可以进行创建，大概等几分钟就可以创建好。然后你的个人主页就应该有你刚才创建的server的详细信息： 点击上图的红圈，就会转到如下页面： 其中红圈的三个是我们后面要用到的信息。 配置server的ss服务ubuntu下打开终端直接输入： 1ssh root@111.111.111 其中root@后面换成你刚才页面中的IP Address，然后回车，之后会让你输入密码，点击你服务器页面信息（就是上一张图）的password后面的复制，然后粘贴到你的终端就可以了，然后就可以顺利连上你的远程服务器。然后运行以下命令进行ShadowSocks搭建： 1: 1wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh 2: 1chmod +x shadowsocks-all.sh 3: 1./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 然后选择脚本（Python、R、Go、libev），任选一个： 123456Which Shadowsocks server you&apos;d select:1.Shadowsocks-Python2.ShadowsocksR3.Shadowsocks-Go4.Shadowsocks-libevPlease enter a number (default 1): 我选的是1，然后输入密码和端口： 1234567891011121314You choose = Shadowsocks-PythonPlease enter password for Shadowsocks-Python(default password: teddysun.com):password = passPlease enter a port for Shadowsocks-Python [1-65535](default port: 8989):port = 8808Press any key to start...or Press Ctrl+C to cancel 注意把上面的password和port换成你自己的。然后其他的配置都是傻瓜式，根据你的需要配置成你自己的就可以，完成后会出现： 12345678Congratulations, Shadowsocks-Go server install completed!Your Server IP : 45.32.73.59Your Server Port : 8808Your Password : psssYour Encryption Method: aes-256-cfbWelcome to visit: https://teddysun.com/486.htmlEnjoy it! 上面的信息就是你在客户端进行登录时需要的信息，直接在ss客户端进行配置即可。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[检讨]]></title>
    <url>%2F2018%2F12%2F08%2F%E6%A3%80%E8%AE%A8%2F</url>
    <content type="text"><![CDATA[亲爱的小草莓： ​ 我怀着无比悲痛的心情写这封检讨书给你，虽然文字已经不能表达我内心的悔恨和痛苦，但是我还是想响应组织的号召正式地写一份检讨书给你以洗刷我的罪孽。 ​ 首先我先解释一下事件的前因后果：那是十月份的一天，那天天气很棒，我走在路上抬头看去，太阳就像你一样，美丽又动人，多看一眼都是享受。然后小gay的女朋友在群里说她的手机丢了，大家的联系方式都没了，让大家发短信到她手机上方便她记录大家的联系方式。由于思想意识的放松，我竟然头脑发热发了个我爱她过去，心想这样会比较有辨识度，她就会知道这个陌生的号码是来自哪里的，发完之后我甚至还一阵得劲，觉得美滋滋，过了两分钟并没有收到她的回复，我有一..失落，为了引起她的重视，我觉得大胆地再爱她一次，所以就又发了一条再爱一次的短信，我知道这条短信发过去就全完了，我辜负了党和组织对我的信任，我想我之前入党失败也是因为这方面原因。再到后来她还是没有回复我的短信，我才意识到这个世界还是你最好，那一瞬间你就像大白兔奶糖一样融化在了我的心里。 ​ 虽然确实有客观因素导致了此次事件的发生，但是作为一个对爱情负责的男人，我不会逃避，更不会为自己找借口，我会痛定思痛反省自己，力争避免类似错误的发生，在这里我做出如下承诺： 以后不主动和女孩子闲聊，如果是女孩子主动找我闲聊，我会尽可能冷淡一点，比及时向你报告 以后只对你说爱你，禁止在其他异性身上使用任何暧昧的字眼 不和陌生的异性搭讪，如果被异性搭讪，我会假装高冷 下雨天不和异性共用一把伞，会站在原地等你来接我 ​ 以上条款如果违反，我自愿给你买一杯奶茶 + 写一份实验报告 + 陪你去吃一次鸡肉卷。 ​ 不知不觉已经写了六百多个字，虽然我还想写，但是由于组织规定我只能写五百字，为了不违反规定，我只能忍住很多很多我想要表达歉意的言辞，但是我的内心是极其后悔的，我不应该惹你生气，希望组织能再给我一次机会，我会尽力表现，争创一流，为实现xx梦而奋斗！ ​ ​ 2018.12.08 ​ ai-exception]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[汇编总结（5）——汇编语言]]></title>
    <url>%2F2018%2F11%2F15%2F%E6%B1%87%E7%BC%96%E6%80%BB%E7%BB%93%EF%BC%885%EF%BC%89%E2%80%94%E2%80%94%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[实地址执行环境寄存器和指令集 32位寄存器EAX、EBX、ECX、EDX、ESP、EBP、ESI和EDI； 16位寄存器AX、BX、CX、DX、SP、BP、SI和DI； 8位寄存器AH、AL、BH、BL、CH、CL、DH和DL。 段寄存器CS、DS、SS和ES，以及段寄存器FS和GS。寄存器CS含有当前代码段的段值，寄存器DS含有当前数据段的段值，寄存器SS含有当前堆栈段的段值。 实方式下指令指针寄存器EIP中的高16位必须是0，相当于只有低16位的IP起作用。 实方式下堆栈指针寄存器ESP中的高16位必须是0，相当于只有低16位的SP起作用。 存储器分段管理IA-32系列处理器的物理地址空间规模达到4G，实地址方式下可访问的物理地址空间只有1M即00000H——FFFFFH，实方式下每个逻辑段必须满足如下两个条件： 逻辑段的起始地址必须是16的倍数 逻辑段的最大长度为64K（2^16），所以后面用16位表示段值？ 这两个条件是为了方便地计算1M地址空间中的20位地址。 由于实方式下段的起始地址必须是16的倍数，所以段的起始地址有如下形式：xxxx0H，这种20位的段起始地址可以省略掉最后的0表示成16位的XXXXH形式，这16位就称为段值。这时候就有如下关系： 段起始地址=段值*16 物理地址=段起始地址+偏移=段值*16+偏移 注意存储段既可以相连，也可以重叠。所以一个物理地址可以对应多个逻辑地址，比如： ​ 1002H:2325H=12345H 1233H:0015H=12345H 上面两个逻辑地址就表示的是一个物理地址。 实地址方式下，段寄存器（CS、SS、DS…）中的内容是段值。 这里需要注意的是给段寄存器赋值的时候只能通过别的寄存器来进行中转赋值，不能直接把立即数赋值给段寄存器，应该像这样： ​ MOV AX,0F0000H MOV DS,AX 而不是： ​ MOV DS,0F0000H 手动指定段寄存器的方法： ​ MOV [ES:EDI] ,EAX 16位存储器寻址方式16位的存储器寻址方式主要用于实地址，在实地址方式下，存储段的长度不超过64K（32位寻址方式的存储段长度也不超过64K），注意这里是 存储段的长度而不是上面的 逻辑段 长度，存储单元有效地址是16位。 16位有效地址EA可以有多种表示形式： 主要形式是 基址+变址+位移量 ，其中： 基址部分可以是寄存器 BX 或 BP ； 变址部分可以是寄存器 SI 或 DI ； 位移量采用补码形式表示，在计算有效地址时，如位移量是 8 位，则被带符号扩展成 16 位。 需要注意的是，像下面这种寻址方式就是错误的： ​ MOV EAX,[SI+DI] 很明显SI不能作为基址部分。 源程序和语句首先再强调几点概念： 汇编语言是一种 程序设计语言 ，是 机器语言的符号化 。 汇编语言的语句主要是 汇编格式指令 和 伪指令 。 把用汇编语言编写的程序称为 汇编语言源程序 ，或称为 汇编源程 序，或简称为 源程序 。 把汇编源程序翻译成目标程序的过程称为 汇编 。 完成汇编工作的工具或程序叫做 汇编程序 。 汇编过程示意图如下： #汇编语言源程序系统功能调用系统功能说白了就是操作系统提供的子程序，其也有入口参数和出口参数，只不过调用系统功能是采用编号的方式而不是采用程序名称的方式，DOS操作系统下： 编号为9的系统功能是显示输出一个以‘$结尾的字符串，入口参数为 字符串首地址 ， DS是首地址段值 ， DX是首地址偏移 。 编号为0AH的系统功能是输入一个字符串到指定缓冲区，DS是缓冲区段地址，DX是首地址偏移 编号为1的系统功能是接受用户按键，用户按键之后的内容放在AL寄存器中 编号为2的系统功能是输出一个字符，字符放在DL中 编号为4CH的系统功能是结束程序运行，返回DOS 调用系统功能的步骤： 根据相应功能填好对应参数 将系统功能号放入寄存器AH中 执行指令INT 21H 其中的INT 21H是一条软中断指令。 比如： ​ //显示字符串 MOV DX, hello ;准备参数 MOV AH, 9 ;9号功能 INT 21H ;调用 ; //结束程序返回DOS MOV AH, 4CH ;4CH号功能 INT 21H ;调用 汇编使用NASM汇编器使用NASM汇编器生成纯二进制代码文件（COM类型的可执行程序）的方法： ​ nasm demo.asm -f bin -o demo.com //命令名称-源程序文件名-格式项-纯二进制格式-目标文件名 语句及其格式语句的种类汇编语言（NASM）有四种类型的语句： 指令语句–指令 指令语句就是表示汇编格式指令的语句，也就是表示符号化的机器指令的语句。用符号表示的机器指令被称为汇编格式的指令。汇编器在对源程序进行汇编时，把指令语句翻译成机器指令。 伪指令语句–伪指令 伪指令语句 就是表示伪指令的语句。 伪指令 并非真正符号化的机器指令。对处理器而言，伪指令不是指令，但对汇编器而言，它却是指令。伪指令主要用于定义变量，预留存储单元。 也就是说，伪指令是为了汇编器存在的，而不是处理器。 比如伪指令可以用来定义数据，安排空间： ​ prompt db “Press a key: “, ‘$’ newline db 0DH, 0AH, ‘$’ result db 0, 0 宏指令语句—宏指令 宏指令语句 表示宏指令。宏指令也被简称为宏，与高级语言中宏的概念相同，就是代表一个代码片段的标识符。 宏指令在使用之前要先声明 。 指示语句–指示 指示（directive）也常被称为汇编器指令或汇编指令，它指示汇编器怎样进行汇编，如何生成目标代码。为了避免与汇编格式指令相混淆，所以把它称为“指示”。 操作数表示常数主要有4种不同类型的常数：整数、字符、字符串、浮点数。 整数 在没有特别标记时，一个整数由十进制表示。 可以采用十六进制、八进制和二进制形式表示整数。 后缀 H 表示十六进制数，后缀 Q 或 O 表示八进制数，后缀 B 表示二进制数。当然也可以用后缀 D 表示十进制数。 为了避免与普通标识符混淆，十六进制数应以数字开头，如果以字母开头，应该再冠以数字 0 。还可以采用 C 风格的前缀 0x 表示十六进制数。 字符 字符常数是一对单引号（或双引号）之间的若干个字符。 每个字符表示一个字节（ 8 个二进制位），可以认为字符的值是对应 ASCII 码值。 在表示 32 位数据时，包含在一对引号中的字符常数最多可以由 4 个字符组成。 对于由多个字符组成的字符常数，在存储时 出现在前面的字符占用低地址存储单元 。这样，按照“ 高高低低 ”存储规则， 出现在前面的字符代表了数值的低位 。 示例： ​ MOV AL , ‘a’ //AL=61H MOV AX, ‘a’ //AX=0061H MOV AX, ‘ab’ //AX=6261H，注意看这里，a存储在了低位，b存储在了高位 MOV EAX, ‘abcd’ //EAX=64636261H MOV BX, ‘abcd’ //BX=6261H,该字符常数过大，汇编器NASM会给出警告，并抛弃高位部分 字符串字符串常数与字符常数很相近，但是字符串常数可以含有更多的字符。 数值表达式 由运算符和括号把常数、记号和标识符等连接起来的式子，被称为 表达式 。 所谓 数值表达式 是指在汇编过程中能够由汇编器计算出具体数值的表达式。 组成数值表达式的各部分必须在汇编时就能完全确定 常见运算符及其优先级： 使用举例： ​ MOV AL , 01000111B | 00100000B ;AL=67H MOV AL, 01101000B &amp; 11011111B ;AL=48H MOV AL, 03H &lt;&lt; 4 ;AL=30H MOV AL, 80H &gt;&gt; 6 ;AL=02H MOV AL, ~ 00000001B ;AL=FEH MOV AL, ! 1 ;AL=00H MOV AL, -1 ;AL=FFH 数据类型说明大部分情况下，能够根据存放操作数的寄存器来确定操作数的类型（尺寸）。 但类似如下指令，操作数类型不明确，NASM会报告错误： ​ MOV [BX], 1 ADD [DI+3], 5 SUB [ESI+ECX*4], 6 ​ 汇编器NASM提供了BYTE、WORD、DWORD等关键字，用于说明操作数的类型（尺寸）。把这些关键词称之为 类型符。在VC2010的嵌入汇编或者生成的汇编格式目标代码中，对应的类型符后面要加一个‘PTR’。 使用示例： ​ MOV DWORD [BX], 1 ;双字 ADD BYTE [DI+3], 5 ;字节 SUB WORD [ESI+ECX4], 6 ;字 ; MOV [BX], DWORD 1 ;双字 ADD [DI+3], BYTE 5 ;字节 SUB [ESI+ECX4], WORD 6 ;字 PUSH WORD 99H 对于把立即数压入堆栈的PUSH指令，在16位代码中默认的操作数是字，在32位代码中默认的操作数是双字，所以需要明确操作数类型。 由于 PUSH指令的操作数至少是16位的 ，所以不能使用类型符BYTE。 伪指令语句和变量伪指令语句 就是表示伪指令的语句。 伪指令并非真正符号化的机器指令。对处理器而言，伪指令不是指令，但对汇编器而言，它却是指令。伪指令主要用于定义变量，预留存储单元。 伪指令语句主要有数据定义语句（定义初始化的数据项）和存储单元定义语句（定义未出初始化的数据项）。 数据定义语句格式： ​ [名字] DB 参数表 ;定义字节数据项 [名字] DW 参数表 ;定义字数据项 [名字] DD 参数表 ;定义双字数据项 DB、DW、DD分别是伪指令符，D代表define，名字是可选的，如果使用名字，那么它就代表存储单元的有效地址。确切地说，名字代表语句所定义的若干数据项中，第一个数据项对应存储单元的有效地址 。 通过数据定义语句可为数据项分配存储单元，并根据需要设置其初值。还可 用名字（标识符）代表数据项 。 举例： ​ wordvar dw 1234H, 55H//定义了两个长度为word的数据，首地址/名字是wordvar dvar dd 99H abcstr db ‘A’, ‘B’, 0DH, 0AH, ‘$’//定义了四个长度为byte的数据，首地址/名字是abcstr 执行完之后的内存单元存储图如下： 注意这里的存储原则也是“高高低低”。 存储单元定义语句格式： ​ [名字] RESB 项数 ;预留字节存储单元 [名字] RESW 项数 ;预留字存储单元 [名字] RESD 项数 ;预留双字存储单元 名字可选，代表预留存储单元的首地址。 “ 项数 ” 表示要定义的存储单元个数，可以是一个数值表达式。 RESB 、 RESW 或 RESD 分别是伪指令符。 RES 的含义是“ 预留 ”，其后字母代表存储单元类型，字节（ Byte ）、字（ Word）和双字（ DoubleWord ）。 存储单元定义语句是伪指令语句。 利用存储单元定义语句可以分配存储单元，但没有初始化。可用名字代表存储单元。如果把这样的存储单元视作为变量，那么就是 没有初始化的变量 。 举例： ​ buffer resb 128 //预留128个字节 wordtab resw 4 //预留4个字 farptr resd 1 //预留1个双字 abuff resb 32*2 //预留64个字节 wtable resw 3+5 //预留8个字 “ 项数”可以是一个数值表达式，但必须是马上可以计算出结果的表达式，不能是类似于EAX+EBX这样的在汇编执行时才能算出来的，因为伪指令语句是汇编层面的，不是处理器层面的。 常数符号声明语句格式： ​ 符号名 EQU 数值表达式 汇编过程中， NASM 会计算出数值表达式的值，然后符号就代表计算结果。在随后的程序中，就可以使用该符号代替这个表达式。 举例： ​ COUNT equ 5+3*2 ;COUNT代表11 MIN equ 8 ;MIN代表8 MAX equ MIN + COUNT + 20 ;MAX代表39 两个特别的符号汇编器NASM支持在表达式中出现两个特别的记号，即’ ′ 和 ′ &#x27;和&#x27; ′ 和 ′ $’。 利用这两个记号，可以方便地获得当前位置值。 $代表它所在源代码行的指令或者数据在段内的偏移，或者就是当前位置在段内的偏移。 比如： ​ jmp $ 代表在当前位置无限循环。 段声明和段间转移段声明语句段声明语句属于指示语句。它指示汇编器，开始一个新的段，或者从当前段切换到另一个段。 格式1： ​ section 段名 [段属性] [；注释] 格式2: ​ segment 段名 [段属性] [；注释] 使用举例： ​ section code//声明段code ..start://开始地址 MOV AX, data MOV DS, AX MOV DX, hello CALL Print_str MOV AH, 4CH INT 21H over: ; section data//声明段data hello db &quot;Hello world!&quot;, 0DH, 0AH, 24H section code//切换到段code Print_str: MOV AH, 9 INT 21H RET ​ 上面的代码经过汇编和连接后可生成exe类型的可执行文件，在Windows控制台窗口利用以下汇编和链接命令即可生成exe的可执行程序： ​ NASM demo.asm -f obj -o demo.obj LINK demo -o表示目标文件是obj格式，LINK后的demo表示生成demo.exe。 无条件段间转移指令格式1： ​ JMP SNAME:LABEL//JMP 段名：标号 格式2: ​ JMP FAR OPRD（LABEL）//JMP 类型说明符 标号/双字存储单元 在实方式下，操作数 OPRD 应该是一个双字存储单元。 FAR 是类型符，明确表示段间转移（远转移）。 指令把双字存储单元 OPRD 中的一个字（高地址的字）作为 16 位的段值送到代码段寄存器 CS，把双字中的另一个字（低地址的字）作为 16 位的偏移送到指令指针寄存器 IP ，从而实现转移。 示例代码： ​ section codeA .. start: MOV AX, data MOV DS, AX MOV DL, [flagch] MOV AH, 2 INT 21H //1: JMP codeB:step2 step4: MOV DL, [flagch] MOV AH, 2 INT 21H MOV AH, 4CH INT 21H section data align=16 flagch db &quot;ABC&quot; section codeC align=16 step3: MOV DL, [flagch +2] MOV AH, 2 INT 21H //2: JMP FAR step4 section codeB align=16 step2: MOV DL, [flagch +1] MOV AH, 2 INT 21H //3: JMP codeC:step3 ​​ 段间过程调用和返回指令IA-32 处理器支持存储器分段管理。 通常一个程序可以含有多个段，不仅代码和数据可以各自独立，而且根据需要不同功能的代码也可以占用不同的段。 段间转移格式1： ​ CALL SNAME : LABEL 格式2： ​ CALL FAR LABEL/OPRD 背后的步骤： 首先把返回地址的 段值 和 偏移 压入堆栈，注意段内过程调用是只压了EIP值即偏移。 然后把双字存储单元 OPRD 中的一个字（高地址的字）作为 16 位的段值送到 CS ，把双字中的另一个字（低地址的字）作为 16 位的偏移送到 IP ，从而转移到子程序。 段间返回格式1： ​ RETF 在实方式下，指令从堆栈先后弹出返回地址的偏移和段值，分别送到 IP 和 CS ，从而实现子程序的段间返回。 格式2： ​ RETF count 指令在实现段间返回的同时，再额外根据 count 值调整堆栈指针。在实方式下具体操作是，先从堆栈弹出返回地址的偏移和段值（当然，会调整堆栈指针SP ），再把 count 加到 SP 上。 示例代码： ​ section codeA align =16 ..start: MOV AX, CS MOV DS, AX MOV AX, codeC CALL FAR [ptsubr]//段间间接调用 MOV DL, 0DH CALL codeC:PutChar//段间直接调用 MOV DL, 0AH CALL codeC:PutChar//段间直接调用 MOV SI, ptsubr MOV AX, codeB CALL FAR [SI]//段间间接调用 MOV AH, 4CH INT 21H ptsubr dw echo4 dw codeB section codeB align=16 ToASCII: AND DL, 0FH ADD DL, &#39;0&#39; CMP DL, &#39;9&#39; JBE lab1 ADD DL, 7 lab1: RET echo4: MOV CX, 4 MOV BX, AX next: ROL BX, 4 MOV DL, BL CALL ToASCII CALL codeC:PutChar//段间直接调用 LOOP next MOV DL, &#39;H&#39; CALL codeC:PutChar RETF//段间返回 section codeC align=16 PutChar: MOV AH, 2 INT 21H RETF//段间返回 ​​ 目标文件和段模式目标文件不同的操作系统，对可执行文件的格式有不同要求。为了满足不同要求，有多种不同格式的目标文件。这些不仅与操作系统有关，也与汇编器和链接器有关。 纯二进制目标文件纯二进制目标文件 ，只含有对应源程序的二进制代码，也即 二进制形式的机器指令和数据，并不含有其他信息。纯二进制目标文件有时很有用，尤其在没有操作系统的场合。 使用nasm生成纯二进制代码文件的方法： ​ nasm xxx. asm -f bin -o xxx.com nasm xxx.asm -o xxx.com //缺省bin（纯二进制）格式 nasm xxx.asm -o yyy //目标文件名可以没有后缀 Windows（ 32位版本 ）仍然支持以纯二进制目标文件形式存在的可执行程序， 只要其扩展名是.com 。为了运行这样的可执行程序，操作系统（Windows中的DOS）总是把纯二进制文件加载到内存代码段的偏移 100H 开始处，执行起始点偏移也是100H 。 这就是为什么： ​ section code org 100H//指示段的起始偏移 begin: MOV AX, begin ;把标号begin代表的偏移送到AX，AX=0100H MOV AX, $ ;把当前偏移送到AX，AX=0103H 。。。。 ​ 这样的代码中org的值一般设为100H。 obj目标文件obj格式目标文件适用于生成EXE类型的可执行程序。早先的DOS操作系统下，可执行程序主要是EXE类型。由 汇编器对源程序汇编生成obj格式目标文件，由 链接器 对obj格式目标文件链接后，生成EXE类型的可执行程序。 obj格式目标文件不仅含有对应源程序的 机器指令和数据 ，而且还含有 其他重要信息。例如，支持引用段值的信息。又如，程序开始执行位置的信息。所以，obj格式目标文件要比纯二进制目标文件来得长。 在用于生成obj格式目标文件的源程序中，段名代表段值，所以可以通过段名来引用段值。还可以利用运算符 seg，获取标号所在段的段值。但是，在这样的源程序中，不能安排起始偏移设定语句org。在多个由链接器链接到一起的目标文件中，有且只能有1个目标文件含有开始执行的位置 。就汇编器NASM而言，程序开始执行的位置，在源程序中由特定的标号…start给出。 段模式声明语句无论是保护方式还是实方式，IA-32系列处理器都支持8位、16位和32位的操作数，都支持16位和32位的存储器寻址方式。 为了保持兼容，同时保证效率，IA-32系列处理器支持两种段模式，也即32位段模式和16位段模式。在 保护方式 下，一般采用32位段；在实方式 下，只能使用16位段： 对于32位段，缺省的操作数尺寸是8位和32位，缺省的存储器寻址方式是32位。 对于16位段，缺省的操作数尺寸是8位和16位，缺省的存储器寻址方式是16位。 段模式声明语句的格式​ BITS 32 BITS 16 ​ 第一条指示汇编器NASM按32位段模式来翻译随后的代码； 第二条指示按16位段模式来翻译随后的代码。 比如： ​ segment text org 100H ;设起始偏移100H MOV AX, CS MOV DS, AX bits 16 ;声明16位段模式 MOV AL, 1 ;B0 01 MOV AX, 1 ;B8 01 00 bits 32 ;声明32位段模式 MOV AL, 1 ;B0 01 MOV AX, 1 ;66 B8 01 00 ​​​ 宏宏 指用一个符号表示多个符号，或者代码片段。 在源程序中使用宏的优点： 可以减少重复书写，简化源程序 可以实现整体替换，维护源程序 汇编中的宏类似于高级语言中的宏。 宏指令的声明和使用宏指令的声明指，说明宏指令（宏）与由它代表的多个符号或代码片段之间的替代关系。 格式1: ​ %macro 宏指令名 参数个数 …… %endmacro 举例： 声明一个宏，其接受从键盘输入一个键 ​ %macro GetChar 0 MOV AH, 1 INT 21H %endmacro 接收参数的举例： 声明一个宏，其把一个双字存储单元的内容，送到另一个存储单元 ​ %macro MOVED 2 PUSH EAX MOV EAX, %2 MOV %1, EAX POP EAX %endmacro 调用： ​ MOVED EAX，EBX 单行宏的声明和使用单行宏指，一个符号代表多个符号，由一行表示之。 格式： ​ %define 宏名（参数表） 宏体 可以没有参数表，如果没有参数表，那么也不需要圆括号。 示例： ​ %define count 12 %define array(a,i) dword [a+4*i]//注意这里加入了参数 宏相关方法宏名的脱敏说白了就是想办法让宏名变为大小写不敏感 的，方法： %define ABC 123 –&gt; %idefine ABC 123 就是加了一个 i . 没加之前只能如下引用： ​ MOV EAX,ABC 加了之后： ​ MOV EAX,ABc MOV EBX，abc ​ 宏体中的标号这里主要介绍的是如下情况的解决： ​ %macro TOASC 0 AND AL, 0FH ADD AL, ‘0’ CMP AL, ‘9’ JBE SHORT OK ADD AL, 7 OK: %endmacro 由于这里为了跳过 ADD AL,7 ，使用了 JBE SHORT OK 的方法，这就导致宏体里面有两个 OK,按照书上的意思是这是不合法的，所以为了巧妙跳过下面的一句指令，使用如下代码： ​ %macro TOASC 0 AND AL, 0FH ADD AL, ‘0’ CMP AL, ‘9’ JBE SHORT $+4 ADD AL, 7 %endmacro 主要是 $+4 的使用，之所以 +4 是因为一条指令长度为4字节，如果想跳两条指令就 +8,实际上不仅是在宏里，在汇编代码的编写过程中如果遇到需要跳过紧跟某些指令时不妨使用这个方法（$代表的是当前代码行的位置，这在上文有介绍）。]]></content>
      <categories>
        <category>汇编</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编总结（4）——字符串操作和位操作]]></title>
    <url>%2F2018%2F11%2F14%2F%E6%B1%87%E7%BC%96%E6%80%BB%E7%BB%93%EF%BC%884%EF%BC%89%E2%80%94%E2%80%94%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C%E5%92%8C%E4%BD%8D%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[字符串操作首先明确什么是字符串： 字符串是字符的一个序列，对字符串的操作处理包括复制、比较和检索等，为了有效地处理字符串，IA-32系列处理器有专门处理字符串的指令，称之为字符串操作指令 ，简称为 串操作指令 。 字符串操作指令主要有五种常见的串操作指令： 串装入指令 串存储指令 串传送指令 串扫描指令 串比较指令 对于以上的五种常见操作指令，都对应三种字符尺寸： 字节（8位） 字（16位） 双字（32位） 串操作指令说明： 源串 DS：ESI 目的串 ES：EDI 如果只有一个数据段，或者说源串与目的串在同一个数据段，那么可以简单地认为，ESI指向源串，EDI指向目的串。 可以简单记忆位源串：Start（SI），目的串：End（DI） 串操作指令执行时，会自动调整作为指针使用的寄存器ESI和EDI的值，使之指向下一个字符，每次调整的尺寸与字符串中字符的尺寸一致。 字符串的操作方向一般是由低地址向高地址，但是也可以由高地址向低地址，这是由标志DF决定的： DF为0（复位）：由低到高，按递增方式调整 DF为1（置位）：由高到低，按递减方式调整 而对于DF的调整，有如下两个指令； CLD 清DF，DF=0（clear D） STD 置DF，DF=1（set D） 字符串装入指令（LOAD String）三种使用格式： LOADSB 装入字节（Byte），执行后ESI变化1 &gt; LOADSW 装入字（Word），执行后ESI变化2 &gt; LOADD 装入双字（Double Word），执行后ESI变化4 字符串装入指令的作用是把 ESI指向的字符串中的一个字符装到累加器AL、AX、EAX中，分别对应字节、字、双字，然后根据字符尺寸及方向标志DF的值调整ESI的位置。 字符串存储指令（Store String）三种使用格式： STOSB 存储字节（Byte） &gt; STOSW 存储字（Word），执行后ESI变化2 &gt; STOSD 存储双字（Double Word），执行后ESI变化4 字符串装入指令的作用是把累加器AL、AX、EAX中的字符存到 EDI指向的字符串中，分别对应字节、字、双字的存储，然后根据字符尺寸及方向标志DF的值调整ESI的位置。 字符串传送指令（Moving String）三种使用格式： MOVSB ;字节传送 &gt; MOVSW ;字传送 &gt; MOVSD ;双字传送 作用：把ESI指向的字节/字/双字传送到EDI指向的存储单元中，然后根据操作大小及方向标志DF调整ESI和EDI的值，类似如下两句： ​ LOADSB STOSB 但是并不会影响AL/AX/EAX的值。 字符串扫描指令（Scan String）三种格式： SCASB ;串字节扫描 &gt; SCASW ;串字扫描 &gt; SCASD ;串双字扫描 把累加器AL/AX/EAX中的内容和由寄存器EDI所指向的一个字节/字/双字的目标数据采用相减的方式比较，相减结果反映到各状态标志，但不影响两个操作数，然后根据字符大小和方向标志DF调整EDI的值。 Demo判断一个字符是否是十六进制字符： ​ char string[] =”0123456789ABCDEFabcdef”; char varch= ‘%’; //用于保存其他方式输入的字符 int flag; /反映是否为十六进制数符号 _asm { MOV AL, varch ;把要判断的字符送AL MOV ECX, 22 ;合计22个十六进制数符号 LEA EDI, string NEXT: SCASB ; LOOPNZ NEXT ;没有找遍，且没有找到，继续找 JNZ NOT_FOUND ;没有找到 FOUND: ;找到，字符是十六进制数符号 MOV flag, 1 JMP SHORT OVER NOT_FOUND: ;字符不是十六进制数符号 MOV flag, 0 OVER: } printf(“flag=%d\n”, flag); //显示为flag=0 return 0; ​​ 核心算法思想是将呆判断字符放在AL中，将EDI指向十六进制标准字符串的首地址，然后使用SCASB，如果执行SCASB后ZF标志位不为0，就说明待判断字符和十六进制标准字符串中的当前字符不等，然后进入下一个循环，注意此时EDI已经自动指向了十六进制标准字符串的下一位。如果此时ZF为0了，会进入JNZNOT_FOUND 这句，但是由于相等时ZF等于0，所以不会执行JNZ，会执行其下一句FOUND。 这就是主要的逻辑。 字符串比较指令（CoMPare String）三种格式： CMPS**B ;**串字节比较 &gt; CMPS**W ;**串字比较 &gt; CMPS**D ;**串双字比较 把寄存器ESI指向的一个字节/字/双字与EDI所指向的一个字节/字/双字采用相减的方式比较，结果反映到各有关标志中，但不影响两个操作数，然后根据字符尺寸和方向标志DF的值调整ESI和EDI的值。 重复操作前缀串操作指令每次只能处理一个字符，为了进一步提高效率，IA-32系列CPU提供重复操作前缀，重复操作前缀加在字符串操作指令之前，起到重复执行其后面一条字符串操作指令的作用。 主要设计三个： REP REPZ/REPE REPNZ/REPNE REPREP每一次先判断寄存器ECX是否为0，如果为0就结束对其后字符操作指令的重复，否则ECX减1，然后重复其后的串操作指令，所以当ECX值等于0时就不执行其后的串操作指令。 它与LOOP指令差不多，但是LOOP指令时先给ECX减1再判断ECX是否为0，而REP是先判读是否为0，不是0的话再减1，二者的共性是操作过程中给ECX减1不影响标志位。 REP只要用在MOVS和STOS之前。 Demo以下两段代码等价： 使用LOOP： ​ MOV ECX ,8; MOVSD; DEC ECX; LOOP ECX; 使用REP： ​ MOV ECX,8; REP MOVSD; REPE/REPZREPE和REPZ是一个前缀的两个助记符，说白了他们两功能一样： 重复前，先判断ECX是否为0，每重复一次，ECX值减1（不影响标志位），一直重复到ECX为0或者串操作指令使ZF为0为止，只有ZF为1（相等）的时候才有可能继续重复。 主要用在CMPS和SCAS之前。 Demo跳过字符串前面的空格符： ​ MOV EDI ,string； MOV ECX,-1; MOV AL,20H;//空格符 REPE SCASB;//SCASB会让当前EDI所指的值和AL（空格）比较，当相等时ZF为0，结束REPE的条件 DEC EDI;//上面多调整了一次EDI的值，这里减1 REPNE/REPNZ每次重复前先判断ECX是否为0，不为0时进行重复，每重复一次ECX值减1，一直到ECX为0或者ZF为1，只有当不相等（ZF为0）时才有可能重复。 REPNE/REPNZ主要用在SCAS之前。 Demo求字符串长度： ​ XOR AL, AL ;AL= 0（字符串结束标记值） MOV ECX, -1 ;假设字符串足够长（0FFFFFFFFH） REPNZ SCASB ;寻找字符串结束标记 NOT ECX DEC ECX ;至此ECX含字符串长度 ​ 位操作无论在表示、存储或者处理时，位（bit）是计算机系统中最基本的单位，为了提高位操作的效率，IA-32系列处理器提供专门的位操作指令，所谓的位操作指令 ，就是以位（bit）为操作单位的指令。 位测试及设置指令组位测试及设置指令组含有如下4条指令： BT 位测试指令（Bit test） BTC 位测试并取反指令（Bit test and complement） BTR 位测试并复位指令（Bit test and reset） BTS 位测试并置位指令（bit test and set） 一般格式： ​ BT OPRD1，OPRD2 BTC OPRD1，OPRD2 BTR OPRD1，OPRD2 BTS OPRD1，OPRD2 操作数OPRD1指定位串，可以是16位或32位 通用寄存器 ，可以是16位或32位 存储单元地址 。 操作数OPRD2指定位号，可以是操作数OPRD1 尺寸相同的通用寄存器 ，也可以是8位 立即数 。 如果操作数OPRD1是32位（16位）寄存器，那么被测位串也就限于32位（16位），实际被测位号将是操作数OPRD2取32（或16）的 余数 。 具体解释： BT：把被测试位的值送到进位标志CF BTC：把被测试位送到进位标志CF，并且把被测试位取反 BTR：把被测试位送到进位标志CF，并且把被测试位复位（清0） BTS：把被测试位送到进位标志CF，并且把被测试位置位（置1） 需要注意的是： 如果给出被测位串的操作数 OPRD1 是 32 位（或 16位）存储单元的地址，那么意味着被测的位串在存储器中。存储器中的被测位串可以足够长，可以是多个 32 位（或 16 位）假设由OPRD1 给出的存储单元有效地址是 EA ，由 OPRD2 给出的位号是 BitOffset 。 ​ 在 OPRD1 是 32 位存储单元的情况下： ​ 实测存储单元 = EA + (4 ∗ (BitOffset DIV 32)) //4 ∗ (BitOffset DIV32)表示第BitOffset DIV 32个存储单元，因为一个32位存储单元4个字节，所以乘4，下面的乘2是同样的道理 ​ 存储单元中的实测位号 = BitOffset MOD 32 ​ 在 OPRD1 是 16 位存储单元的情况下： ​ 实测存储单元 = EA + (2 ∗ (BitOffset DIV 16)) ​ 存储单元中的实测位号 = BitOffset MOD 16 在这种情况下，由于操作数OPRD2可以是有符号整数值，所以当OPRD2是32位时，可访问(-2G）至（2G-1）范围内的位串；当OPRD2为16位时，可访问(-32K)至(32K-1)范围内的位串，注意这里的正负是相对于EA为0点而言的。 位扫描指令组包含两条指令： BSF：顺向位扫描（bit scan forward） BSR：逆向位扫描（bit scan reverse） 一般格式： ​ BSF OPRD1，OPRD2 BSR OPRD1，OPRD2 操作数OPRD1是16或32位通用寄存器，操作数OPRD2可以是16位或32位通用寄存器或者存储单元；但操作数OPRD1和OPRD2的位数(长度)必须相同。 功能如下： 顺向位扫描指令BSF，从右向左（位0至位15或位31）扫描字或双字操作数OPRD2中第一个含“1”的位，并把扫描到的第一个含“1”的位的位号送操作数OPRD1。 逆向位扫描指令BSR，从左向右（位15或位31至位0）扫描字或双字操作数OPRD2中第一个含“1”的位，并把扫描到的第一个含“1”的位的位号送操作数OPRD1。 如果字或双字操作数OPRD2等于0，那么零标志ZF被置1，操作数OPRD1的值不确定；否则零标志ZF被清0。 Demo​ MOV EBX , 12345678H//1在第28位 BSR EAX, EBX ;ZF=0, EAX=1CH=12+16=28 BSF DX, AX ;AX=CH=1100B,ZF=0, DX=2=10B BSF CX, DX ;ZF=0, CX=1 条件设置字节指令一般格式： ​ SETcc OPRD 符号cc是代表各种条件的缩写，是指令助记符的一部分；操作数OPRD只能是8位寄存器或者字节存储单元，用于存放设置结果。当条件满足时，那么将目的操作数OPRD设置成1，否则设置成0。这里的条件与条件转移指令中的条件一样 。 应用场景：一般在使用条件转移指令且涉及到对1的操作时考虑使用条件设置指令代替条件转移指令，比如： 设r1、r2、r3都代表通用寄存器，要计算r3=（r1 的值 &gt;=r2的值）?1:0: 使用条件转移： ​ CMP r1, r2 MOV r3, 1 Jae NEXT MOV r3, 0 NEXT: 使用条件设置字节： ​ XOR r3, r3 CMP r1, r2 SETae r3]]></content>
      <categories>
        <category>汇编</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编总结（3）——程序设计初步]]></title>
    <url>%2F2018%2F11%2F14%2F%E6%B1%87%E7%BC%96%E6%80%BB%E7%BB%93%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%88%9D%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[堆栈的作用汇编语言中的堆栈就是高级语言中的栈。 堆栈主在汇编程序设计中主要有三个作用： 过程调用&amp;返回指令 参数传递 局部变量 过程调用&amp;返回指令过程调用中的过程指什么？ 汇编语言中的过程就是高级语言里面说的子程序，调用子程序（过程、函数）的本质就是控制转移，它与无条件转移的区别是 调用子程序需要考虑返回 。 过程调用指令 用于由主程序转移到子程序； 过程返回指令 用于由子程序返回到主程序。 指令 中文名 格式 解释 备注 CALL 过程调用指令 CALL LABEL 段内直接调用LABEL 与jmp的区别在于call指令会在调用label之前保存返回地址（call 中return之后主程序还可以继续执行，jmp当label执行完毕后不能返回主程序继续执行）RET | 段内过程返回指令 | RET | 使子程序结束，继续执行主程序 | call指令的背后段内直接调用的背后操作其实是两步： （1）把返回地址（EIP内容）压入堆栈 （2）使得EIP内容为目标地址偏移，从而实现转移 返回地址：紧随过程调用指令的下一条指令的地址（有效地址） 目标地址：子程序开始处的地址（有效地址） 与无条件转移相比，过程调用指令call只是多了第一步（保护现场）。 ret指令的背后过程返回指令的执行其实进行的是如下操作： 从堆栈中弹出地址偏移，送到指令指针寄存器EIP中，这个返回地址通常就是在执行相应的调用指令时所压入堆栈的返回地址。 参数传递入口参数：主程序传给子程序的参数 出口参数：子程序传给主程序的参数 参数传递的方法主要有： 寄存器传递法 、 堆栈传递法 、约定内存单元传递法、call后续区传递法等。具体情况需要事先约定好。 一般c语言的习惯是使用堆栈传递入口参数，使用寄存器传递出口参数，因为一般入口参数比较多，出口参数比较少。 局部变量这里就一个结论，堆栈可以用于安排动态局部变量。 算术逻辑运算指令乘除指令无符号数乘法指令（MUL）指令格式： ​ MUL OPRD 该指令实现两个无符号数的乘法运算，乘数是OPRD，被乘数位于AL、AX或EAX中（由OPRD的尺寸决定）。 需要注意的是乘积之后尺寸翻倍，两个8位的数乘积为16位，结果存放在AX中，类似的，两个16位数的乘积结果为32位，放在DX：AX中，最后，64位的乘积放在EDX：EAX中。 操作数OPRD可以是通用寄存器、存储单元，但是 不能是立即数 。 有符号数乘法指令（IMUL）有符号乘法指令有三种使用形式： ​ IMUL OPRD ; IMUL DEST,SRC; IMUL DEST,SRC1,SEC2; 具体解释如下： IMUL OPRD 单操作数乘法指令和无符号数乘法的规则差不多，只是在乘的时候把乘数和被乘数都当成有符号数。 IMUL DEST,SRC 数据流方向是DEST&lt;=DEST*SRC &gt; 要求目的操作数DEST只能是16位或32位通用寄存器，源操作数SRC可以是通用寄存器或存储单元， 需与目的操作数尺寸一致，可以是一个立即数（尺寸不能超过目的操作数）。 &gt; 乘数和被乘数均作为有符号数。 IMUL DEST,SRC1,SEC2 数据流方向为DEST &lt;=SRC1*SRC2 &gt; 目的操作数DEST只能是16位或32位通用寄存器。 &gt; SRC1可以是通用寄存器或者存储单元，须 与目的操作数尺寸一致 ，但 不能是立即数 。 &gt; SRC2只能是一个立即数， 尺寸不能超过目的操作数 。 &gt; 被乘数和乘数均为有符号数。 无符号数除法指令（DIV）一般格式： ​ DIV OPRD OPRD是除数，被除数位于AX、DX：AX或EDX：EAX中，由OPRD的尺寸决定，被除数的尺寸翻倍，商在AL、AX或者EAX中，余数在AH、DX或者EDX中，商和余数的尺寸和OPRD相同。 操作数OPRD可以是通用寄存器，可以是存储单元，但 不能是立即数 。 注意使用DIV指令时要防止除溢出，比如： 比如上图，除完之后应该商300余0，可是300超出了AL的表示范围，这时候就产生了溢出情况，在实际使用中要注意防范类似情况。 有符号数除法指令（IDIV）指令格式： ​ IDIV OPRD 基本原则和DIV一样，不同之处在于： 除法时有符号的 如果不能整除，余数的符号与被除数符号一致，而且余数的绝对值小于除数的绝对值。 总结 指令 中文名 MUL 无符号数乘法指令 IMUL 有符号数乘法指令 IMUL DEST，SRC 有符号数乘法指令 IMUL DEST,SRC1,SRC2 有符号数乘法指令 DIV 无符号数除法指令 IDIV OPRD 有符号数除法指令 符号拓展指令符号拓展指令的实质是用被拓展寄存器的符号位占据目标拓展寄存器。 指令 中文名 格式 解释 CBW 字节转化为字指令 CBW 把寄存器AL中的符号拓展到寄存器AH； 如果AL最高有效位、为0，则AH=0，如果AL最高位为1，则AH=FFHCWD | 字转化为双字指令 | CWD | 把寄存器AX中的符号拓展到寄存器DX；AX最高位0和1不同情况的拓展策略同CBWCDQ | 双字转化为四字指令 | CDQ | 把寄存器EAX中的符号拓展到EDX；AX最高位0和1不同情况的拓展策略同CBWCWDE | 字转化为双字指令 | CWDE | 把AX中的符号拓展到EAX的高16位；AX最高位0和1不同情况的拓展策略同CBW 使用举例： 符号拓展传送指令（MOVSX）一般格式： ​ MOVSX DEST,SRC 把SRC符号拓展后送到DEST。 目的操作数的尺寸必须大于源操作数的尺寸。源操作数的尺寸可以是8位或16位，目的操作数的尺寸可以是8位或16位。 使用举例： 零拓展传送指令（MOVZX）一般格式： ​ MOVZX DEST,SRC 把SRC零拓展后送到DEST。 源操作数可以是8位或16位，目的操作数可以是16位或32位。 使用举例： 逻辑运算指令需要注意： 只有通用寄存器或者存储单元可作为目的操作数，用于存放运算结果。 指令 中文名 格式 解释 备注 NOT 否运算指令 NOT OPRD 把操作数OPRD按位取反，然后送回OPRD AND 与运算指令 AND DEST，SRC 把两个操作数进行与运算之后结果送回DEST 同1得1，否则得0 OR 或运算指令 OR DEST，SRC 把两个操作数进行或运算之后结果送回DEST 同0得0，否则得1 XOR 异或运算 XOR DEST，SRC 把两个操作数进行异或运算之后结果送回DEST 相同得0不同得1 TEST 测试指令 TEST DEST，SRC 与AND指令类似，将各位相与，但是结果不送回DEST，仅影响状态位标志，指令执行后，ZF、PF、SF反映运算结果，CF和OF被清零 通常用于检测某些位是否为1，但又不希望改变操作数的值 test使用举例： 判断AL中的位6和位2是否有一位为1: ​ test al ,01000100B; 随后，判断标志位ZF，如果ZF为0，说明al第6位和第2位都为0，否则说明二者有一个为1. 移位指令一般移位指令 指令 中文名 格式 解释 备注 SAL 算术左移 SAL OPRD，count 把操作数oprd左移count位，右边补0 与shl指令一样 通过截取count的低5位，实际的移位数被限于0到31之间。SHL | 逻辑左移 | SHL OPRD，count | 把操作数oprd左移count位，右边补0 | 与sal指令一样通过截取count的低5位，实际的移位数被限于0到31之间。SAR | 算术右移 | SAR OPRD，count |把操作数oprd右移count位，同时每右移一位，左边补符号位，移出的最低位进入标志位CF |通过截取count的低5位，实际的移位数被限于0到31之间。SHR | 逻辑右移 | SHR OPRD，count | 把操作数oprd右移count位，左边补0，移出的最低位进入标志位CF |通过截取count的低5位，实际的移位数被限于0到31之间。 循环移位指令 指令 中文名 格式 解释 备注 ROL 左循环移位指令 ROL OPRD,count 左循环移一位之后最高位移到最低位的同时也进入CF 通过截取count的低5位，实际的移位数被限于0到31之间。ROR | 右循环移位指令 | ROR OPRD,count | 右循环移一位之后最低位移到最高位的同时也进入CF |通过截取count的低5位，实际的移位数被限于0到31之间。RCL | 带进位左循环移位 | RCL OPRD,count | 相当于CF在最高位直接参与循环移位 | 大循环左移通过截取count的低5位，实际的移位数被限于0到31之间。RCR | 带进位右循环移位 | RCR OPRD,count | 相当于CF在最高位直接参与循环移位 | 大循环右移通过截取count的低5位，实际的移位数被限于0到31之间。 使用实例： 实现把al的最低位送到bl的最低位，仍保持al不变。 ​ ror bl,1;//bl循环右移一位 ror al,1;//al循环右移一位，最低位进入cf rcl bl,1;//bl带进位左移，带进了来自al的最低位（cf） rol al,1;//恢复al 双精度移位指令双精度移位指令是为了方便地把一个操作数的部分内容通过移位复制到另一个操作数。 格式： 双精度左移：SHLD OPRD1,OPRD2,count 双精度右移：SHRD OPRD1,OPRD2,count 解释： SHLD OPRD1,OPRD2,count &gt;将OPRD1左移指定的count位，在低端空出的位用操作数OPRD2高端的count位填补，但是OPRD2内容保持不变，操作数OPRD1中最后移出的位保留在进位标志CF中。 SHRD OPRD1,OPRD2,count &gt;将OPRD1右移指定的count位，空出的位用OPRD2低端的count位填补，但是OPRD2内容保持不变，操作数OPRD1中最后移出的位保留在进位标志CF中。 分支程序设计无条件和条件转移指令段内转移和段间转移 段内转移（近转移） ：仅仅重新设置指令指针寄存器EIP的转移，由于没有调整CS，所以转移后继续执行的指令仍在同一代码段中。 段间转移（远转移） ：不仅重新设置EIP，而且重新设置代码段寄存器CS的转移，由于重置了CS，转移后继续执行的指令在另一代码段中。 对于段内转移和段间转移需要注意： 条件转移指令 和 循环指令 只能实现 段内转移 ； 无条件转移指令 和 过程调用指令 以及 返回指令 ，既可以是 段内转移 ，也可以是 段间转移 ； 软中断指令 和 中断返回指令 一定是 段间转移 ； 直接转移和间接转移 直接转移：转移指令中直接给出转移目标地址的转移； 间接转移：转移指令中给出包含转移目标地址的寄存器或者存储单元的转移； 需要注意无条件转移指令和过程调用指令集可以是直接转移也可以是间接转移。 无条件转移指令无条件转移指令分为4种： 段内直接转移 段内间接转移 段间直接转移 段间间接转移 需要说明的是无条件转移指令均不影响标志寄存器的状态标志。 无条件段内直接转移​ JMP LABEL； 标号LABEL表示要转移的目标位置（转移目的地）。 无条件段内直接转移的机器码构成如下： ​ 操作码OP 地址差rel 地址差rel实际上是LABEL所指定的指令的地址偏移与紧跟JMP指令的下一条指令的地址偏移之间的差值，rel可正可负，这样才可以实现前后的跳转。地址差rel可以用一个字节表示，也可用4个字节或2字节表示，如果只用一个字节表示，就称之为短（short）转移 ，否则称为 近（near）转移。一般如果当汇编器汇编到某条转移指令时可以计算出地址差rel，汇编器会自动判断出应该用1字节表示rel还是4字节或2字节，否则汇编器会使用较多的位数来表示地址差。所以，当程序员在写程序时能顾及出用8位就可以表示出地址差，那么可以在标号前加一个汇编器操作符“SHORT”来指定用一个字节表示地址差，表示转移的目的地就在附近。 无条件段内间接转移​ JMP OPRD OPRD是32位通用寄存器或者双字存储单元，比如： ​ JMP ECX; JMP DWORD PTR [EBX]; 无条件段间转移指令JMP段间转移指令和段内转移指令差不多，只是涉及到改变代码段寄存器CS的内容，情况较为复杂，在之后的文章中介绍。 条件转移指令条件转移指令在前一篇文章已经介绍，这里不再赘述，只是需要特别明确一下rel偏移量的概念。 多路分支的实现多路分支实际上指的就是switch-case的汇编实现，这里的实现原理主要是通过无条件间接转移指令和目标地址表来实现多路分支，举个例子： 考虑一下多路分支程序： ​ int cf319(int x, int operation) { int y; //多路分支 switch ( operation ) { case 1: y = 3x; break; case 2: y = 5x+6; break; case 4: case 5: y = xx ; break; case 8: y = xx+4*x; break; default: y = x ; } if ( y &gt; 1000 ) y = 1000; return y; } 上面的程序为了更加具有一般性，刻意没有安排连续的case值，其汇编的实现如下： ​ push ebp mov ebp, esp ; switch ( operation ) { mov eax, DWORD PTR [ebp+12] ;取得参数operation（case值） dec eax ;从0开始计算，所以先减去1 cmp eax, 7 ;从0开始计算，最多就是7 ja SHORT LN2cf319 ;超过，则转default（LN2cf319对应defalut处理语句） ; jmp DWORD PTR LN12cf319[ eax*4 ] ;这句是关键，这里实现了多路分支 ; ​ LN12cf319: ;多向分支目标地址表 DD LN6cf319 ; case 1 DD LN5cf319 ; case 2 DD LN2cf319 ; default DD LN4cf319 ; case 4 DD LN4cf319 ; case 5 DD LN2cf319 ; default DD LN2cf319 ; default DD LN3cf319 ; case 8 看上面的汇编实现，其核心思想是巧妙地运用了无条件段内间接转移和目标地址表，因为 目标地址表每项占4个字节，所以跳转的地址是目标地址表的起始地址加case对象（这里是operation）乘以4，如果operation为0，跳到目标地址表的首地址，即就是LN6c，如果operation为1，跳到LN5c，以此类推就实现了多路分支的巧妙跳转。 使用该方法的一般建议是：当多路分支数超过5时，考虑无条件间接转移方式和目标地址表结合实现多路分支会更高效。 循环程序设计循环指令循环指令类似于条件转移指令，其采用的是段内相对转移的方式，是通过在指令指针寄存器EIP上加一个地址差的方式实现的转移，需要注意的是循环指令中的这个地址差只用了一个字节（8位）来表示，所以转移范围仅在-128-127之间。在保护方式（32位代码段）下，ECX作为循环计数器，实方式下，以CX为循环计数器，循环指令不影响各标志位。 指令 中文名 格式 解释 备注 LOOP 计数循环指令 LOOP LABEL 使ECX的值减1，当ECX的值不为0的时候跳转至LABEL，否则执行LOOP之后的语句 LOOPE 等于循环指令 LOOPE LABEL 使ECX的值减1，如果结果不等于0并且零标志ZF等于1（表示相等），那么就转移到LABEL，否则执行LOOPE之后的语句 ECX的减1并不影响标志位，ZF是否为1取决于循环指令之前指令对其的影响。LOOPZ | 零循环指令 | LOOPZ LABEL |使ECX的值减1，如果结果不等于0并且零标志ZF等于1（表示相等），那么就转移到LABEL，否则执行LOOPZ之后的语句 |ECX的减1并不影响标志位，ZF是否为1取决于循环指令之前指令对其的影响。LOOPNE | 不等于循环指令 | LOOPE LABEL |使ECX的值减1，如果结果不等于0并且零标志ZF等于0（表示不相等），那么就转移到LABEL，否则执行LOOPNE之后的语句 |ECX的减1并不影响标志位，ZF是否为1取决于循环指令之前指令对其的影响。LOOPNZ | 非零循环指令 | LOOPNZ LABEL |使ECX的值减1，如果结果不等于0并且零标志ZF等于0（表示不相等），那么9就转移到LABEL，否则执行LOOPNZ之后的语句 |ECX的减1并不影响标志位，ZF是否为1取决于循环指令之前指令对其的影响。JECXZ | 计数转移指令 | JECXZ LABEL | 当寄存器ECX的值为0时转移到LABEL，否则顺序执行 |注意与LOOP的关系是JECXZ是直接判断ECX，没有先减ECX通常在循环开始之前使用该指令，所以循环次数为0时，就可以跳过循环体 子程序设计调用约定 -_cdecl 被称为 C 调用约定。缺省调用约定。参数按照从右至左的顺序入堆栈，函数本身不清理堆栈。 _stdcall 被称为 pascal 调用约定。参数按照从右至左的顺序入堆栈，函数自身清理堆栈。 _fastcall 是快速调用约定。通过 寄存器传递参数。前两个参数由 ECX 和 EDX 传送，其他参数按照从右至左的顺序入堆栈，函数自身清理堆栈。]]></content>
      <categories>
        <category>汇编</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编总结（1）——基础知识]]></title>
    <url>%2F2018%2F11%2F13%2F%E6%B1%87%E7%BC%96%E6%80%BB%E7%BB%93%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[CPU简介这部分主要介绍CPU的基本功能、汇编语言的概念、数据的表示和存储。 CPU的基本功能目标代码 ： &gt;计算机系统中的cpu只能执行机器指令，而由机器指令组成的程序就叫目标程序（目标代码），事实上无论你用什么语言编程，计算机系统最终运行的都是目标程序（目标代码）。 cpu的基本功能主要有三：执行机器指令、暂存少量数据、访问存储器 执行机器指令机器器指令 ：CPU能够直接识别并遵照执行的指令； CPU的指令集 ：CPU能够执行的全部机器指令； CPU一条接一条地依次执行存放在存储器中的机器指令，每一条机器指令的功能通常很有限。 按指令的功能来划分，通常机器指令可分为以下几大类: 数据传送指令 、 算术逻辑运算指令 、 转移指令 、 处理器控制指令 、其他指令 等 暂存少量数据这个功能主要指的是cpu的寄存器中可以暂存少量数据，因为利用寄存器存放数据和运算结果，其效率是最高的，但是寄存器的数量是有限的。 访问存储器既然最有效的寄存器存放数据法只能使用于少量数据的暂存，那么cpu应该从哪里读取数据以进行运算，运算完成之后又应该把数据送到哪里呢？自然是内存（存储器）： CPU要执行目标程序，就要访问存储器。目标程序在存储器中，待处理的数据也在存储器中。这里存储器是指CPU能够直接访问的计算机系统的物理内存. 存储器(内存)由一系列存储单元线性地组成， 最基本的存储单元为一个字节。为了标识和存取每一个存储单元，给每一个存储单元规定一个编号，也就是存储单元地 址. CPU支持以多种形式表示存储单元的地址。一些功能较强的CPU还支持以多种方式组织管理存储器 汇编语言概念主要介绍三部分：机器指令、汇编格式指令、汇编语言及其优缺点： 机器指令CPU能够直接识别并遵照执行的指令称为 机器指令 。 机器指令的构成：操作码、操作数，其中： 操作码 ：指出要进行的操作或运算，比如加、减、传送 操作数 ：指出参与操作或运算的对象，也指出操作或运算结果存放的位置，例如，寄存器、存储单元和数据等 汇编格式指令由指令助记符、操作符号和常量等表示的指令被称为 汇编格式指令 ，其中： 指令助记符 ：人们为了表示指令的操作码而采用的便于记忆、并能描述指令功能的符号 。 操作符号 ：表示操作数的符号，比如寄存器、存储单元地址等。 汇编语言的优缺点明确几个概念： 把用汇编语言编写的程序称为汇编语⾔言源程序，或称为 汇编源程序 ，或简称为 源程序 。 把汇编源程序翻译成目标程序的过程称为 汇编 。 把完成汇编工作的工具或程序叫做 汇编程序(汇编器) 。 他们之间的关系如下： 优点 ：效率高、与机器关系密切 缺点 ：汇编语言源程序繁琐、汇编语言程序调试困难 综上，汇编语言适合的场景： 执行时间/存储容量有较高要求 需要提高大型软件效率 软件要直接和有效控制硬件 没有合适的高级语言 数据的表示和存储数据的表示这部分主要为数的二进制表示、有符号数的补码表示、符号拓展等。 数据的存储首先明确数据是以二进制形式表示的数据和代码存放在存储器(内存)之中。 内存由一系列基本存储单元线性地组成，每一个基本存储单元有一个唯一的地址。通常，基本存储单元由 8个连续的位构成，可用于存储一个字节的数据。所以，基本存储单元也被称为字节存储单元。 可以把内存看作为一个很大的一维字符数组，把地址看作为标识数组元素的下标。]]></content>
      <categories>
        <category>汇编</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编总结（2）——IA-32处理器基本功能]]></title>
    <url>%2F2018%2F11%2F13%2F%E6%B1%87%E7%BC%96%E6%80%BB%E7%BB%93%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94IA-32%E5%A4%84%E7%90%86%E5%99%A8%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[IA-32处理器简介这部分主要介绍了主要的IA-32系列处理器以及著名的保护方式和实地址方式的工作模式。 IA-32系列处理器IA-32系列处理器指什么首先明确IA-32系列处理器是什么： IA-32系列处理器泛指基于英特尔IA-32架构的32位微处理器 代表的型号比如： Intel 80386/80486 Intel Pentium(奔腾) Intel Xeon(至强) Intel Core(酷睿) 其最大特点是保持了与先前处理器的兼容。 处理器的主要指标 处理器的位数 16位 32位 64位 主频 平行化程度 流水线 多核 保护方式和实地址方式保护方式保护方式是IA-32系列处理器的常态工作方式，只有在保护方式下， IA-32系列处理器才能发挥出其全部性能和特点 。 windows和Linux都运行于保护方式。 保护方式的主要特点： 全部32根地址线有效，可寻址高达4G字节的物理地址空间 支持存储器分段管理和可选的存储器分页管理机制 支持虚拟存储器的实现 提供完善的保护机制 支持操作系统实现多任务管理 实地址方式（实方式）实地址方式(Real-address mode)是最初的工作方式，是处理器重新开始运行后的最初工作方式。 实地址方式是IA-32系列处理器中最初的处理器的工作方式（最早的8086/8088只能工作在实地址方式，因为其没有保护方式）。 实地址方式的特点： 只能访问最低端的1M字节的物理地址空间。地址空间的范围是00000H至FFFFFH 。 只支持存储器的分段管理，而且每个存储段的大小限于 64K字节 。 实地址对应保护方式下的虚地址。这应该是实地址方式 的名称由来。实地址方式常常被简称为实⽅方式 。 在实方式下，IA-32系列处理器不能发挥其全部性能。 通用寄存器及使用关于寄存器的几点注意点： 寄存器是处理器内的特殊存储单元。 &gt; 处理器内有多种不同用途的寄存器。 &gt; 寄存器分别有各自的名称，以便表示及访问。 IA-32系列CPU有8个32位通用寄存器：EAX、 EBX、 ECX、 EDX、 ESI、 EDI、 EBP、 ESP 主要功能：存储数据、参与算术逻辑运算、给出存储单元的地址。 注意：可以单独直接访问这些通用寄存器的低16位，他们是8个16位通用寄存器，名称分别是：AX、BX、CX、DX、SI、DI、BP、SP，对应16位处理器Intel8086的8个通用寄存器。 还可以单独直接访问AX、BX、CX、DX的高8位和低8位，示意图如下： 带H的寄存器（比如AH、BH）代表的是X寄存器（AX、BX）的High（高）字节，对应的，AL代表的就是AX的Low（低）字节。 简单传送指令 指令 中文名 格式 解释 备注 MOV 传送指令 MOV DEST,SRC DEST &lt;=SRC 源和目标的尺寸必须一致，不能同时是存储单元。 XCHG 交换指令 XCHG OPER1,OPER2 把操作数oper1的内容与操作数oper2的内容交换 oper1和oper2可以是通用寄存器或存储单元，但不能同时是操作单元，也不能是立即数，也不能同时是存储单元。 简单加减指令 指令 中文名 格式 解释 备注 ADD 加法指令 ADD DEST,SRC DEST&lt;=DEST+SRC 两数相加 SUB 减法指令 SUB DEST,SRC DEST&lt;=DEST-SRC 两数相减 INC 加1指令 INC DEST DEST&lt;=DEST+1 DEC 减1指令 DEC DEST DEST&lt;=DEST-1 NEG 取补指令 NEG OPRD OPRD=0-OPRD 对操作数取补（相反数） 标志寄存器及使用标志寄存器（FLAGS register）标志寄存器 是一个32位的寄存器，主要反映处理器的状态和运算结果的某些特征，认为主要是 状态标志 和 控制标志 以及系统标志 三部分。 如上图所示，标两个字母的是状态标志位，标着X的是系统标志位，标着字母C的是控制标志位，阴影部分是不使用的保留位。 状态标志 标志 标志名 主要功能 CF 进位标志（Carry flag） 当算术运算产生进位或者借位时，置标志（1），否则清标志（0）。 SF 符号标志（Sign flag） 反映运算结果的符号位(符号位为1，置标志;否则清)，与运算结果的最高位相同。 ZF 零标志（Zero flag） 当运算结果为0时，置标志;否则清标志。 OF 溢出标志（Overflow flag） 反映有符号数的加减运算是否引起溢出，如果溢出，置标志，否则清标志。 PF 奇偶标志（Parity flag） AF 辅助进位标志（Auxiliary Carry flag） 状态标志操作指令 指令 中文名 格式 解释 CLC（clear carry flag） 清进位标志指令 CLC 使进位标志CF为0 STC(set carry flag) 置进位标志指令 STC 使进位标志CF为1 CMC（complement carry flag） 进位标志取反指令 CMC 使进位标志CF取反 LAHF（load status flags into AH register） 获取状态标志操作指令 LAHF 把位于标志寄存器低端的8位同时送到寄存器AH的对应位SAHF（store AH into Flags） | 设置状态标志操作指令 | SAHF |对标志寄存器中的低8位产生影响，使得状态标志位SF、ZF、AF、PF和CF分别成为来自寄存器AH中对应位的值，但保留位（位1、位3、位5）不受影响 带进位加减指令 指令 中文名 格式 解释 备注 ADC（add with carry） 带进位加法指令 ADC DEST,SRC DEST &lt;=DEST+SRC+CF 与add指令不同之处是要再加上进位标志cf的值SBB(substraction with borrow) | 带借位减法 | SBB DEST,SRC |DEST&lt;=DEST-(SRC+CF) | 与sub指令不同之处是要再减上借位标志cf的值 段寄存器存储器分段CPU能够通过其总线直接寻址访问的 存储器 被称为 内存 ，每一个字节存储单元有一个唯一的地址，称之为 物理地址 。CPU的地址线数量决定了可产生的最大物理地址， n根地址线，可形成的最大物理地址是 2 n 2^n 2 n-1,所有可形成的物理地址的集合被称为物理地址空间. 物理地址空间大小不等于实际安装的物理内存大小。 为了有效地管理存储器，常常把地址空间划分为若干逻辑段， 对应存储空间被划分为若干存储段。逻辑段和存储段是一致的。一般说来，运行着的程序在存储器中映像有三部分组成: 代码，代码是要执行的指令序列； 数据，数据是要处理加工的内容； 堆栈，堆栈是按“先进后出”规则存取的区域。 通常，代码、数据和堆栈分别占用不同的存储器段，相应的段也就被称为 代码段 、 数据段 和 堆栈段 。 在分段之后，程序中使用的某个存储单元总是属于某个段。 所以，可以采用某某段某某单元的方式来表示存储单元。 逻辑地址在程序中用于表示存储单元的地址被称为 逻辑地址 。 由于采用分段存储管理方式，程序中使用的逻辑地址是二维的，第一维给出某某段，第二维给出段内的某某单元。 二维的逻辑地址: 段号∶偏移 在实方式和保护方式下，都通过偏移指定段内的某某单元。在实方式下，段号是 段值 ;在保护方式下，段号则是 段选择子 。 逻辑地址转换为物理地址的过程为由段号得到段起始地址，再加上偏移。 需要注意的是； 保护方式下，物理地址是32位，段起始地址是32位，偏移是32位; 在实方式下，物理地址是20位，段起始地址是20位，偏移是16位。 逻辑地址中的段号(段值或者段选择子)存放在哪里呢?答案是，当前使用段的段号存放在段寄存器(Segment Registers)中。 段寄存器 段寄存器名称 中文名 解释 出现时期 CS（Code Segment） 代码段寄存器 当前代码段 Intel 8060处理器 SS（Stack Segment） 堆栈段寄存器 当前堆栈段 Intel 8060处理器 DS（Data Segment） 数据段寄存器 当前数据段 Intel 8060处理器 ES（Extra Segment） 附加段寄存器 可用于指定数据段 Intel 8060处理器 FS 附加段寄存器 可用于指定数据段 80386开始 GS 附加段寄存器 可用于指定数据段 80386开始 寻址方式表示指令中操作数所在的方法称为寻址方式，主要分为三大类： 立即寻址 寄存器寻址 存储器寻址 此外还有固定寻址和I/O端口寻址等 立即寻址方式和寄存器寻址方式立即寻址方式说白了当操作数是立即数的时候就是立即寻址方式，比如： ​ mov eax,12345678H 所以： 立即数作为指令的一部分，跟在操作码后面存放在代码段 如果立即数由多个字节构成，那么作为指令的一部分存储时，也采用“高高低低”规则 只有源操作数才可采用立即寻址方式， 目的操作数不能采用立即寻址方式 寄存器寻址方式就是操作数在CPU内部的寄存器中，指令中指定寄存器，不需要通过访问存储器来取得操作数，所以采用寄存器寻址方式的指令执行速度较快。 32位的存储器寻址方式当指令的操作数在存储单元时，指定存储单元就指定了操作数。 为了灵活地访问存储器，IA-32系列CPU提供了多种表示存储单元偏移的方式，即有多种存储器寻址方式： 直接寻址 寄存器间接 寄存器相对 基址加变址 通用 直接寻址方式操作数在存储器中，指令直接包含操作数所在存储单元的有效地址。 ​ mov ecx,[95480H] 寄存器间接寻址操作数在存储器中，由八个32位通用寄存器之一给出操作数所在存储单元的有效地址。 寄存器间接寻址方式中，给出操作数所在存储单元有效地址的寄存器相当于c语言中的指针变量，它含有要访问存储单元的地址。 ​ mov ecx,[esi] 32位寄存器寻址方式的通用表示存储单元的有效地址可以由三部分内容相加构成: 一个32位的基地址寄存器 一个可乘上比例因子1、2、4或8的32位的变址寄存器 一个8位、16位或32位的位移量 这三部分可省去任意的两部分。 ​ add dx ,[ecx+5328H]//寄存器相对寻址方式 xchg [ebx,esi],dx//基址加变址寻址方式 mov ebx,[edi+eax*4+300H]//基址加放大因子的变址寻址方式 在某条具体的指令中，如果有存储器操作数，那么其尺寸是确定的。在大多数情况下，存储器操作数的尺寸是一 目了然的，因为通常要求一条指令中的多个操作数的尺寸一致，所以指令中的寄存器操作数的尺寸就决定了存储器操作数的尺寸。 在少数情况下，需要显式地指定存储器操作数的尺寸。 ​ LEA EBX , bufi MOV DWORD PTR [EBX], 5 // 双字 MOV WORD PTR [EBX+4], 5 //字 MOV BYTE PTR [EBX+8], 5 //字节 注意如果 基址寄存器 不是 EBP 或者 ESP ，那么缺省引用的段寄存器是 DS ; 如果 基址寄存器 是EBP或者ESP，那么缺省引 用的段寄存器是 SS 。 当EBP作为 变址寄存器 使用( ESP不 能作为变址寄存器使用 )时，缺省引用的段寄存器仍然是 DS 。 无论存储器寻址方式简单或者复杂，如果由基址寄存器、 带比例因子的变址寄存器和位移量这三部分相加所得 超过 32位，那么有效地址仅为低32位 。 取有效地址指令 指令 中文名 格式 解释 备注 LEA（load effective address） 取有效地址指令 LEA REC,OPRD 把操作数oprd的有效地址传送到操作数rec，源操作数oprd必须是一个存储器操作数，目的操作数rec必须是一个16位或32位的通用寄存器 与mov指令的区别：mov：移动地址中的值lea：将地址进行移动 lea指令的妙用： 指令寄存器和简单控制转移指令指令指针寄存器IA-32系列CPU有一个32位的指令指针寄存器EIP，由CS和EIP确定所取指令的存储单元地址。段寄存器CS给出当前代码段的段号，指令指针寄存器EIP给出偏移。 实方式下，段的最大范围是64K，EIP中高16位必须是0，相当于只有低16位的IP起作用。 CPU 执行代码(程序)就是一条接一条地执行机器指令。可以把CPU执行指令的过程看作一条处理指令的流水线，其第一步是从存储器中取出指令。在取出一条指令后，会根据所取指令的长度，自动调整指令指针寄存器 E IP 的值，使其指向下一条指令。这样，就实现了顺序执⾏指令。 那么如果我们不想顺序执行指令，而想非自动顺序调整EIP的内容，这就是所谓的 转移 。 衍生出的 控制转移指令 就是专门用于改变EIP内容的指令，主要包括： 条件转移指令 无条件转移指令 循环指令 函数调用及返回指令 等 这些控制转移指令的实质就是根据不同的情形改变EIP的内容以实现转移。 常用条件转移指令条件转移所谓条件转移指，当某一条件满足时，发生转移，否则继续顺序执行。换句话说，当某一条件满足时，就改变 EIP的内容，从而实施转移，否则顺序执行 。 标志寄存器中的 状态标志 被用于表示条件。绝大部分条件转移指令 根据某个标志或者某几个标志 来判断条件是否满足。 条件转移类似于高级语言的分支。 条件转移指令主要可以分为三类： 根据一个标志判别 根据两个标志判别 根据三个标志判别 指令格式 转移条件 转移说明 其他说明 JZ 标号 JE 标号 ZF=1 同上 等于0转移(Jump if zero) 相等转移(Jump if equal) 单个标志 JNZ 标号 JNE 标号 ZF=0 同上 不等于0转移(Jump if not zero) 不相等转移(Jump if not equal) 单个标志 JB 标号 JNAE 标号 JC 标号 CF=1 同上 同上 低于转移 不高于等于转移 进位位被置转移 单个标志 (无符号数) JNBE 标号 JA 标号 (CF或ZF)=0 同上 不低于等于转移 高于转移 两个标志 (无符号数) JLE 标号 JNG 标号 ((SF异或OF)或ZF)=1 同上 小于等于转移 不大于转移 三个标志 (有符号数) JNLE 标号 JG 标号 ((SF异或OF)或ZF)=1 同上 不小于等于转移 大于转移 三个符号（有符号数） 注意条件转移指令本身不影响标志。 条件转移指令在条件满足的情况下， 只改变指令指针寄存器EIP 。也就是说，条件转移的转移目的地仅限于 同一个代码段内。这种不改变代码段寄存器CS，仅改变EIP的 转移被称为 段内转移 。 条件转移指令可以实现向前方转移，也可以实现向后方 转移。 比较指令和数值大小比较 指令 中文名 格式 解释 备注 CMP 比较指令 CMP DEST,SRC 根据dest-src的差影响各状态标志寄存器 不把dest- src的结果送入dest 比较指令是根据DEST-SRC的差影响标志寄存器的各状态标志（但不把结果送到DEST中）来判断两个数的大小关系的，判断的准则如下： 根据零标志ZF是否置位，判断两者是否相等; 如果两者是无符号数，可根据进位标志CF判断大小; 如果两者是有符号数，要同时根据符号标志SF和溢出标志OF判断大小。 为了方便进行数值大小比较，IA-32系列CPU提供两套以数值大小为条件的条件转移指令，一套适用于无符号数之间的比较，另一套适用于有符号数之间的比较： 有符号数间的次序关系称为大于(G)、等于(E) 和小于（L）； 无符号数间的次序关系称为高于（A）、等于（E）和低于（B）； 简单无条件转移指令类似于高级语言中的goto语句，就是jmp语句： 指令 中文名 格式 解释 备注 JMP 无条件段内直接转移指令 JMP LABEL 使控制无条件地转移到标号为label的位置 无条件转移指令本身不影响标志 堆栈和堆栈操作所谓堆栈其实就是一段内存区域，只是对它的访问操作仅限于一端进行，地址较 小 的一端被称为 栈顶 ，地址较 大 的一端被称为栈底 。 堆栈段寄存器 SS 含有当前堆栈段的 段号 ，SS指示堆栈所在内存区域的位置。 堆栈指针寄存器 ESP含有栈顶的偏移（有效地址），ESP指向 栈顶 。 堆栈的主要用途： 保护寄存器内容或者保护现场; 保存返回地址; 传递参数; 安排局部变量或者临时变量。 堆栈操作 指令 中文名 格式 解释 备注 PUSH 进栈指令 PUSH SRC 把源操作数src压入堆栈 源操作数src可以是32位通用寄存器、16位通用寄存器和段寄存器，也可以是双字存储单元或者字符存储单元，还可以是立即数POP | 出栈指令 | POP DEST | 从栈顶弹出一个双字或字数据到目的操作数 |如果目的操作数是双字的，那么就从栈顶弹出一个双字数据，否则，从栈顶弹出一个字数据，出栈至少弹出一个字（16位）PUSHA | 16位通用寄存器全进栈指令 | PUSHA | 将所有8个16位通用寄存器的内容压入堆栈 | 压入顺序是AX CX DXBX SP BP SI DI，然后对战指针寄存器SP的值减16，所以SP进栈的内容是PUSHA指令执行之前的值POPA | 16位通用寄存器全出栈指令 | POPA | 以PUSHA相反的顺序从堆栈中弹出内容，从而恢复PUSHA之前的寄存器状态 |SP的值不是由堆栈弹出的，而是通过增加16来恢复PUSHAD | 32位通用寄存器全进栈指令 | PUSHAD | 将所有8个32位通用寄存器的内容压入堆栈 | 压入顺序是EAX ECXEDX EBX ESP EBP ESI EDI，然后对战指针寄存器SP的值减32，所以SP进栈的内容是PUSHAD指令执行之前的值POPAD | 32位通用寄存器全出栈指令 | POPAD | 以PUSHAD相反的顺序从堆栈中弹出内容，从而恢复PUSHAD之前的寄存器状态| ESP的值不是由堆栈弹出的，而是通过增加32来恢复]]></content>
      <categories>
        <category>汇编</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Normalizing rows with Python]]></title>
    <url>%2F2018%2F11%2F09%2FNormalizing%20rows%20with%20Python%2F</url>
    <content type="text"><![CDATA[A common technique we use in Machine Learning and Deep Learning is tonormalize our data. It often leads to a better performance because gradientdescent converges faster after normalization. Here, by normalization we mean changing x to $\frac{x}{||x||}$(dividing each row vector of x by its norm). For example, if x=\begin{bmatrix} 0&3&4\\ 2&6&4 \end{bmatrix} then \| x\| = np.linalg.norm(x, axis = 1, keepdims = True) = \begin{bmatrix} 5 \\\ \sqrt{56} \\\ \end{bmatrix}and x_{normalized}= \frac{x}{\| x\|} = \begin{bmatrix} 0 & \frac{3}{5} & \frac{4}{5} \\\ \frac{2}{\sqrt{56}} & \frac{6}{\sqrt{56}} &\frac{4}{\sqrt{56}} \\\ \end{bmatrix}Exercise : Implement normalizeRows() to normalize the rows of a matrix.After applying this function to an input matrix x, each row of x should be avector of unit length (meaning length 1). implement1234567891011121314151617181920def normalizeRows(x): """ Implement a function that normalizes each row of the matrix x (to have unit length). Argument: x -- A numpy matrix of shape (n, m) Returns: x -- The normalized (by row) numpy matrix. You are allowed to modify x. """ ### START CODE HERE ### (≈ 2 lines of code) # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True) x_norm = np.linalg.norm(x,axis=1,keepdims=True) # Divide x by its norm. x = x/x_norm ### END CODE HERE ### return x 使用： 1234x = np.array([ [0, 3, 4], [1, 6, 4]]) print("normalizeRows(x) = " + str(normalizeRows(x))) output:]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Normalizing</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logistic Regression with a Neural Network mindset]]></title>
    <url>%2F2018%2F10%2F06%2FLogistic%20Regression%20with%20a%20Neural%20Network%20mindset%2F</url>
    <content type="text"><![CDATA[Logistic Regression with a Neural Network mindsetGeneral Architecture of the learning algorithmIt’s time to design a simple algorithm to distinguish cat images from non-cat images. I will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why Logistic Regression is actually a very simple Neural Network! Mathematical expression of the algorithm: For one example Missing superscript or subscript argument x^{(i)} : z^{(i)} = w^T x^{(i)} + b \tag{1} \hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\tag{2} \mathcal{L}(a^{(i)}, y^{(i)}) = - y^{(i)} \log(a^{(i)}) - (1-y^{(i)} ) \log(1-a^{(i)})\tag{3}The cost is then computed by summing over all training examples: J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{6}Key steps:In this exercise, I will carry out the following steps: - Initialize the parameters of the model Learn the parameters for the model by minimizing the cost Use the learned parameters to make predictions (on the test set) Analyse the results and conclude Building the parts of algorithmThe main steps for building a Neural Network are: Define the model structure (such as number of input features) Initialize the model’s parameters Loop: Calculate current loss (forward propagation) Calculate current gradient (backward propagation) Update parameters (gradient descent) You often build 1-3 separately and integrate them into one function we call model(). Helper functionssigmoid Using code from “Python Basics”, implement sigmoid(). As we seen in the figure above, I will compute $sigmoid( w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions. I will use np.exp(). 1234567891011121314151617def sigmoid(z): """ Compute the sigmoid of z Arguments: z -- A scalar or numpy array of any size. Return: s -- sigmoid(z) """ ### START CODE HERE ### (≈ 1 line of code) s = 1 / (1 + np.exp(-z)) ### END CODE HERE ### return s initialize_with_zeros12345678910111213141516171819202122def initialize_with_zeros(dim): """ This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0. Argument: dim -- size of the w vector we want (or number of parameters in this case) Returns: w -- initialized vector of shape (dim, 1) b -- initialized scalar (corresponds to the bias) """ ### START CODE HERE ### (≈ 1 line of code) w = np.zeros(shape=(dim, 1)) b = 0 ### END CODE HERE ### assert (w.shape == (dim, 1)) assert (isinstance(b, float) or isinstance(b, int)) return w, b Forward and Backward propagationNow that our parameters are initialized, we can do the “forward” and “backward” propagation steps for learning the parameters. Exercise: Implement a function propagate() that computes the cost function and its gradient. Hints: Forward Propagation: I get X I compute $A = \sigma(w^T X + b) = (a^{(1)}, a^{(2)}, …, a^{(m-1)}, a^{(m)})$ I calculate the cost function: $J = -\frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$ Here are the two formulas I will be using: \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T\frac{\partial J}{\partial b} = \frac{1}{m} \sum_{i=1}^m (a^{(i)}-y^{(i)})12345678910111213141516171819202122232425262728293031323334353637383940414243def propagate(w, b, X, Y): """ Implement the cost function and its gradient for the propagation explained above Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: cost -- negative log-likelihood cost for logistic regression dw -- gradient of the loss with respect to w, thus same shape as w db -- gradient of the loss with respect to b, thus same shape as b Tips: - Write your code step by step for the propagation. np.log(), np.dot() """ m = X.shape[1] # FORWARD PROPAGATION (FROM X TO COST) ### START CODE HERE ### (≈ 2 lines of code) A = sigmoid(np.dot(w.T, X) + b) # compute activation cost = -(1 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A), axis=1) # compute cost ### END CODE HERE ### # BACKWARD PROPAGATION (TO FIND GRAD) ### START CODE HERE ### (≈ 2 lines of code) dw = (1 / m) * np.dot(X, (A - Y).T) db = (1 / m) * np.sum(A - Y) ### END CODE HERE ### assert (dw.shape == w.shape) assert (db.dtype == float) cost = np.squeeze(cost) assert (cost.shape == ()) grads = &#123;"dw": dw, "db": db&#125; return grads, cost Optimization I have initialized our parameters. We are also able to compute a cost function and its gradient. Now, I want to update the parameters using gradient descent. Exercise: Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\theta$, the update rule is $ \theta = \theta - \alpha \text{ } d\theta$, where $\alpha$ is the learning rate. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False): """ This function optimizes w and b by running a gradient descent algorithm Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of shape (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- True to print the loss every 100 steps Returns: params -- dictionary containing the weights w and bias b grads -- dictionary containing the gradients of the weights and bias with respect to the cost function costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve. Tips: You basically need to write down two steps and iterate through them: 1) Calculate the cost and the gradient for the current parameters. Use propagate(). 2) Update the parameters using gradient descent rule for w and b. """ costs = [] for i in range(num_iterations): # Cost and gradient calculation (≈ 1-4 lines of code) ### START CODE HERE ### grads, cost = propagate(w, b, X, Y) ### END CODE HERE ### # Retrieve derivatives from grads dw = grads["dw"] db = grads["db"] # update rule (≈ 2 lines of code) ### START CODE HERE ### w = w - learning_rate * dw b = b - learning_rate * db ### END CODE HERE ### # Record the costs if i % 100 == 0: costs.append(cost) # Print the cost every 100 training iterations if print_cost and i % 100 == 0: print("Cost after iteration %i: %f" % (i, cost)) params = &#123;"w": w, "b": b&#125; grads = &#123;"dw": dw, "db": db&#125; return params, grads, costs predictExercise: The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function. There are two steps to computing predictions: Calculate $\hat{Y} = A = \sigma(w^T X + b)$ Convert the entries of a into 0 (if activation &lt;= 0.5) or 1 (if activation &gt; 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this). 12345678910111213141516171819202122232425262728293031323334353637def predict(w, b, X): ''' Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b) Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Returns: Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X ''' m = X.shape[1] Y_prediction = np.zeros((1, m)) w = w.reshape(X.shape[0], 1) # Compute vector "A" predicting the probabilities of a cat being present in the picture ### START CODE HERE ### (≈ 1 line of code) A = sigmoid(np.dot(w.T, X) + b) ### END CODE HERE ### for i in range(A.shape[1]): # Convert probabilities A[0,i] to actual predictions p[0,i] ### START CODE HERE ### (≈ 4 lines of code) if A[0][i] &lt; 0.5: Y_prediction[0][i] = 0 else: Y_prediction[0][i] = 1 ### END CODE HERE ### assert (Y_prediction.shape == (1, m)) return Y_prediction What to rememberWe’ve implemented several functions that: Initialize (w,b) Optimize the loss iteratively to learn parameters (w,b): computing the cost and its gradient updating the parameters using gradient descent Use the learned (w,b) to predict the labels for a given set of examples Merge all functions into a modelYou will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order. Exercise: Implement the model function. Use the following notation: - Y_prediction_test for your predictions on the test set Y_prediction_train for your predictions on the train set w, costs, grads for the outputs of optimize() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False): """ Builds the logistic regression model by calling the function you've implemented previously Arguments: X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train) Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train) X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test) Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test) num_iterations -- hyperparameter representing the number of iterations to optimize the parameters learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize() print_cost -- Set to true to print the cost every 100 iterations Returns: d -- dictionary containing information about the model. """ ### START CODE HERE ### # initialize parameters with zeros (≈ 1 line of code) w, b = initialize_with_zeros(X_train.shape[0]) # Gradient descent (≈ 1 line of code) params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations=num_iterations, learning_rate=learning_rate, print_cost=print_cost) # Retrieve parameters w and b from dictionary "parameters" w = params["w"] b = params["b"] # Predict test/train set examples (≈ 2 lines of code) Y_prediction_test = predict(w, b, X_test) Y_prediction_train = predict(w, b, X_train) ### END CODE HERE ### # Print train/test Errors print("train accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100)) print("test accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)) d = &#123;"costs": costs, "Y_prediction_test": Y_prediction_test, "Y_prediction_train": Y_prediction_train, "w": w, "b": b, "learning_rate": learning_rate, "num_iterations": num_iterations&#125; return d train1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.005, print_cost=True) test our image123456789101112## START CODE HERE ## (PUT YOUR IMAGE NAME) my_image = "my_image.jpg" # change this to the name of your image file ## END CODE HERE ### We preprocess the image to fit your algorithm.fname = "images/" + my_imageimage = np.array(ndimage.imread(fname, flatten=False))my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).Tmy_predicted_image = predict(d["w"], d["b"], my_image)plt.imshow(image)print("y = " + str(np.squeeze(my_predicted_image)) + ", your algorithm predicts a \"" + classes[int(np.squeeze(my_predicted_image)),].decode("utf-8") + "\" picture.") linksgithub]]></content>
  </entry>
  <entry>
    <title><![CDATA[Planar data classification with one hidden layer]]></title>
    <url>%2F2018%2F10%2F06%2FPlanar%20data%20classification%20with%20one%20hidden%20layer%2F</url>
    <content type="text"><![CDATA[From Logistic Regression with a Neural Network mindset, we achieved the Neural Network which use Logistic Regression to resolve the linear classification . In this blog ,we will achieve a Neural Network with one hidden layer to resolve the no-linear classification as : Which I will Code Implement a 2-class classification neural network with a single hidden layer Use units with a non-linear activation function, such as tanh Compute the cross entropy loss Implement forward and backward propagation Defining the neural network structurelayer_size()This function will define three variables: n_x: the size of the input layer n_h: the size of the hidden layer (set this to 4) n_y: the size of the output layer 123456789101112131415161718def layer_sizes(X, Y): """ Arguments: X -- input dataset of shape (input size, number of examples) Y -- labels of shape (output size, number of examples) Returns: n_x -- the size of the input layer n_h -- the size of the hidden layer n_y -- the size of the output layer """ n_x = X.shape[0] # size of input layer n_h = 4 n_y = Y.shape[0] # size of output layer return (n_x, n_h, n_y) Initialize the model’s parametersinitialize_parameters() To make sure our parameters’ sizes are right. Refer to the neural network figure above if needed. I will initialize the weights matrices with random values. Use: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b). I will initialize the bias vectors as zeros. Use: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros. 12345678910111213141516171819202122232425262728293031323334def initialize_parameters(n_x, n_h, n_y): """ Argument: n_x -- size of the input layer n_h -- size of the hidden layer n_y -- size of the output layer Returns: params -- python dictionary containing your parameters: W1 -- weight matrix of shape (n_h, n_x) b1 -- bias vector of shape (n_h, 1) W2 -- weight matrix of shape (n_y, n_h) b2 -- bias vector of shape (n_y, 1) """ np.random.seed(2) # we set up a seed so that our output matches ours although the initialization is random. W1 = np.random.randn(n_h,n_x) * 0.01 b1 = np.zeros((n_h,1)) W2 = np.random.randn(n_y,n_h) * 0.01 b2 = np.zeros((n_y,1)) assert (W1.shape == (n_h, n_x)) assert (b1.shape == (n_h, 1)) assert (W2.shape == (n_y, n_h)) assert (b2.shape == (n_y, 1)) parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters The Loopforward_propagation()Step Retrieve each parameter from the dictionary “parameters” (which is the output of initialize_parameters()) by using parameters[&quot;..&quot;]. Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all our predictions on all the examples in the training set). Values needed in the backpropagation are stored in “cache“. The cache will be given as an input to the backpropagation function. Code123456789101112131415161718192021222324252627282930313233343536def forward_propagation(X, parameters): """ Argument: X -- input data of size (n_x, m) parameters -- python dictionary containing your parameters (output of initialization function) Returns: A2 -- The sigmoid output of the second activation cache -- a dictionary containing "Z1", "A1", "Z2" and "A2" """ # Retrieve each parameter from the dictionary "parameters" W1 = parameters['W1'] b1 = parameters['b1'] W2 = parameters['W2'] b2 = parameters['b2'] # Implement Forward Propagation to calculate A2 (probabilities) Z1 = np.dot(W1,X)+b1 A1 = np.tanh(Z1) Z2 = np.dot(W2,A1)+b2 A2 = sigmoid(Z2) assert(A2.shape == (1, X.shape[1])) cache = &#123;"Z1": Z1, "A1": A1, "Z2": Z2, "A2": A2&#125; return A2, cache compute_cost()Now that I have computed A^{[2]} (in the Python variable “A2“), which contains $a^{2}$ for every example, I can compute the cost function as follows: J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large{(} \small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large{)} \small\tag{1}12345678910111213141516171819202122232425def compute_cost(A2, Y, parameters): """ Computes the cross-entropy cost given in equation (1) Arguments: A2 -- The sigmoid output of the second activation, of shape (1, number of examples) Y -- "true" labels vector of shape (1, number of examples) parameters -- python dictionary containing your parameters W1, b1, W2 and b2 Returns: cost -- cross-entropy cost given equation (13) """ m = Y.shape[1] # number of example # Compute the cross-entropy cost logprobs = np.multiply(Y,np.log(A2))+np.multiply((1-Y),np.log(1-A2)) cost = -np.sum(logprobs)/m cost = np.squeeze(cost) # makes sure cost is the dimension we expect. # E.g., turns [[17]] into 17 assert(isinstance(cost, float)) return cost backward propagation()Backpropagation is usually the hardest (most mathematical) part in deep learning. Here is the slide from the lecture on backpropagation. I’ll want to use the six equations on the right of this slide, since I are building a vectorized implementation. $\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } = \frac{1}{m} (a^{2} - y^{(i)})$ $\frac{\partial \mathcal{J} }{ \partial W2 } = \frac{\partial \mathcal{J} }{ \partial z{2}^{(i)} } a^{[1] (i) T}$ $\frac{\partial \mathcal{J} }{ \partial b2 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z{2}^{(i)}}}$ $\frac{\partial \mathcal{J} }{ \partial z{1}^{(i)} } = W_2^T \frac{\partial \mathcal{J} }{ \partial z{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $ $\frac{\partial \mathcal{J} }{ \partial W1 } = \frac{\partial \mathcal{J} }{ \partial z{1}^{(i)} } X^T $ $\frac{\partial \mathcal{J} i }{ \partial b_1 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z{1}^{(i)}}}$ Note that $*$ denotes elementwise multiplication. The notation I will use is common in deep learning coding: dW1 = $\frac{\partial \mathcal{J} }{ \partial W_1 }$ db1 = $\frac{\partial \mathcal{J} }{ \partial b_1 }$ dW2 = $\frac{\partial \mathcal{J} }{ \partial W_2 }$ db2 = $\frac{\partial \mathcal{J} }{ \partial b_2 }$ Tips: To compute dZ1 we need to compute $g^{[1]’}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]’}(z) = 1-a^2$. So we can compute$g^{[1]’}(Z^{[1]})$ using (1 - np.power(A1, 2)). 1234567891011121314151617181920212223242526272829303132333435363738394041424344def backward_propagation(parameters, cache, X, Y): """ Implement the backward propagation using the instructions above. Arguments: parameters -- python dictionary containing our parameters cache -- a dictionary containing "Z1", "A1", "Z2" and "A2". X -- input data of shape (2, number of examples) Y -- "true" labels vector of shape (1, number of examples) Returns: grads -- python dictionary containing your gradients with respect to different parameters """ m = X.shape[1] # First, retrieve W1 and W2 from the dictionary "parameters". ### START CODE HERE ### (≈ 2 lines of code) W1 = parameters['W1'] W2 = parameters['W2'] ### END CODE HERE ### # Retrieve also A1 and A2 from dictionary "cache". ### START CODE HERE ### (≈ 2 lines of code) A1 = cache['A1'] A2 = cache['A2'] ### END CODE HERE ### # Backward propagation: calculate dW1, db1, dW2, db2. ### START CODE HERE ### (≈ 6 lines of code, corresponding to 6 equations on slide above) dZ2 = A2-Y dW2 = np.dot(dZ2,A1.T)/m db2 = np.sum(dZ2,axis=1,keepdims=True)/m dZ1 = np.dot(W2.T,dZ2)*(1-np.power(A1,2)) dW1 = np.dot(dZ1,X.T)/m db1 = np.sum(dZ1,axis=1,keepdims=True)/m ### END CODE HERE ### grads = &#123;"dW1": dW1, "db1": db1, "dW2": dW2, "db2": db2&#125; return grads General gradient descent rule: $ \theta = \theta - \alpha \frac{\partial J }{ \partial \theta }$ where $\alpha$ is the learning rate and $\theta$ represents a parameter. Illustration: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley. if the learning rate is fit, the training gradient will descent as the left Gif, While if we use a too bad learning rate ,the gradient will descent like the right Gif. 123456789101112131415161718192021222324252627282930313233343536373839404142def update_parameters(parameters, grads, learning_rate = 1.2): """ Updates parameters using the gradient descent update rule given above Arguments: parameters -- python dictionary containing your parameters grads -- python dictionary containing your gradients Returns: parameters -- python dictionary containing your updated parameters """ # Retrieve each parameter from the dictionary "parameters" W1 = parameters['W1'] b1 =parameters['b1'] W2 = parameters['W2'] b2 =parameters['b2'] # Retrieve each gradient from the dictionary "grads" dW1 = grads["dW1"] db1 = grads['db1'] dW2 = grads['dW2'] db2 = grads['db2'] # Update rule for each parameter W1 = W1-learning_rate*dW1 b1 = b1-learning_rate*db1 W2 = W2-learning_rate*dW2 b2 = b2-learning_rate*db2 parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters Integrate above base function in nn_model()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False): """ Arguments: X -- dataset of shape (2, number of examples) Y -- labels of shape (1, number of examples) n_h -- size of the hidden layer num_iterations -- Number of iterations in gradient descent loop print_cost -- if True, print the cost every 1000 iterations Returns: parameters -- parameters learnt by the model. They can then be used to predict. """ np.random.seed(3) n_x = layer_sizes(X, Y)[0] n_y = layer_sizes(X, Y)[2] # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: "n_x, n_h, n_y". Outputs = "W1, b1, W2, b2, parameters". parameters = initialize_parameters(X.shape[0],n_h,Y.shape[0]) W1 = parameters['W1'] b1 = parameters['b1'] W2 = parameters['W2'] b2 = parameters['b2'] # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation. Inputs: "X, parameters". Outputs: "A2, cache". A2, cache = forward_propagation(X,parameters) # Cost function. Inputs: "A2, Y, parameters". Outputs: "cost". cost = compute_cost(A2,Y,parameters) # Backpropagation. Inputs: "parameters, cache, X, Y". Outputs: "grads". grads = backward_propagation(parameters,cache,X,Y) # Gradient descent parameter update. Inputs: "parameters, grads". Outputs: "parameters". parameters = update_parameters(parameters,grads) # Print the cost every 1000 iterations if print_cost and i % 1000 == 0: print ("Cost after iteration %i: %f" %(i, cost)) return parameters PredictionsNow I will use our model to predict by building predict().Use forward propagation to predict results. Reminder: predictions = $y_{prediction} = \mathbb 1 \textfalse = \begin{cases}​ 1 &amp; \text{if}\ activation &gt; 0.5 \​ 0 &amp; \text{otherwise}​ \end{cases}$ As an example, if we would like to set the entries of a matrix X to 0 and 1 based on a threshold we would do: 12345678910111213141516171819202122```pythondef predict(parameters, X): &quot;&quot;&quot; Using the learned parameters, predicts a class for each example in X Arguments: parameters -- python dictionary containing your parameters X -- input data of size (n_x, m) Returns predictions -- vector of predictions of our model (red: 0 / blue: 1) &quot;&quot;&quot; # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold. A2, cache = forward_propagation(X,parameters) predictions = (A2&gt;0.5) return predictions It is time to run the model and see how it performs on a planar dataset: 12345parameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)# Plot the decision boundaryplot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)plt.title("Decision Boundary for hidden layer size " + str(4)) Output; Cost after iteration 9000 0.218607 Print accuracy12predictions = predict(parameters, X)print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%') Output: Accuracy 90% Tuning hidden layer size (optional/ungraded exercise)1234567891011plt.figure(figsize=(16, 32))hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]for i, n_h in enumerate(hidden_layer_sizes): plt.subplot(5, 2, i+1) plt.title('Hidden Layer of size %d' % n_h) parameters = nn_model(X, Y, n_h, num_iterations = 5000) plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y) predictions = predict(parameters, X) accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) print ("Accuracy for &#123;&#125; hidden units: &#123;&#125; %".format(n_h, accuracy)) Output: Interpretation The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data. The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to fits the data well without also incurring noticable overfitting. You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting. linksgithub]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编常用指令]]></title>
    <url>%2F2018%2F10%2F06%2F%E6%B1%87%E7%BC%96%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[通用寄存器及使用IA-32系列有8个32位通用寄存器，名称分别为：EAX,EBX,ECX,EDX,ESP,EBP,ESI,EDI，如图： 简单传送指令 指令 中文名 格式 解释 备注 MOV 传送指令 MOV DEST,SRC DEST&lt;=SRC XCHG 交换指令 XCHG OPER1,OPER2 把操作数oper1的内容与操作数oper2的内容交换 oper1和oper2可以是通用寄存器或存储单元，但不能同时是操作单元，也不能是立即数。 简单加减指令 指令 中文名 格式 解释 备注 ADD 加法指令 ADD DEST,SRC DEST&lt;=DEST+SRC 两数相加 SUB 减法指令 SUB DEST,SRC DEST&lt;=DEST-SRC 两数相减 INC 加1指令 INC DEST DEST&lt;=DEST+1 DEC 减1指令 DEC DEST DEST&lt;=DEST-1 NEG 取补指令 NEG OPRD OPRD=0-OPRD 对操作数取补（相反数） 标志寄存器及其使用状态标志 标志 中文名 解释 CF（carry flag） 进位标志 主要反映算术运算是否产生进位或借位，若产生，则CF=1，否则CF=0 ZF 零标志 反映运算结果是否为0 SF（sign flag） 符号标志 根据运算结果的最高位，若最高位为1则SF为1，否则为0，反映了有符号数运算结果的正负（0正1负） OF（overflow flag） 溢出标志 反映有符号数运算结果是否产生溢出，是置1，否置0 PF（parity flag） 奇偶标志 偶数置1奇数置0 AF 辅助进位标志 状态标志操作指令 指令 中文名 格式 解释 CLC（clear carry flag） 清进位标志指令 CLC 使进位标志CF为0 STC(set carry flag) 置进位标志指令 STC 使进位标志CF为1 CMC（complement carry flag） 进位标志取反指令 CMC 使进位标志CF取反 LAHF（load status flags into AH register） 获取状态标志操作指令 LAHF 把位于标志寄存器低端的5个状态标志位（p26图2.3）信息同时送到寄存器AH的对应位SAHF（store AH into Flags） | 设置状态标志操作指令 | SAHF |对标志寄存器中的低8位产生影响，使得状态标志位SF、ZF、AF、PF和CF分别成为来自寄存器AH中对应位的值，但保留位（位1、位3、位5）不受影响 带进位加减指令 指令 中文名 格式 解释 备注 ADC（add with carry） 带进位加法指令 ADC DEST,SRC DEST&lt;=DEST+SRC+CF 与add指令不同之处是要再加上进位标志cf的值SBB(substraction with borrow) | 带借位减法 | SBB DEST,SRC |DEST&lt;=DEST-(SRC+CF) | 与sub指令不同之处是要再减上借位标志cf的值 取有效地址指令 指令 中文名 格式 解释 备注 LEA（load effective address） 取有效地址指令 LEA REC,OPRD 把操作数oprd的有效地址传送到操作数rec，源操作数oprd必须是一个存储器操作数，目的操作数rec必须是一个16位或32位的通用寄存器 与mov指令的区别：mov：移动地址中的值lea：将地址进行移动 指令指针寄存器和简单控制转移指令常用条件转移指令location：p45 指令 中文名 格式 解释 备注 CMP 比较指令 CMP DEST,SRC 根据dest-src的差影响各状态标志寄存器 不把dest- src的结果送入destJMP | 无条件段内直接转移指令 | JMP LABEL | 使控制无条件地转移到标号为label的位置 | 无条件转移指令本身不影响标志 堆栈和堆栈操作 指令 中文名 格式 解释 备注 PUSH 进栈指令 PUSH SRC 把源操作数src压入堆栈 源操作数src可以是32位通用寄存器、16位通用寄存器和段寄存器，也可以是双字存储单元或者字符存储单元，还可以是立即数 POP 出栈指令 POP DEST 从栈顶弹出一个双字或字数据到目的操作数 如果目的操作数是双字的，那么就从栈顶弹出一个双字数据，否则，从栈顶弹出一个字数据，出栈至少弹出一个字（16位） PUSHA 16位通用寄存器全进栈指令 PUSHA 将所有8个16位通用寄存器的内容压入堆栈 压入顺序是AX CX DX BX SP BP SI DI，然后对战指针寄存器SP的值减16，所以SP进栈的内容是PUSHA指令执行之前的值 POPA 16位通用寄存器全出栈指令 POPA 以PUSHA相反的顺序从堆栈中弹出内容，从而恢复PUSHA之前的寄存器状态 SP的值不是由堆栈弹出的，而是通过增加16来恢复 PUSHAD 32位通用寄存器全进栈指令 PUSHAD 将所有8个32位通用寄存器的内容压入堆栈 压入顺序是EAX ECX EDX EBX ESP EBP ESI EDI，然后对战指针寄存器SP的值减32，所以SP进栈的内容是PUSHAD指令执行之前的值 POPAD 32位通用寄存器全出栈指令 POPAD 以PUSHAD相反的顺序从堆栈中弹出内容，从而恢复PUSHAD之前的寄存器状态 过程调用和返回指令 指令 中文名 格式 解释 备注 CALL 过程调用指令 CALL LABEL 段内直接调用LABEL 与jmp的区别在于call指令会在调用label之前保存返回地址（call 中return之后主程序还可以继续执行，jmp当label执行完毕后不能返回主程序继续执行） RET 段内过程返回指令 RET 使子程序结束，继续执行主程序 算术逻辑运算指令 指令 中文名 MUL 无符号数乘法指令 IMUL 有符号数乘法指令 IMUL DEST，SRC 有符号数乘法指令 IMUL DEST,SRC1,SRC2 有符号数乘法指令 DIV 无符号数除法指令 IDIV OPRD 有符号数除法指令 符号拓展指令 指令 中文名 格式 解释 CBW 字节转化为字指令 CBW 把寄存器AL中的值符号拓展到寄存器AH CWD 字转化为双字指令 CWD 把寄存器AX中的值符号拓展到寄存器DX CDQ 双字转化为四字指令 CDQ 把寄存器EAX中的值符号拓展到EDX CWDE 字转化为双字指令 CWDE 把AX中的值符号拓展到EAX的高16位 拓展传送指令 指令 中文名 格式 解释 备注 MOVSX 符号拓展传送指令 MOVSX DEST,SRC 把源操作数SRC符号拓展后送至目的操作数DEST src可以是通用寄存器或者存储单元，但是dest只能是通用寄存器（零拓展传送指令不会改变源操作数，也不影响标志寄存器的状态） MOVZX MOVZX DEST,SRC 把源操作数SRC零拓展后送至目的操作数DEST 逻辑运算指令 指令 中文名 格式 解释 备注 NOT 否运算指令 NOT OPRD 把操作数OPRD按位取反，然后送回OPRD AND 与运算指令 AND DEST，SRC 把两个操作数进行与运算之后结果送回DEST 同1得1，否则得0 OR 或运算指令 OR DEST，SRC 把两个操作数进行或运算之后结果送回DEST 同0得0，否则得1 XOR 异或运算 XOR DEST，SRC 把两个操作数进行异或运算之后结果送回DEST 相同得0不同得1 TEST 测试指令 TEST DEST，SRC 与AND指令类似，将各位相与，但是结果不送回DEST，仅影响状态位标志，指令执行后，ZF、PF、SF反映运算结果，CF和OF被清零 通常用于检测某些位是否为1，但又不希望改变操作数的值 移位指令一般移位指令 指令 中文名 格式 解释 备注 SAL 算术左移 SAL OPRD，count 把操作数oprd左移count位，右边补0 与shl指令一样通过截取count的低5位，实际的移位数被限于0到31之间。 SAR 算术右移 SAR OPRD，count 把操作数oprd右移count位，同时每右移一位，左边补符号位，移出的最低位进入标志位CF 通过截取count的低5位，实际的移位数被限于0到31之间。 SHR 逻辑右移 SHR OPRD，count 把操作数oprd右移count位，左边补0，移出的最低位进入标志位CF 循环移位指令 指令 中文名 格式 解释 备注 ROL 左循环移位指令 ROL OPRD,count 通过截取count的低5位，实际的移位数被限于0到31之间。 ROR 右循环移位指令 ROR OPRD,count 通过截取count的低5位，实际的移位数被限于0到31之间。 RCL 带进位左循环移位 RCL OPRD,count 相当于CF在最高位参与循环移位 大循环左移，通过截取count的低5位，实际的移位数被限于0到31之间 RCR 带进位右循环移位 RCR OPRD,count 相当于CF在最高位参与循环移位 大循环右移，通过截取count的低5位，实际的移位数被限于0到31之间。 循环指令 指令 中文名 格式 解释 备注 LOOP 计数循环指令 LOOP LABEL 使ECX的值减1，当ECX的值不为0的时候跳转至LABEL，否则执行LOOP之后的语句 LOOPE 等于循环指令 LOOPE LABEL 使ECX的值减1，如果结果不等于0并且零标志ZF等于1（表示相等），那么就转移到LABEL，否则执行LOOPE之后的语句 LOOPZ 零循环指令 LOOPZ LABEL 使ECX的值减1，如果结果不等于0并且零标志ZF等于1（表示相等），那么就转移到LABEL，否则执行LOOPZ之后的语句 LOOPNE 不等于循环指令 LOOPE LABEL 使ECX的值减1，如果结果不等于0并且零标志ZF等于0（表示不相等），那么就转移到LABEL，否则执行LOOPNE之后的语句 LOOPNZ 非零循环指令 LOOPNZ LABEL 使ECX的值减1，如果结果不等于0并且零标志ZF等于0（表示不相等），那么9就转移到LABEL，否则执行LOOPNZ之后的语句 JECXZ 计数转移指令 JECXZ LABEL 当寄存器ECX的值为0时转移到LABEL，否则顺序执行 通常在循环开始之前使用该指令，所以循环次数为0时，就可以跳过循环体]]></content>
      <categories>
        <category>汇编</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iTerm2常用快捷键]]></title>
    <url>%2F2018%2F09%2F26%2FiTerm2%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[基本功能 control + a: 到行首 control + e: 行末 control + f/b: 前进后退，相当于左右方向键，但是显然比移开手按方向键更快 control + p: 上一条命令，相当于方向键上 control + r: 搜索命令历史，这个大家都应该很熟悉了 control + d: 删除当前字符 control + h: 删除之前的字符 control + w: 删除光标前的单词 control + k: 删除到文本末尾 control + t: 交换光标处文本 control + u: 删除一行 ⌘ + —/+/0: 调整字体大小 ⌘ + r:清屏，其实是滚到新的一屏，并没有清空。ctrl + l 也可以做到 command + t： 新建标签 command + w： 关闭标签 command + 数字 command + 左右方向键： 切换标签 command + enter： 切换全屏 command + d 垂直分屏 command + shift + d 水平分屏 command + option + 方向键 command + [ 或 command + ]： 切换屏幕 command + shift + h 查看剪贴板历史 ctrl + r 搜索命令历史 高效功能 粘贴历史：使用Command + Shift + h 可以呼出粘贴历史，支持模糊检索。 全屏模式：command+enter command+; 根据上下文呼出自动完成窗口，上下键选择 即时回放：Command + Opt + b 打开即时回放，按Esc退出。即时回放可以记录终端输出的状态，看看你以前都干了啥。 历史信息查找和粘贴：command + f，呼出查找功能，找到后 tab 键可以选中找到的文本，通过option + 回车粘贴 Expose Tabs：option + command + e]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>iTerm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在云服务器上部署gitblit]]></title>
    <url>%2F2018%2F09%2F24%2F%E5%A6%82%E4%BD%95%E5%9C%A8%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2gitblit%2F</url>
    <content type="text"><![CDATA[环境说明本机：macOs 10.13.6 服务器端：Ucloud CentOS 6.5 64位 服务器端部署首先保证ssh连接上服务器，然后： 安装Java环境首先查看自带JDK是否安装： ​ yum list installed | grep java 如果没有任何输出，就说明没有安装好jdk，输入以下命令进行安装： ​ yum -y list java* # 查看yum库中java安装包 yum -y install java-1.8.0-openjdk* # 安装java-1.8.0相关java库 执行完毕后即成功安装jdk 下载GitBlit依次执行以下命令： ​ mkdir -p /opt/gitblit cd /opt/gitblit wget http://dl.bintray.com/gitblit/releases/gitblit-1.8.0.tar.gz 如果下载过程中出现提示 ​ -bash: wget: command not foundls 说明没有安装wget程序，用yum库装一个即可 ​ yum install wget 解压GitBlit在/opt/gitblit下执行： ​ sudo tar -zxvf gitblit-1.8.0.tar.gz 修改配置文件修改data/defaults.properties​ sudo vim data/defaults.properties 主要修改： ​ server.httpPort = xxxx server.httpsPort = localhost 这里的端口有两种设置方法： 根据自己的喜好指定，然后在云服务器的打开防火墙，登录你云服务器的控制台，进入安全组配置xxxx端口（http访问） 一般你建好云服务器之后，它会给你自动分配一个外网防火墙，外网防火墙里面默认开放了几个可直接访问的端口，比如我的： 这个时候你可以把xxxx设置为上面的端口，比如22或者3389，但是这么做有个风险，就是有可能这几个端口被其他service占用了，所以最好在设置之前先查看一下对应端口是否被占用： lsof -i :xxxx 如果什么都没有输出，就说明该端口未被占用（如果已经被占用可以杀死该端口对应的service，具体方法自行google，不建议这样）。 修改完成后保存退出。 修改service-centos.sh 在/opt/gitblib下： sudo vim service-centos.sh 主要修改： GITBLIT_HTTP_PORT = xxxx 这里的xxxx是你刚才在defaults.properties设置的httpPort的值。 启动GitBlit这里提供有两种方法启动GitBlit： 1: ​ java -jar gitblit.jar —baseFolder data 启动成功后应有类似输出： 这种方法启动的缺点是服务器重启后就死了，需要重复手动启动。 2: 直接在/opt/gitblit下执行： ​ ./service-centos.sh start 成功后： 还有其他启动方法，这里不再一一赘述，需要的自行google。 这里只介绍http访问的设置方法，https的类似，不再赘述。 客户端这里的客户端其实浏览器，确保你服务器端启动了gitblit，然后在你的chrome地址栏输入： http://ip :port,这里的ip是你服务器的公网ip，port是你刚才设置的http的ip，如果你设置的是https，则进行对应变化即可。 成功的话应该可以看到： 在右上角输入username和password，默认是admin和admin，然后就登陆成功了： 添加用户看图： 然后点击： 然后进入： 然后就可以自由发挥了。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>gitblit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activity 与 Fragment 通信方式总结]]></title>
    <url>%2F2018%2F09%2F21%2FActivity%20%E4%B8%8E%20Fragment%20%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[概述通常，Fragment 与 Activity 通信存在三种情形： Activity 操作内嵌的 Fragment Fragment 操作宿主 Activity Fragment 操作同属 Activity中的其他 Fragment 在Android中我们可以通过以下几种方式优雅地实现Activity和fragment之间的通信： Handler 广播 EventBus 接口回调 Bundle和setArguments(bundle) Handler​123456789101112131415161718192021222324public class MainActivity extends FragmentActivity&#123; //声明一个Handler public Handler mHandler = new Handler()&#123; @Override public void handleMessage(Message msg) &#123; super.handleMessage(msg); //相应的逻辑处理代码 &#125; &#125; &#125; public class MainFragment extends Fragment&#123; //保存Activity传递的handler private Handler mHandler; @Override public void onAttach(Activity activity) &#123; super.onAttach(activity); if(activity instance MainActivity)&#123; mHandler = ((MainActivity)activity).mHandler; &#125; &#125; &#125; 这种方式的缺点： Fragment对具体的Activity存在耦合，不利于Fragment复用 不利于维护，若想删除相应的Activity，Fragment也得改动 没法获取Activity的返回数据 所以一般不建议使用这种方法。 广播在 Activity 中注册广播接收器，在 Fragment中发送广播： 1234567891011121314151617181920private BroadcastReceiver mBroadcastReceiver = new BroadcastReceiver() &#123; @Override public void onReceive(Context context, Intent intent) &#123; String action = intent.getAction(); if (action.equals(ACTION_NAME)) &#123; String msg = intent.getStringExtra("msg"); Toast.makeText(MainActivity.this, msg, Toast.LENGTH_SHORT).show(); &#125; &#125;&#125;;public void registerBoradcastReceiver() &#123; IntentFilter myIntentFilter = new IntentFilter(); myIntentFilter.addAction(ACTION_NAME); registerReceiver(mBroadcastReceiver, myIntentFilter);&#125;@Overrideprotected void onDestroy() &#123; super.onDestroy(); unregisterReceiver(mBroadcastReceiver);&#125; EventBus MainActivity //注册订阅者 1234567EventBus.getDefault().register(this);//定义接收信息的方法@Subscribe public void onEventMainThread(UserEvent event) &#123; btn.setText(event.getUserName()); service_tv.setText(event.getUserName()); &#125; Fragment发送信息 1234 UserEvent event=new UserEvent(); EventBus.getDefault().post(event); 接口回调 在 Fragment 中定义一个接口 调用接口中的抽象方法 在 Activity 中实现接口，并具体实现接口中的方法，完成通信。 Fragment​12345678910111213141516171819202122232425262728293031public class MainFragment extends Fragment&#123; public FragmentListener mListener; //MainFragment开放的接口 public static interface FragmentListener&#123; //跳到h5页面 void toH5Page(); //展示消息 void showMsg(String str); &#125; @Override public void onAttach(Activity activity) &#123; super.onAttach(activity); //对传递进来的Activity进行接口转换 if(activity instance FragmentListener)&#123; mListener = ((FragmentListener)activity); &#125; &#125; ...其他处理代码省略 mButton.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; msgListener.showMsg("Hello 传递数据给Activity展示"); &#125; &#125;);&#125; Activity​123456789101112// MainActivity 实现 MainFragment开放的接口 public class MainActivity extends FragmentActivity implements FragmentListener&#123; @override public void toH5Page()&#123;... &#125; @Override public void showMsg(String str) &#123; Toast.makeText(MainActivity.this, str, Toast.LENGTH_SHORT).show(); &#125; ...其他处理代码省略 &#125; ​ Bundle和setArguments(bundle)参见 Android如何优雅地向Fragment传递参数 Fragment &amp;&amp; Fragment 数据交互Fragment和Fragment间数据交互，应该也是会经常用到的。我们可以使用宿主Activity做传递媒介。原理其实也是通过使用onActivityResult回调，完成Fragment&amp;&amp; Fragment的数据交互，这其中有两个比较重要的方法：Fragment.setTargetFragment、getTargetFragment()。 在 FirstFragment 中，通过setTargetFragment来连接需要交互的Fragment： ​1secondFragment.setTargetFragment(FirstFragment.this, REQUEST_CODE); ​ 接着实现onActivityResult,处理传递过来的数据： ​12345678910@Override public void onActivityResult(int requestCode, int resultCode, Intent data) &#123; super.onActivityResult(requestCode, resultCode, data); if(resultCode != Activity.RESULT_OK)&#123; return; &#125;else&#123; Integer str = data.getIntExtra("key",-1); //处理数据... &#125; &#125; 在 SecondFragment 中调用sendResult（）方法，回传数据给 FirstFragment: ​123456789private void sendResult(int resultOk) &#123; if(getTargetFragment() == null)&#123; return; &#125;else&#123; Intent intent = new Intent(); intent.putExtra("key", 520); getTargetFragment().onActivityResult(FirstFragment.REQUEST_CODE,resultOk,intent); &#125; &#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Fragment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android使edittext弹出的软键盘位于输入框下面而不是覆盖输入框]]></title>
    <url>%2F2018%2F09%2F21%2FAndroid%E4%BD%BFedittext%E5%BC%B9%E5%87%BA%E7%9A%84%E8%BD%AF%E9%94%AE%E7%9B%98%E4%BD%8D%E4%BA%8E%E8%BE%93%E5%85%A5%E6%A1%86%E4%B8%8B%E9%9D%A2%E8%80%8C%E4%B8%8D%E6%98%AF%E8%A6%86%E7%9B%96%E8%BE%93%E5%85%A5%E6%A1%86%2F</url>
    <content type="text"><![CDATA[提供三个方法： 1:在你的activity中的oncreate中setContentView之前写上这个代码 1getWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_ADJUST_PAN)； 2:在项目的AndroidManifest.xml文件中界面对应的里加入: 1android:windowSoftInputMode="stateVisible|adjustResize" //这样会让屏幕整体上移android:windowSoftInputMode="adjustPan" //这样键盘会覆盖屏幕 3:把顶级的layout替换成ScrollView，或者说在顶级的Layout上面再加一层ScrollView的封装。这样就会把软键盘和输入框一起滚动了，软键盘会一直处于底部。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>EditText</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android fragment生命周期解析]]></title>
    <url>%2F2018%2F09%2F21%2FAndroid%20fragment%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Fragment生命周期图 Fragment与Activity生命周期对比图 生命周期分析 当一个fragment被创建的时候，它会经历以下状态： onAttach()onCreate()onCreateView()onActivityCreated() 当这个fragment对用户可见的时候，它会经历以下状态： onStart()onResume() 当这个fragment进入“后台模式”的时候，它会经历以下状态： onPause()onStop() 当这个fragment被销毁了（或者持有它的activity被销毁了），它会经历以下状态： onPause()onStop()onDestroyView()onDestroy()onDetach() 就像activitie一样，在以下的状态中，可以使用Bundle对象保存一个fragment的对象。 onCreate()onCreateView()onActivityCreated() fragment的大部分状态都和activity很相似，但fragment有一些新的状态： onAttached() —— 当fragment被加入到activity时调用（在这个方法中可以获得所在的activity）。onCreateView() ——当activity要得到fragment的layout时，调用此方法，fragment在其中创建自己的layout(界面)。onActivityCreated() —— 当activity的onCreated()方法返回后调用此方法onDestroyView() —— 当fragment中的视图被移除的时候，调用这个方法。onDetach() —— 当fragment和activity分离的时候，调用这个方法。 一旦activity进入resumed状态（也就是running状态），你就可以自由地添加和删除fragment了。因此，只有当activity在resumed状态时，fragment的生命周期才能独立的运转，其它时候是依赖于activity的生命周期变化的。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Fragment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android设置点击物理返回键后应用后台运行而不是退出]]></title>
    <url>%2F2018%2F09%2F21%2FAndroid%E8%AE%BE%E7%BD%AE%E7%82%B9%E5%87%BB%E7%89%A9%E7%90%86%E8%BF%94%E5%9B%9E%E9%94%AE%E5%90%8E%E5%BA%94%E7%94%A8%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E9%80%80%E5%87%BA%2F</url>
    <content type="text"><![CDATA[1234567891011//后台运行而不退出程序@Override public void onBackPressed() &#123;//重写的Activity返回 Intent intent = new Intent(); intent.setAction("android.intent.action.MAIN"); intent.addCategory("android.intent.category.HOME"); startActivity(intent);&#125; ​]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>后台运行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android实现textview文字滚动显示（跑马灯效果）]]></title>
    <url>%2F2018%2F09%2F21%2FAndroid%E5%AE%9E%E7%8E%B0textview%E6%96%87%E5%AD%97%E6%BB%9A%E5%8A%A8%E6%98%BE%E7%A4%BA%EF%BC%88%E8%B7%91%E9%A9%AC%E7%81%AF%E6%95%88%E6%9E%9C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[自定义Textview并对其进行改造,主要目的是让textview获取焦点，这样文字才能滚动起来 123456789101112131415161718public class MyTextView extends android.support.v7.widget.AppCompatTextView &#123; public MarqueeTextView(Context context) &#123; super(context); &#125; public MarqueeTextView(Context context, AttributeSet attrs) &#123; super(context, attrs); &#125; public MarqueeTextView(Context context, AttributeSet attrs, int defStyle) &#123; super(context, attrs, defStyle); &#125; @Override public boolean isFocused() &#123;//必须重写，且返回值是true，表示始终获取焦点 return true; &#125;&#125; xml文件中设置必要属性 12345678910&lt;MyTextView android:layout_width="match_parent" android:layout_height="match_parent" android:ellipsize="marquee" //设置跑马灯效果 android:focusable="true" //需要有焦点才会滚动 android:focusableInTouchMode="true" android:marqueeRepeatLimit="marquee_forever" //设置循环滚动为无限循环 android:scrollHorizontally="true" android:singleLine="true" //单行显示 /&gt; ​]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>TextView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android如何优雅地向Fragment传递参数]]></title>
    <url>%2F2018%2F09%2F05%2FAndroid%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%90%91Fragment%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言很多人提到向Fragment传递参数会下意识想到重写Fragment的构造方法并传入自己的参数。事实上，这种方式时极不科学和极不安全的，因为Android在很多场景下都会出现Fragment的重建情况（比如横竖屏的切换），但是重建的时候系统并不会使用你编写的Fragment的构造方法而是调用Fragment默认的构造方法，这个时候你传的参数将会消失导致各种异常。那么如何更安全地向Fragment传递参数呢，这里建议大家使用Google官方推荐的setArguments方法： 使用 初始化Fragment实例并setArguments 1234DiscoverFragment discoverFragment = new DiscoverFragment();Bundle bundle = new Bundle();bundle.putString("email", email);discoverFragment.setArguments(bundle); 在Fragment中拿到Arguments： 12345678910@Nullable @Override public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) &#123; View view = inflater.inflate(R.layout.fragment_discover, null); Bundle bundle = getArguments(); //这里就拿到了之前传递的参数 email = bundle.getString("email"); return view; &#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Fragment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android FragmentTransaction commit already called解决方案]]></title>
    <url>%2F2018%2F09%2F05%2FAndroid%20FragmentTransaction%20commit%20already%20called%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[原因这种情况一般是因为你在全局范围实例化了一个FragmentTransaction，然后多次使用同一个实例进行fragment跳转 解决方案将： 12345678910111213141516171819202122private FragmentManager fragmentManager;private FragmentTransaction fragmentTransaction; @Overrideprotected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); fragmentManager = getSupportFragmentManager(); fragmentTransaction = fragmentManager.beginTransaction(); .....&#125; @Overridepublic void startfragment(Fragment targetFragment, boolean addToBackStack) &#123; fragmentTransaction.replace(R.id.id_fragment_layout, targetFragment, targetFragment.getClass().getName()); if (addToBackStack) &#123; fragmentTransaction.addToBackStack(null); &#125; else &#123; mainPresenter.initActivityData(); &#125; fragmentTransaction.commitAllowingStateLoss();&#125; 改为： 1234567891011121314 private FragmentManager fragmentManager;private FragmentTransaction fragmentTransaction; @Override public void startfragment(Fragment targetFragment, boolean addToBackStack) &#123; fragmentManager = getSupportFragmentManager(); fragmentTransaction = fragmentManager.beginTransaction(); fragmentTransaction.replace(R.id.id_fragment_layout, targetFragment, targetFragment.getClass().getName()); if (addToBackStack) &#123; fragmentTransaction.addToBackStack(null); &#125; else &#123; mainPresenter.initActivityData(); &#125; fragmentTransaction.commitAllowingStateLoss(); &#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android将数据导出为excel文件的方法]]></title>
    <url>%2F2018%2F09%2F05%2FAndroid%E5%B0%86%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E4%B8%BAexcel%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[需求描述将应用内的数据导出为excel表格。 实现添加依赖包在app的build.gradle里面添加依赖包: 1implementation group: 'net.sourceforge.jexcelapi', name: 'jxl', version: '2.6.12' 编写excel工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155package cn.xiaojii.cashgift.util.io;import jxl.Workbook;import jxl.WorkbookSettings;import jxl.format.Colour;import jxl.write.Label;import jxl.write.WritableCell;import jxl.write.WritableCellFormat;import jxl.write.WritableFont;import jxl.write.WritableSheet;import jxl.write.WritableWorkbook;import jxl.write.WriteException;/** * @author dmrfcoder * @date 2018/8/9 */public class ExcelUtil &#123; private static WritableFont arial14font = null; private static WritableCellFormat arial14format = null; private static WritableFont arial10font = null; private static WritableCellFormat arial10format = null; private static WritableFont arial12font = null; private static WritableCellFormat arial12format = null; private final static String UTF8_ENCODING = "UTF-8"; /** * 单元格的格式设置 字体大小 颜色 对齐方式、背景颜色等... */ private static void format() &#123; try &#123; arial14font = new WritableFont(WritableFont.ARIAL, 14, WritableFont.BOLD); arial14font.setColour(jxl.format.Colour.LIGHT_BLUE); arial14format = new WritableCellFormat(arial14font); arial14format.setAlignment(jxl.format.Alignment.CENTRE); arial14format.setBorder(jxl.format.Border.ALL, jxl.format.BorderLineStyle.THIN); arial14format.setBackground(jxl.format.Colour.VERY_LIGHT_YELLOW); arial10font = new WritableFont(WritableFont.ARIAL, 10, WritableFont.BOLD); arial10format = new WritableCellFormat(arial10font); arial10format.setAlignment(jxl.format.Alignment.CENTRE); arial10format.setBorder(jxl.format.Border.ALL, jxl.format.BorderLineStyle.THIN); arial10format.setBackground(Colour.GRAY_25); arial12font = new WritableFont(WritableFont.ARIAL, 10); arial12format = new WritableCellFormat(arial12font); //对齐格式 arial10format.setAlignment(jxl.format.Alignment.CENTRE); //设置边框 arial12format.setBorder(jxl.format.Border.ALL, jxl.format.BorderLineStyle.THIN); &#125; catch (WriteException e) &#123; e.printStackTrace(); &#125; &#125; /** * 初始化Excel * * @param fileName 导出excel存放的地址（目录） * @param colName excel中包含的列名（可以有多个） */ public static void initExcel(String fileName, String[] colName) &#123; format(); WritableWorkbook workbook = null; try &#123; File file = new File(fileName); if (!file.exists()) &#123; file.createNewFile(); &#125; workbook = Workbook.createWorkbook(file); //设置表格的名字 WritableSheet sheet = workbook.createSheet("账单", 0); //创建标题栏 sheet.addCell((WritableCell) new Label(0, 0, fileName, arial14format)); for (int col = 0; col &lt; colName.length; col++) &#123; sheet.addCell(new Label(col, 0, colName[col], arial10format)); &#125; //设置行高 sheet.setRowView(0, 340); workbook.write(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (workbook != null) &#123; try &#123; workbook.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; @SuppressWarnings("unchecked") public static &lt;T&gt; void writeObjListToExcel(List&lt;T&gt; objList, String fileName, Context c) &#123; if (objList != null &amp;&amp; objList.size() &gt; 0) &#123; WritableWorkbook writebook = null; InputStream in = null; try &#123; WorkbookSettings setEncode = new WorkbookSettings(); setEncode.setEncoding(UTF8_ENCODING); in = new FileInputStream(new File(fileName)); Workbook workbook = Workbook.getWorkbook(in); writebook = Workbook.createWorkbook(new File(fileName), workbook); WritableSheet sheet = writebook.getSheet(0); for (int j = 0; j &lt; objList.size(); j++) &#123; ProjectBean projectBean = (ProjectBean) objList.get(j); List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(projectBean.getName()); list.add(projectBean.getProject()); list.add(projectBean.getMoney()); list.add(projectBean.getYear() + " " + projectBean.getMonth()+" "+projectBean.getDay()); list.add(projectBean.getBeizhu()); for (int i = 0; i &lt; list.size(); i++) &#123; sheet.addCell(new Label(i, j + 1, list.get(i), arial12format)); if (list.get(i).length() &lt;= 4) &#123; //设置列宽 sheet.setColumnView(i, list.get(i).length() + 8); &#125; else &#123; //设置列宽 sheet.setColumnView(i, list.get(i).length() + 5); &#125; &#125; //设置行高 sheet.setRowView(j + 1, 350); &#125; writebook.write(); Toast.makeText(c, "导出Excel成功", Toast.LENGTH_SHORT).show(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (writebook != null) &#123; try &#123; writebook.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 使用​12345678910File file = new File(path); //文件夹是否已经存在 if (!file.exists()) &#123; file.mkdirs(); &#125; String[] title = &#123;"姓名", "项目", "收支", "日期", "备注"&#125;; String fileName = file.toString() + "/" + excelname.xls; ExcelUtil.initExcel(fileName, title); ExcelUtil.writeObjListToExcel(list, fileName, (MainActivity) mainView);]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Excel导出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android使用系统指纹对应用进行解锁加密的方法]]></title>
    <url>%2F2018%2F09%2F05%2FAndroid%E4%BD%BF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%8C%87%E7%BA%B9%E5%AF%B9%E5%BA%94%E7%94%A8%E8%BF%9B%E8%A1%8C%E8%A7%A3%E9%94%81%E5%8A%A0%E5%AF%86%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[之前有给应用加上指纹解锁的需求，在这里记录一下相关方法： 说明Android的指纹支持是在6.0以后才引入的，所以要求api必须大于23. 流程判断当前手机是否支持指纹识别12345if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) &#123; Log.i("info", "手机支持指纹识别"); &#125; else &#123; Log.i("info", "手机不支持指纹识别"); &#125; 调用首先声明并实例化指纹管理类： 1234567private FingerprintManagerCompat fingerprintManagerCompat; //用于取消指纹识别器监听的对象private CancellationSignal cancellationSignal;fingerprintManagerCompat = FingerprintManagerCompat.from(getActivity());cancellationSignal = new CancellationSignal(); fingerprintManagerCompat.authenticate(null, 0, cancellationSignal, new FingerDiscentListener(), null); 编写FingerDiscentListener继承自 FingerprintManagerCompat.AuthenticationCallback： ​12345678910111213141516171819202122232425262728293031323334353637private class FingerDiscentListener extends FingerprintManagerCompat.AuthenticationCallback &#123; @Override public void onAuthenticationError(int errMsgId, CharSequence errString) &#123; super.onAuthenticationError(errMsgId, errString); if (errMsgId == 5) &#123; //取消识别 &#125; else if (errMsgId == 7) &#123; //tvHint.setText("操作过于频繁，请稍后重试"); if (cancellationSignal != null) &#123; cancellationSignal.cancel(); cancellationSignal = null; &#125; &#125; &#125; @Override public void onAuthenticationSucceeded(FingerprintManagerCompat.AuthenticationResult result) &#123; super.onAuthenticationSucceeded(result); //指纹识别成功 cancellationSignal.cancel();//取消指纹的监听 &#125; @Override public void onAuthenticationFailed() &#123; super.onAuthenticationFailed(); //指纹识别失败 &#125; @Override public void onAuthenticationHelp(int helpMsgId, CharSequence helpString) &#123; super.onAuthenticationHelp(helpMsgId, helpString); &#125; &#125; ​ 结合上面的代码，加上你自己的逻辑调用，基本上就可以满足日常使用了。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>指纹加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android如何跳转至目标Activity后按返回键不返回前一个Activity]]></title>
    <url>%2F2018%2F09%2F05%2FAndroid%E5%A6%82%E4%BD%95%E8%B7%B3%E8%BD%AC%E8%87%B3%E7%9B%AE%E6%A0%87Activity%E5%90%8E%E6%8C%89%E8%BF%94%E5%9B%9E%E9%94%AE%E4%B8%8D%E8%BF%94%E5%9B%9E%E5%89%8D%E4%B8%80%E4%B8%AAActivity%2F</url>
    <content type="text"><![CDATA[有时候我们希望从一个activity离开后，按返回键不要再回去（比如点击退出登陆后跳转至登陆界面，这是点击返回键不希望返回到之前的退出登陆界面），那么我们需要把这个activity从栈区中去除。考虑在activityA中调用 activity B，不允许从activity B中返回activity A，只要将原来的跳转代码替换为如下： 1234567Intent intent=new Intent();intent.setFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK|Intent.FLAG_ACTIVITY_NEW_TASK);intent.setClass(A.this,B.class);startActivity(intent); 即可实现该效果。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Activity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android添加listview item左滑事件的方法（仿QQ实现左滑弹出删除menu）]]></title>
    <url>%2F2018%2F09%2F03%2FAndroid%E6%B7%BB%E5%8A%A0listview%20item%E5%B7%A6%E6%BB%91%E4%BA%8B%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E4%BB%BFQQ%E5%AE%9E%E7%8E%B0%E5%B7%A6%E6%BB%91%E5%BC%B9%E5%87%BA%E5%88%A0%E9%99%A4menu%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在使用 listview时经常会遇到左滑弹出删除或者对item进行其他操作的需求，就是下图中红色圈圈的部分： 本文本着避免重造轮子的原则使用这个 开源库 ，具体用法； 添加依赖​ dependencies { compile ‘com.baoyz.swipemenulistview:library:1.3.0’ } 代码使用​12345678910111213141516171819202122SwipeMenuCreator creater = new SwipeMenuCreator() &#123; @Override public void create(SwipeMenu menu) &#123; // create置顶item SwipeMenuItem item1 = new SwipeMenuItem(getActivity()); // set item background item1.setBackground(new ColorDrawable(Color.rgb(0xF9, 0x3F, 0x25))); // set item width item1.setWidth(dp2px(90)); // set item title item1.setTitle("删除"); // set item title fontsize item1.setTitleSize(18); // set item title font color item1.setTitleColor(Color.WHITE); // add to menu menu.addMenuItem(item1); &#125; &#125;;listview.setMenuCreator(creater); 添加点击事件： 1234567891011121314151617181920212223242526listview.setOnMenuItemClickListener(new SwipeMenuListView.OnMenuItemClickListener() &#123; @Override public boolean onMenuItemClick(final int position, SwipeMenu menu, int index) &#123; switch (index) &#123; case 0: new AlertDialog(getActivity()) .setTitle("删除亲友") .setMessage("将彻底删除该亲友的所有条目，确认删除？") .setLeftButton("取消", null) .setRightButton("确定", new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; //删除的逻辑 &#125; &#125;) .show(); break; default: break; &#125; return false; &#125; &#125;);]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>listview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android解决Can't create handler inside thread that has not called Looper.prepare()]]></title>
    <url>%2F2018%2F09%2F03%2FAndroid%E8%A7%A3%E5%86%B3Can't%20create%20handler%20inside%20thread%20that%20has%20not%20called%20Looper.prepare()%2F</url>
    <content type="text"><![CDATA[在Android子线程中使用Toast时会报错： 代码： 1Toast.makeText(this, "", Toast.LENGTH_LONG) .show()； 报错： 1java.lang.RuntimeException: Can't create handler inside thread that has not called Looper.prepare() 解决方案： 方案一：增加Looper.prepare(); 123 Looper.prepare();Toast.makeText(this, "", Toast.LENGTH_LONG) .show()；Looper.loop();// 进入loop中的循环，查看消息队列 方案二：post 给主线程去处理 123456789101112 mainHandler.post(new Runnable() &#123; @Override public void run() &#123; if (toast == null) &#123; toast = Toast.makeText(context, "", Toast.LENGTH_SHORT);&#125;toast.setText(msg);toast.setDuration(Toast.LENGTH_SHORT);toast.show(); &#125;&#125;);]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android okhttp cookie持久化方法]]></title>
    <url>%2F2018%2F09%2F03%2FAndroid%20okhttp%20cookie%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[cookie的作用当app需要保持用户登陆状态等，这个时候我们通常就要进行对cookie的管理来实现。如果你使用的是okhttp网络请求，那么就可以直接对cookie进行持久化管理。 使用okhttp3进行cookie的持久化处理主要原理是使用okhttp3中新增的Cookiejar这个接口，通过这个接口我们可以直接进行cookie的持久化管理，代码如下： 首先实现cookieJar，里面有一个管理cookie的公共接口CookieStore，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import java.net.CookieStore;import java.util.List;import okhttp3.Cookie;import okhttp3.CookieJar;import okhttp3.HttpUrl;/*** @author dmrfcoder* @date 2018/8/28*/public class CookieJarImpl implements CookieJar &#123; public interface CookieStore &#123; /** * 保存url对应所有cookie */ void saveCookie(HttpUrl url, List&lt;Cookie&gt; cookie); /** * 保存url对应所有cookie */ void saveCookie(HttpUrl url, Cookie cookie); /** * 加载url所有的cookie */ List&lt;Cookie&gt; loadCookie(HttpUrl url); /** * 获取当前所有保存的cookie */ List&lt;Cookie&gt; getAllCookie(); /** * 获取当前url对应的所有的cookie */ List&lt;Cookie&gt; getCookie(HttpUrl url); /** * 根据url和cookie移除对应的cookie */ boolean removeCookie(HttpUrl url, Cookie cookie); /** * 根据url移除所有的cookie */ boolean removeCookie(HttpUrl url); /** * 移除所有的cookie */ boolean removeAllCookie(); &#125; private CookieStore cookieStore; public CookieJarImpl(CookieStore cookieStore) &#123; if (cookieStore == null) &#123; throw new IllegalArgumentException("cookieStore can not be null!"); &#125; this.cookieStore = cookieStore; &#125; @Override public synchronized void saveFromResponse(HttpUrl url, List&lt;Cookie&gt; cookies) &#123; cookieStore.saveCookie(url, cookies); &#125; @Override public synchronized List&lt;Cookie&gt; loadForRequest(HttpUrl url) &#123; return cookieStore.loadCookie(url); &#125; public CookieStore getCookieStore() &#123; return cookieStore; &#125;&#125; 实现cookie的序列化： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210import android.content.ContentValues;import android.database.Cursor;import android.util.Log;import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;import java.util.Locale;import okhttp3.Cookie;/*** @author dmrfcoder* @date 2018/8/28*/public class SerializableCookie implements Serializable &#123; private static final long serialVersionUID = 6374381323722046732L; public static final String HOST = "host"; public static final String NAME = "name"; public static final String DOMAIN = "domain"; public static final String COOKIE = "cookie"; public String host; public String name; public String domain; private transient Cookie cookie; private transient Cookie clientCookie; public SerializableCookie(String host, Cookie cookie) &#123; this.cookie = cookie; this.host = host; this.name = cookie.name(); this.domain = cookie.domain(); &#125; public Cookie getCookie() &#123; Cookie bestCookie = cookie; if (clientCookie != null) &#123; bestCookie = clientCookie; &#125; return bestCookie; &#125; private void writeObject(ObjectOutputStream out) throws IOException &#123; out.defaultWriteObject(); out.writeObject(cookie.name()); out.writeObject(cookie.value()); out.writeLong(cookie.expiresAt()); out.writeObject(cookie.domain()); out.writeObject(cookie.path()); out.writeBoolean(cookie.secure()); out.writeBoolean(cookie.httpOnly()); out.writeBoolean(cookie.hostOnly()); out.writeBoolean(cookie.persistent()); &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; in.defaultReadObject(); String name = (String) in.readObject(); String value = (String) in.readObject(); long expiresAt = in.readLong(); String domain = (String) in.readObject(); String path = (String) in.readObject(); boolean secure = in.readBoolean(); boolean httpOnly = in.readBoolean(); boolean hostOnly = in.readBoolean(); boolean persistent = in.readBoolean(); Cookie.Builder builder = new Cookie.Builder(); builder = builder.name(name); builder = builder.value(value); builder = builder.expiresAt(expiresAt); builder = hostOnly ? builder.hostOnlyDomain(domain) : builder.domain(domain); builder = builder.path(path); builder = secure ? builder.secure() : builder; builder = httpOnly ? builder.httpOnly() : builder; clientCookie = builder.build(); &#125; public static SerializableCookie parseCursorToBean(Cursor cursor) &#123; String host = cursor.getString(cursor.getColumnIndex(HOST)); byte[] cookieBytes = cursor.getBlob(cursor.getColumnIndex(COOKIE)); Cookie cookie = bytesToCookie(cookieBytes); return new SerializableCookie(host, cookie); &#125; public static ContentValues getContentValues(SerializableCookie serializableCookie) &#123; ContentValues values = new ContentValues(); values.put(SerializableCookie.HOST, serializableCookie.host); values.put(SerializableCookie.NAME, serializableCookie.name); values.put(SerializableCookie.DOMAIN, serializableCookie.domain); values.put(SerializableCookie.COOKIE, cookieToBytes(serializableCookie.host, serializableCookie.getCookie())); return values; &#125; /** * cookies 序列化成 string * * @param cookie 要序列化 * @return 序列化之后的string */ public static String encodeCookie(String host, Cookie cookie) &#123; if (cookie == null) &#123; return null; &#125; byte[] cookieBytes = cookieToBytes(host, cookie); return byteArrayToHexString(cookieBytes); &#125; public static byte[] cookieToBytes(String host, Cookie cookie) &#123; SerializableCookie serializableCookie = new SerializableCookie(host, cookie); ByteArrayOutputStream os = new ByteArrayOutputStream(); try &#123; ObjectOutputStream outputStream = new ObjectOutputStream(os); outputStream.writeObject(serializableCookie); &#125; catch (IOException e) &#123; Log.e("cookieToBytes: ", e.toString()); return null; &#125; return os.toByteArray(); &#125; /** * 将字符串反序列化成cookies * * @param cookieString cookies string * @return cookie object */ public static Cookie decodeCookie(String cookieString) &#123; byte[] bytes = hexStringToByteArray(cookieString); return bytesToCookie(bytes); &#125; public static Cookie bytesToCookie(byte[] bytes) &#123; ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes); Cookie cookie = null; try &#123; ObjectInputStream objectInputStream = new ObjectInputStream(byteArrayInputStream); cookie = ((SerializableCookie) objectInputStream.readObject()).getCookie(); &#125; catch (Exception e) &#123; Log.e("bytesToCookie: ", e.toString()); &#125; return cookie; &#125; /** * 二进制数组转十六进制字符串 * * @param bytes byte array to be converted * @return string containing hex values */ private static String byteArrayToHexString(byte[] bytes) &#123; StringBuilder sb = new StringBuilder(bytes.length * 2); for (byte element : bytes) &#123; int v = element &amp; 0xff; if (v &lt; 16) &#123; sb.append('0'); &#125; sb.append(Integer.toHexString(v)); &#125; return sb.toString().toUpperCase(Locale.US); &#125; /** * 十六进制字符串转二进制数组 * * @param hexString string of hex-encoded values * @return decoded byte array */ private static byte[] hexStringToByteArray(String hexString) &#123; int len = hexString.length(); byte[] data = new byte[len / 2]; for (int i = 0; i &lt; len; i += 2) &#123; data[i / 2] = (byte) ((Character.digit(hexString.charAt(i), 16) &lt;&lt; 4) + Character.digit(hexString.charAt(i + 1), 16)); &#125; return data; &#125; /** * host, name, domain 标识一个cookie是否唯一 */ @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; SerializableCookie that = (SerializableCookie) o; if (host != null ? !host.equals(that.host) : that.host != null) &#123; return false; &#125; return (name != null ? name.equals(that.name) : that.name == null) &amp;&amp; (domain != null ? domain.equals(that.domain) : that.domain == null); &#125; @Override public int hashCode() &#123; int result = host != null ? host.hashCode() : 0; result = 31 * result + (name != null ? name.hashCode() : 0); result = 31 * result + (domain != null ? domain.hashCode() : 0); return result; &#125;&#125; 使用 SharedPreferences 持久化存储 cookie： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206package cn.xiaojii.cashgift.bean.net;import android.content.Context;import android.content.SharedPreferences;import android.text.TextUtils;import java.util.ArrayList;import java.util.Collection;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.ConcurrentHashMap;import okhttp3.Cookie;import okhttp3.HttpUrl;/*** @author dmrfcoder* @date 2018/8/28*/public class SPCookieStore implements CookieJarImpl.CookieStore &#123; private static final String COOKIE_PREFS = "sp_cookie"; //cookie使用prefs保存 private static final String COOKIE_NAME_PREFIX = "cookie_"; //cookie持久化的统一前缀 private final Map&lt;String, ConcurrentHashMap&lt;String, Cookie&gt;&gt; cookies; private final SharedPreferences cookiePrefs; public SPCookieStore(Context context) &#123; cookiePrefs = context.getSharedPreferences(COOKIE_PREFS, Context.MODE_PRIVATE); cookies = new HashMap&lt;&gt;(); //将持久化的cookies缓存到内存中,数据结构为 Map&lt;Url.host, Map&lt;CookieToken, Cookie&gt;&gt; Map&lt;String, ?&gt; prefsMap = cookiePrefs.getAll(); for (Map.Entry&lt;String, ?&gt; entry : prefsMap.entrySet()) &#123; if ((entry.getValue()) != null &amp;&amp; !entry.getKey().startsWith(COOKIE_NAME_PREFIX)) &#123; //获取url对应的所有cookie的key,用","分割 String[] cookieNames = TextUtils.split((String) entry.getValue(), ","); for (String name : cookieNames) &#123; //根据对应cookie的Key,从xml中获取cookie的真实值 String encodedCookie = cookiePrefs.getString(COOKIE_NAME_PREFIX + name, null); if (encodedCookie != null) &#123; Cookie decodedCookie = SerializableCookie.decodeCookie(encodedCookie); if (decodedCookie != null) &#123; if (!cookies.containsKey(entry.getKey())) &#123; cookies.put(entry.getKey(), new ConcurrentHashMap&lt;String, Cookie&gt;()); &#125; cookies.get(entry.getKey()).put(name, decodedCookie); &#125; &#125; &#125; &#125; &#125; &#125; private String getCookieToken(Cookie cookie) &#123; return cookie.name() + "@" + cookie.domain(); &#125; /** * 当前cookie是否过期 */ private static boolean isCookieExpired(Cookie cookie) &#123; return cookie.expiresAt() &lt; System.currentTimeMillis(); &#125; /** * 将url的所有Cookie保存在本地 */ @Override public synchronized void saveCookie(HttpUrl url, List&lt;Cookie&gt; urlCookies) &#123; for (Cookie cookie : urlCookies) &#123; saveCookie(url, cookie); &#125; &#125; @Override public synchronized void saveCookie(HttpUrl url, Cookie cookie) &#123; if (!cookies.containsKey(url.host())) &#123; cookies.put(url.host(), new ConcurrentHashMap&lt;String, Cookie&gt;()); &#125; //当前cookie是否过期 if (isCookieExpired(cookie)) &#123; removeCookie(url, cookie); &#125; else &#123; saveCookie(url, cookie, getCookieToken(cookie)); &#125; &#125; /** * 保存cookie，并将cookies持久化到本地 */ private void saveCookie(HttpUrl url, Cookie cookie, String cookieToken) &#123; //内存缓存 cookies.get(url.host()).put(cookieToken, cookie); //文件缓存 SharedPreferences.Editor prefsWriter = cookiePrefs.edit(); prefsWriter.putString(url.host(), TextUtils.join(",", cookies.get(url.host()).keySet())); prefsWriter.putString(COOKIE_NAME_PREFIX + cookieToken, SerializableCookie.encodeCookie(url.host(), cookie)); prefsWriter.apply(); &#125; /** * 根据当前url获取所有需要的cookie,只返回没有过期的cookie */ @Override public synchronized List&lt;Cookie&gt; loadCookie(HttpUrl url) &#123; List&lt;Cookie&gt; ret = new ArrayList&lt;&gt;(); if (!cookies.containsKey(url.host())) &#123; return ret; &#125; Collection&lt;Cookie&gt; urlCookies = cookies.get(url.host()).values(); for (Cookie cookie : urlCookies) &#123; if (isCookieExpired(cookie)) &#123; removeCookie(url, cookie); &#125; else &#123; ret.add(cookie); &#125; &#125; return ret; &#125; /** * 根据url移除当前的cookie */ @Override public synchronized boolean removeCookie(HttpUrl url, Cookie cookie) &#123; if (!cookies.containsKey(url.host())) &#123; return false; &#125; String cookieToken = getCookieToken(cookie); if (!cookies.get(url.host()).containsKey(cookieToken)) &#123; return false; &#125; //内存移除 cookies.get(url.host()).remove(cookieToken); //文件移除 SharedPreferences.Editor prefsWriter = cookiePrefs.edit(); if (cookiePrefs.contains(COOKIE_NAME_PREFIX + cookieToken)) &#123; prefsWriter.remove(COOKIE_NAME_PREFIX + cookieToken); &#125; prefsWriter.putString(url.host(), TextUtils.join(",", cookies.get(url.host()).keySet())); prefsWriter.apply(); return true; &#125; @Override public synchronized boolean removeCookie(HttpUrl url) &#123; if (!cookies.containsKey(url.host())) &#123; return false; &#125; //内存移除 ConcurrentHashMap&lt;String, Cookie&gt; urlCookie = cookies.remove(url.host()); //文件移除 Set&lt;String&gt; cookieTokens = urlCookie.keySet(); SharedPreferences.Editor prefsWriter = cookiePrefs.edit(); for (String cookieToken : cookieTokens) &#123; if (cookiePrefs.contains(COOKIE_NAME_PREFIX + cookieToken)) &#123; prefsWriter.remove(COOKIE_NAME_PREFIX + cookieToken); &#125; &#125; prefsWriter.remove(url.host()); prefsWriter.apply(); return true; &#125; @Override public synchronized boolean removeAllCookie() &#123; //内存移除 cookies.clear(); //文件移除 SharedPreferences.Editor prefsWriter = cookiePrefs.edit(); prefsWriter.clear(); prefsWriter.apply(); return true; &#125; /** * 获取所有的cookie */ @Override public synchronized List&lt;Cookie&gt; getAllCookie() &#123; List&lt;Cookie&gt; ret = new ArrayList&lt;&gt;(); for (String key : cookies.keySet()) &#123; ret.addAll(cookies.get(key).values()); &#125; return ret; &#125; @Override public synchronized List&lt;Cookie&gt; getCookie(HttpUrl url) &#123; List&lt;Cookie&gt; ret = new ArrayList&lt;&gt;(); Map&lt;String, Cookie&gt; mapCookie = cookies.get(url.host()); if (mapCookie != null) &#123; ret.addAll(mapCookie.values()); &#125; return ret; &#125;&#125; 进行取出cookie和删除cookie等公共类的封装： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*** @author dmrfcoder* @date 2018/8/28*/import android.util.Log;import java.util.List;import cn.xiaojii.cashgift.bean.net.CookieJarImpl;import cn.xiaojii.cashgift.bean.net.OkManager;import okhttp3.Cookie;import okhttp3.HttpUrl;/*** cookie管理工具类* @author dmrfcoder*/public class CookieUtil &#123; /** * 获取指定URL对应的cookie * * @param baseUrl * @param url * @return */ public static List&lt;Cookie&gt; cookies(String baseUrl, String url) &#123; //一般手动取出cookie的目的只是交给 webview 等等，非必要情况不要自己操作 CookieJarImpl.CookieStore cookieStore = OkManager.getInstance().getCookieJar().getCookieStore(); HttpUrl httpUrl = HttpUrl.parse(baseUrl + url); List&lt;Cookie&gt; cookies = cookieStore.getCookie(httpUrl); Log.e("cookies: ", httpUrl.host() + "对应的cookie如下：" + cookies.toString()); return cookies; &#125; /** * 获取所有的cookie * * @return */ public static List&lt;Cookie&gt; cookieList() &#123; CookieJarImpl.CookieStore cookieStore = OkManager.getInstance().getCookieJar().getCookieStore(); List&lt;Cookie&gt; allCookie = cookieStore.getAllCookie(); Log.e("所有cookie如下: ", allCookie.toString()); return allCookie; &#125; public static String getCookie() &#123; CookieJarImpl.CookieStore cookieStore = OkManager.getInstance().getCookieJar().getCookieStore(); List&lt;Cookie&gt; allCookie = cookieStore.getAllCookie(); for (int i = 0; i &lt; allCookie.size(); i++) &#123; return allCookie.get(i).toString(); &#125; return null; &#125; /** * 删除cookie（这里是全部删除，也可指定的地址删除） */ public static void removeCookie() &#123; CookieJarImpl.CookieStore cookieStore = OkManager.getInstance().getCookieJar().getCookieStore(); cookieStore.removeAllCookie(); &#125;&#125; 最终的Okmanager类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.concurrent.TimeUnit;import okhttp3.OkHttpClient;/*** @author dmrfcoder* @date 2018/8/28*/public class OkManager &#123; public OkHttpClient getClient() &#123; return client; &#125; private OkHttpClient client; private volatile static OkManager okManager; private final String TAG = OkManager.class.getSimpleName(); OkHttpClient.Builder httpBuilder; public OkManager() &#123; //需要设置请求超时调用下面两行 httpBuilder = new OkHttpClient.Builder(); client = httpBuilder.readTimeout(10, TimeUnit.SECONDS) .connectTimeout(10, TimeUnit.SECONDS).writeTimeout(15, TimeUnit.SECONDS) //设置超时 .cookieJar(new CookieJarImpl(new SPCookieStore(CashApplication.getContextObject()))) .build(); //将上面的CashApplication换成你自己的Application或者传入同样性质的参数 &#125; /** * 获取全局的cookie实例 */ public CookieJarImpl getCookieJar() &#123; return (CookieJarImpl) client.cookieJar(); &#125; /** * 采用单例获取对象 * * @return */ public static OkManager getInstance() &#123; if (okManager == null) &#123; synchronized (OkManager.class) &#123; if (okManager == null) &#123; okManager = new OkManager(); &#125; &#125; &#125; return okManager; &#125;&#125; 使用1private OkHttpClient okHttpClient = OkManager.getInstance().getClient(); 然后就实现了cookie的持久化。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>cookie</tag>
        <tag>okhttp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android如何设置顶部状态栏颜色（主题）]]></title>
    <url>%2F2018%2F09%2F03%2FAndroid%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E9%A1%B6%E9%83%A8%E7%8A%B6%E6%80%81%E6%A0%8F%E9%A2%9C%E8%89%B2%EF%BC%88%E4%B8%BB%E9%A2%98%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在Android中我们经常需要设置屏幕顶部状态栏的主题和应用页面保持同一风格，本文介绍几种常用的设置方案： 状态栏将显示为纯净的颜色，没有渐变效果​1234567891011121314151617181920212223242526272829303132/** * 状态栏相关工具类 * */ public class StatusBarUtils &#123; //设置Activity对应的顶部状态栏的颜色 public static void setWindowStatusBarColor(Activity activity, int colorResId) &#123; try &#123; if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.LOLLIPOP) &#123; Window window = activity.getWindow(); window.addFlags(WindowManager.LayoutParams.FLAG_DRAWS_SYSTEM_BAR_BACKGROUNDS); window.setStatusBarColor(activity.getResources().getColor(colorResId)); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; //设置Dialog对应的顶部状态栏的颜色 public static void setWindowStatusBarColor(Dialog dialog, int colorResId) &#123; try &#123; if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.LOLLIPOP) &#123; Window window = dialog.getWindow(); window.addFlags(WindowManager.LayoutParams.FLAG_DRAWS_SYSTEM_BAR_BACKGROUNDS); window.setStatusBarColor(dialog.getContext().getResources().getColor(colorResId)); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; 通过style来设置应用顶部状态栏的颜色首先给出一张图： 通过上图，我们可以通过设置不同的属性来达到控制不同位置颜色的目的，下面给出使用示例，修改res/values-19里面的内容： ​1234&lt;style name="AppTheme" parent="Theme.AppCompat.Light.NoActionBar"&gt;&lt;item name="colorPrimary"&gt;@android:color/holo_blue_bright&lt;/item&gt;&lt;item name="colorPrimaryDark"&gt;@android:color/holo_blue_bright&lt;/item&gt;&lt;/style&gt; 主要是设置 colorPrimary，colorPrimaryDark这两个属性的值来设置状态栏的颜色，需要注意的是： 1:AndroidManifest.xml文件中的targetSdkVersion必须设置在 21 以上。 2.parent主题必须是 Theme.AppCompat 开头，兼容包下的主题，所以必须一用 v7 包。 在顶部标题栏设置属性值达到风格一致的目的首先修改res/values-v19文件夹下的styles.xml文件内容如下（如果没有可以新建一个）： ​123&lt;style name= "AppTheme" parent="@style/BaseAppTheme"&gt;&lt;item name="android:windowTranslucentStatus"&gt;true&lt;/item&gt;&lt;/style&gt; 然后设置顶部标题控件的两个属性： ​12android:background="@android:color/holo_blue_bright"android:fitsSystemWindows="true" 这时状态栏会保持与设置fitsSystemWindow属性的控件的背景颜色一致。 参考 Android状态栏颜色修改]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android顶部状态栏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android将Uri转化为文件路径的方法]]></title>
    <url>%2F2018%2F09%2F03%2FAndroid%E5%B0%86Uri%E8%BD%AC%E5%8C%96%E4%B8%BA%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[直接贴代码： ​123456789101112131415161718192021222324252627282930313233343536373839404142@RequiresApi(api = Build.VERSION_CODES.KITKAT) public static String getpath(Context context, Uri uri)&#123; if (ContentResolver.SCHEME_CONTENT.equals(uri.getScheme())) &#123; if (DocumentsContract.isDocumentUri(context, uri)) &#123; if (isExternalStorageDocument(uri)) &#123; // ExternalStorageProvider final String docId = DocumentsContract.getDocumentId(uri); final String[] split = docId.split(":"); final String type = split[0]; if ("primary".equalsIgnoreCase(type)) &#123; String path = Environment.getExternalStorageDirectory() + "/" + split[1]; return path; &#125; &#125; else if (isDownloadsDocument(uri)) &#123; // DownloadsProvider final String id = DocumentsContract.getDocumentId(uri); final Uri contentUri = ContentUris.withAppendedId(Uri.parse("content://downloads/public_downloads"), Long.valueOf(id)); String path = getDataColumn(context, contentUri, null, null); return path; &#125; else if (isMediaDocument(uri)) &#123; // MediaProvider final String docId = DocumentsContract.getDocumentId(uri); final String[] split = docId.split(":"); final String type = split[0]; Uri contentUri = null; if ("image".equals(type)) &#123; contentUri = MediaStore.Images.Media.EXTERNAL_CONTENT_URI; &#125; else if ("video".equals(type)) &#123; contentUri = MediaStore.Video.Media.EXTERNAL_CONTENT_URI; &#125; else if ("audio".equals(type)) &#123; contentUri = MediaStore.Audio.Media.EXTERNAL_CONTENT_URI; &#125; final String selection = "_id=?"; final String[] selectionArgs = new String[]&#123;split[1]&#125;; String path = getDataColumn(context, contentUri, selection, selectionArgs); return path; &#125; &#125; &#125; return null; &#125; ​12345678910111213141516171819202122232425262728private static String getDataColumn(Context context, Uri uri, String selection, String[] selectionArgs) &#123; Cursor cursor = null; final String column = "_data"; final String[] projection = &#123;column&#125;; try &#123; cursor = context.getContentResolver().query(uri, projection, selection, selectionArgs, null); if (cursor != null &amp;&amp; cursor.moveToFirst()) &#123; final int column_index = cursor.getColumnIndexOrThrow(column); return cursor.getString(column_index); &#125; &#125; finally &#123; if (cursor != null) cursor.close(); &#125; return null;&#125;private static boolean isExternalStorageDocument(Uri uri) &#123; return "com.android.externalstorage.documents".equals(uri.getAuthority());&#125;private static boolean isDownloadsDocument(Uri uri) &#123; return "com.android.providers.downloads.documents".equals(uri.getAuthority());&#125;private static boolean isMediaDocument(Uri uri) &#123; return "com.android.providers.media.documents".equals(uri.getAuthority());&#125; ​]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Url</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android数据加密之AES加密]]></title>
    <url>%2F2018%2F09%2F03%2FAndroid%E6%95%B0%E6%8D%AE%E5%8A%A0%E5%AF%86%E4%B9%8BAES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[高级加密标准（英语：Advanced Encryption Standard，缩写：AES），在密码学中又称 Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的 DES，已经被多方分析且广为全世界所使用。简单说就是 DES 的增强版，比 DES的加密强度更高。 AES 与 DES一样，一共有四种加密模式：电子密码本模式（ECB）、加密分组链接模式（CBC）、加密反馈模式（CFB）和输出反馈模式（OFB）。关于加密模式的介绍，推荐这篇文章： 高级加密标准AES的工作模式（ECB、CBC、CFB、OFB） 直接给代码： 加密(byte级别)​12345678910111213141516171819202122232425 /* 加密使用的 key */ private static final String AES_KEY = "KUbHwTqBy6TBQ2gN"; /* 加密使用的 IV */ private static final String AES_IV = "pIbF6GR3XEN1PG05";/** * AES 加密 * * @param content 待加密内容 * @param key 密钥 * @return 加密的数据 */ public static byte[] encryptAES(byte[] content, byte[] key) &#123; try &#123; SecretKeySpec secretKeySpec = new SecretKeySpec(key, "AES"); // AES 是加密方式, CBC 是工作模式, PKCS5Padding 是填充模式 Cipher cipher = Cipher.getInstance("AES/CBC/PKCS5Padding"); // IV 是初始向量，可以增强密码的强度 cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, new IvParameterSpec(AES_IV.getBytes())); return cipher.doFinal(content); &#125; catch (Exception e) &#123; logger.error(e); &#125; return null; &#125; ​ 解密 （byte级别）​123456789101112131415161718/** * AES 解密 * * @param content 待解密内容 * @param key 密钥 * @return 解密的数据 */ public static byte[] decryptAES(byte[] content, byte[] key) &#123; try &#123; SecretKeySpec secretKeySpec = new SecretKeySpec(key, "AES"); Cipher cipher = Cipher.getInstance("AES/CBC/PKCS5Padding"); cipher.init(Cipher.DECRYPT_MODE, secretKeySpec, new IvParameterSpec(AES_IV.getBytes())); return cipher.doFinal(content); &#125; catch (Exception e) &#123; logger.error(e); &#125; return null; &#125; ​ 加密（String级别）​1234567891011121314private final static String TOKEN_KEY = "91a29fa7w46d8x41";public static String encrypt(String plain) &#123; try &#123; Cipher cipher = Cipher.getInstance("AES/CBC/PKCS5Padding"); AlgorithmParameterSpec ivSpec = new IvParameterSpec(new byte[16]); SecretKeySpec newKey = new SecretKeySpec(TOKEN_KEY.getBytes(), "AES"); cipher.init(Cipher.ENCRYPT_MODE, newKey, ivSpec); return new String(cipher.doFinal(plain.getBytes())); &#125; catch (Exception e) &#123; Ln.e(e); return null; &#125;&#125; ​​ 解密（String级别）​123456789101112public static String decrypt(String encoded) &#123; try &#123; Cipher cipher = Cipher.getInstance("AES/CBC/PKCS5Padding"); AlgorithmParameterSpec ivSpec = new IvParameterSpec(new byte[16]); SecretKeySpec newKey = new SecretKeySpec(TOKEN_KEY.getBytes(), "AES"); cipher.init(Cipher.DECRYPT_MODE, newKey, ivSpec); return new String(cipher.doFinal(encoded.getBytes())); &#125; catch (Exception e) &#123; Ln.e(e); return null; &#125; &#125; ​]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>AES加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[36 句话看完锤子科技 2018 夏季新品发布会]]></title>
    <url>%2F2018%2F08%2F21%2F36%20%E5%8F%A5%E8%AF%9D%E7%9C%8B%E5%AE%8C%E9%94%A4%E5%AD%90%E7%A7%91%E6%8A%80%202018%20%E5%A4%8F%E5%AD%A3%E6%96%B0%E5%93%81%E5%8F%91%E5%B8%83%E4%BC%9A%2F</url>
    <content type="text"><![CDATA[锤子科技于 2018 年 8 月 20日在北京凯迪拉克中心（原五棵松体育馆）举行了新品发布会，发布了搭载颠覆性的“无限屏”功能与“TNT”大屏幕操作系统的坚果 Pro 2S及众多新品配件。现在，我们用 36 句话看完这场发布会。 我们是来自四川省成都市成华区的知名企业锤子科技，非常欢迎大家来到凯迪拉克中心，观看锤子科技 2018 年第 3 场发布会。再次感谢全国几十家视频平台直播今天这次活动。 今年 5 月，我们在鸟巢发布的新品旗舰机坚果 R1，可谓命运多舛：不仅赶上了中国智能手机市场萎缩的历史时期，还在第一批产品里出现了一些问题。即便如此，坚果 R1 仍然得到了专业行家们的一致认同：“锤子科技一直以来在手机的工业设计上都可称得上是教科书级别的存在，在坚果 R1 上更显得淋漓尽致。” 同样于鸟巢发布的 TNT 大屏系统就没这么幸运了，我们甚至很难从网上找到关于 TNT 的正面评论。不过，这三个月来，当我们想到那些先知先觉的前人时，这一切其实也没想象的那么糟。“原谅他们，因为他们不知道自己在做什么。”——《圣经》路家福音 23 章 34 节 2018 年的产品线我们是这样规划的：4 月份发布的坚果 3 和 5 月份发布的坚果 R1 在今年的产品定位中属于正常定位；TNT 风险非常大，投入非常高，回报非常慢，所以对企业来讲，它是个冒险、激进的方案；今天发布的是一款稳健的产品；到了年终我们还有一场发布会，会发布一些“没人相信的东西”。 今天的主角是稳健型产品：坚果 Pro 2S。坚果 Pro 系列是锤子科技历史上整体最成熟均衡、好评度最高的一款产品线，坚果 Pro 2 更是在去年被几十家知名数字媒体评为“年度最佳中档手机”。沿着这条成功的产品线，今天我们要推出 0.5 代升级版——坚果 Pro 2S。 工业设计方面，坚果 Pro 2S 的外形和坚果 Pro 2 差不多，所有的经典设计都得以保留。但这次我们采用了全新的 CMF 色彩工艺，除了传统的黑白经典配色，新增了闷骚的炫光蓝、明骚的炫光红版本。 硬件配置及功能是此次升级很重要的方面。首先采用的是比较新的骁龙 710，相对于坚果 Pro 2，坚果 Pro 2S 的单核性能提升了 15.7%，多核性能提升了 5%，图形性能戏剧性地提高了 56.84%，AI 性能提升了 100%。 这次成像效果相对于坚果 Pro 2 是个非常大的进步和提升。坚果 Pro 2S 采用了 1200 万+500 万旗舰级 AI 双摄，1.4μm 超大像素传感器，索尼 IMX363 传感器，Dual PD 双核对焦，ArcSoft 提供专业图像算法。由旷视 Face++提供的 AI 技术，自动识别画面 18 个大类型和 200 多种场景。1600 万前置摄像头，背景虚化、实时美颜。 我们把相机送去权威机构 DxOMark 测了一下影像效果，结果怎么样呢？只拿了 95 分（微笑）。注意，我们作为中档机型，这个成绩仅次于 iPhone 8 Plus，竟然好于 iPhone 8，在这个价位的手机里是非常了不起的。 坚果 Pro 2S 采用高通提供的 TV-OUT 2K 超高清输出，随时随地连大屏，手游畅玩不卡顿。传统的手机投屏有 31 毫秒的延迟，而坚果 Pro 2S 的屏只有 14 毫秒的延迟。14 毫秒什么概念？少于一帧，人类不可感知。除非你是苍蝇，有复眼。 我们非常努力地只增加了 100mAh 电池，因为同时把它做薄到只有 7.15mm；如果不做薄，我们可以加更多的电池，但 3600mAh 电池，对 80%、90% 的用户都足够了。 全新低功耗 OLED 屏幕，超高对比度达到 100000:1，100% 覆盖 P3 广色域，相信大家会对这块屏感到满意。 全局采用了线性马达，它仿真了一些真实物理世界的触感，虽然是假的，但摸起来像是真的。拥有 36 种振动效果，52 种振动场景。 这次发布的 Smarteisan OS v6.6.5，新增了 41 项功能，优化了 25 次产品细节。今天要给大家主要介绍的是三个板块：第一个就是 TNT。我们并不是简单地要卖一个一万块钱的大屏幕，重要的是我们要做一个用手机替代 PC、Mac 全功能的桌面级的系统。实际上如果你不考虑触控版本，只是考虑键鼠版本的话，任何一个普通的显示器都可以，买一个市面上 34 寸的显示器，装上以后用键鼠模式就可以用，比目前任何一家做的手机转大屏都可以做得更好。 TNT 的众测版 8 月 20 日提供下载。如果你手里已经有了坚果 R1，今天就可以到网站上下载 TNT 的众测版，可以用键鼠模式；坚果 Pro 2S 在 9月12日开始提供下载，下载地址在我们官网论坛 bbs.t.tt 上有非常详细的说明和连接。 子弹短信是锤子科技和快如科技联合推出的超高效率的次世代即时通讯工具。起初它是为大屏幕设计的，今天我们把大部分精髓移植到了手机屏幕上，把短信沟通效率提高到了难以置信的程度。 在子弹短信中，你的每一条语音消息都会同文字一同发送，如果对方对文字如果有所困惑，听语音就可以解决，此外你也可以任意拖动语音的进度条。语音+文字的形式能够保证信息快速发出，且不用因为纠错而对人产生困扰。 你可以在列表页完成绝大部分的回复操作，点击消息后面的按键可以直接以语音或文本的形式进行回复，群聊的未读信息也可以在不进入群的情况下直接展开并单独回复任意一条。 对于坚果手机，在任何情况下按住闪念胶囊键说话，可以直接将信息发送给好友；对于非坚果手机的安卓用户，屏幕上会显示一个悬浮球，按住它说话，也能达到相同的效果；而对于 iPhone 用户，使用 3D Touch 按压子弹短信图标也会弹出说话的按钮，你一闪而过的想法可以当场得到解决。 还有一些十分贴心的细节设计比如：查看并锁定好友的历史头像、帮助你回忆起好友是谁避免尴尬的“这是谁来着？”、将日常对话设置为稍后处理以免忘记、以及帮助大家进行社交的“发现锤友”功能。 我们也打破了必须要双方共同安装才能使用社交软件的尴尬，只要你有对方的手机号，你可以随时向对方发送文本、语音、文件等，对方会以短信的形式收到，同时可以打开网页版子弹短信进行详细查看。 子弹短信会从 8 月 20 日起正式开放下载，大家可以到 zidanduanxin.com，或者到锤子科技官方论坛 bbs.t.tt 进行下载。同时我们会在 8 月 20 日- 10 月 8 日期间和 UI 中国合作举办子弹短信的 Bmoji 表情符设计大赛，如果大家有兴趣可以来参加我们的活动。 今天真正的重头戏是“无限屏”。整个行业的精英们都是每天致力于“超高屏占比屏”、“全面屏”、“刘海屏”、“美人尖屏”、“真全面屏”，这真是解决问题的方向吗？小巧的 3.5 吋手机比例很好，但体验会很差，手机很大，又会显得很傻，我相信如果没有意外的话，未来相当一段时间，5.5-6 吋之间的尺寸是最主流的。 所以我们做出了一些突破，带来了一个新的软件解决方案：“无限屏”，也叫 Infinite Screen。将手指从屏幕底部边缘向上推，你就能进入一个神奇的无限屏世界，只要用手进行挪动，你就可以迅速在多任务管理器中进行选择，或者选择某个光标，进入程序。 大家自拍的时候会把手机仰起来，是因为这样显瘦，当你在无限屏模式下向上举起手机，你就能直接进入自拍模式。 同时无限屏的最下面是一个地球，当你对准它然后松手，你就会进入地图，以往我们使用电子地图，需要用手反复滑动屏幕，很容易就不耐烦了，但在无限世界里，我们已经画好了一个足够详尽的地图，只要你将手机沿路线滑动过去就够了，这才是我们大脑的工作方式，是一个梦幻般的体验。 我们也把能同时显示 14 个窗口的子弹短信重新带入了无限屏，你可以在无限屏内随易跳转窗口，在某一窗口复制，然后拖动到任意窗口进行粘贴，此外你也可以同时打开多个购物 app 进行比价，以及像桌面电脑一样自如地拖拽各类文件。 “无限屏”在相册中也有不一样的体验，你只需要拖动手机，就能随意查看长图中的任何一个细节。我们终于有了对祖先的伟大作品进行致敬的方式，终于有了在手机上观赏《清明上河图》的唯一正确方式，这是一个工匠对另一个工匠的致敬。 对于无限屏的功能还有很多展示，为了纪念这一刻，我们拍摄了下面这个短片： 虽然坚果 Pro 2S 相比“两千元价位没有对手的”坚果 Pro 2 进行了全方位的升级，但我们讲过做手机是为了交朋友，为了交定你们这些朋友，我们决定把 4GB RAM+64GB ROM 的版本定价为 1798 元，6GB RAM+64GB ROM 的版本定价为 1998 元，6GB RAM+128GB ROM 的版本也只要 2298 元。 我们也发布了一些配件：添加了手电筒功能的“电池形电池”，售价 69 元；Pro 2S 软胶透明保护套，售价 29 元； Pro 2S TPU 软硅胶保护套，售价 49 元；五款全新的“足迹”系列背壳，售价 79 元；颜色随机的坚果彩虹数据线，售价 19 元。 同时为了释放工业设计部门过剩的设计能力和欲望，我们还推出了坚果砖式蓝牙小音箱，售价 149 元。如果你财力过剩，你可以购买两个我们的小音箱，并把它们组成立体声。 我们也很高兴地与湛庐文化进行了合作，在两年左右时间里引入了三本非常难得的三本书：《深泽直人》、《索尼设计，塑造现代》与《博朗设计——卓越创新 50 年》，有志投身工业设计，希望能引领中国的新国货运动或者新制造运动的朋友可以到京东图书或者锤子科技官方商城购买。 还有一件很伤感的事情。由于我们在短短四个半月时间里在同一城市连续开了三场发布会，频率过于密集，导致此次发布会的门票收入情况与我们预想的有一些出入，只有 493,300 元钱，但为了继续支持开源社区的工作，锤子科技 CEO 罗永浩会自掏腰包，凑齐一百万继续支持 OpenSSL 和 OpenBSD 开源社区的工作。另外我们可能在半年之内就会从底层启动下一代不基于安卓的 OS 计划，为下一代的计算平台，不仅仅是手机，做出全新的努力。 今年是手机行业非常艰难的一年，没有想到手机衰落期来得这么早。今年上半年整个行业迎来了百分之十八点九几的下滑，我们作为小厂商更加地困难。但在这个过程里我们还是排除万难做了一些不一样的创新。尽管 TNT 被嘲笑，被调侃，鸟巢的发布会也远谈不上是成功，但是我们在这里承诺一定会在 TNT 后续的成熟版本里给大家做出惊艳的东西来。 最后，为了不让大家对一个小改款升级的机型感到失望，这一次我们在非常非常短的时间里，花费了很大的时间与精力，最终拿出了“无限屏”，我们会承受着你们这种温暖的支持一直走下去，谢谢。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Android 设置EditText 默认弹出数字软键盘并限制其输入内容]]></title>
    <url>%2F2018%2F07%2F28%2FAndroid%20%E8%AE%BE%E7%BD%AEEditText%20%E9%BB%98%E8%AE%A4%E5%BC%B9%E5%87%BA%E6%95%B0%E5%AD%97%E8%BD%AF%E9%94%AE%E7%9B%98%E5%B9%B6%E9%99%90%E5%88%B6%E5%85%B6%E8%BE%93%E5%85%A5%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[前言设置 EditText 首次输入弹出数字键盘，然后可以随便切换输入模式，另外以输入身份证号 为例，因为身份证号只可能是数字 + 字母X，所以这里不仅做了首次弹出数字键盘，还实现了对于其他键盘模式输入做了限制，只能输入字母 X 。 代码xml​1234567891011121314151617181920&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android" xmlns:tools="http://schemas.android.com/tools" android:layout_width="match_parent" android:layout_height="match_parent" tools:context="com.example.mu_16jj.edittextinputtypedemo.MainActivity"&gt; &lt;EditText android:id="@+id/et_main" android:layout_width="300dp" android:layout_height="45dp" android:layout_centerHorizontal="true" android:layout_marginTop="25dp" android:background="@drawable/sh_et_blue_bg" android:gravity="center_vertical" android:hint="默认弹出数字键盘" android:paddingLeft="5dp" android:textColor="@android:color/black" /&gt;&lt;/RelativeLayout&gt; 注意：这里并没有指定输入类型，因为如果指定了输入类型，那么就限定死了。 Java​1234567891011121314151617181920212223242526272829303132private void initView() &#123; setContentView(R.layout.activity_main); editText = (EditText) findViewById(R.id.et_main); editText.setKeyListener(listener); &#125; KeyListener listener = new NumberKeyListener() &#123; /** * @return ：返回哪些希望可以被输入的字符,默认不允许输入 */ @Override protected char[] getAcceptedChars() &#123; char[] chars = new char[]&#123;'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'X'&#125;; return chars;// return new char[0]; &#125; /** * 0：无键盘,键盘弹不出来 * 1：英文键盘 * 2：模拟键盘 * 3：数字键盘 * * @return */ @Override public int getInputType() &#123; return 3; &#125; &#125;;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>EditText</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android studio Session 'app' Error Installing APK解决方法]]></title>
    <url>%2F2018%2F07%2F28%2FAndroid%20studio%20Session%20'app'%3A%20Error%20Installing%20APK%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[有三种方法可以尝试： 1：尝试Build -&gt; Clean Project再编译 2：进行手机重新链接 3：改变Android studio的设置，去掉第一个复选框的勾，如下图：]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>Android Studio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android之——模拟实现检测心率变化的应用实例]]></title>
    <url>%2F2018%2F07%2F28%2FAndroid%E4%B9%8B%E2%80%94%E2%80%94%E6%A8%A1%E6%8B%9F%E5%AE%9E%E7%8E%B0%E6%A3%80%E6%B5%8B%E5%BF%83%E7%8E%87%E5%8F%98%E5%8C%96%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[[转]Android之——模拟实现检测心率变化的应用实例当今，市面上有了一些可以通过Android应用来检测病人心率，血压，体温，等等，一系列方便人们日常生活的Android手机应用。那么，这些实用的手机应用程序是怎么做出来的呢？那么，今天，我就给大家奉上一个很有意思的应用，那就是Android上模拟实现检测心率的变化。我利用Android模拟实现了通过手机摄像头来感知用户指尖毛细血管的变化来检测心率的功能。哇哦，听起来是不是很高大上呢？瞬间对这个功能充满了膜拜与好奇，有木有？！有木有呢？！哈哈，那就让我们一起来实现这些功能吧。 一、原理首先我们还是要讲讲这个应用的原理吧，在下认为，要做一个Android应用程序，咱们还要先弄懂它的实现原理吧。不然，看了半天各位都不知道这个应用是基于什么原理做的呢。是吧，那就让我们一起来分析下它的实现原理。 通过摄像头来获得心率，搜了一下这个技术真不是噱头，据说在iPhone早有实现，主要原理是：当打开软件时，手机的闪光灯也会被自动打开，用户将手指放在摄像头上时，指尖皮下血管由于有血液被压入，被光源照射的手指亮度（红色的深度）会有轻微的变化。这个过程可以凭借感光元件捕捉到。这样毛细血管的搏动就能通过画面明度的周期性变化反映出来。 好了，原理说完了，大家有木有看懂呢？ 二、实现1、创建图像处理类ImageProcessing这个类主要提供处理图像本身的方法。 具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.lyz.monitor.utils; /** * 图像处理类 * @author liuyazhuang * */public abstract class ImageProcessing &#123; /** * 内部调用的处理图片的方法 * @param yuv420sp * @param width * @param height * @return */ private static int decodeYUV420SPtoRedSum(byte[] yuv420sp, int width,int height) &#123; if (yuv420sp == null) return 0; final int frameSize = width * height; int sum = 0; for (int j = 0, yp = 0; j &lt; height; j++) &#123; int uvp = frameSize + (j &gt;&gt; 1) * width, u = 0, v = 0; for (int i = 0; i &lt; width; i++, yp++) &#123; int y = (0xff &amp; ((int) yuv420sp[yp])) - 16; if (y &lt; 0) y = 0; if ((i &amp; 1) == 0) &#123; v = (0xff &amp; yuv420sp[uvp++]) - 128; u = (0xff &amp; yuv420sp[uvp++]) - 128; &#125; int y1192 = 1192 * y; int r = (y1192 + 1634 * v); int g = (y1192 - 833 * v - 400 * u); int b = (y1192 + 2066 * u); if (r &lt; 0) r = 0; else if (r &gt; 262143) r = 262143; if (g &lt; 0) g = 0; else if (g &gt; 262143) g = 262143; if (b &lt; 0) b = 0; else if (b &gt; 262143) b = 262143; int pixel = 0xff000000 | ((r &lt;&lt; 6) &amp; 0xff0000) | ((g &gt;&gt; 2) &amp; 0xff00) | ((b &gt;&gt; 10) &amp; 0xff); int red = (pixel &gt;&gt; 16) &amp; 0xff; sum += red; &#125; &#125; return sum; &#125; /** * 对外开放的图像处理方法 * @param yuv420sp * @param width * @param height * @return */ public static int decodeYUV420SPtoRedAvg(byte[] yuv420sp, int width, int height) &#123; if (yuv420sp == null) return 0; final int frameSize = width * height; int sum = decodeYUV420SPtoRedSum(yuv420sp, width, height); return (sum / frameSize); &#125;&#125; 2、MainActivity实现为了简单，我没有单独新建别的类来分解这些功能，我直接在MainActivity中实现了这些功能，那么我们就一起来看看是如何一步步实现的吧。 (1)程序中用到的属性首先，我们来看看程序中定义了哪些属性字段，来实现这些功能吧。 具体属性字段如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//曲线private Timer timer = new Timer();//Timer任务，与Timer配套使用private TimerTask task;private static int gx;private static int j; private static double flag=1;private Handler handler;private String title = "pulse";private XYSeries series;private XYMultipleSeriesDataset mDataset;private GraphicalView chart;private XYMultipleSeriesRenderer renderer;private Context context;private int addX = -1;double addY;int[] xv = new int[300];int[] yv = new int[300];int[] hua=new int[]&#123;9,10,11,12,13,14,13,12,11,10,9,8,7,6,7,8,9,10,11,10,10&#125;; // private static final String TAG = "HeartRateMonitor";private static final AtomicBoolean processing = new AtomicBoolean(false);//Android手机预览控件private static SurfaceView preview = null;//预览设置信息private static SurfaceHolder previewHolder = null;//Android手机相机句柄private static Camera camera = null;//private static View image = null;private static TextView text = null;private static TextView text1 = null;private static TextView text2 = null;private static WakeLock wakeLock = null;private static int averageIndex = 0;private static final int averageArraySize = 4;private static final int[] averageArray = new int[averageArraySize];//设置默认类型private static TYPE currentType = TYPE.GREEN;//获取当前类型public static TYPE getCurrent() &#123; return currentType;&#125;//心跳下标值private static int beatsIndex = 0;//心跳数组的大小private static final int beatsArraySize = 3;//心跳数组private static final int[] beatsArray = new int[beatsArraySize];//心跳脉冲private static double beats = 0;//开始时间private static long startTime = 0; 咋一看，是不是很多？有木有一种头晕乎乎的赶脚呢？没关系，通过后面具体的功能实现，相信大家能弄明白每个属性字段的作用与含义的。不要掉队，继续认真向下看哦。 (2)定义枚举类型来标识当前颜色颜色类型，我在这里用一个枚举类型来定义，这个枚举类型很简单，只有两种颜色，一种是绿色，一种是红色。默认颜色为绿色。 具体实现的代码如下: 1234567891011121314 /** * 类型枚举 * @author liuyazhuang **/ public static enum TYPE &#123; GREEN, RED &#125;; //设置默认类型private static TYPE currentType = TYPE.GREEN; //获取当前类型public static TYPE getCurrent() &#123; return currentType; &#125; (3)初始化配置方法initConfig这个方法总体上的功能是初始化程序的各个配置，包括调用其他方法，例如页面图表的初始化，UI控件的初始化，应用程序启动后显示的样式，调用相机，通过Handler接收其他方法传递过来的消息信息来更新UI，，等等。主要是实现应用的配置功能，同时这个方法相当于一个应用程序的管家，它来直接或间接的调用其他方法，来使整个应用程序顺利运行起来。 具体代码实现如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 初始化配置 */ private void initConfig() &#123; //曲线 context = getApplicationContext(); //这里获得main界面上的布局，下面会把图表画在这个布局里面 LinearLayout layout = (LinearLayout)findViewById(R.id.linearLayout1); //这个类用来放置曲线上的所有点，是一个点的集合，根据这些点画出曲线 series = new XYSeries(title); //创建一个数据集的实例，这个数据集将被用来创建图表 mDataset = new XYMultipleSeriesDataset(); //将点集添加到这个数据集中 mDataset.addSeries(series); //以下都是曲线的样式和属性等等的设置，renderer相当于一个用来给图表做渲染的句柄 int color = Color.GREEN; PointStyle style = PointStyle.CIRCLE; renderer = buildRenderer(color, style, true); //设置好图表的样式 setChartSettings(renderer, "X", "Y", 0, 300, 4, 16, Color.WHITE, Color.WHITE); //生成图表 chart = ChartFactory.getLineChartView(context, mDataset, renderer); //将图表添加到布局中去 layout.addView(chart, new LayoutParams(LayoutParams.FILL_PARENT, LayoutParams.FILL_PARENT)); //这里的Handler实例将配合下面的Timer实例，完成定时更新图表的功能 handler = new Handler() &#123; @Override public void handleMessage(Message msg) &#123; // 刷新图表 updateChart(); super.handleMessage(msg); &#125; &#125;; task = new TimerTask() &#123; @Override public void run() &#123; Message message = new Message(); message.what = 1; handler.sendMessage(message); &#125; &#125;; timer.schedule(task, 1,20); //曲线 //获取SurfaceView控件 preview = (SurfaceView) findViewById(R.id.preview); previewHolder = preview.getHolder(); previewHolder.addCallback(surfaceCallback); previewHolder.setType(SurfaceHolder.SURFACE_TYPE_PUSH_BUFFERS); // image = findViewById(R.id.image); text = (TextView) findViewById(R.id.text); text1 = (TextView) findViewById(R.id.text1); text2 = (TextView) findViewById(R.id.text2); PowerManager pm = (PowerManager) getSystemService(Context.POWER_SERVICE); wakeLock = pm.newWakeLock(PowerManager.FULL_WAKE_LOCK, "DoNotDimScreen"); &#125; (4)创建图表的方法buildRenderer这个方法主要是利用了第三方的类库类实现创建图标的操作。 具体代码实现如下: 12345678910111213141516171819/** * 创建图表 * @param color * @param style * @param fill * @return */ protected XYMultipleSeriesRenderer buildRenderer(int color, PointStyle style, boolean fill) &#123; XYMultipleSeriesRenderer renderer = new XYMultipleSeriesRenderer(); //设置图表中曲线本身的样式，包括颜色、点的大小以及线的粗细等 XYSeriesRenderer r = new XYSeriesRenderer(); r.setColor(Color.RED);// r.setPointStyle(null);// r.setFillPoints(fill); r.setLineWidth(1); renderer.addSeriesRenderer(r); return renderer; &#125; (5)设置图表的样式方法setChartSettings这个方法主要是对(4)中创建的图表，进行样式的设置。 具体代码如下： 12345678910111213141516171819202122232425262728293031323334 /** * 设置图标的样式* @param renderer * @param xTitle：x标题 * @param yTitle：y标题 * @param xMin：x最小长度 * @param xMax：x最大长度 * @param yMin:y最小长度 * @param yMax：y最大长度* @param axesColor：颜色 * @param labelsColor：标签*/protected void setChartSettings(XYMultipleSeriesRenderer renderer, String xTitle, String yTitle, double xMin, double xMax, double yMin, double yMax, int axesColor, int labelsColor) &#123; //有关对图表的渲染可参看api文档 renderer.setChartTitle(title); renderer.setXTitle(xTitle); renderer.setYTitle(yTitle); renderer.setXAxisMin(xMin); renderer.setXAxisMax(xMax); renderer.setYAxisMin(yMin); renderer.setYAxisMax(yMax); renderer.setAxesColor(axesColor); renderer.setLabelsColor(labelsColor); renderer.setShowGrid(true); renderer.setGridColor(Color.GREEN); renderer.setXLabels(20); renderer.setYLabels(10); renderer.setXTitle("Time"); renderer.setYTitle("mmHg"); renderer.setYLabelsAlign(Align.RIGHT); renderer.setPointSize((float) 3 ); renderer.setShowLegend(false); &#125; (6)更新图表updateChart这个方法主要实现了对图表中曲线图的更新绘制，同时检测手机摄像头感应的手指位置，如果手指位置不正确，则会提示“请用您的指尖盖住摄像头镜头”的信息来提示用户。动态的更新绘制曲线图来模拟用户心跳频率。 具体代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 更新图标信息 */ private void updateChart() &#123; //设置好下一个需要增加的节点 if(flag==1) addY=10; else&#123;// addY=250; flag=1; if(gx&lt;200)&#123; if(hua[20]&gt;1)&#123; Toast.makeText(MainActivity.this, "请用您的指尖盖住摄像头镜头！", Toast.LENGTH_SHORT).show(); hua[20]=0;&#125; hua[20]++; return;&#125; else hua[20]=10; j=0; &#125; if(j&lt;20)&#123; addY=hua[j]; j++; &#125; //移除数据集中旧的点集 mDataset.removeSeries(series); //判断当前点集中到底有多少点，因为屏幕总共只能容纳100个，所以当点数超过100时，长度永远是100 int length = series.getItemCount(); int bz=0; //addX = length; if (length &gt; 300) &#123; length = 300; bz=1; &#125; addX = length; //将旧的点集中x和y的数值取出来放入backup中，并且将x的值加1，造成曲线向右平移的效果 for (int i = 0; i &lt; length; i++) &#123; xv[i] = (int) series.getX(i) -bz; yv[i] = (int) series.getY(i); &#125; //点集先清空，为了做成新的点集而准备 series.clear(); mDataset.addSeries(series); //将新产生的点首先加入到点集中，然后在循环体中将坐标变换后的一系列点都重新加入到点集中 //这里可以试验一下把顺序颠倒过来是什么效果，即先运行循环体，再添加新产生的点 series.add(addX, addY); for (int k = 0; k &lt; length; k++) &#123; series.add(xv[k], yv[k]); &#125; //在数据集中添加新的点集 //mDataset.addSeries(series); //视图更新，没有这一步，曲线不会呈现动态 //如果在非UI主线程中，需要调用postInvalidate()，具体参考api chart.invalidate(); &#125; //曲线 (7)相机预览回调方法previewCallback这个方法中实现动态更新界面UI的功能，通过获取手机摄像头的参数来实时动态计算平均像素值、脉冲数，从而实时动态计算心率值。 具体代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * 相机预览方法 * 这个方法中实现动态更新界面UI的功能， * 通过获取手机摄像头的参数来实时动态计算平均像素值、脉冲数，从而实时动态计算心率值。 */ private static PreviewCallback previewCallback = new PreviewCallback() &#123; public void onPreviewFrame(byte[] data, Camera cam) &#123; if (data == null) throw new NullPointerException(); Camera.Size size = cam.getParameters().getPreviewSize(); if (size == null) throw new NullPointerException(); if (!processing.compareAndSet(false, true)) return; int width = size.width; int height = size.height; //图像处理 int imgAvg = ImageProcessing.decodeYUV420SPtoRedAvg(data.clone(),height,width); gx=imgAvg; text1.setText("平均像素值是"+String.valueOf(imgAvg)); //像素平均值imgAvg,日志 //Log.i(TAG, "imgAvg=" + imgAvg); if (imgAvg == 0 || imgAvg == 255) &#123; processing.set(false); return; &#125; //计算平均值 int averageArrayAvg = 0; int averageArrayCnt = 0; for (int i = 0; i &lt; averageArray.length; i++) &#123; if (averageArray[i] &gt; 0) &#123; averageArrayAvg += averageArray[i]; averageArrayCnt++; &#125; &#125; //计算平均值 int rollingAverage = (averageArrayCnt &gt; 0)?(averageArrayAvg/averageArrayCnt):0; TYPE newType = currentType; if (imgAvg &lt; rollingAverage) &#123; newType = TYPE.RED; if (newType != currentType) &#123; beats++; flag=0; text2.setText("脉冲数是"+String.valueOf(beats)); //Log.e(TAG, "BEAT!! beats=" + beats); &#125; &#125; else if (imgAvg &gt; rollingAverage) &#123; newType = TYPE.GREEN; &#125; if (averageIndex == averageArraySize) averageIndex = 0; averageArray[averageIndex] = imgAvg; averageIndex++; // Transitioned from one state to another to the same if (newType != currentType) &#123; currentType = newType; //image.postInvalidate(); &#125; //获取系统结束时间（ms） long endTime = System.currentTimeMillis(); double totalTimeInSecs = (endTime - startTime) / 1000d; if (totalTimeInSecs &gt;= 2) &#123; double bps = (beats / totalTimeInSecs); int dpm = (int) (bps * 60d); if (dpm &lt; 30 || dpm &gt; 180||imgAvg&lt;200) &#123; //获取系统开始时间（ms） startTime = System.currentTimeMillis(); //beats心跳总数 beats = 0; processing.set(false); return; &#125; //Log.e(TAG, "totalTimeInSecs=" + totalTimeInSecs + " beats="+ beats); if (beatsIndex == beatsArraySize) beatsIndex = 0; beatsArray[beatsIndex] = dpm; beatsIndex++; int beatsArrayAvg = 0; int beatsArrayCnt = 0; for (int i = 0; i &lt; beatsArray.length; i++) &#123; if (beatsArray[i] &gt; 0) &#123; beatsArrayAvg += beatsArray[i]; beatsArrayCnt++; &#125; &#125; int beatsAvg = (beatsArrayAvg / beatsArrayCnt); text.setText("您的的心率是"+String.valueOf(beatsAvg)+" zhi:"+String.valueOf(beatsArray.length) +" "+String.valueOf(beatsIndex)+" "+String.valueOf(beatsArrayAvg)+" "+String.valueOf(beatsArrayCnt)); //获取系统时间（ms） startTime = System.currentTimeMillis(); beats = 0; &#125; processing.set(false); &#125; &#125;; (8)SurfaceHolder.Callback这个方法主要是相机摄像头，捕捉信息改变时调用。 具体代码实现如下： 123456789101112131415161718192021222324252627282930313233/** * 预览回调接口 */ private static SurfaceHolder.Callback surfaceCallback = new SurfaceHolder.Callback() &#123; //创建时调用 @Override public void surfaceCreated(SurfaceHolder holder) &#123; try &#123; camera.setPreviewDisplay(previewHolder); camera.setPreviewCallback(previewCallback); &#125; catch (Throwable t) &#123; Log.e("PreviewDemo-surfaceCallback","Exception in setPreviewDisplay()", t); &#125; &#125; //当预览改变的时候回调此方法 @Override public void surfaceChanged(SurfaceHolder holder, int format, int width,int height) &#123; Camera.Parameters parameters = camera.getParameters(); parameters.setFlashMode(Camera.Parameters.FLASH_MODE_TORCH); Camera.Size size = getSmallestPreviewSize(width, height, parameters); if (size != null) &#123; parameters.setPreviewSize(size.width, size.height); // Log.d(TAG, "Using width=" + size.width + " height=" + size.height); &#125; camera.setParameters(parameters); camera.startPreview(); &#125; //销毁的时候调用 @Override public void surfaceDestroyed(SurfaceHolder holder) &#123; // Ignore &#125; &#125;; (9)获取相机最小的预览尺寸方法getSmallestPreviewSize这个方法的功能是获取当前手机相机最小的预览尺寸。 具体代码实现如下: 123456789101112131415161718192021222324/** * 获取相机最小的预览尺寸 * @param width * @param height * @param parameters * @return */ private static Camera.Size getSmallestPreviewSize(int width, int height, Camera.Parameters parameters) &#123; Camera.Size result = null; for (Camera.Size size : parameters.getSupportedPreviewSizes()) &#123; if (size.width &lt;= width &amp;&amp; size.height &lt;= height) &#123; if (result == null) &#123; result = size; &#125; else &#123; int resultArea = result.width * result.height; int newArea = size.width * size.height; if (newArea &lt; resultArea) result = size; &#125; &#125; &#125; return result; &#125; (10)onCreate方法这个方法是Android原生自带的方法，通常在这个方法中我们会实现页面控件的初始化以及一些数据的初始化工作。我们这个项目中，主要是设置要显示的UI和调用initConfig方法来启动应用程序的配置，从而实现应用程序的顺利运行。 具体实现代码如下： 123456 @Overridepublic void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); initConfig(); &#125; (11)其他一些Android原生自带方法12345678910111213141516171819202122232425262728@Overridepublic void onDestroy() &#123; //当结束程序时关掉Timer timer.cancel(); super.onDestroy();&#125;;@Override public void onConfigurationChanged(Configuration newConfig) &#123; super.onConfigurationChanged(newConfig);&#125; @Overridepublic void onResume() &#123; super.onResume(); wakeLock.acquire(); camera = Camera.open(); startTime = System.currentTimeMillis();&#125; @Overridepublic void onPause() &#123; super.onPause(); wakeLock.release(); camera.setPreviewCallback(null); camera.stopPreview(); camera.release(); camera = null;&#125; (12)MainActivity完整代码最后我还是给出MainActivity的完整代码吧，大家根据上面的分析仔细阅读几遍，便会体会这其中的奥妙了。嘿嘿，加油哦！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484package com.lyz.xinlv.activity;import java.util.Timer;import java.util.TimerTask;import java.util.concurrent.atomic.AtomicBoolean; import org.achartengine.ChartFactory;import org.achartengine.GraphicalView;import org.achartengine.chart.PointStyle;import org.achartengine.model.XYMultipleSeriesDataset;import org.achartengine.model.XYSeries;import org.achartengine.renderer.XYMultipleSeriesRenderer;import org.achartengine.renderer.XYSeriesRenderer; import android.app.Activity;import android.content.Context;import android.content.res.Configuration;import android.graphics.Color;import android.graphics.Paint.Align;import android.hardware.Camera;import android.hardware.Camera.PreviewCallback;import android.os.Bundle;import android.os.Handler;import android.os.Message;import android.os.PowerManager;import android.os.PowerManager.WakeLock;import android.util.Log;import android.view.SurfaceHolder;import android.view.SurfaceView;import android.view.ViewGroup.LayoutParams;import android.widget.LinearLayout;import android.widget.TextView;import android.widget.Toast; import com.lyz.monitor.utils.ImageProcessing; /** * 程序的主入口 * @author liuyazhuang * */public class MainActivity extends Activity &#123; //曲线 private Timer timer = new Timer(); //Timer任务，与Timer配套使用 private TimerTask task; private static int gx; private static int j; private static double flag=1; private Handler handler; private String title = "pulse"; private XYSeries series; private XYMultipleSeriesDataset mDataset; private GraphicalView chart; private XYMultipleSeriesRenderer renderer; private Context context; private int addX = -1; double addY; int[] xv = new int[300]; int[] yv = new int[300]; int[] hua=new int[]&#123;9,10,11,12,13,14,13,12,11,10,9,8,7,6,7,8,9,10,11,10,10&#125;; // private static final String TAG = "HeartRateMonitor"; private static final AtomicBoolean processing = new AtomicBoolean(false); //Android手机预览控件 private static SurfaceView preview = null; //预览设置信息 private static SurfaceHolder previewHolder = null; //Android手机相机句柄 private static Camera camera = null; //private static View image = null; private static TextView text = null; private static TextView text1 = null; private static TextView text2 = null; private static WakeLock wakeLock = null; private static int averageIndex = 0; private static final int averageArraySize = 4; private static final int[] averageArray = new int[averageArraySize]; /** * 类型枚举 * @author liuyazhuang * */ public static enum TYPE &#123; GREEN, RED &#125;; //设置默认类型 private static TYPE currentType = TYPE.GREEN; //获取当前类型 public static TYPE getCurrent() &#123; return currentType; &#125; //心跳下标值 private static int beatsIndex = 0; //心跳数组的大小 private static final int beatsArraySize = 3; //心跳数组 private static final int[] beatsArray = new int[beatsArraySize]; //心跳脉冲 private static double beats = 0; //开始时间 private static long startTime = 0; @Override public void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); initConfig(); &#125; /** * 初始化配置 */ private void initConfig() &#123; //曲线 context = getApplicationContext(); //这里获得main界面上的布局，下面会把图表画在这个布局里面 LinearLayout layout = (LinearLayout)findViewById(R.id.linearLayout1); //这个类用来放置曲线上的所有点，是一个点的集合，根据这些点画出曲线 series = new XYSeries(title); //创建一个数据集的实例，这个数据集将被用来创建图表 mDataset = new XYMultipleSeriesDataset(); //将点集添加到这个数据集中 mDataset.addSeries(series); //以下都是曲线的样式和属性等等的设置，renderer相当于一个用来给图表做渲染的句柄 int color = Color.GREEN; PointStyle style = PointStyle.CIRCLE; renderer = buildRenderer(color, style, true); //设置好图表的样式 setChartSettings(renderer, "X", "Y", 0, 300, 4, 16, Color.WHITE, Color.WHITE); //生成图表 chart = ChartFactory.getLineChartView(context, mDataset, renderer); //将图表添加到布局中去 layout.addView(chart, new LayoutParams(LayoutParams.FILL_PARENT, LayoutParams.FILL_PARENT)); //这里的Handler实例将配合下面的Timer实例，完成定时更新图表的功能 handler = new Handler() &#123; @Override public void handleMessage(Message msg) &#123; // 刷新图表 updateChart(); super.handleMessage(msg); &#125; &#125;; task = new TimerTask() &#123; @Override public void run() &#123; Message message = new Message(); message.what = 1; handler.sendMessage(message); &#125; &#125;; timer.schedule(task, 1,20); //曲线 //获取SurfaceView控件 preview = (SurfaceView) findViewById(R.id.preview); previewHolder = preview.getHolder(); previewHolder.addCallback(surfaceCallback); previewHolder.setType(SurfaceHolder.SURFACE_TYPE_PUSH_BUFFERS); // image = findViewById(R.id.image); text = (TextView) findViewById(R.id.text); text1 = (TextView) findViewById(R.id.text1); text2 = (TextView) findViewById(R.id.text2); PowerManager pm = (PowerManager) getSystemService(Context.POWER_SERVICE); wakeLock = pm.newWakeLock(PowerManager.FULL_WAKE_LOCK, "DoNotDimScreen"); &#125; // 曲线 @Override public void onDestroy() &#123; //当结束程序时关掉Timer timer.cancel(); super.onDestroy(); &#125;; /** * 创建图表 * @param color * @param style * @param fill * @return */ protected XYMultipleSeriesRenderer buildRenderer(int color, PointStyle style, boolean fill) &#123; XYMultipleSeriesRenderer renderer = new XYMultipleSeriesRenderer(); //设置图表中曲线本身的样式，包括颜色、点的大小以及线的粗细等 XYSeriesRenderer r = new XYSeriesRenderer(); r.setColor(Color.RED);// r.setPointStyle(null);// r.setFillPoints(fill); r.setLineWidth(1); renderer.addSeriesRenderer(r); return renderer; &#125; /** * 设置图标的样式 * @param renderer * @param xTitle：x标题 * @param yTitle：y标题 * @param xMin：x最小长度 * @param xMax：x最大长度 * @param yMin:y最小长度 * @param yMax：y最大长度 * @param axesColor：颜色 * @param labelsColor：标签 */ protected void setChartSettings(XYMultipleSeriesRenderer renderer, String xTitle, String yTitle, double xMin, double xMax, double yMin, double yMax, int axesColor, int labelsColor) &#123; //有关对图表的渲染可参看api文档 renderer.setChartTitle(title); renderer.setXTitle(xTitle); renderer.setYTitle(yTitle); renderer.setXAxisMin(xMin); renderer.setXAxisMax(xMax); renderer.setYAxisMin(yMin); renderer.setYAxisMax(yMax); renderer.setAxesColor(axesColor); renderer.setLabelsColor(labelsColor); renderer.setShowGrid(true); renderer.setGridColor(Color.GREEN); renderer.setXLabels(20); renderer.setYLabels(10); renderer.setXTitle("Time"); renderer.setYTitle("mmHg"); renderer.setYLabelsAlign(Align.RIGHT); renderer.setPointSize((float) 3 ); renderer.setShowLegend(false); &#125; /** * 更新图标信息 */ private void updateChart() &#123; //设置好下一个需要增加的节点 if(flag==1) addY=10; else&#123;// addY=250; flag=1; if(gx&lt;200)&#123; if(hua[20]&gt;1)&#123; Toast.makeText(MainActivity.this, "请用您的指尖盖住摄像头镜头！", Toast.LENGTH_SHORT).show(); hua[20]=0;&#125; hua[20]++; return;&#125; else hua[20]=10; j=0; &#125; if(j&lt;20)&#123; addY=hua[j]; j++; &#125; //移除数据集中旧的点集 mDataset.removeSeries(series); //判断当前点集中到底有多少点，因为屏幕总共只能容纳100个，所以当点数超过100时，长度永远是100 int length = series.getItemCount(); int bz=0; //addX = length; if (length &gt; 300) &#123; length = 300; bz=1; &#125; addX = length; //将旧的点集中x和y的数值取出来放入backup中，并且将x的值加1，造成曲线向右平移的效果 for (int i = 0; i &lt; length; i++) &#123; xv[i] = (int) series.getX(i) -bz; yv[i] = (int) series.getY(i); &#125; //点集先清空，为了做成新的点集而准备 series.clear(); mDataset.addSeries(series); //将新产生的点首先加入到点集中，然后在循环体中将坐标变换后的一系列点都重新加入到点集中 //这里可以试验一下把顺序颠倒过来是什么效果，即先运行循环体，再添加新产生的点 series.add(addX, addY); for (int k = 0; k &lt; length; k++) &#123; series.add(xv[k], yv[k]); &#125; //在数据集中添加新的点集 //mDataset.addSeries(series); //视图更新，没有这一步，曲线不会呈现动态 //如果在非UI主线程中，需要调用postInvalidate()，具体参考api chart.invalidate(); &#125; //曲线 @Override public void onConfigurationChanged(Configuration newConfig) &#123; super.onConfigurationChanged(newConfig); &#125; @Override public void onResume() &#123; super.onResume(); wakeLock.acquire(); camera = Camera.open(); startTime = System.currentTimeMillis(); &#125; @Override public void onPause() &#123; super.onPause(); wakeLock.release(); camera.setPreviewCallback(null); camera.stopPreview(); camera.release(); camera = null; &#125; /** * 相机预览方法 * 这个方法中实现动态更新界面UI的功能， * 通过获取手机摄像头的参数来实时动态计算平均像素值、脉冲数，从而实时动态计算心率值。 */ private static PreviewCallback previewCallback = new PreviewCallback() &#123; public void onPreviewFrame(byte[] data, Camera cam) &#123; if (data == null) throw new NullPointerException(); Camera.Size size = cam.getParameters().getPreviewSize(); if (size == null) throw new NullPointerException(); if (!processing.compareAndSet(false, true)) return; int width = size.width; int height = size.height; //图像处理 int imgAvg = ImageProcessing.decodeYUV420SPtoRedAvg(data.clone(),height,width); gx=imgAvg; text1.setText("平均像素值是"+String.valueOf(imgAvg)); //像素平均值imgAvg,日志 //Log.i(TAG, "imgAvg=" + imgAvg); if (imgAvg == 0 || imgAvg == 255) &#123; processing.set(false); return; &#125; //计算平均值 int averageArrayAvg = 0; int averageArrayCnt = 0; for (int i = 0; i &lt; averageArray.length; i++) &#123; if (averageArray[i] &gt; 0) &#123; averageArrayAvg += averageArray[i]; averageArrayCnt++; &#125; &#125; //计算平均值 int rollingAverage = (averageArrayCnt &gt; 0)?(averageArrayAvg/averageArrayCnt):0; TYPE newType = currentType; if (imgAvg &lt; rollingAverage) &#123; newType = TYPE.RED; if (newType != currentType) &#123; beats++; flag=0; text2.setText("脉冲数是"+String.valueOf(beats)); //Log.e(TAG, "BEAT!! beats=" + beats); &#125; &#125; else if (imgAvg &gt; rollingAverage) &#123; newType = TYPE.GREEN; &#125; if (averageIndex == averageArraySize) averageIndex = 0; averageArray[averageIndex] = imgAvg; averageIndex++; // Transitioned from one state to another to the same if (newType != currentType) &#123; currentType = newType; //image.postInvalidate(); &#125; //获取系统结束时间（ms） long endTime = System.currentTimeMillis(); double totalTimeInSecs = (endTime - startTime) / 1000d; if (totalTimeInSecs &gt;= 2) &#123; double bps = (beats / totalTimeInSecs); int dpm = (int) (bps * 60d); if (dpm &lt; 30 || dpm &gt; 180||imgAvg&lt;200) &#123; //获取系统开始时间（ms） startTime = System.currentTimeMillis(); //beats心跳总数 beats = 0; processing.set(false); return; &#125; //Log.e(TAG, "totalTimeInSecs=" + totalTimeInSecs + " beats="+ beats); if (beatsIndex == beatsArraySize) beatsIndex = 0; beatsArray[beatsIndex] = dpm; beatsIndex++; int beatsArrayAvg = 0; int beatsArrayCnt = 0; for (int i = 0; i &lt; beatsArray.length; i++) &#123; if (beatsArray[i] &gt; 0) &#123; beatsArrayAvg += beatsArray[i]; beatsArrayCnt++; &#125; &#125; int beatsAvg = (beatsArrayAvg / beatsArrayCnt); text.setText("您的的心率是"+String.valueOf(beatsAvg)+" zhi:"+String.valueOf(beatsArray.length) +" "+String.valueOf(beatsIndex)+" "+String.valueOf(beatsArrayAvg)+" "+String.valueOf(beatsArrayCnt)); //获取系统时间（ms） startTime = System.currentTimeMillis(); beats = 0; &#125; processing.set(false); &#125; &#125;; /** * 预览回调接口 */ private static SurfaceHolder.Callback surfaceCallback = new SurfaceHolder.Callback() &#123; //创建时调用 @Override public void surfaceCreated(SurfaceHolder holder) &#123; try &#123; camera.setPreviewDisplay(previewHolder); camera.setPreviewCallback(previewCallback); &#125; catch (Throwable t) &#123; Log.e("PreviewDemo-surfaceCallback","Exception in setPreviewDisplay()", t); &#125; &#125; //当预览改变的时候回调此方法 @Override public void surfaceChanged(SurfaceHolder holder, int format, int width,int height) &#123; Camera.Parameters parameters = camera.getParameters(); parameters.setFlashMode(Camera.Parameters.FLASH_MODE_TORCH); Camera.Size size = getSmallestPreviewSize(width, height, parameters); if (size != null) &#123; parameters.setPreviewSize(size.width, size.height); // Log.d(TAG, "Using width=" + size.width + " height=" + size.height); &#125; camera.setParameters(parameters); camera.startPreview(); &#125; //销毁的时候调用 @Override public void surfaceDestroyed(SurfaceHolder holder) &#123; // Ignore &#125; &#125;; /** * 获取相机最小的预览尺寸 * @param width * @param height * @param parameters * @return */ private static Camera.Size getSmallestPreviewSize(int width, int height, Camera.Parameters parameters) &#123; Camera.Size result = null; for (Camera.Size size : parameters.getSupportedPreviewSizes()) &#123; if (size.width &lt;= width &amp;&amp; size.height &lt;= height) &#123; if (result == null) &#123; result = size; &#125; else &#123; int resultArea = result.width * result.height; int newArea = size.width * size.height; if (newArea &lt; resultArea) result = size; &#125; &#125; &#125; return result; &#125;&#125; 3、UI布局这里就不多说了，对于UI布局的实现，相信大家看了源码都懂得。 具体代码实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" xmlns:tools="http://schemas.android.com/tools" android:layout_width="match_parent" android:layout_height="match_parent" android:orientation="vertical" &gt; &lt;SurfaceView android:id="@+id/preview" android:layout_width="fill_parent" android:layout_height="200dp" android:layout_marginLeft="50dip" android:layout_marginRight="50dip" /&gt; &lt;LinearLayout android:id="@+id/linearLayout1" android:layout_width="match_parent" android:layout_height="200dp" android:orientation="vertical" &gt; &lt;/LinearLayout&gt; &lt;TextView android:id="@+id/text" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_marginLeft="50dip" android:layout_weight="1" android:text="@string/show" &gt; &lt;/TextView&gt; &lt;TextView android:id="@+id/text1" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_marginLeft="50dip" android:layout_weight="1" android:text="@string/show" &gt; &lt;/TextView&gt; &lt;TextView android:id="@+id/text2" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_marginLeft="50dip" android:layout_weight="1" android:text="@string/show" &gt; &lt;/TextView&gt; &lt;/LinearLayout&gt; 4、strings.xml12345678&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;resources&gt; &lt;string name="app_name"&gt;心率检测&lt;/string&gt; &lt;string name="action_settings"&gt;Settings&lt;/string&gt; &lt;string name="hello_world"&gt;Hello world!&lt;/string&gt; &lt;string name="show"&gt;显示&lt;/string&gt;&lt;/resources&gt;xxxxxxxxxx &lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;resources&gt; &lt;string name="app_name"&gt;心率检测&lt;/string&gt; &lt;string name="action_settings"&gt;Settings&lt;/string&gt; &lt;string name="hello_world"&gt;Hello world!&lt;/string&gt; &lt;string name="show"&gt;显示&lt;/string&gt;&lt;/resources&gt; 8. &lt;/resources&gt; 5、授权AndroidManifest.xml最后，我把授权文件贴出来吧。 具体代码实现如下： 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;manifest xmlns:android="http://schemas.android.com/apk/res/android" package="com.lyz.xinlv.activity" android:versionCode="1" android:versionName="1.0" &gt; &lt;uses-sdk android:minSdkVersion="15" android:targetSdkVersion="15" /&gt; &lt;uses-permission android:name="android.permission.WAKE_LOCK" /&gt; &lt;uses-permission android:name="android.permission.CAMERA" /&gt; &lt;uses-feature android:name="android.hardware.camera" /&gt; &lt;uses-feature android:name="android.hardware.camera.autofocus" /&gt; &lt;application android:allowBackup="true" android:icon="@drawable/ic_launcher" android:label="@string/app_name" android:theme="@style/AppTheme" &gt; &lt;activity android:name="com.lyz.xinlv.activity.MainActivity" android:label="@string/app_name" &gt; &lt;intent-filter&gt; &lt;action android:name="android.intent.action.MAIN" /&gt; &lt;category android:name="android.intent.category.LAUNCHER" /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;/application&gt; &lt;/manifest&gt; 至此，这个应用开发完成，亲们，是不是比想象的简单呢？ 三、运行效果]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>心率检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gson自定义序列化与反序列化]]></title>
    <url>%2F2018%2F07%2F28%2FGson%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言在使用Gson的时候我们经常需要根据自己的需求定义序列化和反序列化的规则，本文主要讲解如何优雅地进行Gson的序列化和反序列化。 序列化方法 实现 JsonSerializer 接口 注册自定义的序列化实现 demo 自定义UserInformationBeanSerializer并实现JsonSerializer接口 1234567891011121314151617181920212223public class UserInformationBeanSerializer implements JsonSerializer&lt;UserInformationBean&gt; &#123; @Override public JsonElement serialize(UserInformationBean userInformationBean, Type type, JsonSerializationContext jsonSerializationContext) &#123; JsonObject Server = new JsonObject(); JsonObject data = new JsonObject(); data.addProperty("report", getReport(userInformationBean)); data.addProperty("time", getTimeStr()); JsonObject pollData = new JsonObject(); data.add("pollData", pollData); JsonObject basicData = new JsonObject(); basicData.addProperty("gender", userInformationBean.getSex().ordinal() + ""); basicData.addProperty("payWay", "0"); data.add("basicData", basicData); Server.add("data", data); return Server; &#125;&#125; 注册自定义的UserInformationBeanSerializer 123456789UserInformationBeanSerializer userInformationBeanSerializer = new UserInformationBeanSerializer();Type IntListType = new TypeToken&lt;UserInformationBean&gt;() &#123;&#125;.getType();GsonBuilder builder = new GsonBuilder();builder.registerTypeAdapter(IntListType, userInformationBeanSerializer);Gson gson = builder.create();String datacontent = gson.toJson(userInformationBean); 反序列化方法 实现 JsonDeserializer 接口 注册自定义的反序列化实现 demo 自定义TcmJsonBeanDeserializer并实现JsonDeserializer接口 1234567891011121314151617181920212223242526272829303132public class TcmJsonBeanDeserializer implements JsonDeserializer&lt;TcmJsonBean&gt; &#123;@Overridepublic TcmJsonBean deserialize(JsonElement jsonElement, Type type, JsonDeserializationContext jsonDeserializationContext) throws JsonParseException &#123; JsonObject jsonObject = jsonElement.getAsJsonObject(); TcmJsonBean tcmJsonBean = new TcmJsonBean(); if (jsonObject.has("代茶饮")) &#123; tcmJsonBean.setDaiChaYin(jsonObject.get("代茶饮").getAsString()); &#125; if (jsonObject.has("体质类型")) &#123; tcmJsonBean.setDaiChaYin(jsonObject.get("体质类型").getAsString()); &#125; if (jsonObject.has("穴位按摩")) &#123; tcmJsonBean.setDaiChaYin(jsonObject.get("穴位按摩").getAsString()); &#125; if (jsonObject.has("运动")) &#123; tcmJsonBean.setDaiChaYin(jsonObject.get("运动").getAsString()); &#125; if (jsonObject.has("食疗")) &#123; tcmJsonBean.setDaiChaYin(jsonObject.get("食疗").getAsString()); &#125; return null; &#125; &#125; 注册自定义的反序列化实现 1234567891011121314151617String json = readFileToStringUtil.ReadJsonToString(filename); Gson gson = new Gson(); List&lt;JsonElement&gt; list = new ArrayList(); JsonParser jsonParser = new JsonParser(); JsonElement jsonElement = jsonParser.parse(json); //将json字符串转换成JsonElement JsonArray jsonArray = jsonElement.getAsJsonArray(); //将JsonElement转换成JsonArray Iterator it = jsonArray.iterator(); //Iterator处理 tcmJsonBeans = new ArrayList&lt;TcmJsonBean&gt;(); while (it.hasNext()) &#123; //循环 jsonElement = (JsonElement) it.next(); //提取JsonElement json = jsonElement.toString(); //JsonElement转换成String TcmJsonBean questionInJsonBean = gson.fromJson(json, TcmJsonBean.class); //String转化成JavaBean tcmJsonBeans.add(questionInJsonBean);&#125;return tcmJsonBeans;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Gson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用gradle打包指定类为jar包的方法]]></title>
    <url>%2F2018%2F07%2F27%2F%E4%BD%BF%E7%94%A8gradle%E6%89%93%E5%8C%85%E6%8C%87%E5%AE%9A%E7%B1%BB%E4%B8%BAjar%E5%8C%85%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在Android studio中通过gralde脚本打包指定类的为jar包的示例脚本： 打包某个包下的所有文件​123456789101112131415161718task clearJar(type: Delete) &#123; delete 'libs/sdk.jar' &#125; task makeJar(type:org.gradle.api.tasks.bundling.Jar) &#123; //指定生成的jar名 baseName 'sdk' //从哪里打包class文件 from('build/intermediates/classes/debug/org/cmdmac/cloud/pluginsdk/') //打包到jar后的目录结构 into('org/cmdmac/cloud/pluginsdk/') //去掉不需要打包的目录和文件 exclude('test/', 'BuildConfig.class', 'R.class') //去掉R$开头的文件 exclude&#123; it.name.startsWith('R$');&#125; &#125; makeJar.dependsOn(clearJar, build) 在build.gradle写上后，只要在命令行执行gradle makeJar就可以在build/libs目录下找到这个jar。 上面是个简单的例子，只能打包某个包下面的所有文件，如果要实现只打某个包下面的某些子包或者文件可参考如下示例 123456789task makeSdkJar(type:org.gradle.api.tasks.bundling.Jar) &#123; baseName 'pluginsdk' //只打包org.cmdmac下的org.cmdmac.pluginsdk.impl和org.cmdmac.gamecenter,其他子包不会被打包进去 from('build/intermediates/classes/debug/org/cmdmac/') &#123; include 'pluginsdk/impl' include 'gamecenter' &#125; into('org/cmdmac/')&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android控件设置透明度的三种方法]]></title>
    <url>%2F2018%2F07%2F27%2FAndroid%E6%8E%A7%E4%BB%B6%E8%AE%BE%E7%BD%AE%E9%80%8F%E6%98%8E%E5%BA%A6%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[需求有时会需要改变布局颜色透明度，比如设置控件（如View,Button等）的透明度，有3种方法。 实现方法java代码实现​12text = (TextView) findViewById(R.id.text);text.getBackground().setAlpha(12); setAlpha()的括号中可以填0–255之间的数字。数字越大，越不透明。 注意点：在5.0以上系统时，有些机型会出现莫名其妙的颜色值不起作用，变成透明了，也就是用此方法会导致其他共用一个资源的布局（例如：@color/white）透明度也跟着改变。比如text用上述方法设置成透明后，项目中，其他用到text颜色值的控件，都变成透明了。原因：在布局中多个控件同时使用一个资源的时候，这些控件会共用一个状态，例如ColorState，如果你改变了一个控件的状态，其他的控件都会接收到相同的通知。这时我们可以使用mutate()方法使该控件状态不定，这样不定状态的控件就不会共享自己的状态了。 ​1text.getBackground().mutate().setAlpha(12); 在xml布局中进行设置1234567&lt;TextView android:id="@+id/text" android:text="Hello World!" android:background="#987654" android:layout_width="match_parent" android:alpha="0.5" android:layout_height="100dp" /&gt; android:alpha的值为0~1之间的数。数字越大，越不透明。1表示完全不透明，0表示完全透明。 在xml布局中通过android:background设置123456&lt;TextView android:id="@+id/text" android:text="Hello World!" android:background="#80987654" android:layout_width="match_parent" android:layout_height="100dp" /&gt;123456 颜色和不透明度 (alpha) 值以十六进制表示法表示。任何一种颜色的值范围都是 0 到 255(00 到 ff)。对于 alpha，00表示完全透明，ff表示完全不透明。android:background的值的格式为”#AARRGGBB”。AA即透明度，R、G、B是红绿蓝三色。每一位均为0–F的十六位数。其中透明度的数值越大，越不透明。因此这里如果想设置透明度为50%的白色的话，可以如上设置。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>控件透明度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu18.04下若干软件无软件源导致安装失败解决方案]]></title>
    <url>%2F2018%2F07%2F10%2Fubuntu18.04%E4%B8%8B%E8%8B%A5%E5%B9%B2%E8%BD%AF%E4%BB%B6%E6%97%A0%E8%BD%AF%E4%BB%B6%E6%BA%90%E5%AF%BC%E8%87%B4%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[Ubuntu18.04在安装xx软件时出现错误 :仓库 “http://ppa.launchpad.net/xxx/xx/ubuntu bionic Release” 没有 Release 文件原因：ppa:xxx/xx 并没有18.04版本的源解决方法：修改/etc/apt/sources.list.d/xxx-bionic.list文件，将bionic（18.04版本代号）改成xenial（16.04版本代号）然后再执行 12sudo apt-get update sudo apt-get install xx]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Plist转Json的方法]]></title>
    <url>%2F2018%2F07%2F07%2FPlist%E8%BD%ACJson%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要plist，即property list，是苹果手机软件开发中经常用到的存储文件格式，其实质就是XML文件，但是它遵循一定的格式。比如包含一些指定的元素，如plist,array,string,key等。苹果提供了解析该类文件的机制，可惜在安卓开发工具中却没有提供。经常遇到的情况是，在开发苹果和安卓手机软件的时候，要统一资源文件,本文采取的解决方案是将plist转为json进而实现在android上的应用,方法如下: plist转json进入: http://json2plist.sinaapp.com/ 选中plist—&gt;json,将你需要转换的plist的内容粘贴进去点击convert: 格式化json点击convert之后的结果是这样的: 我们需要将其格式化,全选文本框中的内容,复制粘贴到: http://www.bejson.com/ 然后点击校验,结果如下:]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>plist</tag>
        <tag>json</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迅雷创始人程浩：流量、资本红利已成过去式，中国互联网下一个十年属于……]]></title>
    <url>%2F2018%2F06%2F22%2F%E8%BF%85%E9%9B%B7%E5%88%9B%E5%A7%8B%E4%BA%BA%E7%A8%8B%E6%B5%A9%EF%BC%9A%E6%B5%81%E9%87%8F%E3%80%81%E8%B5%84%E6%9C%AC%E7%BA%A2%E5%88%A9%E5%B7%B2%E6%88%90%E8%BF%87%E5%8E%BB%E5%BC%8F%EF%BC%8C%E4%B8%AD%E5%9B%BD%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%8B%E4%B8%80%E4%B8%AA%E5%8D%81%E5%B9%B4%E5%B1%9E%E4%BA%8E%E2%80%A6%E2%80%A6%2F</url>
    <content type="text"><![CDATA[中国过去 20 年互联网行业，为什么大多以模式创新为主？我认为核心原因有两点：第一是流量红利，第二是资本红利。首先这 20 年里，中国互联网人口从零开始激增到了近 8亿人。特别移动互联网的到来，大幅降低使用门槛，拿起智能手机划一划、戳一戳，谁都会用。除了抱在怀里的小孩和迟暮的老人，可以说大部分国人都互联网化了。 面对互联网人口激增带来的巨大流量红利，企业最核心竞争力是什么？就是如何收割流量和如何变现流量，技术发挥的作用并没有那么关键。这是第一个原因，巨大的流量红利，利好追逐规模效应的模式创新，这个时期是“一快遮百丑”。 第二原因就是资本红利。我几乎没听说过一个成功的互联网公司，从来没有做过融资。为什么过去资本偏爱这些模式创新的互联网公司？原因很简单：第一，这事儿容易看懂，甚至很多在美国都有对标的公司。第二，资本回报率高、回报周期短。就像滴滴出行，仅用3 年时间就干到了 100 多亿美元估值。这种依靠网络效应和平台效应，发展呈指数级增长，在技术创新项目上是不可能的，只有模式创新才可能办到。相对来讲，技术创新研发周期长，投入大，特别像芯片这样的业务还要面临全球竞争。回想起前些日子沸沸扬扬的中兴事件，经常有人问为什么 VC很少投芯片？一是看不懂，二是要求资金量大，三是回报周期很长。对大多市场化的资本来说，这个门槛其实是很高的。 其实有不少 VC 过去都投过芯片，但后来都没赚到什么大钱，大家自然就更愿意去投互联网了。从世界范围看其实也一样。现在全球市值最高公司的前 10 名里，有 7家公司是互联网公司，市值都超过了 4000 亿美元。 而全球第一大手机芯片供应商高通，目前的市值只有不足 900 亿美元。当然 NVIDIA 因为押中了人工智能这波浪潮，股价两年翻了 8 倍，才有了 1500亿美元的市值。但比起互联网公司来说仍然是小巫见大巫。所以我相信从美国资本市场来看，投入到芯片的基金，也远远少于投入到互联网或者模式创新公司的基金，这是由市场规律决定的。 PayPal 创始人彼得·蒂尔曾在《从 0 到 1》中举了一个经典的例子，他说 “我们想要飞行的汽车，结果却得到了 140 个字符。”大家知道这句话是什么意思吗？指的就是 Twitter，相当于中国的微博。其实也是在影射硅谷的硬科技创新也比较匮乏。 那么谈了这么多技术创新面临的压力挑战。为什么我们仍坚信下一个 10年，中国技术创新的时代已经到来？核心也是两点原因：第一，随着人口和流量红利消失，模式创新的一个重要前提被削弱了。 第二，我们必须要思考，传统互联网最大的价值是什么？互联网本质上是解决信息不对称，并提供连接。但国内很多行业，信息不对称和连接并不是痛点。例如医疗，我们把全中国的老百姓和三甲医院的大夫都连接了也没什么用，因为一个大夫一天还是只能看这么多病人。出行也是，互联网解决了打车难的问题，但没解决打车价格的问题，因为还是得由一个司机提供服务。 在这些领域，核心问题是生产效率，如何提高生产效率？只有靠技术创新。那么对于技术从业者，如何把握住未来中国技术创新这波大潮，我认为必须要克服一些技术人惯有的思维误区，在这里我总结了 7 条规律： 创业的赛道要建立在大势和红利之上要创业，不管谁选赛道，首先都要建立在一波大势、一波红利之上。我过去的经历告诉我，这样做绝对事半功倍，否则选错了只会事倍功半，你会发现做的特别累，而且特别慢。举个简单例子，早期在开放平台上发展起来的公众号、微博大V 等，都是借助了平台早期红利，现在再做微信公众号，涨粉是非常困难的，因为红利已经过去了。 BAT 为什么能成功？中国互联网人口爆发的流量红利。迅雷为什么能发展起来？宽带迅速普及带来的红利。TMD（头条、美团、滴滴），是得益移动流量爆发的红利。大家有没有发现一个很明显的规律，就是特别牛 X 的公司，他们成立的时间都是比较接近的，就像是一波波浪潮的感觉。 像 BAT 全是在1998-2000 年创立，TMD 大概是在 2010-2012年。这些公司成立的时间，正是流量红利刚刚开始的时候，所以大家成立时间都差不多，这是一个挺有意思的现象。 简言之，不管技术创业，还是模式创新的创业，最重要的是找到一波大势，找到一波红利。这不是机会主义，而是历史经验的总结。我觉得这才是性价比最高的创业。 那么在我看来，现在创业的核心赛道之一是人工智能，这也是远望资本关注的重点，我们高度关注人工智能在汽车、机器人、零售、金融等领域的应用。二是现下正热的微信小程序。要记住所有开放平台，都有它的早期红利。微信小程序是To C 的又一波社交流量红利。但创业者动作一定得快。因为早期红利的实效性是很短的，前期不抓住，这波就没了。 赛道选择不纠结技术主导，也不要有必须当老大的心态技术人创业，一定不要执着于技术主导，否则可能会选中一些发展很慢，很不性感的行业。所以这个顺序很重要，先选高速发展的行业才是第一位的。然后再看这个事到底是不是技术主导。如果是技术主导，完美；如果不是技术主导，也不要紧，你可以找合伙人嘛，甚至可以找CEO ，顺序一定不能乱。 为什么要找合伙人，因为我坚信每个赛道有每个赛道的基因： 如果这个行业是运营驱动的，那 CEO 必须是擅长运营的。所有内容型的项目几乎都是运营驱动的，例如电商、社区、门户（视频、新闻、头条）、电商。另外 O2O 也基本上都是运营驱动。这就是为什么 O2O 这波一来，阿里的人创业的比较多，因为基因是比较接近的。 运营驱动的项目，特点是产品变化频度没那么高，但是非常数据导向。我作为投资人，遇到运营驱动的项目，会问很多细节的业务指标，例如哪些是最重要的，哪些指标是正相关，哪些负相关，大的业务指标如何分解，等等。一个最简单的方法就是直接看数据后台。 如果这个行业是产品主导的，那么产品经理应该是 CEO。几乎所有的工具型产品都是产品主导，例如微信、360、猎豹、迅雷等等。这类项目的特点就需要不断迭代版本，不断研发增加新的功能，来满足用户的需求。我作为投资人，看产品驱动的项目，我首先会把产品仔细用一遍，然后和 CEO 讨论各种产品细节，了解他对用户需求的敏锐度，以及对产品细节的把控。如果这个事是技术驱动，那么懂技术者做 CEO 最合适。例如深科技的项目，CEO 必须有过硬的技术背景。作为VC，看这类项目也是比较累，我们虽然是技术背景，但也不可能对每个技术领域都了解的那么深入，有时候也会请教一些外脑和专家。 当然一个项目的基因有时候也不是那么绝对的。不是说一个运营类的项目，我运营很擅长其他就无所谓了。摩拜运营做的好，首先得产品过关，没产品就谈不上运营。游戏也是类似，游戏需要的也是产品和运营基因。迅雷这个事需要的是产品和技术基因。总之一个事能做多大，取决于最短的那块板，说白了就是“木桶原理”。 但是，总体而言，我们认为 CEO的基因必须要和赛道的基因相一致。换句话说，如果是纯技术背景的人，想做外卖，你会发现技术再牛，你用在外卖上也使不出多少劲儿。那怎么办？找个强运营背景的人做CEO。 所以技术人创业，不能舍本逐末，不要为了追求技术主导或者一定要当老大，而选择一个很不性感、或者天花板很低的赛道，那这事就没价值了。正确的姿势，首先选一个高速发展的行业，然后缺什么补什么样的合伙人。如果这个行业的基因和你个人的不相符，那就找一个CEO，自己做二把手。正如早期的滴滴不是一个技术驱动的公司，但如果你是张博，滴滴显然是一个最正确的决定。这个说起来容易，但其实做到很难，为什么？首先要求对自己有明确的认知 ，知道自己擅长什么，不擅长什么；其次要有能容人、甘居人下的宽广心胸。 To C 的 CEO 是首席产品经理， To B 的 CEO 是首席销售To C 创业公司的 CEO，通常都是首席产品经理。为什么？首先中国互联网 20年发展里，以模式创新为主导。即使是运营驱动的项目，也得先有产品，才有运营，所以 CEO 必须要有很好的产品思维。 当然这不代表我是一个技术创业者，我是一个码农，就不能成为首席产品经理或者首席销售。这样的例子比比皆是，马化腾也是技术出身，但他绝对是腾讯的首席产品经理。 我听说马化腾把腾讯所有产品都用过了。大家知道腾讯有多少个产品吗？我觉得至少有上千个，活的死的，见光死的和没见光就死的。如果说创业公司的 CEO是首席产品经理，这个相对容易做到，因为创业公司就一个产品你还不天天用？但是做得像腾讯这么大了，公司有各种管理各种人事，CEO 还能如此 Focus在产品上，这个是相当难得的。受此影响，整个腾讯都 Carry 了马化腾的产品基因。 所以我整体的感觉是，CEO的基因就是公司的基因。马化腾是产品基因，腾讯就是产品基因。李彦宏是技术基因，百度就是技术基因。我非常相信“基因决定论”，一个公司能做什么不能做什么，不是由他的主观意愿，而是由他的基因决定的。所以BAT 中每一个都把其他两家的事做了一遍（腾讯做了 soso 和易迅，百度做了百度 Hi 和有啊，阿里做了搜索和来往），但没有一个成功的。 说完了 To C，To B 这块更容易理解，To B 业务的 CEO通常来讲都是首席销售。很简单，因为公司很小的时候，第一单肯定是老板自己卖出去的，朋友也好，关系也好。特别一些大单，大单必须老板出马，如果只派一位销售总监，对方客户会觉得你不重视我。所以投资To B 企业我们要求 CEO具有销售基因。万一没有怎么办？那必须有一个强销售的合伙人。大家记住，要求是合伙人，必须有股份的那种，而不是随便找个人来负责销售就完了。 要用户／客户导向，永远不能纯技术导向对于技术创业者，永远要记住：技术是手段，不是目的。目的是满足用户／客户的需求，这个顺序是很清晰的。 所以在技术团队的考核上，如果是 To C 就必须得是用户导向， To B 就必须得是客户导向，记住永远都不能纯技术导向。 我举个简单的例子，我们之前做迅雷看看的时候，就犯了这样的错误。迅雷看看是我们的流媒体业务，对标优酷、爱奇艺。迅雷自身是个非常技术型的公司，我们当时定的KPI 就完全是技术导向的，也就是看传输的总数据量上 P2P 所占的比例。放到今天，大家都会觉得这个 KPI定的是很荒谬的，但当时一点都没觉得有什么问题，因为 P2P 就是迅雷最擅长的。 如果我们以用户体验为导向，应该要求缓冲时长要尽可能的短，中断率要尽可能的少。尽管 P2P的比例越高，带宽占用率就越低，我们的成本就越少，但这不是用户想要的。用户不 care 你的成本，不在乎流媒体的传输是来自 P2P还是服务器，他们只关心看视频流不流畅。而反观我们的竞争对手，他们非常简单粗暴—直接用服务器抗，虽然成本很高，但是比我们流畅。而且我们当时为了追求 P2P的比例，强制要求用户必须装插件，这简直就是把用户活生生的逼给对手。 所以不以用户需求为导向的 KPI，一定是错误的。后面我们把 KPI调成了两点：一个是首缓冲时长，就是点视频播放按钮，到视频开始播放花多长时间，这个要尽量的短；一个是每百小时播放过程的中断次数，这个要尽量的少。这两个 KPI才是保障用户流畅体验所需要的。 因此一定要记住，技术很重要，但最终的目的是服务用户。大家不要为了秀技术而使用技术，而是要让你的技术为商业服务。 技术领先≠ 商业成功一味的追求技术领先，可能会给你带来很多其他问题，例如成本过高，或者可靠性不够，或者你的产品只能停留在实验室，无法大规模商业化等等。 我做 VC经常遇到这样的问题。技术给我讲的非常酷，一谈到成本，说卖给客户三年回不了本，这个就属于典型的太超前了。除非能明显的看到未来有一个显著的降价空间。否则的话，说明你这个事情做的太早了。这样就很容易成为前浪被拍死在沙滩上的那一波。 事实上，很多技术领先的东西最后都死掉了，例如协和式飞机，比现在的波音客机速度快 2倍多，牛吧？但就因为成本高导致价格太贵（一个经济舱的票价和波音的商务舱差不多），同时可靠性不够，发生了一次空难以后，就没有航空公司再给他下订单了，最终破产。 还有 1980 年代末，摩托罗拉耗资 34 亿美元（注意是上个世纪的 34亿美元）打造的铱星计划，这些星群的信号可以覆盖地球的任意一个角落，无论你是地球的哪里，都可以通过星群向世界各地传递信息。但问题是什么呢？太贵，一分钟十几美金的那种贵，最终也失败了。 这些都是很典型的例子，说明技术领先不一定代表商业成功。 技术创业要做“全栈”，不只做“技术提供商”这个话题我之前在《人工智能只做技术服务商死路一条》中讲过，就不具体展开了，简单提几点： 技术型创业公司如果不直接面向用户 / 客户提供整体解决方案，则非常容易被上下游碾压。 因为客户是别人的，你只是整体方案的一部分。今天我可以用你的方案，明天可以不用你的，可以用你竞争对手的，也可以自己搞。如果你的技术壁垒不够高，上游很可能直接把你的事做了，这样的例子比比皆是。 即使在技术门槛很高的行业，技术提供商的日子也不好过，高通和 MTK 这几年日子都不好过，因为苹果、华为、三星、小米有了规模效益都在做自己的芯片。做技术提供商最怕上游太集中，上游有了规模效益一定会自己搞。 如果一个产业链有很多环节，在某一个环节有一个垄断者，那么这个垄断者就有向上下游延展的机会和动力，即使不延展也会把整个产业链的大部分利润吃掉。例如 PC 产业链，做整机的不赚钱，做显示器的不赚钱，做硬盘的不赚钱，赚钱的只有微软和 Intel。 正确的姿势是不能单纯停留在技术服务商层面，而是要把你的技术产品化、然后搞定用户 / 客户实现商业变现、然后获得更多的数据，这样才能再夯实你的技术。一句话讲，要做技术、产品、商业和数据的“全栈”，形成闭环！ “关键性应用”技术创业要耐住寂寞“关键性应用”就是要追求 99% 后面的多个9，一丁点不能犯错的领域，比如自动驾驶和手术机器人。关键性应用创新有一个普遍特点，就是研发投入巨大，周期极长，而且离钱远。 像以色列有一家公司 Mobileye，坚持了 8 年时间才等到产品正式商用。包括谷歌无人车从 2009年开始研发，到现在一直没有商业化；达芬奇手术机器人从启动研发到 2000 年拿到美国食品药品管理局（FDA）的认证，花了十年时间。。 这些在互联网创业里简直不可想象。所以在“关键性应用”领域里创业，首先必须是“高富帅”（大伙看看自己是不是，如果不是就别选这个领域了），因为只有高富帅才能持续融资。 更重要的是必须要有韬光养晦的心态。千万别幻想说这个公司咱做三年，就多少收入，多少估值就去纳斯达克敲钟了，这完全不靠谱。如果你选择了关键性应用作为你的赛道，记住，前三年你可能一分钱收入都没有，所以大家必须得做好8 年抗战的准备，再做这个事。 作者介绍程浩，迅雷（NASDAQ：XNET）创始人，中国互联网行业最早的从业者和开拓者，曾先后在硅谷和百度工作，2003 年联合创办迅雷，并于 2014年在美国纳斯达克上市。程浩先生在科技互联网领域拥有极高的影响力和丰富的高端人脉资源，也是国内人工智能和互联网创业领域的权威专家。目前成立远望资本，目标打造下一支“红杉”（远望资本是一支专注中国科技互联网领域发展的人民币早期基金，主要投资阶段为天使轮和A 轮，聚焦于人工智能与车、机器人、企业服务、金融技术、医疗等行业的结合）。程浩先生拥有南开大学数学系学士学位和美国杜克大学计算机系硕士学位。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What is RNN and LSTM?]]></title>
    <url>%2F2018%2F06%2F22%2FWhat%20is%20RNN%20and%20LSTM%3F%2F</url>
    <content type="text"><![CDATA[摘要本文将介绍一种常用的神经网络—循环神经网络(Recurrent Neural Network,RNN)以及循环神经网络的一个重要的变体—长短时记忆网络(Long Short-Term Memory,LSTM). 循环神经网络循环神经网络的主要用途是处理和预测序列数据.传统的卷积神经网络(CNN)或者全连接神经网络(FC)都是从输入层到隐含层再到输出层,层与层之间是全连接或部分连接的,但是每层之间是没有连接的.考虑这样一个问题,要预测一个句子的下一个单词是什么,比如当前单词是”很”,前一个单词是”天空”,那么下一个单词大概是”蓝”.循环神经网络会记忆之前的信息,并利用之前的信息影响后面节点的输出.也就是说,循环神经网络的隐藏层之间的结点是有连接的,隐藏层的输入不仅包括输入层的输出,还包括上一时刻隐藏层的输出.如下图所示:这是一个典型的循环神经网络.对于循环神经网络一个重要的概念就是时刻.循环神经网络会对每一个时刻的输入结合当前模型的状态给出一个输出.从图中可以看到,循环神经网络的主体结构A的输入除了来自输入层X_t,还有一个循环的边来提供当前时刻的状态.在每个时刻,循环神经网络的模块A会读取t时刻的输入X_t,并输出一个值h_t,同时A的状态会从当前步传递到下一步.因此,循环神经网络理论上可以看做是同一神经网络结构被无限复制的结果.但是处于优化的考虑,目前循环神经网络无法做到真正的无限循环,所以现实中一般会将循环体展开,得到下图:从循环神经网络的结构特征可以很容易看出它所擅长解决的问题是与时间序列相关的,循环神经网络也是处理这类问题最自然的神经网络结构.对于一个序列数据,可以将这个序列上不同时刻的数据依次传入循环神经网络的输入层,而输出可以是对序列中下一个时刻的预测,也可以是对当前时刻信息的处理结果(比如语音识别结果).循环神经网络要求每一个时刻都有一个输入,但是不一定每一个时刻都需要有输出. 如前所述,循环神经网络可以被看做是同一神经网络结构在时间序列上被复制多次的结果,这个被复制多次的结构被称之为结构体.如何设计循环体的网络结构是循环神经网络解决实际问题的关键,类似卷积神经网络参数共享的原则,循环神经网络结构中的参数在不同时刻也是共享的. 如图:上图展示了一个使用最简单的循环神经网络结构的循环神经网络,在这个循环体中只用了一个类似全连接层的神经网络结构.循环神经网络中的状态是通过一个向量来表示的,假设其为h,这个向量的维度也称为循环神经网络隐藏层的大小.假设输入向量的维度为x,那么上图中循环体的全连接层神经网络的输入大小为h+x.也就是将上一时刻的状态与当前时刻的输入拼接成一个大的向量作为循环体中神经网络的输入,因为该神经网络的输出为当前时刻的状态,于是输出层的节点个数也为h,循环体中的参数个数为(h+x)*h+h个.循环体中的神经网络输出不仅提供给下一时刻作为状态,也会提供给当前时刻的输出.为了将当前时刻的状态转化为最终的输出,循环神经网络还需要另外一个全连接神经网络来完成这个过程.这和卷积神经网络最后的全连接层的意义是一样的.为了利于大家理解循环神经网络钱箱传播的过程,这里举一个简单的例子,如图:在上图中,假设状态的维度为2,输入/输出的维度为1,而且循环体中的全连接层的权重为: W_{rnn}=\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix}偏置项的大小为 B_{rnn}=\begin{bmatrix} 0.1&-0.1 \end{bmatrix}用于输出的全连接层权重为 W_{output}= \begin{bmatrix} 1.0 \\ 2.0\\ \end{bmatrix}偏置项大小为$B_{output}$=0.1.那么在t0时刻,因为没有上一时刻,所以将状态初始为[0,0],而当前输入为1,所以拼接得到的向量为[0,0,1],通过循环体中的全连接层神经网络得到的结果为: tanh\{[0,0,1]\times\begin{bmatrix} 0.1&0.2\\ 0.3&0.4\\ 0.5&0.6 \end{bmatrix}+[0.1,-0.1]\}=tanh([0.6,0.5]=[0.537,0.462])将这个结果作为下一个时刻的输入状态,同时循环神经网络也会使用该状态产生输出.将该向量作为输入提供给用于输出的全连接层神经网络可以得到t0时刻的最终输出: [0.537,0.462]\times\begin{bmatrix}{1.0 \\2.0}\end{bmatrix}+0.1=1.56使用t0时刻的状态可以类似地推导得出t1时刻的状态为[0.860,0.884],而t1时刻的输出为2.73. 得到神经网络的前向传播结果之后,可以和其他神经网络类似地定义损失函数.循环神经网络唯一的区别在于因为它每个时刻都有一个输出,所以循环神经网络的总损失为所有时刻(或者部分时刻)上的损失函数的和.理论上循环神经网络可以支持任意序列长度的序列,然而在实际中,如果序列过长会导致优化时出现梯度消散的问题,所以实际中一般会规定一个最大长度,当序列超过规定长度之后会对序列进行截断. 长短时记忆网络(LSTM)结构在有些情况下,模型仅仅需要短期内的信息来执行当前的任务,比如预测短语”大海的颜色是蓝色”中最后一个单词”蓝色”的时候,模型不需要记忆这个短语之前更长的上下文信息,因为这一句话已经包含了足够的信息来预测最后一个词,在这种情况下循环神经网络可以比较容易地利用先前的信息.但是同样也有一些上下文场景更加复杂的情况.比如当模型去预测”某地开设了大量的工厂,空气污染十分严重……这里的天空是灰色的”的最后一个单词的时候,仅仅根据短期依赖就无法很好地解决这种问题.因为只根据最后一段,最后一个词可以是”蓝色的”或者”黑色的”.如果模型要预测清楚具体是什么颜色,就需要考虑先前提到的离当前位置较远的上下文信息.因此,当前预测位置和相关信息之间的文本间隔就有可能变的很大.当这个间隔很大时,上文中的循环神经网络就有可能丧失学习到距离如此远的信息的能力.或者在复杂语境中,有用信息的间隔有大有小,长短不一,循环神经网络的性能也会受到限制. 长短时记忆网络(long short termmemory,LSTM)的设计就是为了解决这个问题的,而且循环神经网络被广泛应用的关键就是LSTM,在很多任务上,采用LSTM结构的神经网络比标准的循环神经网络表现的更好.如上图所示,LSTM靠一些”门”的结构让信息有选择地影响循环神经网络中每个时刻的状态.所谓”门”的结构就是一个使用sigmoid神经网络和一个按位做乘法的操作,这两个操作合在一起就是一个”门”的结构.之所以该结构叫”门”是唯一能使用sigmoid作为激活函数的全连接层神经网络层会输出一个0到1之间的数值,描述当前输入有多少信息量可以通过这个结构.于是这个结构就类似于一个门,当门打开时(sigmoid神经网络的输出为1时),全部信息可以通过;当门关上时(sigmoid神经网络的输出为0时),任何信息都无法通过.具体的每一个门的工作原理如下:为了使循环神经网更有效的保存长期记忆,图中“遗忘门”和“输入门”至关重要,它们是LSTM结构的核心.“遗忘门”的作用是让循环神经网络“忘记”之前没有用的信息.比如一段文章中先介绍了某地原来是绿水蓝天,但后来被污染了.于是在看到被污染了之后,循环神经网络应该“忘记”之前绿水蓝天的状态.这个工作是通过“遗忘门”来完成的.“遗忘门”会根据当前的输入$Xt$和上一时刻的状态$C{t-1}$和上一时刻的输出$H{t-1}$共同决定哪一部分记忆需要被遗忘.在循环神经网络“忘记”了部分之前的状态后,它还需要从当前的输入补充最新的记忆.这个过程就是“输入门”完成的.“输入门”会根据$X_t$、$C{t-1}$和$H{t-1}$决定哪些部分将进入当前时刻的状态$C_t$。比如当看到文章中提到环境被污染之后，模型需要将这个信息写入新的状态。通过“遗忘门”和“输入门”，LSTM结构可以更加有效的决定哪些信息应该被遗忘，哪些信息应该得到保留。LSTM结构在计算得到新的状态$C_t$后需要产生当前时刻的输出，这个过程是通过“输出门”完成的。“输出门”会根据最新的状态$C_t$以及上一时刻的输出$H{t-1}$和当前的输入$X_t$来决定该时刻的输出$H_t$。比如当前的状态为被污染，那么“天空的颜色”后面的单词很可能就是“灰色的”。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>RNN</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android解决Gradle sync failed java.lang.AssertionError Invalid libraryOrderEntry错误]]></title>
    <url>%2F2018%2F06%2F19%2Fandroid%E8%A7%A3%E5%86%B3Gradle%20sync%20failed%20%20java.lang.AssertionError%3A%20Invalid%20libraryOrderEntry%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[File &gt; Invalidate Caches/Restart]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Error:Execution failed for task 'app:preDebugAndroidTestBuild'.解决方案]]></title>
    <url>%2F2018%2F06%2F18%2FError%3AExecution%20failed%20for%20task%20'%3Aapp%3ApreDebugAndroidTestBuild'.%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[报错如下:解决方法很简单:Rebuild,你懂的]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Studio gradle无法下载解决方案]]></title>
    <url>%2F2018%2F06%2F18%2FAndroid%20Studio%20gradle%E6%97%A0%E6%B3%95%E4%B8%8B%E8%BD%BD%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[ubuntu下打开~/.gradle/wrapper/dists,可以看到类似下图:然后打开:http://services.gradle.org/distributions/ 找到你的目录下的gradle版本并点击下载将下载到的压缩包放到类似~/.gradle/wrapper/dists/gradle-4.4-all/9br9xq1tocpiv8o6njlyu5op1目录下,不需要解压,直接把压缩包放进去就可以,然后重启as就可跳过gradle的在线下载]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android Studio</tag>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Studio解决org.gradle.api.resources.ResourceException Could not get resource]]></title>
    <url>%2F2018%2F06%2F18%2FAndroid%20Studio%E8%A7%A3%E5%86%B3org.gradle.api.resources.ResourceException%3A%20Could%20not%20get%20resource%2F</url>
    <content type="text"><![CDATA[报错信息如下: ​1Caused by: org.gradle.api.resources.ResourceException: Could not get resource ‘https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/3.1.0/gradle-3.1.0.pom 7 解决方案:]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>Android Studio</tag>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python matplotlib实现动图绘制]]></title>
    <url>%2F2018%2F06%2F13%2F%E4%BD%BF%E7%94%A8python%20matplotlib%E5%AE%9E%E7%8E%B0%E5%8A%A8%E5%9B%BE%E7%BB%98%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言想写数据动态可视化很久了，但是网上竟然没有一份能直接用的代码，昨天终于狠下心来死啃了一波开发者文档搞定了这部分，贴一篇blog记录一下希望可以帮到你。 思路动图的核心函数是matplotlib.animation.FuncAnimation，基本用法： ​123456789anim = animation.funcanimation(fig, animate, init_func=init, frames=100, interval=20, blit=true)# fig: 是我们创建的画布# animat: 是重点，是我们每个时刻要更新图形对象的函数，返回值和init_func相同# init_func: 初始化函数，其返回值就是每次都要更新的对象，# 告诉FuncAnimation在不同时刻要更新哪些图形对象# frames: 相当于时刻t，要模拟多少帧图画，不同时刻的t相当于animat的参数# interval: 刷新频率，毫秒# blit: blit是一个非常重要的关键字，它告诉动画只重绘修改的部分，结合上面保存的时间，# blit=true会使动画显示得会非常非常快 动图绘制的关键是动态更新数据并刷新图像，更新数据需要写一个animat函数，看具体实现： 实现给出代码及对应注释，你应该会秒懂： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# -*-coding:utf-8-*-import randomfrom matplotlib.backends.backend_agg import FigureCanvasfrom matplotlib import pyplot as pltfrom matplotlib import animationimport numpy as npimport seaborn as snsfrom matplotlib.image import imreadgesture_i = [0] * 2200gesture_q = [0] * 2200acc_first = [0] * 6acc_second = [0] * 6acc_first_max_index = 0acc_second_max_index = 0acc_first_max = 0acc_second_max = 0cur_data_count = 0update_first_flag = Falseupdate_second_flag = Falsename_list = ["Static", "Approach", "Apart", "Click", "Flip", "Circle"]# 创建画布，包含4个子图fig = plt.figure(figsize=(15, 10))bgimg=imread("bac2.jpg")#设置背景图片fig.figimage(bgimg,resize=True)#设置窗口自适应（背景图片）ax1 = fig.add_subplot(2, 2, 1)ax1.set_facecolor('none')#设置该子图背景透明，其他子图同理ax2 = fig.add_subplot(2, 2, 3)ax2.set_facecolor('none')ax3 = fig.add_subplot(2, 2, 2)ax3.set_facecolor('none')ax4 = fig.add_subplot(2, 2, 4)ax4.set_facecolor('none')# 绘制初始图形bar1 = ax3.bar(range(len(acc_first)), acc_first, color='rgb', tick_label=name_list)bar2 = ax4.bar(range(len(acc_first)), acc_first, color='rgb', tick_label=name_list)x = np.arange(0, 2200, 1) # x轴ax1.set_ylim(-1, 1)#设置y轴范围为-1到1line1, = ax1.plot(x, gesture_i,color='coral')ax2.set_ylim(-1, 1)line2, = ax2.plot(x, gesture_q,color='coral')#初始化函数def init(): # 构造开始帧函数init # 改变y轴数据，x轴不需要改 line1.set_ydata(gesture_i) line2.set_ydata(gesture_q) bar1 = ax3.bar(range(len(acc_first)), acc_first, color='rgb', tick_label=name_list) bar2 = ax4.bar(range(len(acc_second)), acc_second, color='rgb', tick_label=name_list) ax1.set_xlabel("I") ax2.set_xlabel("Q") return line1, line2, ax1 # 注意返回值，我们要更新的就是这些数据#更新图像的函数def animate(i): #注意这里必须要用global声明，不然可能出现无法动态更新数据的情况 global gesture_i global gesture_q global update_first_flag global update_second_flag line1.set_ydata(gesture_i) ax3.cla() bar1 = ax3.bar(range(len(acc_first)), acc_first, color='rgb', tick_label=name_list) ax3.legend() ax4.cla() bar2 = ax4.bar(range(len(acc_second)), acc_second, color='rgb', tick_label=name_list) ax4.legend return line1, line2, ax1def draw_view():# 调用FuncAnimation函数生成动画。参数说明：# fig 进行动画绘制的figure# func 自定义动画函数，即传入刚定义的函数animate# frames 动画长度，一次循环包含的帧数# init_func 自定义开始帧，即传入刚定义的函数init# interval 更新频率，以ms计# blit 选择更新所有点，还是仅更新产生变化的点。应选择True，但mac用户请选择False，否则无法显示动画 ani = animation.FuncAnimation(fig=fig, func=animate, frames=100, init_func=init, interval=100, blit=False) plt.show()if __name__ == '__main__': draw_view() 说明：实现动态数据可视化的思路是将绘制图像所用的数据写成全局变量，然后动态更新你的数据，UI层会一帧一帧地刷新图像，这样只要你的数据在变，图像就会是变化的，给一张效果图：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
        <tag>动图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python搭建服务器并实现Android端与之通信]]></title>
    <url>%2F2018%2F06%2F13%2F%E4%BD%BF%E7%94%A8python%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B9%B6%E5%AE%9E%E7%8E%B0Android%E7%AB%AF%E4%B8%8E%E4%B9%8B%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[前言好久没有更技术文了，再不写怕是博客要废掉了，今天更一篇关于搭建服务端并与Android端通信的文章，为了节省代码量，服务端使用Python Flask，Android端使用Okhttp，还是老样子，文章不讲原理只给具体实现，想要了解原理可至官网详细研究。 服务端环境：服务端使用Python3.5+PyCharm 新建Flask项目看图：然后create，初始化完成之后项目结构应该类似如下：其实这时候直接启动项目就可以在浏览器访问到： 这就是使用现成框架的好处hhh，但是我们希望实现与客户端的通信，自然需要再做进一步code. 编写代码接受来自客户端的数据首先我们看一下hello_world的代码： ​123@app.route('/')def hello_world(): return 'Hello World!' 这里@app.route(‘/’)意思就是访问你服务端地址时调用这个方法，所以我们可以通过这种方式实现自己的需求，比如： ​12345@app.route('/demo', methods=['POST'])def demo(): value = request.form['demo_tag'] print(value) return "ok" 上面代码的意思就是你可以通过 http://127.0.0.1:5000/demo 访问到demo方法，request.form[‘demo_tag’]的返回值是你客户端发送的tag为demo_tag的数据，下文会详细介绍如何发送数据，最后返回值你可以自己指定，这里随便给了一个。到这里服务端已经ok了，我们看看客户端如何实现. Android端客户端使用Okhttp，需要导入两个jar包，地址jar包下载地址： http://square.github.io/okhttp/ 注意2个jar包都要，图中3个圈点完就ok了，下载到本地自己导入，这部分就不详细写了，不会导入的可以Google一下。 如果不想手动导入jar包可以: ​ implementation ‘com.squareup.okhttp3:okhttp:3.11.0’ 导入之后直接看代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586@Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); ok = findViewById(R.id.ok); username = findViewById(R.id.username); password = findViewById(R.id.password); ok.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; String name = String.valueOf(username.getText()); String pass = String.valueOf(password.getText()); String url = "http://112.86.199.151:5000/gesture";//替换成自己的服务器地址 SendMessage(url, name, pass); &#125; &#125;); &#125; private void SendMessage(String url, final String userName, String passWord) &#123; value = new float[550]; Random random = new Random(); for (int i = 0; i &lt; 550; i++) &#123; if (i % 2 == 0) &#123; value[i] = random.nextFloat(); &#125; else &#123; value[i] = -random.nextFloat(); &#125; &#125; String str_value = FloatArrayToString(value); OkHttpClient client = new OkHttpClient(); FormBody.Builder formBuilder = new FormBody.Builder(); formBuilder.add("demo", str_value); Request request = new Request.Builder().url(url).post(formBuilder.build()).build(); Call call = client.newCall(request); call.enqueue(new Callback() &#123; @Override public void onFailure(Call call, IOException e) &#123; runOnUiThread(new Runnable() &#123; @Override public void run() &#123; runOnUiThread(new Runnable() &#123; @Override public void run() &#123; Toast.makeText(MainActivity.this, "服务器错误", Toast.LENGTH_SHORT).show(); &#125; &#125;); &#125; &#125;); &#125; @Override public void onResponse(Call call, final Response response) throws IOException &#123; final String res = response.body().string(); runOnUiThread(new Runnable() &#123; @Override public void run() &#123; if (res.equals("0")) &#123; runOnUiThread(new Runnable() &#123; @Override public void run() &#123; Toast.makeText(MainActivity.this, "失败", Toast.LENGTH_SHORT).show(); &#125; &#125;); &#125; else &#123; runOnUiThread(new Runnable() &#123; @Override public void run() &#123; Toast.makeText(MainActivity.this, "成功"+res, Toast.LENGTH_SHORT).show(); &#125; &#125;); &#125; &#125; &#125;); &#125; &#125;); &#125; 我这里随机生成了一个数组并将其发送到了服务器端，核心代码很简单，有框架真的可以为所欲为，写不动了吃饭去了，也许有心情会再更的详细点，给份现成代码自己研究研究吧： https://github.com/DmrfCoder/OkHttpDemo]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《微反应》]]></title>
    <url>%2F2018%2F06%2F11%2F%E3%80%8A%E5%BE%AE%E5%8F%8D%E5%BA%94%E3%80%8B%2F</url>
    <content type="text"><![CDATA[关于作者姜振宇，中国政法大学中国法律信息中心主任，著名测谎专家，领导着国内首家应用微反应理论进行测谎的研究团队。 关于本书《微反应》是姜振宇及其团队经过5年研究，与8家司法科研机构合作，在一万多条测试数据的基础上写成的，对微反应进行了系统的分析和归类，并融入了大量常见的生活案例，非常便于应用。了解这些“微反应”，不仅可以有效地判断谎言，识别伪装，还可以从自身的微反应中发现自己没有意识到的情绪，帮助你更好地认识自己。 核心内容 什么是微反应； 常见的微反应类型及其背后的心理机制。 什么是微反应人在面对突发情况和刺激时，不由自主地表现出的微小反应，它源于 人的生存本能。人和动物的不同，是在长期进化中发展了智力，可以有意识地控制自己的反应和行为，甚至可以很好地伪装自己的真实反应。然而，在受到突然的刺激和威胁时，由于生存本能的强大作用，人会在极短的时间内退回动物的水平，出现种种瞬间的、微小的动作或表情。 常见的微反应类型及其背后的心理机制冻结反应是人在惊讶、恐惧的心理状态下产生的微反应。在遇到意外的情况时，本能地减少动作，保持不动。（1）面部惊讶 人在惊讶时，往往会面部呆滞，眼睛睁大，嘴巴微张，这其实就是冻结的一种表现。（2）呼吸控制呼吸的冻结反应，是不自觉地屏住呼吸或者放慢呼吸。（3）手脚约束女性常见的动作是把双手拉住放在身前，男性常见的动作则是把双手拉住放在身后，或者插在裤兜里。脚的拘束最常见的是把双腿固定成一种不能乱动的状态，比如把两腿并拢别在椅子背后；而在站姿中，则表现为双腿并拢挺直，肌肉紧张，不敢轻松随意地叉开双腿站立。 安慰反应（1）视觉安慰视线转移。婴儿会更喜欢看对他笑的人，而板起脸的人，会让婴儿转过头去甚至啼哭。而当一个成年人感到负面情绪时，往往会下意识地转移视线，减少目光接触，降低受到的负面刺激，而下一步，可能是看向自己比较熟悉，或者能让自己感到安全的地方。（2）口唇安慰紧张时大口喝水、吸烟、咬铅笔等等。在潜意识中告诉自己：“不要怕，没关系，现在我有充足的食物，我在吃东西，我很安全。”（3）皮肤安慰最常见的皮肤安慰集中在头部、脸部，这是因为这两个部位距离大脑很近，而且布满了血管和神经，非常敏感。对这个区域进行安慰动作，效果最快。比如，挠头往往用来缓解尴尬，抚摸鼻子和嘴，揉搓脖子可以有效地消除不安。手部和胸腹部的微反应，比较常见的动作是搓手、反复交错手指，抚摸手背，背后隐藏的是焦虑。对胸腹部皮肤的安慰，也会使人产生许多微反应，比如抓住衣领或者按住胸口，让压力得以缓解。 逃离反应遇到危险逃跑是生物的本能，逃离反应是逃跑行为的变形。比如，人在焦急紧张的时候会跺脚，忧虑的时候会来来回回地在房间里走，都是内心想要逃跑的表现。（1）视觉逃离视觉逃离和视觉安慰的区别是，视觉安慰是让视线离开负面刺激，下一步通常是寻找积极的刺激。而视觉逃离往往没有下一步动作，只是因为想要逃离危险，这就是为什么视觉逃离往往表现为眼神飘忽不定，这说明了对方的心虚。（2）角度扭转双腿倾斜变成双腿并拢直立，是逃离的准备动作。在坐姿上，翘二郎腿是比较轻松舒适的坐姿，而当对方感到不快或者受到威胁时，典型的微反应是收起二郎腿，把双脚一前一后摆好，还有可能用双手撑住座椅。在站姿上，当某人想要逃离的时候，会把双脚的位置调整成一前一后，而不会同时面向让他感到威胁的方向。双脚一前一后，其实正是一种起跑的姿态。头部转移，对方把头转向一边，好像在观察别的地方，稍后再转回头来，保持微笑，好像是告诉你“我还在听”，过了一会儿却又把头转开。这也是一种逃离的表现，它隐含的语言是：“这个话题我不感兴趣”。 仰视反应（1）仰头或低头下巴抬高，头向后仰，心理的状态是不屑和傲慢。满意、骄傲时，也常常是微微抬头的状态。低头表示谦卑和服从。如果在低头时，对方的背依旧是挺直的，他的心里通常是服从但不服气。如果在低头时，背部是弯曲的，而身体的其他部分也表现出向地弯曲的状态，那么可以基本判定，对方没有反抗的心态。（2）拥抱标准的拥抱是双方的身体正面贴在一起，手臂搂住对方并且向自己一方用力；而违心的拥抱，是对胸部以下距离的控制。如果两个人面带笑容地走到一起，热情地拥抱对方，但是在抱在一起的时候，只有肩部和头部贴在一起，而胸部以下并不接触，也就是说，双方都有点驼着背在拥抱，这其实是有意让躯干和腿远离对方，这也暴露了内心的疏远。 领地反应动物会用味道来圈定自己的领地，而人圈定领地的方式是一些微小的姿态和动作。观察这些微反应，可以及时把握人际交往的距离。领地反应有两个表现，一是在领地里展示权威，二是在领地外表示防御。（1）在领地里展示权威双腿叉开，两臂张开，拳头向下，让自己所占的面积扩大，起到威慑的作用。（2）在领地外表示防御，抱起双臂，交叉胸前。肌肉的收缩和重叠，可以让上身看起来更加魁梧，增加威慑的效果。无论是两臂张开，还是抱起双臂，都可以帮你判断出对方产生了戒备心理。 战斗反应这种微反应的背后往往是愤怒的情绪。在所有的情绪中，愤怒是最难控制的一种情绪，一旦被唤醒，会调动全身上下的战斗状态来应对威胁，也会消耗最多的身体能量。（1）脸部的战斗反应眼睛瞪大，鼻孔张大，眉头紧皱，咬牙切齿。整个脸部的肌肉都变为紧张状态，这就是为什么，我们会形容一个人的脸“因为愤怒而扭曲”。（2）身体的战斗反应身体绷紧，双拳握紧，准备迎战。 案例某个单位为了测试员工的心理水平，设计了一场比赛，每回答对一道题目，答题者就会获得相应的奖金，同时可以选择继续答题或放弃，如果继续答题并回答错误，之前的奖金就会一笔勾销。比赛中有一位女士，连续答对了很多问题，但随着问题的难度逐渐加大，她犹豫要不要回答下一道问题的时间也越来越长。研究员认为，她还会选择继续答题。因为这位女士的拳头频频用力握紧，呈现出经典的战斗预备反应，说明还在调动身体的全部能量，打算继续接受挑战，而不会中途放弃。果然，这位女士选择继续答题。（3）手指的微动作战斗反应在手指上的动作，最经典的表现就是去指别人。如果对方在说话时，下意识地用力用手指点，基本可以判断对方正处在愤怒之中；还有一个表现是食指和中指并拢，用力按在桌子上，这也可以表示对方内心的不满和愤怒。 案例克林顿面对公众发表谈话：我从没有和那个女人，莱温斯基小姐发生过关系，从来没有。说这段话的时候，他的语气平和，语速也很正常。但他的动作泄露了内心的愤怒和不安。因为在说话时，他的右手食指飞快地多次用力指向前下方，这个动作其实是战斗中攻击动作的变形，表达了他在说谎时恼羞成怒的真实心理。 金句 双手交叉抱臂，看起来很怕冷是示弱的表现，常常被用来获取怜爱和关注。 低头表示了谦卑和服从。而低头时脊背是否挺直，往往表达了内心是否真正的服从。 冻结反应背后的动物本能，一是减少被猎手的关注，二是减少能量损耗，以迅速决定下一步要采取的行动。 用手撑住座椅背后的心理活动是，害怕仅靠腿的力量逃跑得不够迅速，因此想要用手撑一下来起跑得更快。 抱起双臂，交叉在胸前，让肌肉的收缩和重叠，使上身看起来更加魁梧，增加威慑效果。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《隐秘的知识》]]></title>
    <url>%2F2018%2F06%2F11%2F%E3%80%8A%E9%9A%90%E7%A7%98%E7%9A%84%E7%9F%A5%E8%AF%86%E3%80%8B%2F</url>
    <content type="text"><![CDATA[关于作者大卫·霍克尼，英国画家，长期住在美国。20世纪中期，他的油画就已经享誉世界。 关于本书大卫·霍克尼是个画家，但一般人不知道的是，他还对绘画制作的理论、材料以及工具做过认真的研究，这本《隐秘的知识》就是成果之一。这本书最初实际上不是一本书，而是BBC 给霍克尼做的一个75分钟长的纪录片。在这个纪录片里，霍克尼细细地叙述了他 在西方绘画史当中所发现的秘密，也就是书名所说的“隐秘的知识”。在这本书里，他将和你探讨“ 什么是艺术的真实 ”这个问题。 核心内容大卫·霍克尼说，西方古代绘画大师之所以画得那么逼真，是因为他们用了一个失传的秘密方法，也就是光学仪器。但是那种逼真在大卫·霍克尼看来，是虚假的，只不过是一种真实的幻象，而不是我们眼睛真实感受到的有生命的东西。与西方古代绘画不同，当代西方和古代东方，包括中国，一直都是画家以自己的肉眼观看和描绘世界，用心灵体味世界。图片来源：得到 前言本片文章主要介绍大卫·霍克尼的《隐秘的知识——重新发现西方绘画大师的失传技艺》。在这本书里，一个西方画家和我们探讨了“ 画中所画的东西是否真实”这个问题。我们都觉得西方古代绘画特别逼真，但作者告诉我们，它们其实是用了光学仪器的，所以，西方古代绘画只不过是一种 真实的幻象，而不是我们眼睛真实感受到的有生命的东西。与西方古代绘画不同的是，当代西方和古代东方，包括中国，一直都是画家以自己的肉眼观看和描绘世界，用心灵体味世界。你可能会问，古代画家用光学仪器来画画这事儿为什么是个秘密，又怎么会失传了呢？这是因为在过去，这个知识就像魔术师的机密，只是在师徒之间秘密相传，从没有人真正公开讨论过这些绘画技巧。不但从未讨论过，而且讳莫如深，因为这个秘密一旦传出去，就毁了画家的名声，承认了自己的高超画艺不过是临摹镜子的投影而已。到了19世纪末，随着照相机的发明，画家们有了新的秘密工具，因此这个隐秘的知识就失传了。是霍克尼拿出福尔摩斯的探究能力和对绘画的深刻理解，并用书信的形式跟大量画家、研究者沟通，终于使这个隐秘暴露在阳光下。首先介绍一下这本书的作者，大卫·霍克尼。他是一个英国画家，长期住在美国。20世纪中期，他的油画就已经享誉世界，国内美术圈里的人对这个名字不会觉得陌生。早在70年代末，他就来过中国，到中央美术学院，和那里的学生、研究生、老师交流，后来他还把在北京这几天的记忆和经历写成了一本书，叫《北京日记》。前两年他又来到中国，在北京大学做过一个演讲，据说是人山人海，水泄不通。大卫·霍克尼是个画家，但一般人不知道的是，他还对绘画制作的理论、材料以及工具做过很认真的研究，这本《隐秘的知识》就是他的成果之一。这本书最初实际上不是一本书，是BBC 给霍克尼做的一个75分钟长的纪录片。在这个纪录片里，霍克尼细细地叙述了他在西方绘画史当中所发现的秘密，也就是书名所说的“隐秘的知识”。那么，霍克尼作为一个画家，他为什么要讨论这个问题呢？他探究西方古代大师作品真实背后的秘密，其实是为了解决两个重要的问题：第一个，就是当代艺术、当代绘画和古代绘画艺术的区别究竟在哪儿 ；第二个对于我们中国人来说更重要，他分析了中国古代大师和西方古代大师绘画的重大区别究竟在哪儿 。霍克尼的最终结论应该会让我们中国人感到很自豪，那就是我们前面说的，西方古代大师其实没有用自己的心和眼睛去观看世界，而是借用光学器材和自己的技法，在画面上临摹了光学工具投射在画布上逼真的、微妙的、精确的光影效果，这些绘画欺骗了我们的眼睛。我们看到的是这些光影在画面上造成的视觉上的幻觉，也就是像真的一样。在这一点上，西方当代艺术反倒是和中国古代艺术一样，是真实的，是用自己的眼睛、跟着自己的心去观看自然。换句话说，中国古代绘画很接近西方当代的观察和表现方式，他们画的是一种心灵感受，这就是霍克尼要表达的真正核心。当然，霍克尼说这些，其实背后都还有一个更为重要的出发点，就是——我，大卫·霍克尼，是一个当代画家，我的画和古代油画大师的画不同之处是，我没临摹复制光学工具投射的幻影。好，下面我们就来一步一步地看看这本书究竟怎么论证了这个观点。 第一部分我们要说的第一个问题是，书名所说的“隐秘的知识”是什么？霍克尼回顾了西方绘画史中很多经典作品，追问西方人怎么能够做到在画中用如此精准的透视手法，把对象刻画得令人叹为观止。在追问中，霍克尼列举了西方艺术史上许多经典大师，其中包括著名的维米尔、卡拉瓦乔和拉图尔。在讲这些画家的画里面有什么样的秘密之前，我先来解释一下什么是透视。根据欧洲艺术史的记载，意大利建筑师布鲁内列斯基在1420年发明了透视，也就是 焦点透视，这也成了西方绘画的一个基本原则。其实，霍克尼写这本书就源自他对透视这个问题的迷恋。在这本书的中译本中，霍克尼特别对中国读者说了一段话，他说，透视就是借以在二维平面上描绘出三维空间的系统，就是在一个平面的纸上怎么画出有立体空间和深度的一张画。这是一个非常令人着迷的问题，今天谈这个问题的人不多了，但在百年以前的巴黎，它却是热门话题。他接着说，中国人从来都不用所谓的文艺复兴发展出来的透视体系，这是因为中国人对风景的态度和欧洲人不同：欧洲人是通过一扇扇窗户来看风景，把自己隔在景外；相反，中国人是随着景色漫步，观者就在景中 。当然，光学透视今天已经主宰了电视、电影、摄影的世界，不过新技术能改变这一状况，或许一个崭新的满怀自信的中国能够对此有所贡献，给人类带来比现在更好的、更加人性的观看世界的方式。这段话是写给中国读者的，其实也几乎是霍克尼写这本书真正的核心目标之一。下面我们回到主题。通过一一分析大量西方美术史里著名画家的作品，大卫·霍克尼发现了一个非常有趣的现象，那就是在14世纪，西方的画家还画得非常拙稚，尽管画面非常好看，已经掌握了普通的、初浅的透视效果和原理，但是画中人物衣服上的图案却画得很简单拙劣，甚至文艺复兴初期画家画的透视效果还非常幼稚；而到了文艺复兴中后期，也就是15世纪末16世纪初，写实绘画的技术突飞猛进，用了一百来年的时间，画家居然就能够把服装上的图案画得惟妙惟肖，逼真准确，和今天照相机拍出来的效果有一拼。这是怎么做到的呢？难道透视原理能够使画家看到如此准确的图案变化吗？大卫·霍克尼说，不是这样的。霍克尼指出，欧洲画家在一百年的时间内掌握了一个秘密，这个秘密就是借助镜子或者透镜在画布上投射出阳光下物体的影像，然后用笔把这些影像描绘出来 。霍克尼举了一个比较早的例子，那就是文艺复兴后期画家乔瓦尼·巴蒂斯塔·莫罗尼所能够画出的最为精准、精致的服装上的图案。那衣服表面张扬复杂的纹样，居然画得非常逼真准确，令人信服，特别是微妙的高光和阴影，以及图案随着身体的变化而变化，那种准确感、那种完美的逼真感、那种真实感，简直是不可思议。他是怎样才能够画出这样效果？大卫·霍克尼说，这样的准确度一定是使用了新工具，因为不可能依赖眼睛做到。问题是，他们究竟使用了什么样的工具？我把大卫·霍克尼的发现总结成三个不同的秘密。 乔瓦尼·巴蒂斯塔·莫罗尼，Isotta Brembati 的画像 第一个秘密，是 维米尔的小镜子 。有一幅画叫《带珍珠耳环的少女》，让无数人着迷，还有人以这幅画为灵感拍了一部同名电影，这幅画的作者就是维米尔。几年前，中央美术学院给前院长靳尚谊先生举办了一个展览，叫做《向维米尔致敬》，特别强调了对维米尔逼真描绘生活的艺术手法的敬仰。由于维米尔的作品几乎都是在室内画的，透过一扇窗户的光线照在室内的物体和人物上，形成令人着迷的光影效果，因此他也被称为绘画的光影大师。维米尔是17世纪的荷兰人，荷兰是光学器材的发源地之一，也是非常发达的光学器材制造地之一，所以很多人都认为维米尔使用了光学器材。大家一直都在猜测，维米尔是不是用了针孔成像，可是大卫·霍克尼认为不是，因为针孔成像只能在墙面上或者是画布上形成一种模模糊糊的图像，不可能给维米尔提供如此准确的结果。霍克尼说，维米尔的画应该用的是其他光学工具，这个工具应该类似我们现在的照相机，或者是其他镜面投射的手段。霍克尼的研究结果是惊人的，维米尔使用的是小镜子。如果你看过本书的封面照片就会知道，这本书的封面就是大卫·霍克尼在使用小镜子投射物体到画布上的姿态。他模拟的是维米尔当时画画的情景，把小镜子调整好角度面对着对象，让小镜子里折射的图像与桌面上的画布重合，只要用笔顺着小镜子的边缘描绘出和小镜子重叠的部分图像，就能在画布上准确地描绘出小镜子上的颜色和图像，最后画出完整的对象来。也就是说，用这种方法可以准确无误地从光学的角度再现对象，所以霍克尼推测，维米尔真的就是在复制他用光学器材的折射效果投射出来的图像。 霍克尼在用使用小镜子作画 霍克尼找到了维米尔的秘密。除了霍克尼，美国还有一个叫汤姆的光学专家也关注到这个密秘。在他退休之后，由于对光学原理和维米尔的画着迷，他按一比一的比例复制了一间维米尔画中的房间。通过使用小镜子，这位完全没有受过绘画训练的光学专家，面对着维米尔画中复制出来的房间的景色、光源等等，用自己没有受过绘画训练的手，居然也画出了类似的逼真的光影变化。霍克尼和这位光学专家最后都得出结论，维米尔的作品一定是使用了这样的小镜子。有些东西在小镜子上面呈现的是带有很准确的焦距，带有很准确的焦点，而另外地方有些模糊。维米尔对这些焦点和失去了焦点的模糊感很着迷，他的画面上也呈现出来了，你可以看文中的插图，是能够感觉到的。接着霍克尼就说，这是维米尔的秘密，但是欧洲其他大师，比如说文艺复兴晚期以使用模特作画而著名的卡拉瓦乔用的是什么方法？为什么没有模特，卡拉瓦乔就不作画？霍克尼说，从画面看，卡拉瓦乔用的应该不是维米尔这种方法。霍克尼同样也再现了卡拉瓦乔和一系列使用这个方法的画家的秘密，这就是我们要说的第二个秘密，暗室投影法 。在这种画法中，画家坐在一间比较暗的屋子里，不是全部的漆黑，然后在这个屋子的门上开一个像画布一样的方洞，让被画者在门外强烈的光线下坐着，再用镜子折射被画者的像，透过那个方洞投进来，投射在画布上。用这种手法在画布上所呈现的图像就达到了光学高度的精准，而且是有色彩的，只不过当你用凹透镜的时候，这个图像是倒过来的，而用平面镜子的时候这个图像是向上的。其实，对画家来说颠倒不颠倒都不重要，就按着画布上投射的图像直接勾描就行了。这就是卡拉瓦乔的秘密，就是他没有模特就不能作画的原因。 卡拉瓦乔 《琉特琴乐手》在研究暗室投影法的时候，大卫·霍克尼还发现了第三个秘密，就是在很多大型的、多人物的绘画作品中，虽然也是用了光学原理，但是这些作品中的人物并不是一次性同时画成的，而是多次单独投射绘制，最后拼接在一起的。因为不可能在同一时间，所有的画中人物都穿上道具服装坐在太阳光下，让画家慢慢地一个一个画下来，这样的话，这些人物都要晒得油汗直淌。霍克尼确定地认为，这些画家是分别画了人物之后，再把人物拼接在一起，最后才成为多人物大型作品的。他的理由是，作品中存在着多个几何形图案的透视关系不统一的现象。如果一幅画不是拼接而是一次完成的，按照焦点透视的画法，画中所有的人物应该有一个共同的焦点，但是这些画中的人物不是。比如画面上的桌布，不同人物面前的桌布图案和透视有相当的误差，虽然这个误差在拼接时调整过，但是人物众多，这个人面前的图案与透视消失点准确地重合了，另一个人面前的就不一定准确，所以只好不断调整，调整来、调整去，调整出一个勉强的图案，但是明眼人就会发现它有些不正确、不准确。这个发现是在大卫·霍克尼通过暗室投射的方法一一画出不同的人后才发现的，因此也就找到了另一个依据，来说明这些画家有可能使用了镜面或透镜投射的手法来制作这些精准的图像。由于我们肉眼的生理构成无法观察到如此细微的光影变化，因此，古代大师在画中画出了眼睛无法捕捉到的光影效果，这背后一定使用了秘密工具，而霍克尼找到了他们作画的秘密——他们之所以能够把物体和形态画得如此精准，是借用了光学工具和手段，把带有光影的形态投射到画布上，再描摹出来。因为西方绘画追求的是逼真的形似，所以画家就要不择手段地将人物和各种东西以及自然景观真实地或者说是在观者眼中乱真地描绘出来。 第二部分说完了古代大师的秘密，下面我们再来说说霍克尼对这个秘密的态度。霍克尼比较了两件作品：一件作品是西方现代艺术之父保罗·塞尚的《裸女》，另一件作品是19世纪末法国矫饰主义写实油画家布格柔的《海边的裸女》。塞尚和梵高、莫奈是同一时期的画家，他的影响力甚至超过了这两位著名的画家，就是因为他决心要客观地表现世界。而这个布格柔，他跟中国美术界其实有很密切的关系，布格柔的学生之一是达仰，而达仰是中国20世纪油画的祖师爷徐悲鸿的老师，按照这个师承关系续下来，徐悲鸿是布格柔的徒孙，那中国很多油画家都是布格柔徒孙的子子孙孙，这就续下好多代了，也就很有意思了。 塞尚，《裸女》布格柔，《海边的裸女》这两幅《裸女》摆在一起，给人的视觉感受截然相反。塞尚的《裸女》，画面特别简单，只能看清人物的边缘和姿势，用笔粗粝，甚至会让你觉得有点粗糙，跟背景统一在一片蓝灰色的调子里，从中你可以感受到他创作所追求的那种结实而深邃的感觉。而布格柔的《裸女》就像我们现在的明星海报一样清晰，人物的脸孔皮肤、身边的海水、背后的岩石，每一个细节都细腻而柔和。但霍克尼在书中说，塞尚的裸女是真实的、有生命的，而布格柔的裸女是矫揉造作而又虚假的形象。西方近现代美术史对布格柔持有批评态度，而且是毫不留情的批评，认为在布格柔所处的19世纪末，现代艺术已经崛起了，而他居然依然用这种看似逼真实际上是欺骗视网膜的方法作画，太不真实了。那么布格柔的作品哪里不真实呢？霍克尼认为，布格柔的这个裸女一定是借助光学器材手法画出来的。你可以打开文稿，仔细看这件作品，你就会发现裸女本身跟海水的关系、她坐的岩石跟海水的关系，这三个东西是完全不吻合的，是三个元素拼在一起的。这件作品不表现任何自然或生活中的场景，只是以一个矫揉造作的女性人体欺骗观者的眼睛，这种逼真是为了博得观者产生视觉上的幻觉真实，这是一种对眼睛的欺骗、对视网膜的欺骗。而塞尚的作品完全没有利用任何器材来辅助，完全是用自己眼睛看到的真实裸女，他的作品追求的不是一种视觉上的真实，而是一种心灵的真实。塞尚的心灵和眼睛聚在一处，心与眼的观察最后在画面上呈现，因此，他画中的裸女是真实的。所以霍克尼的结论是，塞尚的裸女看起来好像很简约，实际是真实的心灵的体现，而布格柔画得很细腻，看似很逼真，但这是一种迷惑视网膜的欺骗 。霍克尼的发现和他这些骇世惊俗的话，一说出来就引发了美术史界对他的狂暴攻击。他在这个 BBC节目公开播放之后，有好长一段时间不得不穿着一件汗衫，汗衫上印着几个大字“我知道我是正确的”。你有没有发现，说到布格柔，大卫·霍克尼是持强烈的批评态度的。他没说古代的大师是欺骗，他只是说古代大师用这种方法画出了真实的作品，欺骗了我们的眼睛，让我们的眼睛受了骗，他却明确地说布格柔欺骗了我们。他对布格柔这么苛刻，其实是有原因的。这主要是因为，在布格柔的时代已经有了摄影和照相机，也有了各种光学器材，在布格柔的晚年更有了现代艺术运动，而布格柔居然依旧用这种光学的手法来欺骗人们的眼睛，所以霍克尼认为这太廉价了——在现代运动如火如荼的年代，你居然继续做这样欺骗视网膜的行货。在这本书里，霍克尼从古代大师讲到布格柔，也讲到他自己和亚洲美术，这就是第二个问题，也是对我们普通人来说最重要的问题，就是今天我们到底应该怎么理解绘画中的真实。这本书的第一部分，就是我们前面讲的，他发现了古代欧洲大师的作画秘密，而在第二部分他开始介绍亚洲人怎么画画，波斯人、印度人、日本人，尤其是中国人怎么画画。他说这些文明中的人通通没有使用光学器材来辅助作画，而且对这些没有兴趣，因为他们要画的不是欺骗眼睛的真实图像，他们要画的是心灵所感受到的，对心灵、对大脑来说同时是真实的图像。霍克尼分析了一系列东方的作品，包括波斯细密画和黄公望的《富春山居图》。这使我想起好多年前霍克尼还有一个节目，是在美国纽约大都会博物馆做的。在这个节目里，他探讨的就是东方艺术和西方艺术的区别。他在这个节目里仔细观察了大都会博物馆所藏的两张画，一张是欧洲的风景画，一张是《康熙南巡图》。他说，欧洲古代的这张风景画是站在窗户后面所看到的风景，窗户就是一个镜框，这是焦点透视，并且是闭上一只眼睛、另外一个眼睛盯着这个焦点所画出来的画。而《康熙南巡图》的画家，好像是跟着康熙一路记录下来所见，而且还有动感，透视的角度随着他身躯的移动而产生变化，于是带着观者看到这些房屋在透视下的变化，好像是摄影机在跟踪摄影这些房屋的时候，房屋的透视在摄影机的下面产生的变化，这就是散点透视。他觉得中国人的散点透视太先进了，根本就是一种生态的、伴随着人的眼睛和心灵的透视，并且能够在画面上体现出来，根本不像西方美术史所说的，这是一种原始的、不发达的、不科学的透视方法。《康熙南巡图》（局部） 总结霍克尼发现的秘密和他对绘画的真实看法我们就讲完了，下面我们来回顾一下。西方古代大师用了秘密工具，达到了一种精准的视觉表现，其实是为了欺骗人的眼睛。而塞尚和他的时代的作品，也就是现代艺术运动以来的绘画作品，是心灵跟着眼睛、没用任何光学器材画出来的，对于大脑来说是真实的图像。也就是塞尚所说，我的作品是真实的，有生命的。说到古代绘画手法的弊病，霍克尼特别拿出布格柔来证明自己的观点：发展到如今已经有了照相机的时代，这类作品就是虚假的，没有生命的。之后是霍克尼对东方和西方美术的讨论。他在这个 BBC 节目和书中说，东方不比西方低矮，东方不比西方落后，东方画的是“我手写我心”。中国的散点透视是世界上最高明的一种透视方式，散点透视表现出观看的动感，散点透视的高明和先进，达到了用平面静止的图像表现出我们用摄像机所捕捉的透视效果，是带有动感的，步移景移的散点透视。到今天为止，很多中国人依然认为西方古代的绘画是先进的，比中国古代绘画好，因为他们有光影，因为他们的光影表现了体量，也就是人对事物的一种直观感受。霍克尼说，不，这种体量是虚假的，只有用光学器材才能够捕捉住光影效果，而我们人类的眼睛看东西是不需要光影的。光线的投射使我们看见了东西，但我们的眼睛总是忽略影子的存在，因为影子虽然对我们捕捉物像的状态、色彩和状态起到一定作用，但其实是不必画到作品里的。对于画家来说，把握和描绘世界的方法是多种的，而如果没有光影，没有光线和影子，光学器材就无法呈现对象，这是人类与机械观察世界的最大的区别。我们看到的外轮廓，我们在大脑中把它总结成线条来勾勒，这个形象就出来了，而光学器材只有用光影才能显现出形态来。可以想象，听到霍克尼的这个说法，整个西方美术界就翻了天了，对他的反感、对他的批评扑面而来，说他攻击古代大师的都有。大卫·霍克尼说，我没说他们欺骗我们，而是说他们使用的艺术表现手法、他们追求真实刻画的手法，使我们的眼睛受了欺骗。其实，霍克尼没有必要和那些有偏见的人辩论，因为他们永远都不愿从偏见的美梦中醒来。这就涉及到这本书里最后的一个问题，也是前面说的两个问题背后的潜台词：我，大卫·霍克尼画了一辈子的画，我是现当代艺术运动中的旗手，而我的画是最真实的，我没用任何光学器材；我找到了你们作画逼真的秘密，因此我知道我比你高妙，我高就高在我画的不是光影投射在画布上之后用临摹、描摹的手法绘制出来的东西，我不画照片，我不借助光学器材；我画的是我的心灵，我像亚洲人一样，画的是自己的心灵，我的画像黄公望的《富春山居图》一样，是一种心灵之旅在画面上留下的痕迹。因此，合上这本书，我对大卫·霍克尼更增加了一层敬重。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《大学之路》]]></title>
    <url>%2F2018%2F06%2F10%2F%E3%80%8A%E5%A4%A7%E5%AD%A6%E4%B9%8B%E8%B7%AF%E3%80%8B%2F</url>
    <content type="text"><![CDATA[关于作者吴军，著名的计算机科学家，投资人，“得到”订阅专栏《吴军的谷歌方法论》的主理人，毕业于清华大学和美国的约翰・霍普金斯大学，在清华大学担任过班主任，参与过约翰・霍普金斯大学的管理工作。 关于本书《大学之路》是一本介绍西方大学教育的书，是作者吴军在陪女儿走访过十几所欧美顶级名校之后写成的，重点讨论了西方高等教育这一宏观话题。 核心内容 东西方人对大学的认知差异； 两种不同的办学理念，通才教育和专才教育； 介绍美国私立大学的管理。 东西方人对大学的认知差异亚洲人认为，大学几乎是一个必选项，一定要上，只有上大学，以后才能有体面的生活；而西方人认为，大学只是众多选项里的一个，只有想从事某些特定的职业，才需要上大学。为什么会存在这么大的差异呢？吴军认为，这是因为东西方大学的历史传统有本质的区别 。中国高等教育的雏形，可以追溯到 孔子时代。孔子时代的教育，主要学的不是具体的谋生手段，而是社会精英应该有的智慧和见识。到了隋代，有了科举制度，科举成为了国家选拔人才的主要手段，也是普通人进入上层社会的唯一通道，从这时开始，中国的教育和考试开始紧密结合，自然而然地和社会地位、做官就联系在一起了。这种观念对国人影响深远，直到今天，很多中国人还是把考试、升学和获得社会地位联系起来。从这个角度来看，中国人千方百计地要读大学、接受高等教育，也就不难理解了。西方高等教育的萌芽，和中国很相似，也是一位智者带着一帮学生，这个人就是 毕达哥拉斯，古希腊的数学家、哲学家。现代大学是在中世纪诞生的，“大学”是指一种包括老师和学生在内的团体，这种团体直接受到领主保护，拥有学术特权。和中国的大学不一样，接受学术特权的西方大学，教授的内容大多数都是神学知识、拉丁文写作技巧和自然科学的知识，来这里上大学的学生，一开始想的就不是升官发财。这个传统一直延续至今，也是西方人并不是全民都想上大学的思想根源。虽然东西方高等教育在历史上的差异很大，但就现在来说，中国人读大学也并不都是抱着功利的目的，很多人都是因为对知识纯粹的渴望去读大学的（也许这指的就是我hhh）。不过，在吴军看来，不管有没有上大学、抱着什么目的去上大学，这都不重要，人生是一场马拉松，拿到一所名牌大学的毕业证，不过是在马拉松赛跑里取得了一个还不错的站位而已。看过马拉松的人都知道，在起跑的一瞬间道路非常拥挤，但等比赛过了四分之一，选手和选手之间的距离已经拉开很远了，起跑时占的那一点点便宜早就没什么意义了。我们经常听到一句话，说不能让孩子输在起跑线上，但事实上，成功的道路并没有想象中的那么拥挤，在人生的马拉松上，绝大多数人跑不到一半就弃权了，到后来剩下的少数人，不是嫌竞争对手太多，而是要发愁怎么才能找到一个同伴，陪自己一起跑下去。笑到最后的，一定是终身学习者 。 两种教育理念纽曼式的通才教育纽曼认为， 学生们除了学习知识以外，更重要的是要互相交流、互相学习，彼此成为朋友 。他还认为，教育的终极目的，是培养有能力服务于社会的人，而不是教授一些具体的雕虫小技。纽曼反对一上来就给学生教授某个专业的具体技能，认为大学生的知识面一定要广，不能过早地局限在某个具体的专业里。当然，想要实现通才式的教育，光有理念上的认同是不够的，还必须同时具备两个要素：第一，是给学生选课和换专业的自由 ，第二，是 学校要有实力开出足够多、足够广泛的课程 。 案例哈佛大学，首先在选课上给予了学生绝对的自由，大一新生不分专业，学生们可以随便选课，在学习的过程中慢慢地了解自己的真实兴趣；其次，哈佛开出了足够多的课程，哈佛大约有6000名本科生，他们居然开出了6000门课，而且还可以去隔壁的麻省理工学院选课 。 洪堡式的专才教育洪堡建立的高等教育体系，非常重视职业教育和技能教育，强调 大学生在学校要学习马上就能用的知识，一走出校园就能为社会提供服务、创造价值。为了能让学生做到这一点，实行洪堡制大学的很多专业都需要五年才能毕业，最后两年学习的是非常精深的专业知识。而且，采取洪堡制的大学都会花大价钱建立研究生院，这也是实现专才教育的物质基础。 案例著名的麻省理工学院，就是实施洪堡式专才教育的典范，它最突出的一个特点，是让大一新生就有机会参与真正的科研。一般大学里让本科生参与的科研，其实就是教授让学生们练练手，随便做点事情，因为很多教授认为，自己的科研项目本科生做不了，他也没时间手把手地辅导学生，但MIT 不一样，MIT 的教授会让本科生参与自己拿了经费的科研项目，并且让他们承担这个项目里的一个工作，这就需要教授花时间来指导学生，还要承担相应的风险。 美国私立大学的管理终身教职有的教授公开发表一些反教会的观点，或者是公开地批评某一个资本家，学校就会遭到宗教势力和资本家的施压，被逼迫着解雇那些他们不喜欢的教授，这种现象会干扰到教授们的学术研究，为了让教授们自由发声，美国的几所大学和美国教授协会开始号召实行不能随意解雇教授的制度，也就是现在的终身教职制度。终身教职强调的不是铁饭碗，而是学术自由。 教授治校教授们的管理范围只到系这一级，主要的工作就是制定制度和执行制度。在美国大部分的学校里，每次系里面制定或者修改制度，一般都需要系里面全体教授的通过。在制度的执行过程里，除了在教授晋升上，资深教授更有发言权之外，其他事情的发言权一律平等，不分新老，不看资历，非常民主。教授治校，行政成本低，学校管理公正透明，还维护了教授们的尊严和权威，保证了学术自由，是很好的管理制度。 校董会总的来说，对内，校董负责筹集资金、拍板大事、规划未来；对外，校董们就是学校的形象大使，到处给人布道，用他们自己的影响力，在世界各地帮学校做宣传，帮助大学和各种机构建立合作。大学校董并不是一个用钱买来的虚职，真正的校董，会为大学的发展尽心尽力，提供最多的帮助。 金句 到了隋代，有了科举制度，科举是国家选拔人才的主要手段，也是普通人进入上层社会的唯一通道，从这时开始，中国的教育和考试开始紧密结合，自然而然地就和社会地位、做官联系在一起了。 我们经常听到一句话，说不能让孩子输在起跑线上，但事实上，成功的道路并没有想象中得那么拥挤，在人生的马拉松上，绝大多数人跑不到一半就弃权了，笑到最后的，一定是终身学习者。 清华大学老校长梅贻琦有句名言，大概意思是说，大学之所以叫大学，不是因为这里面有大楼，而是因为这里面有大师。但吴军认为，大楼的作用也许被严重低估了， 大师固然重要，但没有大楼，也就是没有物质基础，大师们的教育理念也很难实现 。 当许多聪明、求知欲强、具有同情心而又目光敏锐的年轻人聚在一起，即使没有人教，他们也能互相学习，所以， 你也许不用纠结自己是去接受通才教育还是专才教育，上大学本身，也许就是最好的教育 。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《重来》]]></title>
    <url>%2F2018%2F06%2F10%2F%E3%80%8A%E9%87%8D%E6%9D%A5%E3%80%8B%2F</url>
    <content type="text"><![CDATA[关于作者本书的作者有两位，分别是贾森·弗里德和戴维·汉森。他们是美国一家小型互联网公司 37signals的联合创始人，而且都是程序员出身（这才是最重要的），崇尚用极简主义的风格来设计软件和管理公司。 关于本书在本书里，两位作者从自己的亲身经验出发，为我们展示了在创办和经营一家企业的过程中，可能会面临的问题和相关经验。全书以清单体排列，由几十篇短文构成，每篇短文都是一个经营要点。本书多次登顶美国和英国的管理类图书榜单，畅销全球。 核心内容本书的核心思想只有两个字： 简单。作者用自己的亲身经验告诉我们，创办经营一家企业，你不需要成为工作狂，不需要大量招兵买马，更不用把时间浪费在会议和规划上，甚至可能不需要一间办公室。你只要抓住“赚钱”这个公司存在的最根本目的，做好自己最该做好的本职业务，从一切方面尽可能地提高公司的经营效率，你的公司就能变得更加成功。 图片来源：得到 前言本文主要记录书中精髓： 追求简单和效率，是让一家企业变得更赚钱的最好方法 。很多企业管理类的书里都会大谈特谈制订商业计划，分析竞争形势，寻找投资人等等这些事，但是本书可不是这样。翻开本书的第一页，它就说了，“如果你要找的是那样的书，那就把这本书放回书架吧”。这本书不是一本传统意义上的企业管理书，也不会教给你那些传统的商业知识。实际上，这本书无论是从形式还是理念上讲，都算是相当另类的。比如这本书的排版就很特别，书虽然有200多页，但全书是以清单体排列的，由几十篇短文构成，每篇短文都是一个经营要点。而且每个要点大多只有一页纸，并配有一整页的插图，所以每张纸的正反两面都自成体系。美国科普作家凯西·西拉看过这本书之后给了一个很幽默的评价，“我必须努力克制住把每一页书都撕下来贴在墙上的冲动”。除了排版，本书作者的经营理念也特别不拘一格，他们认为经营一家企业的方法可以非常简单，传统的经验也可以完全是错的，一切都可以重新定义，一切都可以重来。所以这本书的名字就是：Rework——重来。本书一开始就指出，这本书的目标受众，不仅仅是企业家或者创业者，所有梦想着有自己事业的人，比如职场白领、失业者或者艺术家，都可以从本书中获得灵感。这本书的核心思想只有两个字：简单。作者用自己的亲身经验告诉我们，创办经营一家企业，你不需要成为工作狂，并不需要大量招兵买马，更不用把时间浪费在会议和规划上，你甚至不需要一间办公室，只要做好自己最该做好的本职业务，你的公司就能赚钱。听到这儿你可能觉得，作者的口气还挺大。作者之所以有底气来写一本这么与众不同的商业管理书，是因为他们有着与众不同的，成功的创业经历。本书的作者有两位，分别是贾森·弗里德和戴维·汉森，他们是美国一家小型互联网公司37signals 的联合创始人。两位作者都是程序员出身，而且崇尚用极简主义的风格来设计软件和管理公司。这本书里介绍的商业管理经验，也都是这两个人在创办37signals 时一步步摸索出来的，所以也有着鲜明的极简主义风格。大部分读者可能对 37signals 这家公司不太了解，这很正常，因为这本书出版时 37signals也只有16名员工，是一个名副其实的小公司，主要业务就是制作一些网站上的应用程序。但公司规模小并不意味着实力弱，毕竟，全球有超过300万人在使用他们的产品。37signals创办近20年以来，美国无数的互联网公司建立又倒闭，但 37signals不仅顽强地存活了下来，而且每年都能盈利好几百万美元，所以作者觉得自己的公司还算成功。当然了，作为一家小型互联网公司，他们在这本书里提出的管理经验适合他们自己，如果推广开的话，对小型的创业公司 可能更适用一些。接下来就让我们看看本书到底介绍了些什么不一样的经验吧。整本书虽然由好几十篇相对独立的短文组成，但是根据内容可以分成四个方面，我就来按照这四个方面的重点内容，来介绍这本书。第一个重点， 公司文化 方面，计划、会议、工作狂和规章制度，看起来都很有用，但实际上可能是效率杀手。第二个重点， 公司规模 方面，小公司并不只是一块跳板，小公司本身就可以是一个伟大的目标。第三个重点， 人力资源 方面，要控制员工数量，放慢招聘步伐，这样每个人才能独当一面。第四个重点， 外部关系 方面，坚持主见，不模仿不盲从，面对对手和客户时才能占据主动。 第一部分我们就先来看看第一个重点，从公司文化方面来分析企业，计划、会议、工作狂和规章制度，表面上看起来都很有用，但实际上可能是效率杀手。所有公司存在的目的都是为了赚钱（那些号称为了改变世界而生的公司就另说了），公司的一切也都要为赚钱而服务，公司文化作为公司宏观层面的理念，自然也要做到这一点。现有的制度和规范要是不能帮助公司赚钱，就没有继续存在下去的理由，不管它有多么地完美。作者认为，只有简单和效率才是王道。作为一本观点不拘一格的商业书，作者一针见血地批判了几个看似必须，但实际上会拖累公司效率的现象，我在这里给你讲其中最重要的四个，分别是：计划、会议、工作狂和规章制度 。 先说 计划 。不出意外的话，几乎每个公司都会有自己的经营计划，但是作者认为， 计划就是瞎猜，预估的都是垃圾。你会不会觉得很意外？作者的理由是这样的，因为在经济活动中不能掌控的因素太多了，比如市场环境、竞争对手、客户群体等等都是不可控的因素，而制定计划会让人感觉自己把握住了某些东西，但实际上根本就不现实。比如你有没有遇到过这种情况：本来说去楼下超市随便逛一下，可是一回来却发现过去了俩小时；或者本来打算花俩小时采购商品，可实际上二十分钟就搞定了。人连这种小事儿都估算不准，更别说长达几个月甚至几年的计划了。作者认为，不做计划不代表无视未来，预防练习总是有必要的，没人喜欢看篇幅庞大的计划书，长篇大论的计划只会放在柜子里吃土。有这精力还不如做好眼前的事情，找到下一项最重要的任务，然后行动就行了。 作者批判的第二个现象是 开会 。 开会会降低效率，因为会议能传达的信息量一般不多，而且很多时候7分钟就能说完的事，总是被会议拖到半小时以上。毕竟，没人会订一间7分钟的会议室。随着开会时间的增加，会议的成本就高的吓人，比如一个1小时的会议如果有10人参加，那时间成本实际上就是10个小时。你可以想想，开这种会真的值么？所以作者说会议有毒，会拖累工作的效率，就算要开会，会议时间也应该被严格控制 ，开始后就直接切入主题，而且 最好还别去会议室，就在出现问题的地点开会。这些方法可以抓住事情的本质，大大节约每个人的时间，提高工作效率。第三个再来说说 工作狂 。作者也在书里批判了他们，这可能也会让很多人大跌眼镜，因为不少人都觉得企业里有工作狂是个好事。但作者认为，工作狂的文化不仅没有必要，而且还特别蠢。因为工作狂们看似能解决一些问题，但其实制造的麻烦更多。比如他们总是用蛮力来弥补思维上的惰性，结果只能折腾出一堆不实用的方案。而且在工作狂扎堆的环境里，就连按时上下班好像都成了一种无理要求，这会让其他正常工作的员工士气低落，最后的结果就是大家都低效率地加着班，这有什么意义呢。所以作者批评说，工作狂们不是英雄，他们做的更多的只是浪费时间 。作者推崇的是按时上下班，下班时间一到就准时放人，因为我们追求的不是工作时间，而是工作效率。每个员工都有自己的生活，当他们家里有事时，就会努力在办公时间内把活儿干完。而且为了提高工作效率，作者还建议一定要按时睡觉。偶尔一两次熬夜没什么问题，但要是长期熬夜，问题可就多了去了，比如人的工作效率会降低，同时缺乏创意，士气低落，还会容易情绪失控。总之，作者坚决反对工作狂文化，因为工作狂只是表面上的努力工作，实际效率却很低 。 作者批评的第四个现象是 规章制度 。他们认为，规章制度在某种程度上是组织机体上的伤疤，也是 官僚主义产生的温床。如果某个员工做错了事，告诉他不要再犯就行了。比如有个新来的员工穿着短裤来上班，那老板最好的做法，就是告诉这个员工下次别穿成这样就行。要是着急就这件事制定规章，那就是对个人过失的集体惩罚，真没那个必要。只有一件事重复发生时，才需要为此制定规章制度。以上就是第一个重点，说了这么多，作者的目的其实只有一个，那就是企业文化要为企业的根本目的，也就是为赚钱服务，这就要求企业提高效率，集中精力做真正有意义的事儿。计划、会议、工作狂和规章制度，看起来是一家成功公司的必须要素，但实际上却往往会给公司的效率拖后腿，所以如果它们真的降低了效率，那公司管理者一定要敢于抛弃 。总之一句话， 提高效率才是王道 。 第二部分作者认为，37signals 正是因为做到了这一点，所以才能保持高效，在创造出相对较多利润的同时还能保持一个比较小的规模。而 37signals的小规模也是作者很引以为傲的一件事，所以接下来的第二个重点讲的就是，公司规模方面，小公司并不只是一块跳板，小公司本身就可以是一个伟大的目标。企业的经营者们可能经常会被问到这样一个问题：你的公司有多大？一般来说，经营者说出的规模越大，就越容易得到别人的夸赞。但你有没有想过，为什么要把扩张当做奋斗目标，大就一定好吗？作者觉得可不一定。举个例子，扩大招生规模、在全世界到处开分校，这种做法并不会让哈佛和牛津变得更伟大。所以同样地，更大的规模也不一定会让一个公司变得更强大。也许一个公司的最佳规模就是5个人，也没准是一个人加一台电脑就成。作者觉得，创业者不要一开始就给公司设立一个目标规模，而是要找到合适的目标定位 。对求职者来说也是一样，要知道 就算是小公司，同样也可以很伟大 。比如 37signals自己就是这样，十几个人的小公司能拥有300万以上的客户，作者认为这样的规模就够了，所以没有必要再扩大自己的规模。再比如著名的分类广告网站Craigslist，也只有几十个员工，每年却能实现几千万美元的利润，而且他们还在很大程度上改变了美国广告行业的格局，让整个报刊行业的竞争对手失去大量客户。所以对很多公司来说，真没必要一定去追求大规模。当然了，很多公司的特点决定了它们确实需要比较多的人手、比较大的规模，比如外卖和快递行业，但这不是问题，只要符合自己公司的真正需求，大或者小都是好的。作者只是想提醒经营者，做公司确实没必要一味地追求“大” 。而且，应该在创业初期就规划好公司的规模。很多创业者都会面临资金问题，而要想获得足够的种子资金，可能就需要借助外部投资。作者认为，如果创业者创办的是一家工厂或餐厅，那确实有很多需要用钱的地方，比如租赁场地，购买设备。但今天大量的服务型公司，资金门槛其实非常低，比如咨询、软件、平面设计公司等，这些公司本身不需要太多的资金投入，如果创办的是这种公司，作者建议那最好别用别人的钱。作者总结了不少原因，比如最直接的，融资会稀释你的股份；还有投资人的那种“套现离场”的想法，会毁掉你创建伟大公司的梦想。总之作者的态度很简单，那就是花别人的钱看似轻松，但都是有代价的。一句话，能不融资就千万别融资 。这时候肯定有人会问，不融资说得轻松，那我要租办公室，买办公设备，给员工发工资，不融资哪儿来的钱啊？作者的回答很简单，那就是公司的需求可能没有想象的那么多。比如企业经营者可能不需要雇10个人，3个人也能应付；可能不需要一间大办公室，在家办公也行；可能不需要会计，自己用软件记账也不错。37signals就是这样，它刚推出第一个产品时，连办公室都没有，员工们只能和别人共用办公室；他们也没做广告，只是通过在网上分享经验来传播自己，不过这些都没有影响公司的发展。而且作者认为，外部条件受限其实也是一种好事，因为有限的资源能激发你在现有条件下的创造力 。美国西南航空公司就是一个很好的例子，它只有波音737这一种型号的飞机，这就意味着，公司的每一个飞行员、空乘员和地勤人员遇到的问题，都只可能是一个机型上出现的问题，这样他们就能为航空公司的所有航班服务，而且所有飞机的配件都是通用的，这些都大大降低了公司的运营成本和运营难度。所以西南航空公司的运营成本特别低，赚的钱却不比别人少。你看，条件受限反而成了好事了。公司规模不仅仅指的是公司的大小，也包括公司的业务种类。作者相信， 把一件事做好要比同时做一堆傻事要有意义得多，所以对公司来说，能把自己的主业做好就不错了，没必要参与太多的副业。著名大厨戈登·拉姆齐在他的书《厨房噩梦》中就提到，在失败餐馆的菜单上，菜品总是太多。所以拉姆齐到一个餐馆工作时的第一步就是删减菜单，然后把剩下的菜品做成精品。公司的业务也是这样，专注做好一个业务比把一堆任务都做得马马虎虎要有意义得多。而且，公司事业的核心原则应该是不会随时间改变的，比如日本汽车厂商追求的核心原则是可靠性、性价比和实用性，人们对这几点的追求不会改变，再过30年也一样。37signals的宗旨是简洁易用，放到10年后也不会有人说“哥们，我觉得软件还是难用一些好”。上面就是第二个重点，这部分作者的主要观点， 不是反对扩大公司规模，只是说不要一味地追求扩大规模，有什么样的条件做什么样的事儿。要是能把业务做好，把钱赚到手，那小公司本身就可以很伟大，追求简单和效率的原则又在这里得到体现。小规模不是所有公司发展过程中必然要经过的跳板阶段，有时候它也是公司发展的最终和最佳形态，可别掉进越大越好的怪圈里。 第三部分说完了比较宏观的公司文化和公司定位，作者还为我们分享了一些更微观的操作经验。下面我们来说第三个重点，在人力资源方面，公司要控制员工数量，放慢招聘步伐，这样每个员工才能独当一面 。其实这个部分里作者提到的控制员工数量，也算是公司规模的一方面，但因为作者花了很大的篇幅，专门讲述人力资源方面的经营经验，所以我们在这儿就把员工规模的内容也一并说了。就像扩大公司规模一样，很多公司也特别喜欢招很多员工，更多的人既能分担更多的活儿，也能让老板觉得有面子。但作者认为，公司招人的基本原则，应该是为了解除过多的工作带来的痛苦。如果公司能用一套软件或者更好的工作方法来完成任务，那就可以不用招那么多人。作者的亲身经验是，招人的最佳时机应该是：因为工作太多，给你带来了长久的压力，甚至让你的工作质量下滑了，这时才是公司真正应该招人的时候 。就算公司真的需要招人了，那老板们还应该注意， 招人的速度别太快。作者举了个例子，假如你去参加一个都是陌生人的酒会，你是不是会只谈一些无聊的八卦，而且会有意识地回避严肃或有争议的观点，只有在老朋友或者熟人的聚会上时，你才会毫不保留地说出你真正的想法。所以如果一个公司在短时间内招了太多人，那给员工们的感觉就特别像是进入了一个都是陌生人的酒会，人们一团和气、互不攻击，看起来好像很融洽，但结果却是，没人好意思站出来指出他看到的问题，这样一来公司的效率又从何谈起呢？所以作者才说，放慢招聘的步伐很有必要。不过，光控制员工数量和招人的速度可远远不够，人力资源方面的另一个重点是要知道该招什么样的人。这就需要问一个问题了，判断员工最重要的条件是什么？你可能会回答，学历和工作经验。要是这么说，那可正好撞到作者的枪口上了。先说学历，作者觉得学历其实没有那么重要，因为象牙塔外面的聪明人多得是。作者统计，美国500强企业的CEO 里，有90%都没有在常青藤学校接受过本科教育，但你能说这些 CEO 水平差吗？肯定不能。再来看工作经验，很多公司特别看重这个，动不动就要求，比方说五年以上的工作经验，其实这真没必要。员工确实一般都需要半年或一年的时间，来养成工作习惯，掌握一定的工作技巧，但这段时间之后，成长曲线其实就趋于平缓了。作者认为，有6个月的工作经验和有6年工作经验的应聘者，他们之间的差距一般不会大。因为真正干得好的人，几个月就能轻松上手，而没有天赋的人，干上一辈子也不会有什么出息。所以你不能拿时间长短论英雄，真正重要的是他们到底做得有多好。所以下次招聘的时候，还是别看那些虚的了，判断员工的能力才是最重要的。假如企业管理者完成了招聘任务，团队到齐之后，接下来要做的事，就是让每个人都上场干活。那有的管理者就会想，要不要再招个评估绩效的人，记录大家都干了多少活呢？作者觉得，尤其在小公司里面，其实根本不需要那种监督别人干活的监工，每个人都应该撸起袖子加油干，为公司创造价值。在做到了上面的几点之后，公司里的员工应该个个都是干活儿的能手了，所以他们每个人自然都有能力去独当一面，公司管理者在招人时付出的辛苦，都会转化为日后的高效和轻松。以上就是第三个重点，这部分作者给出的建议是：在人力资源方面要谨慎，要尽可能少、尽可能慢地招实实在在有能力的员工，然后每个员工要尽可能多地创造价值。做到这一点，招人的目的就算达到了。总之就是简简单单，效率第一 。 第四部分从企业的社会关系层面来看，人力资源属于企业的内部关系，那讲完了内部关系，企业的外部关系也不能忽视。所以接下来，为你介绍的最后一个重点：在处理外部关系方面，我们要坚持主见，不模仿不盲从，这样面对对手和客户时才能占据主动 。对手和客户，可能是让所有公司管理者都头痛的两种人。对付他们，作者给出了一个聪明的策略，那就是 坚持主见、做好业务，这样就能占据主动，让对手和客户围着你转。具体该怎么做呢？ 先说对手。作者认为，对手不值得关注。这是因为，如果一个企业的领袖要是太操心对手，就会陷入紧张和焦虑之中，成天会想着对手在干什么，而忘记自己该干什么。所以要想战胜对手，管理者在做好本职业务的同时，首先从态度上就不能太把他们当回事 。有了态度然后就是行动，管理者在和竞争对手竞争的过程中，行动上也要有自己的主见。作者认为，既然要和对手竞争，管理者首先就应该拒绝照搬对手的做法。虽然有时照猫画虎也是一种学习过程，但商业上的模仿却不太招人喜欢。一家公司当然可以轻松地复制粘贴，剽窃别人的文字、图像或者代码，但这种方式是注定是会失败的。因为简单的复制会让一家公司失去深刻理解的能力，而只有理解才能激发成长 。要是只会抄别人的，那这个公司就永远没法掌握主动，只能当个尾随者了。不过，就算不抄袭别人，别的公司也有可能抄袭我们。尤其是当自己的公司获得成功时，那模仿者肯定就蜂拥而上了。那这时公司又该怎么保护自己不被模仿者吞没呢？作者在这儿给了个建议，那就是可以让自己成为产品或服务的一部分，这样对手就再也模仿不来了。举个例子，美国著名的农业公司“多元农场”，它就把自己变成了产品的一部分。他们是这么做的：多元农场会不顾成本地给牛喂食昂贵的草饲料，而且坚持不给牲畜使用抗生素，这样肉制品的品质就会更好、更健康。它还开放了自己的农场，让所有人随意参观肉制品制作的整个生产流程。正因为这种“看得见的健康”，它的客户甚至愿意开车200公里来采购牛肉和鸡肉。所以你看，“多元农场”看起来卖的是农产品，但实际上卖的是自己的这种健康理念，卖的是自己这块招牌，这样，别人就算是想模仿也模仿不来。刚才我们说了，公司的外部关系由对手和客户组成，说完了对手，咱再来看看该怎么对付客户。作者对客户的态度特别简单粗暴，那就是“ 别太把客户当回事”，要学会对他们说“不”。美国汽车大王亨利·福特曾说过，“如果一味听顾客的，我就只能给他们弄一匹更快的马”。话虽然好笑，但却很有道理，因为客户有可能不知道自己到底想要什么。如果他们提的要求企业管理者都答应，就很可能不得不改变自己思考了很久的创意，让本来可以顺利完成的事情变复杂，最后把自己的产品弄得一团糟。尤其是对一些大客户，作者说，千万别太恭维他们。因为 公司如果处处迎合这些大客户的话，只要有一天客户离开，那这家公司就可能要饿死。因为他们的产品一直以来都是为了迎合特定的客户而设计的，所以可能已经不再有吸引力大众的能力，公司就容易经营不下去了。37signals就绝不恭维客户，只做好自己的本职工作， 宁可让客户放弃自己的产品，也不愿意做任何妥协。因为他们一直记得一句话，那就是，没有用过你们产品的客户永远比用过的多。作者认为，确保自己的产品容易让所有人上手，这就是持续成长的潜力所在。总之在公司的外部关系上，作者认为，企业管理者要把对手和客户放到一个合适的位置上。不能因为他们的存在就迷失自己，坚持主见做好自己的本职工作，不模仿也不盲从，这样才能不被别人扰乱自己的节奏，面对对手和客户时主动权自然就掌握在自己手里了。这又是一种以简单取胜的思维。 总结说到这儿，本篇文章的内容就说得差不多了。下面来简单为你回顾一下这本书的内容：首先，在公司文化方面，计划、会议、工作狂和规章制度，看起来都很有用，但实际上可能是效率的杀手。虽然很多公司都乐此不疲地制定计划和规章，不断地开会和加班，但这些东西，其实公司并不一定真的需要。判断公司是不是需要它们，要看它们到底能不能帮公司赚钱。如果发现这些行为原来都是效率的杀手，那还不如早早取消这些制度。第二，在公司规模方面，公司不一定要做大才有意义，小公司本身就可以是一个伟大的目标。对管理者来说，有什么样的条件就做什么样的事儿，有限的资源还能激发公司的创造力，激励公司尽可能地缩减不必要的开支。要是能把业务做得好能赚钱，那小公司完全可以作为企业管理者奋斗的最终目标。第三，在人力资源方面，公司要控制员工数量，放慢招聘步伐，这样每个人才能独当一面。作者说，不到万不得已绝不多招人，只有控制好新员工进入的速度，公司的气氛才适合高效的工作。而且，学历和工作经验不应该成为判断一个员工是否合适的标准，管理者应该实在点儿评判：只要能把活干好就是好员工。做到这几点，公司里的每个员工就都能独当一面，不会出现人浮于事的情况。最后，在外部关系方面，坚持主见，不模仿不盲从，面对对手和客户时才能占据主动。面对对手，管理者在态度上不能太把他们当回事，行动上别抄袭他们，也要注意别让他们抄袭自己。面对客户，别围着他们转，也别因为他们的要求而改变自己的主见，永远要做好自己的本职业务。做到这些，公司才能在面对对手和客户时占据主动。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《最强大脑》]]></title>
    <url>%2F2018%2F06%2F10%2F%E3%80%8A%E6%9C%80%E5%BC%BA%E5%A4%A7%E8%84%91%E3%80%8B%2F</url>
    <content type="text"><![CDATA[关于作者苏珊娜•埃尔库拉诺-乌泽尔，神经学家，美国范德堡大学心理学与生物科学系副教授，TED大会演讲人。苏珊娜从经常被大众忽略的神经元数量入手，以一种全新的理论解释了为什么人类比其他物种更聪明。 关于本书本书是一本探讨人类大脑进化的新锐研究作品。它开创了崭新的研究方法，同时以简明易懂的语言为读者阐明了 影响智力水平的因素 。更重要的是，本书针对人类大脑为什么更聪明 这个问题提出了与以往研究截然不同的全新理论。 核心内容大脑皮层的 神经元数量决定了动物的智力水平，人类大脑皮层中的神经元数量远高于其他物种，所以人类比其他物种更聪明。由于神经元数量越多，大脑的重量越大，对应的身体重量也越大。因此在进化过程中，可用卡路里量的有限性强迫大型类人猿在身体重量和脑子重量之间做出选择。人类因为掌握了烹饪技术而使在短时间内摄入大量卡路里以支持大脑运转成为可能。其他物种则不得不牺牲神经元数量，将摄入的卡路里用于维持身体运转。图片来源：《得到》 神经元缩放规则简单来说，就是每种动物的大脑在进化过程中，都要遵循一定的规则。这种规则规定了神经元数量和大脑体积之间的关系。有的动物进化程度比较高，在相同体积的情况下，能拥有更多的神经元。有的动物进化程度比较低，在相同体积的情况下，神经元数量比较少。需要注意的是，所有动物大脑的重量和体积呈正相关的关系，体积越大，重量也越大。所以在研究的过程中，有的科学家把体积当作参数，有的科学家把重量当作参数，但他们得出的结论是大致相同的。 案例比如以老鼠为代表的啮齿类，它们就属于进化程度比较低的，大脑体积不大，拥有的神经元数量也很少。人类作为一种极其聪明的物种，拥有高达1000亿个神经元。如果我们不幸地遵循了老鼠的神经元缩放规则，为了保持1000亿个神经元，我们的大脑重量就得超过60斤，对应的体重将高达80吨！ 人类的大脑遵循类灵长动物的进化规则人类的大脑之所以展现出异于其他物种的高级能力，是因为作为灵长类动物的一员，人类的大脑严格遵循了灵长类动物的神经元规则，在更小的大脑皮层和小脑里塞进了更多的神经元，在智力水平上把其他物种远远甩在身后。但是人脑也有其自身的特殊性，比如：相对于同等体型的非灵长类动物，人类的脑子足足比大了7倍；人脑每天消耗的能量占人体全部耗能的25%；大猩猩脑子的体积只有人类大脑体积的1/3，在人类面前实在是不值一提。 “脑之汤”的实验方法在“脑之汤”这种方法出现之前，对神经元计数的难点在于大脑内的细胞并不是均衡分布的。通过把固体的大脑变成细胞核在其中自由浮动的、具有均衡性的汤，苏珊娜只要取一小部分汤出来，数清楚里面有多少细胞核，也就知道了大脑中有多少细胞。大脑中除了重要的神经元，还有一些其他类型的细胞。苏珊娜的下一步是将一种只能把神经元染色的抗体加入脑之汤，再数一数被染色的细胞核有多少，从而计算出神经元占大脑所有细胞的比例，以及神经元的真实数量。 决定动物聪明程度的是神经元数量而不是脑容量在科学领域，聪明程度通过“认知能力”的高低来体现。认知能力只与一个东西有关系，那就是大脑皮层中的神经元数量。其他动物的脑子虽然大，但人类大脑皮层中的神经元数量远比其他动物要多，所以人类比其他物种更聪明。 案例苏珊娜选择了重量巨大的大象的脑子与人脑进行比较，试图找出到底是全脑重量还是大脑皮层神经元数量影响了大象和人类的认知水平。人类显然要比大象聪明，我们会说话、会写字、还能把大象拉到实验室里研究一番。但是人类的全脑重量只是大象全脑重量的三分之一，所以首先可以排除全脑重量对认知能力的影响。我们再来看大脑皮层神经元数量。整个大象脑子总共有2570亿神经元，但是其中98%的神经元都存在于大象的小脑。在大脑皮层神经元数量这个最关键的数据上，大象只有56亿，无法与人类的160亿神经元相提并论。这些实验数据有力地证明了这个结论： 大脑重量并不重要，大脑皮层的神经元数量才是决定人类聪明与否的关键 。 烹饪在人类进化的过程中的作用在进化早期，大脑的地位并不太重要。因为觅食能力相对低下，人类和其他动物一样，摄取能量的绝大部分被用于维持身体机能运转。大脑消耗能量的多少跟其拥有的神经元数量密切相关，神经元数量越多，人越聪明，大脑耗能越大。分配给大脑的能量变少了，我们就自然而然地更笨了 。人类掌握烹饪技巧之后，在同样的时间里、耗费同样的体力，能够获得更多的能量。在进化的过程中， 更多的能量意味着人类有机会把多出的能量分配给大脑。久而久之，大脑就有机会拥有更多的神经元，变得更聪明，聪明到学会耕种、学会畜牧，开始农业文明。从这个角度看，如果没有某位祖先在某天突然掌握了烹饪技巧，我们的大脑还会和其他近亲一样，只能沦为身体的附庸，起不到决定性作用。所以我们在潜意识里把烹饪视为极其重要的技能，进而影响了我们对其他人的判断。 金句 人类的优势在于我们是唯一研究自己和其他事物，并且在研究的过程中产生知识，完好无损地传播开来的物种；我们能改变自己，用戴眼镜、植入和手术等方式弥补自己的缺陷，从而改变自然选择的规律；我们彻底改变自己所在的环境，使我们能在任何地方居住；我们使用工具制造工具，使工具变得更强大，能解决更多更困难的问题；我们不断寻找更复杂的问题的解决方案，这让我们自己的能力也随之增长；我们创造描述知识的方法，让后人学习知识时不再需要直接的演示—这些都使我们变得特别。虽然所有需要的认知能力都不是人类独有的，我们应用这些认知能力的复杂性和灵活性显然是其他任何物种难以望其项背的。 我进行了一项名为“你了解你的大脑吗”的调查，其中一个问题是“我们仅使用了大脑的10%”，60%接受过大学教育的里约本地人的答案为“是”，我对此感到非常震惊。我在流行科学杂志甚至宣传片中都看到过这个易使人上当的描述，但是从没预料到它在公众的意识中如此根深蒂固——而且这个说法还是虚构的。我们在任何时候都需要使用整个脑子，我们学习和进步，成就伟大的事业，甚至在睡觉时都使用了100%的脑子，只是使用的方式不同。 我们已经到达这个位置，我们中只有极少的人主宰了现在的技术。谁知道怎么融化和加工金属？更不用说用它来从头制造一辆汽车、一部手机或者一台电脑。能自称科学家甚至不等于我知道怎么制作一支简单的铅笔。当今技术中的很多不再掌握于一个个体。我们夸口从古希腊以来走了很长的路—但是我们不再同时是建筑学、生物学和理学专家。这就是为什么科学（知识）和技术（工艺）必须被小心地栽培、记录和传授给下一代。拥有令人瞩目的大脑皮层神经元数量从而能达到令人瞩目的成就是不够的：我们站立于前人的肩膀之上，并且现在我们这一物种的成就作为一个整体远远超过任何一个个体。人类很久以来就超越了个人。它自强化地匹配了我们大脑皮层中惊人数量的神经元促成的技术发明和文化传播，后者又将我们的性能成形为能力，并让我们成为人——无论情况好还是坏]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《见识》]]></title>
    <url>%2F2018%2F06%2F08%2F%E3%80%8A%E8%A7%81%E8%AF%86%E3%80%8B%2F</url>
    <content type="text"><![CDATA[摘要最近大概读了一下吴军老师的《见识》，觉得写的很不错，分享一些content给大家，书中精髓就是吴军老师讲的几个误区：简单重复，习惯性失败，林黛玉式的困境，狗熊掰棒子。 简单重复有些人的10000小时都是在从事低层次的重复，上文中我提到的伪工作者就是这种人。再举个具体的例子，如果在中学学习数学，不断重复做容易的题，考试成绩永远上不去，当然不会有中学生这么做。但是，在工作中很多人却犯这个错误。比如现在互联网比较热门，一些人学了一点点编程技巧，也能挣到还不错的工资，于是就守着这点技能每天在低水平地重复。我在《智能时代》这本书里提过一个观点：在未来的智能时代，真正受益于技术进步的个人可能不超过人口的2%。坦率地讲，仅仅会写几行Javascript（直译式脚本语言）的人不属于我说的2%的行列，这些人恰恰在未来是要被计算机淘汰的。 习惯性失败这一类人和前面讲的正相反。他们好高骛远，不注重学习，懒得总结教训；同时脸皮还很薄，也不好意思请教。他们迷信失败是成功之母的说法，然而简单地重复失败是永远走不出失败的怪圈的。因此这些人常常是时间花了很多，甚至不止10000小时，但是不见效果。在很多公司里都能见到这种人，一个人在下面捣鼓东西，就是找不到解决问题的方法。 林黛玉式的困境林黛玉其实是我非常喜欢的一个人物，我喜欢她实际上是因为她很有内涵和才气，想问题想得很深，但这也是她致命的弱点，她的才华越高，在自己的世界里越精进，对外界就越排斥（当然外界也排斥她）。我们知道，一个概念内涵越宽，外延就会越窄。你如果泛泛地说“桌子”这个概念，它包括非常多的家具，但是如果你说“法国洛可可宫廷式的核桃木贴面桌子”，世界上可能就没有几件了。林黛玉就是这样，她越是精进，越到后来贾府里只有贾宝玉能够懂她。我们很多人做事都是这样，越是在自己的一亩三分地上耕耘，对外界的所知就越少，而自己的适应性也就越差。有两类科学家，一类是掌握了一个方法，研究什么都是一流的，他们越往后走路越宽，比如爱因斯坦、费米和鲍林（两次获得诺贝尔奖的化学家）；另一类是路越走越窄，比如发明晶体管的夏克利（也因此获得了诺贝尔奖），他对自己研究的晶体管越来越熟悉，就对其他技术越来越不愿意接受，最后无法和工业界和学术界的同行交流。你会发现生活中有大量这样的人。 狗熊掰棒子10000小时的努力需要一个积累的效应，第二次的努力要最大限度地复用第一次努力的结果，而不是每一次都从头开始。希腊科学体系和东方工匠式的知识体系有很大的差别。前者有一个完整的体系，任何发明发现都是可以叠加的，你给几何学贡献了一个新的定理，几何学就扩大一圈。而后者不成体系，是零碎的知识点（甚至只是经验点），每一个新的改进都是孤立的，因此很多后来就失传了，以后的人又要从头开始。我们知道今天几乎任何一所三甲医院的主治医师，水平一定比50年前所谓的名医高很多。但是，今天没有哪个中医敢讲自己比500年前的名医水平高。这就是因为前者有积累效应，而后者没有。很多人读书也是狗熊掰棒子式的，做了一堆题，相互关系没有搞清楚，学到的都是零散的知识点，换一道题就不会做了，因此时间花得不少，成绩却上不去。在工作中也是如此。 对于每个人的情况可能不一样，从我自身来讲，能让我快速走出误区的办法是即使听到不中听的话，也要试着找出其中的合理之处，相当于换位思考，对于与我们意见不符的，我们可能会立即进行反驳，然后两个人闹得不愉快。所以我们要习惯回过头来三思。当某个人和讲一件事，你可能会觉得他完全是胡说八道，但是，一定要想第二遍，是否我错了，他对了。这一遍思考，一定不能假设自己是对的；如果又想了第二遍，还是觉得自己对，对方错，要想第三遍，是否我的境界不够，不能够理解他。为什么要想第三遍呢，因为任何一个想要精进的人，都要和比自己强的人多来往，第三种情况就很可能发生，因此这时候不妨进一步交流，深入了解对方那么说的原因。 其实我们厌恶与见识短浅的人交谈，并非是因为他们自身见识短浅，而是因为，他们用自己浅陋粗鄙的观念，肆无忌惮地评判他人，言语之间毫无半分谦逊与尊重。努力做一个见识渊博的人。时刻告诫自己。 总结最近有人说IT行业入门门槛越来越低，很多人到培训机构魔鬼训练3个月就可以挂牌上岗而且写的一手漂亮的代码。在这种情况下科班出身的程序员怎么才能不被干死呢?答案就是《见识》…]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hack HuaKe]]></title>
    <url>%2F2018%2F06%2F04%2FHack-HuaKe%2F</url>
    <content type="text"><![CDATA[参加由华中科技大学主办的2018 Unique Hackday比赛，开发了一款手势识别的小游戏： 参赛证 比赛中 比赛场地 我们作品的海报 团队合照]]></content>
  </entry>
  <entry>
    <title><![CDATA[罗永浩万字求职信]]></title>
    <url>%2F2018%2F05%2F26%2F%E7%BD%97%E6%B0%B8%E6%B5%A9%E4%B8%87%E5%AD%97%E6%B1%82%E8%81%8C%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[俞校长您好： 我先对照一下新东方最新的招聘要求： 1、有很强的英语水平，英语发音标准 英语水平还好，发音非常标准，我得承认比王强老师的发音差一点。很多发音恐怖的人（宋昊、陈圣元之流）也可以是新东方的品牌教师，我不知道为什么要要求这一条，尽管我没这方面的问题。 2、大学本科或以上学历，英语专业者优先 真不喜欢这么势利的条件，这本来应该是××之流的学校的要求。 3、有过考TOEFL、GRE的经验 GRE考过两次。 4、有教学经验者，尤其是教过以上科目者优先 教过后来被国家明令禁止的传销课，半年。 5、口齿伶俐，中文表达能力强，普通话标准 岂止伶俐，简直凌厉，普通话十分标准，除了对卷舌音不太在意（如果在意，平舌音也会发错，所以两害相衡取其轻）。 6、具备较强的幽默感，上课能生动活泼 我会让他们开心。 7、具备较强的人生和科学知识，上课能旁征博引 除了陈圣元，我在新东方上过课的老师（张旭、王毅峰、王昆嵩）都和文盲差不多，当然他们还小。说到底，陈圣元的全部知识也只是在于让人看不出他没有知识而已。 8、具备现代思想和鼓动能力，能引导学员为前途奋斗 新东方的学员是最合作，最容易被鼓动的，因为他们来上课的最大目的就是接受鼓动，这个没有问题。 9、年龄在40岁以下 28岁。 下面是我的简历或是自述： 罗永浩，男，1972年生于吉林省和龙县龙门公社。 在吉林省延吉市读初中时，因为生性狷介，很早就放弃了一些当时我讨厌的主课，比如代数、化学、英文，后来只好靠走关系才进了当地最好的一所高中，这也是我刚正不阿的三十来年里比较罕见的一个污点。因为我和我国教育制度格格不入又不肯妥协，1989年高中二年级的时候就主动退学了。 有时候我想其实我远比那些浑浑噩噩地从小学读到硕士博士的人更渴望高等教育，我们都知道钱钟书进清华的时候数学是零分（后来经证实其实是15分），卢冀野入东南大学的时候也是数学零分，臧克家去山东国立青岛大学的时候也是差不多的情况。今天的大学校长们有这样的胸襟吗？当然，发现自己文章写的不如钱钟书是多年后的事情了，还好终于发现了。 退学之后基本上我一直都是自我教育（当然我的自我教育远早于退学之前），主要是借助书籍。因为家境还勉勉强强，我得以相对从容地读了几年书，“独与天地精神往来“。 基于“知识分子要活得有尊严，就得有点钱”这样的认识（其实主要是因为书价越来越贵），我从1990年至1994年先后筛过沙子，摆过旧书摊，代理过批发市场招商，走私过汽车，做过期货，还以短期旅游身份去韩国销售过中国壮阳药及其他补品。令人难堪的是做过的所有这些都没有让我“有点钱“，实际上，和共同挣扎过的大部分朋友们比起来，我还要庆幸我至少没有赔钱。 我渐渐意识到我也许不适合经商，对一个以知识分子自许的人来说，这并不是很难接受的事情，除非这同时意味着我将注定贫穷。 1994年夏天，我找了个天津中韩合资企业的工作，并被派去韩国学习不锈钢金属点焊技术，1995年夏天回国的时候，很不幸我姐姐也转到了这家天津的公司并担任了副总经理，为了避嫌我只好另谋出路。 1995年8月至1996年初，经一位做传销公司（上海雅婷）的老同学力邀，我讲了半年左右的传销课，深受广大学员爱戴。遗憾的是国家对这种有争议的商业形式采取的不是整顿而是取缔的政策，所以看到形势不对，我们就在强制命令下达之前主动结束了生意。 因为那时候我爱上了西方音乐（古典以外的所有形式），大概收有上千张英文唱片，为了听懂他们在唱些什么，我在讲传销课的同时，开始学习一度深恶痛绝的英文。我在一个本地的三流私立英语学校上了三个月的基础英语课，后来因为他们巧立名目，拒付曾经答应给我的奖金（我去法院起诉过，又被法院硬立名目拒绝受理），我只好又自学了。 实在不知道困在一个小地方可以做些什么，所以1996年夏天我到天津安顿下来（那时候我很喜欢北京，但是北京房价太丧心病狂了），靠给东北的朋友发些电脑散件，以及后来零星翻译一些机械设备的英文技术文章维生，因为生性懒散不觉蹉跎至今。 我要感谢那本莫名其妙的预言书“诸世纪”，尽管我不是一个迷信的人，但是去年五一我看到那段著名的预言“1999年7月，恐怖的大王将从天而降……”的时候还是有些犹豫，我认真地考虑自己可能即将结束的生命里有什么未了的心愿，结果发现只有减肥。 从我有记忆以来我就是个痛苦的胖子，因为胖，我甚至不得不隐藏我性格里比较敏感忧郁的一面，因为胖子通常被大众潜意识里不由分说地认为应该嘻嘻哈哈，应该性情开朗，应该徐小平。他们对一个矫矫不群的胖子的性格，能够容忍的上限是严肃，再出格一点就不行了，比如忧郁。 虽然他们从来不能如此准确地说出这种想法，但是如果看到一个忧郁的胖子，他们就会直觉哪里不对了，他们的这种直觉的本质是，“你是个胖子，你凭什么忧郁呢？你还想怎么样？你已经是个胖子了。”所以很难见到一个肥胖的并且影响广泛的诗人，因为公众不能接受，任凭他的诗歌惨绿无比。 当然胖子的痛苦永远不值得同情（除非是因为病理或基因导致），因为他们胖通常是因为缺乏坚强的意志（也许除了丘吉尔）。我就是个典型，我的肥胖完全是因为厌恶运动造成的，我有过十几次失败的减肥经历，我试过节食、锻炼、气功和几乎所有流行过的药物，包括在西方严禁非处方使用的芬弗拉明，我总怀疑我不如小时候开朗，是因为误用芬弗拉明造成的，它减肥的药理竟然是通过使人情绪低落从而降低食欲，事实上，它根本就不是研制用来减肥的，它本是用来使轻度狂躁型精神病患者稳定情绪的药。我是中国落后的药检制度的严重受害者。 过了去年的五一节之后，我制定了严格的计划：每天只吃蔬菜、豆腐、全麦面包、鱼肉、橙汁、脱脂牛奶和善存，每天用一个小时跑10公里，也就是标准跑道的25圈。我不得不骄傲的是，我只用了58天就减掉了48斤体重，去掉休息的星期天，几乎是一天一斤。然后我心情平静地迎接了什么事情都没发生的7月。 这件事过后我发现其实我还是很有毅力的一个人。但是我不知道我的毅力应该用来做什么，末日虽然没有来，但是新世纪来了，30岁也快来了，这真是一件让人坐立不安的事情。 后来我一度想移民加拿大，所以一边找资料看，一边到天津大学夜间开办的口语学习班上课，一个班20多个人，一个外国教师（更多的时候是外国留学生）和我们天南地北地胡聊，除了政治。我一共上了四期这样的班，口语就差不多了，当然还是停留在比较普通的交流水平上，至少我看英文电影时还是需要看字幕，尽管在天津的四年间我看过大概600部英文电影。 过了元旦，一个小朋友在和我吃饭的时候突然问我，为什么不去新东方教书，你应该很适合去新东方教书。我说我倒是喜欢讲课，但是一个民办教师有什么前途呢？他说如果年薪百万左右的工作不算前途，那他就没什么可说的了。我得说我很吃惊。 不管怎么样，我仔细地把我能找到的关于新东方的材料都看了一遍，我觉得这个工作很适合我，尤其是看到杨继老师在网页上说“做一个自由而又敬业的人是我的梦想，新东方是实现它的好地方”的时候。在我尽管懒散无为却又是勤于思考的三十来年里，好像还是第一次看到一个很适合我，并且我也有兴趣去做的工作。杨继还转述席勒的话“忠于你年轻时的梦想”。我没看过席勒的东西，光知道有两个能写字儿的席勒，不知道是哪一个说的这话，但是我宁愿把它当成是新东方的精神。 我听说教托福和教GRE薪水差不多，但是GRE的学习要苦得多。 我想了想还是选择了GRE，毕竟托福是专门给非英语国家的学生考的，教书的满足感上逊色很多。 旧历新年的时候，因为不确定是不是需要大学文凭才行，我试着写了一封应聘信给俞老师，提到我只有高中文凭，结果得到的答复是欢迎来面试，除了感激我还能说什么呢？我是说即便没有文凭不行，我还是会来新东方做教师的，但是可能不得不伪造证件，作为一个比大多数人都更有原则、以知识分子自诩的人，如果可能，我还是希望不搞这些虚假的东西，俞校长的开明，使得我不必去做大违我的本性和原则的事情，得以保持了人格的完整，这是我时常感念的。 过了春节处理了一些杂事，很快就到了6月份，我买了本“红宝书”就上山了。鹫峰山上的学习气氛和恶劣条件我都非常喜欢，应该是因为生活有了明确目标的关系吧。但是我很快发现，讲课教师的水平和他们的报酬，以及新东方的声誉比起来还是很不理想的。我看到身边大多数的同学对所有的老师评价都很好，听到那些愚蠢的笑话、对ETS肤浅的分析导致的轻浮谩骂和充满种族歧视、宗教歧视的言论的时候，大多数人都笑得很开心。 这最终再次有力地证实了我一直怀有的一个看法：任何一个相对优秀的群体里面都是笨蛋居多。（励志名言www.lz13.cn）无论台下是300名来听传销的社会闲散人员，还是300名来听GRE的大学毕业生，对于一个讲课的人来说并没有多少区别，这也是他们在台上信口开河、吹牛放炮的信心来源。 当然这里大多数同学专业都很出色，都很勤奋刻苦，积极上进，性格上也远比我更具备成功的素质，我只是说他们缺少情趣，他们聪明（至少他们都敢考GRE的数学，这是我想都不敢想的），但是没有灵气，人品也未必差，只是缺乏独立思考能力。 我只喜欢陈圣元一个人的课，所以后来也就只去上他一个人的课，其他的时候一个人在宿舍背单词。陈圣元除了胡扯闲聊比较有水准之外，治学态度曾经也让我觉得很好，说起charter这个单词的时候，他说为了找到那个填空句子里面表达的意思，查遍了所有的词典都找不到满意的解释，最后花了一千多块钱买了一本巨大沉重的韦氏词典（显然是指MerriamWebster’s Third New International DictionaryUnabridged），才终于在该词典所列的关于charter的25条释义中的最后一条里找到了答案。 说起市面上粗制滥造的填空参考书的时候，他很不以为然，“我以三年的教学经验也精心编写了一本，那些作者对题目绝对没有我钻研得深，他们就会胡编乱造，然后急忙出版抓紧骗钱，我这本可以说是这方面的集大成者，现在正在印刷当中，很快就可以和大家见面”。 由于在山上的时候，单词还没怎么背，题目都没做过，所以他这些态度和表现曾经让我很景仰。发现不对头是下山之后开始的，我录了他的全部课堂录音，我听着录音大量做题的时候，才发现他的分析讲解漏洞百出，尽管他批评过去的新东方老师，都是拿了正确答案再进行分析讲解，可是他的工作显然也是一样，这样才能解释为什么他总是能用错误的分析推理，给你一个正确的答案。 另外我发现所有的三流词典，包括英汉词典，都在charter的第一个释义上就解释了，他声称在韦氏第三版未删节新国际词典的25条释义的最后一条中找到的答案，“由君主或立法机关发给城市或大学，规定其特权及宗旨的特许状”，所以我也买了本十多斤重的韦氏第三版回来，发现只有13条释义，而且在第2条里就解释了这个问题。 现在他的那本填空教程就在我手边，仅在No.4的52道题中，我就找到了18处错误，如果说翻译的错误对学生不重要，那么解题分析的错误也有10处之多。这也最终使得我改了主意，决定做填空老师，本来我想做词汇老师，那样可以海阔天空地胡扯。 我以这样的条件敢来新东方应聘，除了脸皮厚这个最显而易见的表面原因之外，主要还是教填空课的自信。第二次考试之后我一直做填空的备课，最消耗时间的是把NO.4到1994年的全部填空题翻译成中文，400多个句子的翻译，居然用了我整整一个月的时间，基本上是一个小时翻译三个句子，当然快的时候两分钟一个，慢的时候几个小时翻不好一句。 翻译这些句子是我本来的备课计划之外的工作，最终使我不得不做这个工作的原因是，钱坤强和陈圣元那两本“惨不忍睹”的教材。钱坤强的那本就不必说了，此人中文都有问题，尽管我坚信他的英文要远比我的水平高（也许应该说熟练），但是理论上一个人如果母语都掌握不好（这意味着他对语言本身不敏感），那么他肯定掌握不好任何其他语言，即便他能熟练运用，也不适合做语言方面的工作，比如文字翻译。他那本超级填空教程在新东方地下室卖了两年都没正式出版，一定程度上说明了这本书的水准。 至于我非常喜欢的陈圣元，他在那本书的前言中说道：“翻译时尽量体现原文的结构，以便考生能对照原文体会原文句子结构的特征，从而体会结构与答案选项设计之间的关系……这样做会使得句子略显得欧化而不自然……不会去套用貌似华丽实则似是而非的成语。” 作为一个考试学习用的教材，他声称的翻译原则和宗旨是很好的，但是很遗憾，我看到的绝不仅仅是一个欧化或是不自然的问题。首先“体现原文结构”应该表现为翻译成中文之后，原文中的各个句子成分最大限度地在译文中充当同样的成分，而不是把所有的成分不变动位置地翻译成对应的中文单词，这样的做法和那些《金山快译》之类的拙劣软件的翻译结果有什么区别呢？ 实际上《金山快译》这一类翻译软件的译文虽然狗屁不通，但是我们即使看不到原文，通过猜测也能大致明白它想说些什么，这就如同没学过日文的中国人看日文电器说明书里面夹杂的汉字，也能隐约猜出大意一样。陈圣元的译文本质上就是这样的一种东西，当然程度上有些区别。 其实欧化并不可怕，尤其是在一本学习用的教材中，即使是在文学中，一些恶性的欧化今天也成了现代白话文的组成部分。陈圣元的译文根本不是欧化的问题，他的译文和钱坤强的一样，最恐怖也让人难以置信的是，作为所谓的译文，如果脱离了原文的对照，没有一个中国人知道这些句子在说什么，我是说这些句子字面上在说什么都没人看得懂，而不是因为句意晦涩难解而使人看不懂它想表达的内涵。 另外，看得懂的很多句子又翻错了，即便看不懂句子的意思真的不影响正确答案的选择，但是作为一本教学参考书，如果参考译文都翻错了，还怎么让学生信服呢？除非是以一种变态的方式，比如“陈老师的译文都翻错了，可是他的GRE考分那么高，可见看不懂句子对答题反而有帮助”这一种。 我的译文体现了这样几个原则，首先由于不是文学翻译，我注意了最大限度地使用原文的结构，使译文中的句子成分尽量充当原文中的对应成分。为了这种对应，有时候会有些比较不符合中文习惯的句子结构，比如一些在英文中可以置后的定语从句，按照中文的语法放到了修饰对象的前面之后，句子显得臃肿不堪，另外还可能导致断句困难。 针对这样的问题，我在这类句子中大量地使用了括号和破折号，很多时候，如果只读括号外边的内容，读到的就是这个句子完整的主干，那些使句子结构变得复杂的修饰成分都在括号里边，但是如果假定这些括号不存在，把它们连起来读，也是一个通顺完整毫无语病的句子，这样和原文对照阅读时，对应的成分和原句的主干结构清晰可辨。 （注：由于阅读的需要，我删去了罗永浩大量的修正例证。我请一位英语相当不错的博士看过这些例证，他说，水平相当高。） 在解题思路上我修正了陈圣元的书中所有不严谨的地方，难以置信的是这些不严谨的错误，在他的书中竟有三成之多。我的草稿还有很多优点，虽然这些优点是我完成的，但是我不想为了向别人解释“我做的工作牛就牛在……”这样的东西浪费太多的时间，所以不再分析了。 如果我们都接受“不存在完美的东西”这样一个假设，那么我想说的是，我的这本填空教材是离完美最近的那一个。希望我的坦率不会倒了您的胃口，当然我知道新东方的开明气度才会这样讲话。 如果新东方出版参考书的惟一标准是书的质量，而不权衡其他方面的因素，那么陈圣元的那本书的寿命，不会也不应该超过一年。需要做一个效果未必理想的声明是，我并非有意攻击陈圣元，他在课上说起，新东方的同仁们的一个优点是互相不会拆台，也许私下并无深交但是不会互相诋毁，这对事业或是人生的成功起到了相对积极的作用。 这种观点虽然不合我的本性，但是我也知道如果大家都是书生意气，新东方也没有今天。所以我接受了他的这个看法，基于这一点，我也不想对他做更多的攻击，很大程度上我对他的看法现在都坦率地说了出来，是因为他已经离开了，不存在和睦相处的问题。何况，他出色的幽默感和极佳的亲和力都是我很佩服的，毕竟他是新东方我见过的最喜欢的老师（如果不是惟一喜欢的）。对于他的工作和治学态度，我更多的是感到遗憾。 当然我知道会有一些年轻教师不屑地说，教教GRE，算个屁治学？那好吧。 我想我多半看起来像是个怪物，高中毕业，不敢考数学，居然要来做教师。但是我到新东方应聘不是来做教师的，我是来做优秀教师的，所以不适合以常理判断。即使新东方的声誉和报酬使得它从来都不缺教师，我也知道优秀的教师永远都是不嫌多的，如果新东方从来都不缺优秀教师，那么我也知道更优秀的教师从来都是新东方迫切需要的。 龚自珍劝天公“不拘一格降人才”，如果“不拘一格”的结果是降下了各方面发展严重失衡的，虽然远不是全面但又是十分优秀的畸形人才，谁来劝新东方“不拘一格用人才”呢？想想王强老师的经历，所以我也来试试说服您，我们都知道那个美国老头，虽然觉得他很荒唐，但是他还是给了王强老师一个机会去见他，一个机会去说服他，所以我想我需要的也就是这么个机会而已。给我个机会去面试或是试讲吧，我会是新东方最好的老师，最差的情况下也会是“之一”。 如果几年以后你来新东方看到一个人，咦，面熟，就是想不起来是谁，好像是罗永浩的弟弟，注意，我没有弟弟。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下git报错 fatal The remote end hung up unexpectedly解决方案]]></title>
    <url>%2F2018%2F05%2F22%2Fubuntu%E4%B8%8Bgit%E6%8A%A5%E9%94%99fatal%3A%20The%20remote%20end%20hung%20up%20unexpectedly%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[报错信息如下： 123error: RPC failed; curl 56 GnuTLS recv error (-12): A TLS fatal alert has been received.fatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedly 解决方案: ​1git config http.postBuffer 524288000 若报错：则使用命令： ​1git config --global http.postBuffer 524288000 命令作用：调整缓存大小为500M]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>ubuntu</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[libcudart.so.8.0 cannot open shared object file解决方案]]></title>
    <url>%2F2018%2F05%2F22%2Flibcudart.so.8.0%3A%20cannot%20open%20shared%20object%20file%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[报错信息： 1error while loading shared libraries: libcudart.so.8.0: cannot open shared object file: No such file or directory 解决方案： 1sudo ldconfig /usr/local/cuda/lib64]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>caffe</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithm summary]]></title>
    <url>%2F2018%2F05%2F22%2FAlgorithm%20summary%2F</url>
    <content type="text"><![CDATA[2018.5.24日更新：去掉原文中的目录，修正了目前我发现的错别字（其实也没几个，但是本着严谨的态度我还是决定修改过来），增添了部分代码注释（发现自己写的代码现在竟然看不懂，只能强行加注释了～） 一：算法分析基本概念二分搜索Linearsearch​1234567891011121314/* * 输入：n个元素的数组A[1...n]、x * 输出：如果x=A[j]&amp;&amp;1&lt;=j&lt;=n，则输出j，否则输出0 */int Linearsearch(int *A,int x, int n)&#123; int j=0; while (j&lt;n&amp;&amp;x!=A[j])&#123; j++; &#125; if(x==A[j])return j; return 0;&#125; Binarysearch​12345678910111213141516/* * 输入：n个元素的升序数组A[1...n]、x * 输出：如果x=A[j]&amp;&amp;1&lt;=j&lt;=n，则输出j，否则输出0 */int Binarysearch(int *A, int x, int n) &#123; int low = 1, high = n, j = 0; while (low &lt;= high &amp;&amp; j == 0) &#123; int mid = (int) ((low + high) / 2); if (x == A[mid])j = mid; else if (x &lt; A[mid])high = mid - 1; else low = mid + 1; &#125; return j;&#125; 要注意二分搜索的输入一定是一个 升序的数组，实质就是一个二叉搜索树（所以也把二分搜索的执行描述为决策树），对于一个大小为n的排序数组，算法Binarysearch执行比较的最大次数为int（logn）+1（如果输入数组不是递增排好序的，则可在nlogn内对其进行排序后再进行二分搜索）。 合并两个已排序的表​1234567891011121314151617181920212223242526272829303132333435/* * 输入：数组A[1...m]和它的三个索引p，q，r，1&lt;=p&lt;=q&lt;r&lt;=m，p、q、r满足A[p...q]、A[q+1...r]分别按照升序排列 * 输出：合并两个子数组A[p...q]和A[q+1...r]的数组A[p...r] */void Merge(int *A, int p, int q, int r) &#123; int B[r + 1];//B[p...r]是辅助数组 int s = p, t = q + 1, k = p;//s指向A[p...q]子数组，t指向A[q+1...r]子数组，k指向B数组 while (s &lt;= q &amp;&amp; t &lt;= r) &#123; if (A[s] &lt;= A[t]) &#123; B[k] = A[s]; s++; &#125; else &#123; B[k] = A[t]; t++; &#125; k++; &#125; if (s = q + 1) &#123;//说明s指向的数组已经遍历完了 for (int i = t; i &lt;= r; ++i) &#123; B[k++] = A[i]; &#125; &#125; else &#123; for (int i = s; i &lt;= r; ++i) &#123; B[k++] = A[i]; &#125; &#125; for (int j = p; j &lt;= r; ++j) &#123; A[j] = B[j]; &#125;&#125; 设Merge算法要合并两个大小分别为n1和n2的数组（n1 选择排序​12345678910111213141516171819/* * 输入：n个元素的数组A[1...n] * 输出：按非降序排列的数组A[1...n] */void SelectionSort(int *A, int n) &#123; for (int i = 0; i &lt; n; ++i) &#123; for (int j = i + 1; j &lt;= n; ++j) &#123; if (A[i] &gt; A[j]) &#123; int t = A[i]; A[i] = A[i]; A[i] = t; &#125; &#125; &#125;&#125; 算法SelectionSort所需的元素比较次数为n(n-1)/2（n-1+n-2+n-3+…+2+1=n(n-1)/2），因为每次交换需要3次赋值，所以元素的赋值次数介于0到3(n-1)之间。 插入排序思路首先将第二个数与第一个数进行对比，如果第二个数比第一个数小，则将第二个数插入到第一个数之前，这样保证前两个数是有序的；接下来将第三个数与前两个数对比，比较的思路是先将第三个数存下来（记为x），然后将第三个数与第二个数比较，如果第二个数比第三个数大，则直接将第二个数向后移动一位，如果第二个数不比第三个数大，则说明此时前三个数都是有序的，因为之前前两个数是有序的，比较到最后，将x放到第三个数比较的终止位置即可。以此类推，将后面的i个数分别其前面的i-1个数进行对比，并将其插入到第一个比其大的数前面，最后即可完成排序。 代码实现​12345678910111213141516/* * 输入：n个元素的数组A[1...n] * 输出：按非降序排列的数组A[1...n] */void InsertionSort(int *A, int n) &#123; for (int i = 2; i &lt;= n; ++i) &#123; int x = A[i]; int j = i - 1; while (j &gt; 0 &amp;&amp; A[j] &gt; x) &#123; A[j + 1] = A[j]; j--; &#125; A[j + 1] = x; &#125;&#125; 执行算法SelectionSort的元素比较次数在n-1到n(n-1)/2之间，元素赋值次数等于元素比较次数加上n-1. 自底向上合并排序12345678910111213141516171819/* * 输入：n个元素的数组A[1...n] * 输出：按非降序排列的数组A[1...n] */void Merge(int *A, int p, int q, int r);void BottomUpSort(int *A, int n) &#123; int t = 1; while (t &lt; n) &#123; int s = t, t = 2 * s, i = 0; while (i + t &lt;= n) &#123; Merge(A, i + 1, i + s, i + t); i = i + t; &#125; if (i + s &lt; n) &#123; Merge(A, i + 1, i + s, n); &#125; &#125;&#125; 用算法BottomUpSort对n个元素的数组进行排序，当n为2的幂时，元素比较次数在(nlogn)/2到nlogn-n+1之间。执行该算法的元素赋值次数为2nlogn。 时间复杂性O前文提到算法InsertionSort执行的运算次数至多为$o(n^2)$， 其中c为某个适当选择的正常数。这时我们说算法InsertionSort的运行时间是$c(n^2)$，说明当排序元素的个数等于或超过某个阈值n0时，对于某个常量c，运行时间是$cn^2$，O符号描述的是一个上界但不一定是算法的实际执行时间，比如当排序一个已经排序好的数组时InsertionSort的运行时间就不是$O(n^2)$而是O(n)了。 Ω相比于O，Ω描述的是算法执行的 下界，比如算法InsertionSort的运算时间至少是cn，则称算法InsertionSort的运行时间是Ω（n），即无论何时，当被排序的元素个数等于或超过某一个阈值n0时，对于某个常数c，算法的运行时间至少是cn。 SentaSenta描述的是一个确切界限，如果对于任意大小等于或超过某一阈值n0的输入，如果运行时间在c1g(n)和c2g(n)之间，则称算法的运行时间是Senta(g(n))。 复杂性类与 o 符号o符号O 符号给出的上界可以是“紧”的,也可以是非“紧”的。$2n^ 2 =O ( n^ 2 ) $是渐近性紧边界$2n = O ( n^ 2 ) $不是渐近性紧边界 o 符号就用来表示 不是渐近性紧边界 的上界举例: 2 n = o ( n ) , 2 ^n ！= o ( n ) 直观上来说,在小 o 符号中, f ( n ) =o ( g ( n )) ,当 n 趋向于无穷大时, f (n ) 函数相当于 g (n )就变得不再重要了即lim- &gt;+oof(n)/g(n)=0 w符号用类比法来讲,小 w符号相对于大 Ω符号的关系正如 o 符号相对于 O 符号的关系。我们用小 w 符号来表示一个 渐近性非紧密的下界 。比如： (n^2)/2=w(n ) (n^2)/2!=w(n^2) lim- &gt;+oof(n)/g(n)=oo 空间复杂性我们把算法使用的空间 定义 、为:为了求解问题的实例而执行的计算步骤所需要的内存空间,它不包括分配用来存储输入的空间（为了区分那些在整个计算过程中占用了少于输入空间的算法） 。 算法的 空间复杂性不可能超过运行时间的复杂性 ,因为每写入一个内存单元都至少需要一定的时间。所以,如果用 T (n ) 和 S (n )分别代表算法的时间复杂性和空 间复杂性,有: S ( n ) = O ( T ( n )) 。 最优算法如果可以证明任何一个求解问题 T的算法必定是Ω ( f ( n )) ,那么我们把在 O ( f ( n )) 时间内求解问题T的任何算法都称为问题T的最优算法。 如何估计算法的运行时间 计算迭代次数 计算基本运算的频度 &gt;一般来说,在分析一个算法运行时间时,可以找出这样一个元运算,它的频率至少和任何其他运算的频度一样大,称这样的运算为基本运算。我们还可以放宽这个定义,把那些频度和运行时间成正比的运算包括进来。 使用递推关系 &gt;如果一个算法本身是递归算法,那么计算这个算法运行时间的函数通常也是递归的,即是指,这个函数的定义中引用了函数自身。即便一个算法本身是非递归的,我们有时也可以用递归式来计算它的运行时间。 lim- &gt;+oof(n)/g(n)!=oo f(n)=O(g(n))lim-&gt;+oof(n)/g(n)!=0 f(n)=Ω(g(n))lim-&gt;+oof(n)/g(n)==c f(n)=Senta(g(n)) 二：堆和不相交集数据结构在很多情况下我们需要使用一种具有 插入元素 和 查找最大值元素 的数据结构，这种数据结构叫做 优先队列，如果采用普通队列，那么寻找最大元素需要搜索整个队列，开销比较大；如果使用排序数组，插入运算就需要移动很多的元素，开销也会比较大。这时候 堆就是一种 有效的实现优先队列的数据结构 。 堆的特点： 父节点大于等于子节点（但是两个子节点之间的大小关系没有要求），这样可以做到 沿着每条从根节点到叶子节点的路径，元素的键值都是以非升序排列的 。 堆是一个 几乎完全的二叉树 ，所以具有和完全二叉树一样的特点，即一般是存储在一个数组A[n]中，A[i]的左子节点在A[2i]中，右子节点在A[2i+1]中（当他们存在的时候）,A[i]的父亲节点在A[i/2]中（如果存在，i/2向下取整）。 堆需要支持的几种运算： * delete-max[H] 从一个非空的堆H中删除最大元素并将数据项返回 * insert[H,x] 将x插入到对H中 * delete[H,i] 从堆中删除第i项（注意不是删除i） * makeheap[A] 将A转换成一个堆 堆上的运算两个辅助运算SIFT-UP功能当某个节点（H[i]）的值大于他的父亲节点的值时，需要通过SITF-UP将这个节点 沿着从H[i]到H[1]这条唯一的路径上移到合适的位置以形成一个合格的堆。 实现思路将H[i]与其父亲节点H[i/2]比较，如果H[i]大于H[i/2]，则将H[i]与H[i/2]互换，直到H[i]没有父节点或者H[i]不大于H[i/2]。 代码​123456789101112131415161718 int SiftUp(int *H, int i) &#123; while (true) &#123; if (i == 1) &#123; break;//说明当前i是根节点 &#125; if (H[i] &gt; H[(int) i / 2]) &#123;//如果当前节点比父亲节点大 int t; t = H[i]; H[i] = H[(int) i / 2]; H[(int) i / 2] = t; i = i / 2; &#125; else &#123; break; &#125; &#125; return 0;&#125; SIFT-DOWN功能当某个节点（H[i]，i&lt;=(int)n/2即 非叶子节点）的值小于它的两个子节点H[2i]和H[2i+1]（如果存在的话）的最大值时，需要将SIFT-DOWN将渗到合适的位置。 实现思路将H[i]与其两个子节点中值最大的元素比较，如果小于最大的那个节点，则将H[i]与其最大的那个子节点互换。 代码：​123456789101112131415161718192021 int SiftDown(int *H, int i, int n) &#123; while (true) &#123; i = 2 * i; if (i &gt; n) &#123; break; &#125; if (i + 1 &lt;= n) &#123; if (H[i + 1] &gt; H[i]) &#123;//比较两个子节点哪个最大 i++; &#125; &#125; if (H[i] &gt; H[(int) i / 2]) &#123; int t; t = H[i]; H[i] = H[(int) i / 2]; H[(int) i / 2] = t; &#125; &#125;&#125; 插入（insert）功能将元素x插入到已有的堆H中 实现思路首先将堆的大小增加1（n++），然后将x放在H[n]中，然后根据需要将H[n]中的元素x进行上移操作，直到最后形成一个合格的堆。 算法时间复杂度分析一个大小为n的二叉堆其高度应该为（int）logn，所以将一个元素插入大小为n的堆中所需的时间复杂度为 O（logn） 代码123456 void insert(int *H,int x,int &amp;n)&#123; n++; //这里默认H开的空间够用 H[n]=x; SiftUp(H, n);//将x根据需要上移&#125; 删除（delete）功能将堆H中的元素x删除 实现思路用堆中的最后一个元素H[n]替换需要删除的元素H[i]，然后堆的大小减一（n–），然后根据需要对H[i]进行上移或者下渗直到最后形成一个合格的堆。 算法时间复杂度分析一个大小为n的二叉堆其高度应该为（int）logn，所以从一个大小为n的堆中将一个元素删除所需的时间复杂度为 O（logn） 代码​12345678910111213141516 void Delete(int *H, int i, int &amp;n) &#123; if (i == n) &#123;//如果需要删除的是最后一个元素 n--; return; &#125; H[i] = H[n]; n--; if (H[i] &gt; H[(int) i / 2]) &#123;//如果当前节点比父亲节点大则需要上移 SiftUp(H, i); &#125; else &#123;//否则进行下渗 SiftDown(H, i, n); &#125;&#125; 删除最大值（deletemax）功能将堆H中的最大元素x删除并返回最大值。 实现思路用堆中的最后一个元素H[n]替换需要删除的元素H[1]，然后堆的大小减一（n–），然后根据需要对H[1]进行上移或者下渗直到最后形成一个合格的堆。 算法时间复杂度分析一个大小为n的二叉堆其高度应该为（int）logn，所以从一个大小为n的堆中将一个元素删除所需的时间复杂度为 O（logn） 代码​12345 int DeleteMax(int *H,int &amp;n)&#123; int x=H[1]; Delete(H, 1, n); return x;&#125; 创建堆（makeheap）功能给出一个有n个元素的数组H[1….n]，创建一个包含这些元素的堆。 实现思路类似于分治，首先，H的叶子节点（即最下面的一层单个元素）可以认为是若干个小堆，然后我们从倒数第二层开始，将倒数第二层和倒数第一层的元素进行适当调整，使得调整之后整个二叉完全树的最后两层是若干个子堆，按照这个思路，依次向上走，最终走到第1层的时候就可以保证整个完全二叉树是一个符合要求的堆。 需要注意的是对于一个完全二叉树， 倒数第二层的最后一个元素的下标为int(n/2) ，（因为倒数第二层的最后一个节点的下标x应该满足x*2=n）. 算法时间复杂度分析senta(n) 代码​12345 void makeheap(int *H,int n)&#123; for (int i = n/2; i &gt;=1 ; --i) &#123;//从倒数第二层到第一层 SiftDown(H,i,n); &#125;&#125; 堆排序（heapsort）功能利用堆对数组H[n]进行排序。 实现思路首先将数组H[n]调整成为一个（大顶）堆，这时可以保证H[1]是数组中的最大元素，然后将H[1]与H[n]互换位置，然后再调整1——n-1为一个大顶堆，然后将H[1]与H[n-1]互换，以此类推，最后就可以保证H为一个非升序的数组。 算法复杂度分析空间复杂度：因为本算法是在数组H原有的空间基础上进行排序的，所以空间复杂度是Senta（1）。时间复杂度： 建堆 senta(n) 执行n-1次siftdown nlog(n)所以总的时间复杂度是nlog（n） 代码​12345678910void HeapSort(int *H,int n)&#123; makeheap(H,n); int t; for (int i = n; i &gt;=2 ; --i) &#123; t=H[i]; H[i]=H[1]; H[1]=t; SiftDown(H,1,i-1); &#125;&#125; 三：归纳法只调用一次的递归叫做尾递归 基数排序算法思想基数排序需要经历d次，d为所要排序数列中位数最多的数的位数，其过程是首先根据数列中数的个位的数值将所有数入0~9这10个队列，然后从0~9将元素依次出队，然后再根据十位元素的数值再次入队，然后出队，以此类推重复d次，最终即可完成排序。 时间空间复杂度及稳定性 T(n)=O(d*n) d为排序数中最大数的位数 S(n)=O(n) 稳定 代码​123456789101112131415161718192021222324252627void radixSort(vector&lt;int&gt; v) &#123; int d = GetMaxBit(v); int *count = new int[10]; queue&lt;int&gt; q[10]; int radix = 1; for (int i = 0; i &lt; d; ++i) &#123; for (int j = 0; j &lt; v.size(); ++j) &#123; int t; t = (v[j] / radix) % 10; q[t].push(v[j]); &#125; int p = 0; for (int k = 0; k &lt; 10; ++k) &#123; while (!q[k].empty()) &#123; v[p++] = q[k].front(); q[k].pop(); &#125; &#125; radix *= 10; &#125; show(v);&#125; 注意对于任何的基数都可以归纳出算法，而不仅仅是以10做基数。比如可以把二进制的每四位作为一个数字，也就是用16作为基数，表的数目将和基数相等但是要保证从低位开始将数分配到表中。 整数幂场景介绍很多时候我们需要求实数x的n次方即x^n，按照常规做法一般会对x进行n次自乘以得到x^n，但是这是非常低效的，因为它需要senta（n）次乘法，按照输入的大小来说它是指数级的。 归纳法思路一个比较高效的归纳算法是令m=int(n/2)，假设已经知道如何计算x^m,那么根据x^m次方来计算x^n次方就有两种情况： n为偶数 则x^n=（x^m）^2 n为奇数 则x^n=x(x^m)^2 归纳法实现代码（Exprec）​123456789101112131415int power(int x,int n)&#123; if (n==0)&#123; return 1; &#125; int m=n/2; int y; y=power(x,n/2); y=y*y; if (n%2!=0)&#123;//如果n是奇数 y=y*x; &#125; return y;&#125; 迭代法实现思路上述归纳法实现求x^n的关键部分在于采用递归不断判断n/2的奇偶性，所以我们可以采用迭代的办法，因为一个数除以2的k次方后的奇偶性由其化为二进制数的第k低位决定的（因为除法除以2就相当于二进制的左移操作），所以我们可以将n化为二进制数字dk,d(k-1)……d_0，从y=1开始，从左到右扫描二进制数字，如果当前二进制数字为0，则对应递归情况下的偶数情况即应该y=y^2，否则即为y=y(y^m)^2 迭代法实现代码（Exp）​12345678910int Exp(int x,int n)&#123; int d[10];//假设n化为2进制数字后存在d数组里面 int y=1; for (int i = len(d); i &gt;=0 ; --i) &#123; y=y*y; if(d[i]==1)&#123; y=y*x; &#125; &#125;&#125; 总结假设每次乘法的时间是常数，那么这两种方法所需的运行时间都是 senta(lohn) ，他们对于输入大小来说都是 线性 的。 多项式求值（Horner规则）场景介绍假设有n+2个数a0,a_1,……,a_n和x序列，要对多项式 *P_n(x)=a_nx^n+a(n-1)x^(n-1)+…+a_1x**求值，传统的办法是分别对每一个子项求值，然后再对整个式子求值，但是这种方法很低效，因为它需要n+（n-1）+（n-2）+…..+1=n(n+1)/2次乘法。 归纳法解决思路首先我们发现原式可进行如下化简（这么丑的字不是我写的…）：化简之后我们可以发现如果我们假设已知P(n-1)(x)，那么P_n(x)=x*P(n-1)(x)+a_0,所以就有了算法HORNER。 HORNER算法代码实现​12345678int Horner(int *A,int n,int x)&#123;//数组A的长度为n+2，从A[0]到A[n+1]代表了a_0到a_(n+1) int p=A[n+1];//p=a_(n+1) for (int i = 1; i &lt;=n ; ++i) &#123; p=p*x+A[n+1-i];//p=p*x+a_(n-i) &#125;&#125; 寻找多数元素场景描述令A[1…n]是一个整数序列，如果该序列中的某一个数x在该序列中出现的次数多余int(n/2)，则称x为该序列的 多数元素 。 解决方法 蛮力法 将每个元素与其他因素进行比较，并且对每一个元素计数，如果某个元素的计数大于int(n/2)，就可以断言它是多数元素。但是这种方法的比较次数是n(n-1)/2=senta(n^2)，代价过于昂贵。 利用排序 先将原序列进行排序，在最坏情况下，排序这一步需要Ω(nlogn)次比较。 寻找中间元素 因为多数元素排序后一定是中间元素，可以找到该序列的中间元素后扫描整个序列该中间元素的出现次数来验证该元素是否为多数元素，由于中间元素可以在senta(n)时间内找到，这个方法要花费senta(n)时间。 MAJORITY算法 首先我们需要知道，去掉一个序列中的两个不同的数后该序列原来的多数元素现在依然是新序列的多数元素，所以我们……我们能怎么样呢，这不好描述啊，还是看代码吧…… 代码实现​123456789101112131415161718192021222324252627282930313233int majority(int *A, int n) &#123; int c = candidate(A, 1, n); int count = 0; for (int i = 1; i &lt;= n; ++i) &#123; if (A[i] == c) &#123; count++; &#125; &#125; if (count &gt; (int) n / 2) &#123; return c; &#125; else &#123; return NULL; &#125;&#125;int candidate(int *A, int m, int n) &#123;//寻找A[m...n]中的多数元素 int j = m; int c = A[m]; int count = 1; while (j &lt; n &amp;&amp; count &gt; 0) &#123; j++; if (A[j] == c) &#123; count++; &#125; else &#123; count--; &#125; &#125; if (j == n) &#123; return c; &#125; else &#123; return candidate(A, j + 1, n); &#125;&#125; 四：分治法什么是分治一个分治算法把问题实例划分为若干个子问题（一般是两个），并分别使用递归解决每个子实例，然后把这些子实例的解组合起来，得到原问题的解。 举个栗子考虑这样一个问题：我们需要在序列Ａ[1….n]中找到该序列的最大值元素和最小值元素，一种直接的算法是扫描一遍Ａ序列，用两个标志位max和min分别表示最大值和最小值元素，然后扫描时根据每个元素与当前最大最小值的比较情况动态调整最大最小值直至最后找到最大最小值，代码如下： ​12345678910void MaxMin(int *A,int n)&#123; int max,min; min=max=A[0]; for (int i = 1; i &lt;n ; ++i) &#123; if(A[i]&gt;max)max=A[i]; if(A[i]&lt;min)min=A[i]; &#125; cout&lt;&lt;max&lt;&lt;min&lt;&lt;endl;&#125; 显然，此种方法的元素比较次数是２ｎ－２，但是利用分治策略就可以将元素比较次数减少到(３ｎ)/2-2，具体做法：将数组分割成两半，Ａ[1…n/2]和Ａ[n/2+1…n]，在每一半中分别找到最大值和最小值，并返回这两个最小值中的最小值、这两个最大值中的最大值作为最终的最小、最大值。对应伪代码如下： ​1234567891011121314(max min) MaxMin2(int *A,int low,int high)&#123; if (high-low==1)&#123; if (A[low]&lt;A[high])return (A[low],A[high]); else return (A[high],A[low]); &#125; else&#123; int mid=(high+low)/2; (x1,y1)=MaxMin2(A,low,mid); (x2,y2)=MaxMin2(A,mid+1,high); x=min(x1,x2); y=max(y1,y2); return (x,y); &#125;&#125; 按照上述算法，设Ａ[1…n]有ｎ个元素，ｎ为２的幂，则仅用３ｎ/2-2次元素比较就可以在数组Ａ中找出最大值和最小值。 二分搜索分治（递归）实现原理比较简单，给出代码： ​12345678int binarysearch(int *A, int low, int high, int x) &#123;//A是已经排序过的数组,A[1....n] if (low &gt; high)return 0; int mid = (high + low) / 2; if (x == A[mid])return mid; if (x &lt; A[mid])return binarysearch(A, low, mid, x - 1); else return binarysearch(A, mid + 1, high, x);&#125; ​ 算法BINARYSEARCHREC在ｎ个元素组成的数组中搜索某个元素所执行的比较次数不超过((int)logn)+1，时间复杂度是Ｏ(logn)。 迭代实现​1234567891011121314int binarysearch(int *A, int n, int x) &#123;//A是已经排序过的数组,A[1....n] int low, high, j; low =1; high = n; j = 0;//j表示ｘ的下标 while (low &lt;= high &amp;&amp; j == 0) &#123; int mid = (high + low) / 2; if (x == A[mid]) j = mid; else if (x &lt; A[mid])high = mid - 1; else low = mid + 1; &#125; return j;&#125; 总结递归和迭代实现二分搜索算法的元素比较次数都在int(logn)+１内，但是迭代算法只需要senta(１)的空间，而递归算法由于递归深度为Ｏ(logn)，每个递归层次需要senta(1)的空间，所以总的需要的空间总量是Ｏ(logn)。 归并（合并）排序这里需要区分迭代式合并排序和递归式合并排序的区别(自行查阅资料) 迭代式主要思路是将所要排序数列看做若干个有序的小数列，因为将两个有序数列合并之后所得数列还是有序数列，所以经过不断合并，最后可将数列排为有序。 时间空间复杂度及稳定性 T(n)=O(nlog2– &gt;n) S(n)=O(n) 稳定 代码1234567891011121314151617181920212223242526272829303132333435 void MSort(vector&lt;int&gt; v) &#123; vector&lt;int&gt; h; h = v; int start, seg; for (seg = 1; seg &lt; v.size(); seg *= 2) &#123; int k = 0; for (start = 0; start &lt; v.size(); start = start + seg * 2) &#123; int end; end = start + seg; int low = start; while (low &lt; start + seg &amp;&amp; end &lt; start + seg + seg &amp;&amp; low &lt; v.size() &amp;&amp; end &lt; v.size()) &#123; if (v[low] &lt;= v[end]) &#123; h[k++] = v[low]; low++; &#125; else &#123; h[k++] = v[end]; end++; &#125; &#125; while (low &lt; start + seg &amp;&amp; low &lt; v.size()) &#123; h[k++] = v[low++]; &#125; while (end &lt; start + seg + seg &amp;&amp; end &lt; v.size()) &#123; h[k++] = v[end++]; &#125; &#125; v = h; &#125; show(v);&#125; 递归式主要思路是将待排序序列分成两个小部分，然后再对两个小部分运行相同的排序方法进行递归排序，最后将两个小部分合并起来。 代码MergeSort（A,1,n）; ​123456789101112131415161718192021222324252627282930313233void MergeSort(int *A, int low, int high) &#123; if (low &lt; high) &#123; int mid = (high + low) / 2; MergeSort(A, low, mid); MergeSort(A, high, mid + 1); Merge(A, low, mid, high); &#125;&#125;void Merge(int *A, int low, int mid, int high) &#123; int n = high - low; int B[high - low]; int b = mid; int i; for (i = 0; i &lt; n &amp;&amp; low &lt; mid &amp;&amp; b &lt; high; ++i) &#123; if (A[low] &lt; A[b]) &#123; B[i] = A[low++]; &#125; else &#123; B[i] = A[b++]; &#125; &#125; for (int j = low; j &lt; mid; ++j) &#123; B[i] = A[j]; &#125; for (int k = b; k &lt; high; ++k) &#123; B[i] = A[k]; &#125; for (int l = low; l &lt;high ; ++l) &#123; A[l]=B[i]; &#125;&#125; 总结算法MergeSort对一个n个元素的数组排序所需的时间是senta(nlogn)，空间是senta(n). 寻找中项和第k小元素场景描述寻找序列A[1…n]中的第k小元素。 算法描述传统的方法是直接将A[1…n]进行排序，然后取排序后的序列的第k个即为第k小元素，但是这种方法需要Ω(nlogn)的时间，因为任何基于比较的排序过程在最坏情况下必须花费这么多时间，所以我们选择一种新的算法：我们要在n个元素中找到第k小元素的实质是寻找第k小元素在A中的位置，所以我们可以将A划分成三个子序列A1 A2A3，其中A2为单个元素的序列，A1中的所有元素小于A2，A3中的所有元素大于A2，此时就有以下几种情况： 如果A1的长度大于k则A序列中第K小元素一定在A1中，我们只需寻找A1中的第k小元素即可 如果A1的长度等于k-1，则A2中的那个单元素就是我们要找的第k小元素 如果A1的长度小于k-1，则我们需要在A3序列中找到第k-len(A1)-1小元素 这样，我们就可以采用分治的思想将原来的n个元素中寻找第k小元素不断缩小范围最终找到目标元素，具体算法步骤描述如下： SELECT 算法描述 如果数组元素个数小于 44,则直接将数组排序并返回第 k小元素(采用直接的方法来解决问题,因为当总元素个数小于44*5=220的时候用直接的方法解决问题更快)。 把 n 个元素以每组 5 个元素划分为 int( n/5) 组,如果 n 不是 5的倍数则抛弃剩余元素。 对每组进行排序,之后取出每组的中间项(第 3 个元素)。 递归调用 SELECT 算法,得到这些中间项序列中的中项元素 mm 根据 mm,将原数组 A 划分为三个子数组: A1={小于 mm 的元素}; A2={等于 mm 的元素}; A3={大于 mm 的元素}; 根据 k 的大小,判断第 k 小元素会出现在 A1,A2,A3 中的哪一个数组里,之后,或者返回第 k 小元素(mm,在 A2中),或者在 A1 或 A3 上递归。 k 代码实现​1234567891011121314151617181920212223242526272829303132333435363738394041void sort(int *A, int low, int high) &#123; for (int i = low; i &lt; high; ++i) &#123; for (int j = i + 1; j &lt; high; ++j) &#123; if (A[i] &gt; A[j]) &#123; int t = A[i]; A[i] = A[j]; A[j] = t; &#125; &#125; &#125;&#125;int Select(int *A, int low, int high, int k) &#123; int p = high - low + 1; if (p &lt; 44) &#123; sort(A, low, high); return A[k]; &#125; int q = p / 5; int M[q]; for (int i = 0; i &lt; q; ++i) &#123; sort(A, i * 5, (i + 1) * 5);//将A分成q组，每组5个元素，如果5不整除p，则排除剩余元素 M[i] = A[i * 5 + 3];//M为q个子序列中的中项（中项集合） &#125; int mm = M[q / 2];//mm为中项集合的中项 int *A1, a1 = 0; int *A2, a2 = 0; int *A3, a3 = 0; //这里节省空间没有new（其实是懒...） for (int j = low; j &lt; high; ++j) &#123; if (A[j] &lt; mm)A1[a1++] = A[j]; if (A[j] = mm)A2[a2++] = A[j]; if (A[j] &gt; mm)A3[a3++] = A[j]; &#125; if (a1 &gt;= k)return Select(A1, 1, a1, k); if (a1 + a2 == k)return mm; if (a1 + a2 &lt; k)return Select(A3, 1, a3, k - a1 - a2);&#125; 复杂度分析在一个由n个元素组成的线序集合中提取第k小元素，所需的时间是senta(n)(T(n)&lt;=20cn,c是排序43个元素所需的时间)，特别地，n个元素元素的中值可以在senta(n)时间找出。需要注意的是，虽然此算法所需的时间是senta(n)但是其中的倍数常量（20c）还是太大，我们会在随讲机算法的时候提出一个具有较小倍数常量的算法。 快速排序（QuickSort）快速排序（QuickSort）是一种具有senta(nlogn)时间复杂度的排序算法，相比MergeSort，QuickSort不需要辅助的存储空间，这是它的优势。 划分算法（Split）在进行快速排序算法的实现之前我们需要先实现划分算法，它是快速排序算法的基础。 什么是划分算法设A[low…high]是一个包含n个数的序列，设x=a[low],我们希望对A中的元素进行位置调整后实现当i&lt; new index of x时A[i]&lt;x,当i&gt; new index of x时A[i]&gt;x。 实现思路对一个指定序列A[low…high]，从A[low+1]开始向后扫描元素，如果当前元素a&lt;=A[low]，则将a与第A[i]的元素互换位置，其中i是从low开始的，每进行一次元素的互换之前i++，最后，当A中元素扫描完毕时所有小于等于A[low]的元素都在i之前的位置（包括A[i]），所以此时只需将A[low]和A[i]的元素互换位置即可满足划分的定义，此时的i对应的就是元素A[low]的新位置. 代码实现​123456789101112131415161718192021int Split(int *A, int low, int high) &#123;//输入一个序列，返回A[low]对应元素的新位置 int i = low; int x = A[low]; for (int j = low + 1; j &lt;= high; ++j) &#123; if (A[j] &lt;= x) &#123; i++; if (i != j) &#123; int t = A[i]; A[i] = A[j]; A[j] = t; &#125; &#125; &#125; int t; t = A[low]; A[low] = A[i]; A[i] = t; return i;&#125; 复杂度分析因为算法split的元素比较次数恰好是n-1，所以它的时间复杂性为senta(n). 排序算法算法思想算法QuickSort的主要思路是利用Split算法将A[low…high]中的A[low]排列到其正确的位置A[w]，然后对子数组A[low…w-1]和子数组A[w+1…high]递归地进行排序从而产生整个排序数组。 代码实现​1234567void QuickSort(int *A, int low, int high) &#123; if (low &lt; high) &#123; int w = Split(A, low, high);//w为A[low]的新位置 QuickSort(A, low, w - 1); QuickSort(A, w + 1, high); &#125;&#125; 复杂度分析算法QuickSort对n个元素的数组进行排序时执行的平均比较次数是senta(nlogn) 五：动态规划什么是动态规划基本概念动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。动态规划是一种被广泛用于求解组合最优化问题的算法。 算法思想算法思想与分治法类似，也是 将待求解的问题分解为若干个子问题 （阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 与分治法的差别适合于用动态规划法求解的问题，经分解后得到的子问题往往 不是互相独立 的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 适用的情况能采用动态规划求解的问题的一般要具有3个性质： 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（ 该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势 ） 最长公共子序列问题问题描述给定两个长度为n和m的字符串A和B，确定A和B中最长公共子序列的长度。 解决思路 传统算法 一种传统的方式是使用蛮力搜索的方法，列举A所有的2^n个子序列对于每一个子序列子在senta(m)时间内来确定它是否也是B的子序列。该算法的时间复杂性是senta(m2^n)，是指数复杂性的。 动态规划算法 寻找一个求最长公共子序列的递推公式，令A=a_1a_2a_3….a_n和B=b_1b_2b_3…b_m，令L[i,j]表示a_1a_2_3…a_i和b_1b_2b_3…b_j的最长公共子序列的长度，则就有当i和j都大于0的时候，如果a_i=b_j，则L[i,j]=L[i-1,j-1]+1，反之，如果a_i!=b_j，则L[i,j]=max(L[i-1,j],L[i,j-1])所以就有以下递推公式： L [i,j]=0 i==0||j==0 L[i,j]=L[i-1,j-1]+1 i,j&gt;0&amp;&amp;a_i==b_j L[i,j]=max(L[i-1,j],L[i,j-1]) i,j&gt;0&amp;&amp;a_i=b_j 代码实现输入A和B字符串，返回二者的最长子序列长度 ​123456789101112131415161718int Lcs(char *A, int n, char *B, int m) &#123;//A[0...n] B[0...m] int L[n + 1][m + 1]; for (int i = 0; i &lt;= n; ++i) &#123; L[i][0] = 0; &#125; for (int j = 0; j &lt;= m; ++j) &#123; L[0][j] = 0; &#125; for (int k = 1; k &lt;= n; ++k) &#123; for (int i = 1; i &lt;= m; ++i) &#123; if (A[k] == B[i])L[k][i] = L[k - 1][i - 1] + 1; else L[k][i] = L[k][i - 1] &gt; L[k - 1][i] ? L[k][i - 1] : L[k - 1][i]; &#125; &#125; return L[n][m];&#125; 注意，以上算法需要的空间复杂度是senta(mn)，但是因为计算表中每一项的计算仅仅需要其上一行和上一列的元素，所以对算法进行改进可以使得空间复杂度降为senta(min(m,n))（准确来说是需要2min(m,n)的空间，仅仅将前一行和当前行存储下来即可）。 结论最长公共子序列问题的最优解能够在senta(mn)时间和senta(min(m,n))空间内计算得到。 矩阵链相乘问题描述给定一个n个矩阵的序列⟨A1,A2,A3…An⟩,我们要计算他们的乘积：A1A2A3…AnA1A2A3…An，由于矩阵乘法满足结合律，加括号不会影响结果，但是不同的加括号方法，算法复杂度有很大的差别：考虑矩阵链⟨A1,A2,A3⟩，三个矩阵规模分别为10×100、100×5、5×50： 按((A1A2)A3)方式，需要做10∗100∗5=5000次，再与A3相乘，又需要10∗5∗50=2500，共需要7500次运算； 按(A1（A2A3）)方式计算，共需要100∗5∗50+10∗100∗50=75000次标量乘法 以上两种不同的加括号方式具有10倍的差别，可见一个好的加括号方式，对计算效率有很大影响。 解决思路使用一个长度为n+1的一维数组p来记录每个矩阵的规模，其中n为矩阵下标，i的范围1~n，例如对于矩阵Ai而言，它的规模应该是p[i-1]×p[i]。由于i是从1到n取值，所以数组p的下标是从0到n。 用于存储最少乘法执行次数和最佳分段方式的结构是两个二维数组m和s，都是从1~n取值。m[i][j]记录矩阵链&lt; Ai,Ai+1,…,Aj&gt;的最少乘法执行次数 ，而s[i][j]则记录 最优质m[i][j]的分割点k。 需要注意的一点是当i=j时，m[i][j]=m[i][i]=0，因为一个矩阵不需要任何乘法。 假设矩阵链从Ai到Aj，有j-i+1个矩阵，我们从k处分开，将矩阵链分为Ai~Ak和Ak+1到Aj两块，那么我们可以比较容易的给出m[i][j]从k处分隔的公式： ​1m[i][j]=m[i][k]+m[k+1][j]+p[i-1]*p[k]*p[j]； 在一组确定的i和j值的情况下，要使m[i][j]的值最小，我们只要在所有的k取值中（i &lt;=k&lt; j)，寻找一个让m[i][j]最小的值\即可。 假设L为矩阵链的长度，那么L=j-i+1。当L=1时，只有一个矩阵，不需要计算。那么我们可以从L=2到n进行循环，对每个合理的i和j值的组合，遍历所有k值对应的m[i][j]值，将最小的一个记录下来，存储到m[i][j]中，并将对应的k存储到s[i][j]中，就得到了我们想要的结果。 代码​123456789101112131415161718192021222324/* * 输入：ms[1...n+1],ms[i]表示第i个矩阵的行数，ms[i+1]表示第i个矩阵的列数 * 输出：n个矩阵的数量乘法的最小次数 */int dp[1024][1024] = &#123; 0 &#125;;struct Matrix &#123; int row; int column;&#125;;int matrixChainCost(Matrix *ms, int n) &#123; for (int scale = 2; scale &lt;= n; scale++) &#123; for (int i = 0; i &lt;= n - scale; i++) &#123; int j = i + scale - 1; dp[i][j] = INT_MAX; for (int k = i; k &lt; j; k++) &#123; dp[i][j] = std::min(dp[i][j], dp[i][k] + dp[k+1][j] + (ms[i].row*ms[k].column*ms[j].column)); &#125; &#125; &#125; return dp[0][n - 1];&#125; 复杂度分析 时间复杂度：senta(n^3) 空间复杂度：senta(n^2) 所有点对的最短路径问题问题描述设G是一个有向图，其中每条边(i, j)都有一个非负的长度L[i, j]，若点i 到点j 没有边相连，则设L[i, j] = ∞.找出每个顶点到其他所有顶点的最短路径所对应的长度。例如： 则 L： 0 2 9 8 0 6 1 ∞ 0 解决思路（Floyd算法）Floyd算法（所有点对最短路径）就是每对可以联通的顶点之间总存在一个借助于其他顶点作为媒介而达到路径最短的最短路径值（这个值通过不断增添的媒介顶点而得到更新，也可能不更新——通过媒介的路径并不比其原路径更短），所有的值存储于邻接矩阵中，这是典型的动态规划思想。 值得注意的是，Floyd算法本次的状态的获取 只用到了上个阶段的状态 ，而没有用到其他阶段的状态，这就为 压缩空间 奠定了条件。 Floyd算法能够成功的关键之一就是D0(初始矩阵，即权重矩阵)的初始化，凡是不相连接的边必须其dij必须等于正无穷且dii=0(矩阵对角线上的元素！) 代码实现​12345678910111213141516171819202122232425 /* * 输入：n×n维矩阵l[1...n,1...n]，对于有向图G=(&#123;1,2,...n&#125;,E)中的边(i,j)的长度为l[i,j] * 输出：矩阵D，使得D[i,j]等于i到j的距离 * l矩阵需要满足：l[i,i]=0，对于m--&gt;n没有直接连接的有向边（因为是有向图，只考虑单边），应有l[m,n]=INT.MAX（即无穷） * */void Floyd(int **l,int n)&#123; int **d= reinterpret_cast&lt;int **&gt;(new int[n + 1][n + 1]); for (int i = 1; i &lt;=n ; ++i) &#123; for (int j = 1; j &lt;=n ; ++j) &#123; d[i][j]=l[i][j]; &#125; &#125; for (int k = 1; k &lt;=n ; ++k) &#123; for (int i = 1; i &lt;=n ; ++i) &#123; for (int j = 1; j &lt;=n ; ++j) &#123; d[i][j]=min(d[i][j],d[i][k]+d[k][j]); &#125; &#125; &#125;&#125; 复杂度分析算法的运行时间是senta(n^3)算法的空间复杂性是senta(n^2) 背包问题问题描述设U={u1,u2,u3…un}是一个准备放入容量为C的背包中的n项物品的集合。我们要做的是从U中拿出若干物品装入背包C，要求这些物品的总体积不超过C，但是要求装入背包的物品总价值最大。 解决思路有 n 种物品，物品 i 的体积为 v[i], 价值为 p[i]. 假定所有物品的体积和价格都大于 0, 以及背包的体积为 V.mp[x][y] 表示体积不超过 y 且可选前 x 种物品的情况下的最大总价值那么原问题可表示为 mp[n][V]。递归关系： 递归式 解释 mp[0][y] = 0 表示体积不超过 y 且可选前 0 种物品的情况下的最大总价值，没有物品可选，所以总价值为 0 mp[x][0] = 0 表示体积不超过 0 且可选前 x 种物品的情况下的最大总价值，没有物品可选，所以总价值为 0 当 v[x] &gt; y 时，mp[x][y] = mp[x-1][y] 因为 x 这件物品的体积已经超过所能允许的最大体积了，所以肯定不能放这件物品， 那么只能在前 x-1 件物品里选了当 v[x] &lt;= y 时，mp[x][y] = max{ mp[x-1][y] , p[x] +mp[x-1][y-v[x]]（选中A，则其余y-v[x]应在前x-1件物品中选） } | x这件物品可能放入背包也可能不放入背包，所以取前两者的最大值就好了， 这样就将前两种情况都包括进来了 代码​123456789101112131415161718192021222324/* * 输入：物品集合U=&#123;u1,u2,u3...un&#125;，体积为s1,s2,s3...sn，价值为v1,v2,v3...vn，容量为C的背包 * 输出：满足条件的最大价值 * */int Knapsack(int *s,int *v,int C,int n)&#123; int V[n+1][C+1];//V[i][j]表示从前i项找出的装入体积为j背包的最大值 for (int i = 0; i &lt;=n ; ++i) &#123; V[i][0]=0; &#125; for (int j = 0; j &lt;=C ; ++j) &#123; V[0][j]=0; &#125; for (int k = 1; k &lt;=n ; ++k) &#123; for (int i = 1; i &lt;=C ; ++i) &#123; if(s[k]&lt;=i)&#123; V[k][i]=max(V[k-1][i],V[k-1][i-s[k]]+v[k]); &#125; &#125; &#125; return V[n][C];&#125; 算法复杂度背包问题的最优解可以在senta(nC)时间内和senta(C)空间内解得。注意，上述算法的时间复杂性对输入不是多项式的，但是它的运行时间关于输入值是多项式的（时间复杂性+其他耗费时间），故认为它是伪多项式时间算法。 六：贪心算法引言所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说， 不从整体最优上加以考虑 ，他所做出的仅是在某种意义上的局部最优解 。贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备 无后效性，即 某个状态以后的过程不会影响以前的状态，只与当前状态有关 。所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。 最短路径问题问题描述给定一个有向图G=(V,E),s为V中一点,以s为起点,要确定从s出发到V中每一个其他顶点的距离(距离的定义是最短路径对应的长度). Dijkstra算法算法步骤 初始时，S只包含源点，即S＝{v}，v的距离为0。U包含除v外的其他顶点，即:U={其余顶点}，若v与U中顶点u有边，则 &lt; u,v &gt;正常有权值，若u不是v的出边邻接点，则 &lt; u,v &gt; 权值为∞ 从U中选取一个距离v最小的顶点k，把k，加入S中（该选定的距离就是v到k的最短路径长度） 以k为新考虑的中间点，修改U中各顶点的距离；若从源点v到顶点u的距离（经过顶点k）比原来距离（不经过顶点k）短，则修改顶点u的距离值，修改后的距离值的顶点k的距离加上边上的权 重复步骤b和c直到所有顶点都包含在S中 代码​1234567891011121314151617181920212223242526272829303132333435363738394041424344const int MAXINT = 32767;const int MAXNUM = 10;int dist[MAXNUM];//表示距离int prev[MAXNUM];//记录每个顶点的前驱顶点(因为最短路径的唯一性,所以每个点的前驱元素都是唯一的)int A[MAXUNM][MAXNUM];void Dijkstra(int v0)&#123; bool S[MAXNUM]; // 判断是否已存入该点到S集合中 int n=MAXNUM; for(int i=1; i&lt;=n; ++i)//初始化dist[]、prev[] &#123; dist[i] = A[v0][i]; S[i] = false; // 初始都未用过该点 if(dist[i] == MAXINT) //如果该点与源点之间无边 prev[i] = -1; else prev[i] = v0; &#125; dist[v0] = 0; S[v0] = true; for(int i=2; i&lt;=n; i++) &#123; int mindist = MAXINT; int u = v0; // 找出当前未使用的点j的dist[j]最小值 for(int j=1; j&lt;=n; ++j) if((!S[j]) &amp;&amp; dist[j]&lt;mindist)//如果j点没有被用过而且dist[j]小于mindist &#123; u = j; // u保存当前邻接点中距离最小的点的号码 mindist = dist[j]; &#125; S[u] = true; //将u置为已用 for(int j=1; j&lt;=n; j++)//更新u加入已用集合后的未用顶点集合中点到已用集合中点的距离 if((!S[j]) &amp;&amp; A[u][j]&lt;MAXINT) &#123; if(dist[u] + A[u][j] &lt; dist[j]) //在通过新加入的u点路径找到离v0点更短的路径 &#123; dist[j] = dist[u] + A[u][j]; //更新dist prev[j] = u; //记录前驱顶点 &#125; &#125; &#125;&#125; 算法复杂度算法的时间复杂度是senta(n^2) 稠图的线性时间算法稠(臭)图不想看，也许不考… 最小耗费生成树问题描述设G =(V,E)是无向连通带权图，即一个网络。E中的每一条边（v,w）的权为c[v][w]。如果G的子图G’是一棵包含G的所有顶点的树，则称G’为G的生成树。生成树上各边权的总和称为生成树的耗费。在G的所有生成树中，耗费最小的生成树称为G的最小生成树。最小生成树最常见的题就是求解n个城市之间的修路方案问题. Kruskal算法算法描述给定无向连通带权图G = (V,E),V = {1,2,…,n}。Kruskal算法构造G的最小生成树的基本思想是： 将G的n个顶点看成n个孤立的连通分支,将所有的边按权从小大排序。 从第一条边开始，依边权递增的顺序检查每一条边。并按照下述方法连接两个不同的连通分支：当查看到第k条边(v,w)时，如果端点v和w分别是当前两个不同的连通分支T1和T2的端点时，就用边(v,w)将T1和T2连接成一个连通分支，然后继续查看第k+1条边；如果端点v和w在当前的同一个连通分支中，就直接再查看k+1条边。这个过程一个进行到只剩下一个连通分支时为止。 此时，已构成G的一棵最小生成树。 代码实现​1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;#define maxn 110 //最多点个数int n, m; //点个数，边数int parent[maxn]; //父亲节点，当值为-1时表示根节点int ans; //存放最小生成树权值struct eage //边的结构体，u、v为两端点，w为边权值&#123; int u, v, w;&#125;EG[5010];bool cmp(eage a, eage b) //排序调用&#123; return a.w &lt; b.w;&#125;int Find(int x) //寻找根节点，判断是否在同一棵树中的依据&#123; if(parent[x] == -1) return x; return Find(parent[x]);&#125;void Kruskal() //Kruskal算法，parent能够还原一棵生成树，或者森林&#123; memset(parent, -1, sizeof(parent)); sort(EG+1, EG+m+1, cmp); //按权值将边从小到大排序 ans = 0; for(int i = 1; i &lt;= m; i++) //按权值从小到大选择边 &#123; int t1 = Find(EG[i].u), t2 = Find(EG[i].v); if(t1 != t2) //若不在同一棵树种则选择该边，合并两棵树 &#123; ans += EG[i].w; parent[t1] = t2; &#125; &#125;&#125; 复杂度分析当图的边数为e时，Kruskal算法所需的时间是O(eloge). Prim算法算法描述设G = (V,E)是连通带权图，V = {1,2,…,n}。构造G的最小生成树,Prim算法的基本思想是：首先置S ={1}，然后，只要S是V的真子集，就进行如下的贪心选择：选取满足条件i ∈S,j ∈V –S,且c[i][j]最小的边，将顶点j添加到S中。这个过程一直进行到S = V时为止。在这个过程中选取到的所有边恰好构成G的一棵最小生成树。 代码实现​12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* Prim算法生成最小生成树 */void MiniSpanTree_Prim(MGraph MG)&#123; int min, i, j, k; int adjvex[MAXVEX];/* 保存相关顶点的父亲节点 */ int lowcost[MAXVEX];/* 保存相关顶点间边的权值 */ lowcost[0] = 0;/* 初始化第一个权值为0，即v0加入生成树 */ /* lowcost的值为0，在这里就是此下标的顶点已经加入生成树 */ adjvex[0] = 0;/* 初始化第一个顶点下标为0 */ cout &lt;&lt; "最小生成树的边为：" &lt;&lt; endl; for (i = 1; i &lt; MG.numVertexes; i++) &#123; lowcost[i] = MG.arc[0][i];/* 将v0顶点与之有边的权值存入数组 */ adjvex[i] = 0;/* 初始化都为v0的下标 */ &#125; for (i = 1; i &lt; MG.numVertexes; i++) &#123; min = INFINITY; /* 初始化最小权值为∞， */ j = 1; k = 0; while (j &lt; MG.numVertexes)/* 循环全部顶点 */ &#123; if (lowcost[j] != 0 &amp;&amp; lowcost[j] &lt; min)/* 如果权值不为0且权值小于min */ &#123; min = lowcost[j];/* 则让当前权值成为最小值 */ k = j;/* 将当前最小值的下标存入k */ &#125; j++; &#125; cout &lt;&lt; "(" &lt;&lt; adjvex[k] &lt;&lt; ", " &lt;&lt; k &lt;&lt; ")" &lt;&lt; " "; /* 打印当前顶点边中权值最小的边 */ lowcost[k] = 0;/* 将当前顶点的权值设置为0,表示此顶点已经完成任务 */ for (j = 1; j &lt; MG.numVertexes; j++)/* 循环所有顶点 */ &#123; /* 如果下标为k顶点各边权值小于此前这些顶点未被加入生成树权值 */ if (lowcost[j] != 0 &amp;&amp; MG.arc[k][j] &lt; lowcost[j]) &#123; lowcost[j] = MG.arc[k][j];/* 将较小的权值存入lowcost相应位置 */ adjvex[j] = k;/* 将k设为下标j的父亲节点 */ &#125; &#125; &#125; cout &lt;&lt; endl;&#125; 复杂度分析此算法的时间复杂度为O(n^2) 总结（这个写的我也看不懂了…应该是当时笔误，具体想表达什么意思猜猜吧）当e = Ω(n^2)时，Kruskal算法比Prim算法差；但当e = o(n^2)时，Kruskal算法比Prim算法好得多。 七：NP完全问题如果一个算法的最差时间效率属于 O ( p ( n )) ,其中 p (n ) 是问题输入规模 n 的一个多项式函数,我们说该算法能够在多项式的时间内对问题求解 。我们把可以在多项式时间内求解的问题称为 易解的 ,而不能在多项式时间内求解的问题则称为 难解的 。 P和NP问题非正式地说，我们可以把那些 能够在多项式时间内求解 的问题当作计算机科学家所说的 P 集合 。正式点，只有那些 能够回答是或否 的问题（又称判定问题）才属于 P。 P 类问题P 类问题是一类能够用 确定性算法在多项式时间内求解 的 判定问题 。这种问题类型也称为 多项式类型 。 绝大多数判定问题的一个公共特性是: 虽然在计算上对问题求解可能是困难的,但在计算上 判定一个待定解是否解决了该问题 却是简单的,并且,这种判定可以在多项式时间内完成。 一个不确定算法是一个两阶段的过程,它把一个判定问题的实例 l 作为它的输入,并进行下面的操作: 猜测(非确定)阶段: 生成一个任意串 S,把它当作给定实例 l 的一个候选解,但 S也可能是完全不着边际的。 验证(确定)阶段:确定算法把 l 和 S 都作为它的输入,如果 S 的确是 l 的一个解的话,就输出“是”;如果 S 不是 l 的一个解,该算法要么返回“否”,要么就根本停不下来。 如果一个不确定算法在验证阶段的时间效率是多项式级的,我们说它是 不确定多项式类型 的算法。 NP 类问题(Non-deterministicPolynomial)是一类可以用不确定多项式算法求解的判定问题。我们把这种问题类型称为不确定多项式类。 我们说一个判定问题 D 1可以多项式地化简为一个判定问题 D 2 ,条件是存在一个函数 t 能够把 D 1 的实例转化为D 2 的实例,使得: t 把 D 1 的所有真实例映射为 D 2 的真实例,把 D 1 的所有假实例映射为 D 2 的假实例。 t 可以用一个多项式算法计算。 我们说一个判定问题 D 是 NP 完全问题,条件是: 它属于 NP 类型。 NP 中的任何问题都能够在多项式时间内化简为 D。 NP 完全问题: 合取范式的可满足性问题 哈密顿回路问题 旅行商问题 NP 完全问题的定义意味着,如果我们得到了一个 NP 完全问题的多项式确定算法,就说明所有的 NP 问题都能够用一个确定算法在多项式的时间内解出,因此,P= NP.换句话说,得到了一个 NP完全问题的多项式确定性算法可以表明,对于所有类型的判定问题来说,检验待定解和在多项式时间内求解在复杂性上没有本质的差别。这种推论使得大多数计算机科学家相信 P ≠ NP但是,到目前为止,还没有人能从数学上证明这一猜想。 八：回溯算法概述回溯算法是一种组织搜索的一般技术，它常常可以避免搜索所有的可能性，适用于求解那些有潜在的大量解但是有限个数的解已经检查过的问题。 3着色问题问题描述给出一个无向图G=(V,E)，需要用三种颜色之一为V中的每个顶点着色，要求没有两个相邻的顶点有相同的颜色。 算法思想我们称没有两个邻接顶点有同样颜色的着色方案为合法的，反之成为非法的。如果不考虑合法性的要求，给出n个顶点的无向图，将其用三种颜色着色，共有n^3种不同的方法，因为每一个顶点都有三种不同的着色方案，这就构成了一颗三叉树，如图：在该三叉树中，从根到叶子节点的每一条路径代表一种着色方法（合法的和不合法的），我们需要做的就是选出一条合法的从根到叶子的路径即可。所以我们从根节点开始向叶子节点走，这时有两种情况： 从根到当前节点的路径对应一个合法的着色： 当前路径长度等于n：过程终止（除非希望找到不止一种着色方案） 当前路径长度小于n：生成当前节点的一个子节点，并将生成的当前节点的子节点标记为新的当前节点 从根到当前节点的路径对应一个非法的着色：回溯到当前节点的父节点即将当前节点的父节点标记为新的当前节点 代码使用数组c[1…n]代表图的顶点集合，判断合法性只需判断与当前有联系的点中是否存在与之涂色相同的点即可，此处为节省时间省略该部分代码的实现。 迭代法​123456789101112131415161718192021222324252627282930313233343536 void ColorItre(int *c) &#123;//c[1...n] for (int i = 1; i &lt;= n; ++i) &#123; c[i] = 0; &#125; bool flag = false; int k = 1; while (k &gt;= 1) &#123; while (c[k] &lt;= 2) &#123;//从0-2对应三种涂色（实际上是 下面加一之后的1-3对应三种不同颜色） c[k] = c[k] + 1; if (c[k]为合法的)&#123; if (k == n) &#123;//如果k已经是最后一个点 flag = true; break; &#125; else &#123; k++; &#125; &#125; &#125; if (flag) &#123; break; &#125; //如果第二个循环跳出执行到这里，则说明当前节点k试遍了三种颜色仍然没有找到合法的着色，则将k--进行回溯，注意要将c[k]置为初始值0 c[k] = 0; k--; &#125; if (flag) &#123; cout &lt;&lt; "success" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "no solution" &lt;&lt; endl; &#125;&#125; 递归法​12345678910111213141516171819202122232425262728void ColorRec(int *c) &#123;//c[1...n] for (int i = 1; i &lt;= n; ++i) &#123; c[i] = 0; &#125; bool flag = false; flag = graphcolor(c, 1); if (flag) &#123; cout &lt;&lt; "success" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "no solution" &lt;&lt; endl; &#125;&#125;bool graphcolor(int *c, int i) &#123; for (int color = 1; color &lt;= 3; ++color) &#123; c[i] = color; if (c[i]是合法的)&#123; if (i &lt; n) &#123; graphcolor(c, i + 1); &#125; else &#123; return true; &#125; &#125; &#125; //如果执行到这里说明当前节点不存在合法着色，需要回溯，返回false即可激活前一次递归（即让前一层for循环的color加一），以此达到回溯的目的 return false;&#125; 复杂度分析这两种实现方式在最坏情况下生成了O(3^n)个节点，对于每个生成的节点，判断当前节点的合法性（合法、部分、二者都不是）需要O(n)的工作来检查，因此，最坏情况下的运行时间是O(n3^n)。 回溯法的特点 节点是使用深度优先搜索算法生成的 不需要存储整棵搜索树，只需存储根到当前活动节点的路径 8皇后问题代码见 两种不同方式解决八皇后问题，此处主要介绍算法思路。 问题描述八皇后问题是一个以国际象棋为背景的问题：如何能够在 8×8的国际象棋棋盘上放置八个皇后，使得任何一个皇后都无法直接吃掉其他的皇后？为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。八皇后问题可以推广为更一般的n皇后摆放问题：这时棋盘的大小变为n×n，而皇后个数也变成n。当且仅当n = 1 或 n ≥ 4 时问题有解。 代码代码和着色问题代码几乎一样，这里不做过多介绍，给出参考代码： ​123456789101112131415161718192021222324252627282930313233void eight_Queens() &#123; int c[9]; for (int i = 1; i &lt;= 8; ++i) &#123; c[i] = 0; &#125; bool flag = false; int k = 1; while (k &gt;= 1) &#123; while (c[k] &lt;= 7) &#123; c[k]++; if (c[k]为合法着色)&#123; if (k == 8) &#123; flag = true; break; &#125; else &#123; k++; &#125; &#125; &#125; if (flag) &#123; break; &#125; c[k] = 0; k--; &#125; if (flag) &#123; cout &lt;&lt; "success" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "no solution" &lt;&lt; endl; &#125;&#125; 复杂度分析回溯法在最坏情况下需要O（n^2）的运行时间。但是需要注意，虽然蛮力搜索法的最坏情况也需要O（n^2）的时间，但是根据经验回溯法的有效性远远超过蛮力法。(鬼知道这是谁的经验，反正只要知道考试用蛮力法肯定会xx) 一般回溯方法什么是一般回溯法在回溯法中，解向量中每个xi都属于一个有限的线序集Xi，因此，算法最初从空向量开始，然后选择X1中最小的元素作为x1，如果（x1）是一个部分解，算法从X2中找出最小的元素作为x2继续，如果（x1，x2）是一个部分解，则从X3中找出最小元素作为x3，否则跳过x2寻找下一个。一般地，假如算法已经找到部分解（x1,x2,x3…,xj），在判断v=（x1,x2,x3…,xj,x_j+1）时有以下情况： v是最终解：记录下当前v作为一组解，如果只想求得一组解则算法结束，否则继续寻找其他解 v是一组部分解：从X_j+2中寻找新的最小元素继续向前走 v既不是最终解也不是部分解： X_j+1中还有其他元素可供选择：在X_j+1中寻找下一个元素 X_j+1中没有其他元素可供选择：将x_j置为X_j中的下一个元素回溯，如果X_j中仍然没有其他元素可供选择，则照此方法继续向前回溯。 分支限界法算法介绍分支限界法（branch and bound method）是求解 纯整数规划 或 混合整数规划 问题的经典方法，在上世纪六十年代由LandDoig和Dakin等人提出。这种方法灵活且便于用计算机求解，目前已经成功运用于求解生产进度问题、旅行推销员问题、工厂选址问题、背包问题及分配问题等。算法基本思想如下： 按宽度优先策略遍历解空间树； 在遍历过程中，对处理的每个结点vi，根据界限函数，估计沿该结点向下搜索所可能达到的完全解的目标函数的可能取值范围—界限bound(vi)=[downi, upi]； 从中选择使目标函数取的极值(最大、最小)的结点优先进行宽度优先搜索，从而不断调整搜索方向，尽快找到问题解。 各结点的界限函数bound(vi)=[downi,upi]是解决问题的关键，通常依据具体问题而定。常见的两种分支限界法是队列式分支限界法和优先队列式分支限界法，它们分别按照队列先进先出的原则和优先队列中规定的优先级选取下一个节点为扩展节点。 分支限界法与回溯法的区别求解目标不同 回溯法的求解目标是找出解空间树中满足约束条件的 所有解 分支限界法的求解目标则是尽快找出满足约束条件的 一个解 ，或是在满足约束条件的解中找出在某种意义下的 最优解 分支限界法通常用于解决 离散值的最优化问题 搜索方式不同 回溯法以 深度优先 的方式（遍历结点）搜索解空间树 分支限界法以 广度优先 或 最小耗费优先 的方式搜索解空间树 对扩展结点的扩展方式不同 分支限界法中，每一个活结点只有一次机会成为扩展结点，活结点一旦成为扩展结点，就一次性产生其所有儿子结点 重复上述结点扩展过程，直至到找到所需的解或活结点表为空时为止 Demo——旅行商问题求解问题描述给出一个城市的集合和一个定义在 每一对城市之间 的耗费函数，找出耗费最小的旅行。 解决思路考虑下图所示的情况及其代价矩阵，假定起始城市为1号城市： 注意代价矩阵的特点，每条满足要求的回路在代价矩阵中的每一行每一列有且只有1个元素与之对应。据此，我们可以用贪心算法计算问题的上界：以起始城市作为出发城市，每次从当前出发城市发出的多条边中，选择没有遍历过的最短边连接的城市，作为下一步达到城市。在这个问题中，从城市1出发，途经1→3→5→4→2→1，路径长度1+2+3+7+3=16作为上界，即最短路径长度&lt;=16。对于下界，一个简单的办法是直接将矩阵中每一行的最小元素相加，在这个问题中，路径长度1+3+1+3+2=10作为下界，即最短路径长度&gt;=10。更优的计算方式是将矩阵中每一行最小的2个元素相加除以2并向上取整。因为在一条路径上，每个城市有2条邻接边：进入该城市、离开该城市。对每一步经过的城市j，从最近的上一个城市i来，再到下一个最近城市k去，即i→j→k。在这个问题中，路径长度{(1+3)+(3+6)+(1+2)+(3+4)+(2+3)}/2向上取整等于14作为下界，即最短路径长度 =14。因此，以最短路径长度dist作为TSP问题目标函数，则dist的界为[14,16]。在问题求解过程中，如果1个部分解的目标函数dist下界超出此界限，则该部分解对应了死结点，可剪枝。对于1条正在生成的路径/部分解，设已经确定的顶点(已经经过/遍历的城市)集合为U=(r1,r2, …,rk)，则该部分解的目标函数的下界为(已经经过的路径的总长的2倍+从起点到最近未遍历城市的距离+从终点到最近未遍历城市的距离+进入/离开未遍历城市时各未遍历城市带来的最小路径成本)除以2并向上取整。假设正在生成的路径/部分解为1→4,U={1,4},未遍历城市={2,3,5},该部分解下界为{2*5+1+3+(3+6)+(1+2)+(2+3)}/2向上取整等于16： 九：随机算法概述随机算法是一种在接受输入的同时，为了随机选择的目的，还接受一串随机比特流并且在运行过程中使用该比特流的算法(允许算法在执行过程中随机地选择下一个计算步骤)。 随机算法通常有两个 优点 ： 较之那些我们所知的解决同一问题最好的确定性算法，随机算法所需的运行时间或空间通常小一些。 随机算法比较易于理解和实现（呵，站着说话不腰疼）。 随机算法的 基本特征 ：对所求解问题的同一实例用同一随机算法求解两次可能得到完全不同的效果。这两次求解所需的时间、所得到的结果可能会有相当大的差别。 随机算法的类别随机（概率）算法大致分四类： 数值概率算法 常用于数值问题的求解。 这类算法所得到的往往是近似解且近似解的精度随计算时间的增加而不断提高。 在许多情况下,要计算出问题的精确解是不可能的,或者没有必要,此时,用数值概率算法可以得到相当满意的解。 蒙特卡洛(Monte Carlo)算法 用于求问题的准确解。 对于许多问题来说,近似解毫无意义。 例如,一个判定问题其解为“是”或“否” ,二者必居其一, 不存在任何近似解。 又如,我们要求一个整数的因子,这样问题的解答必须是准 确的,一个整数的近似因子没有任何意义。 用蒙特卡洛算法能求得问题的一个解,但这个解未必是正确的。 求得正确解的概率依赖于算法所用的时间,算法所用的时间越多,得到正确解的概率就越高。 蒙特卡洛算法的主要缺点也在于此,即无法有效地判定所得到的解是否肯定正确。 拉斯维加斯(Las Vegas)算法 拉斯维加斯算法不会得到不正确的解。 一旦用拉斯维加斯算法找到一个解,这个解就一定是正确 解。 但有时用拉斯维加斯算法会找不到解。 与蒙特卡洛算法类似,拉斯维加斯算法找到正确解的概率随着它所用的计算时间 的增加而提高。 对于所求解问题的任一实例,用拉斯维加斯算法反复对该实例求解足够多次,可使求解失效的概率任意小。 舍伍德(Sherwood)算法 舍伍德算法总能求得问题的一个解,且所求得的解总是正确的。 当一个确定性算法在最坏情况下的计算复杂性与其在平均情况下的计算复杂性有较大差别时,可在这个确定性算法中引入随机性,将它改造成一个舍伍德算法,消除或减少问题的好坏实例间的这种差别。 例子 Monte Carlo算法 总是给出解，但是偶尔可能会产生非正确的解。然而，可以通过多次运行原算法，并且满足每次运行时的随机选择都相互独立，使产生非正确解的概率可以减到任意小。 主元素问题（多数元素问题）问题描述设T[1…n]是一个长度为n的数组，当某个元素在该数组中存在的数量多于int(s/2)时称该元素为数组T的主元素（多数元素）。 求解思路算法随机选择数组元素x,由于数组T的非主元素个数小于n/2，所以，x不为主元素的概率小于1/2。因此判定数组T的主元素存在性的算法是一个偏真1/2正确的算法。50%的错误概率是不可容忍的，利用重复调用技术将错误概率降低到任何可接受的范围内。对于任何给定的p&gt;0，算法majorityMC重复调用(向上取整)log(1/p)次算法majority。它是一个偏真蒙特卡罗算法，且其错误概率小于p。算法majorityMC所需的计算时间显然是O(nlog(1/p))。 代码实现​1234567891011121314//重复k次调用算法Majoritytemplate&lt;class Type&gt;bool MajorityMC(Type *T,int n,double e)&#123; int k = ceil(log(1/e)/log((float)2)); for(int i=1; i&lt;=k; i++) &#123; if(Majority(T,n)) &#123; return true; &#125; &#125; return false;&#125; ​123456789101112131415161718bool Majority(Type *T,int n)&#123; RandomNumber rnd; int i = rnd.Random(n); Type x = T[i]; //随机选择数组元素 int k = 0; for(int j=0; j&lt;n; j++) &#123; if(T[j] == x) &#123; k++; &#125; &#125; return (k&gt;n/2); //k&gt;n/2时，T含有主元素&#125; 随机化快速排序（可能是最为流行的一种随机算法？）首先要明确传统快速排序的流程：从待排序序列中拿出最后一个（或者第一个）作为主元，将小于它的放在它的前面，大于它的放在它的后面，这时对该主元的前一部分和后一部分再分别递归进行“划分”，最后达到有序。这种方法有一个很大的问题就是当待排序数组是一个几乎有序的序列时其复杂度会很容易达到senta(n^2)，因为如果每次都选择第一个元素或者最后一个元素作为主元进行划分，对一个几乎有序的序列，划分后的递归对象（子序列）将会一个很长一个很短，这样可能经过好多次划分后还是有一个待划分的子部分很长。解决方法是每次不选择第一个或者最后一个作为主元，而是随机产生一个从第一个到最后一个之间的随机数作为主元进行划分，这样即保留了快速排序的优越性又避免了排序几乎有序序列时的痛点。 核心代码​12345678910111213void RandomQuickSort(int low,int high)&#123; if(low&lt;high)&#123; int v=random(low,high); int t=A[low]; A[low]=A[v]; A[v]=t; Split(A[low...high],low); RandomQuickSort(low,v-1); RandomQuickSort(v+1,high); &#125;&#125; 该算法在最坏情况下仍然是senta(n^2)，但这与输入形式无关。如果最坏情况发生，那是因为用随机数选取的主元不凑巧，这个事件发生的概率是非常小的。事实上，没有一种输入的排列可以引起它的最坏情况，算法的期望运行时间是senta(nlogn). 随机化的选择算法（寻找第k小元素）什么是选择算法： SELECT 算法描述 如果数组元素个数小于 44,则直接将数组排序并返回第 k小元素(采用直接的方法来解决问题,因为当总元素个数小于44*5=220的时候用直接的方法解决问题更快)。 把 n 个元素以每组 5 个元素划分为 int( n/5) 组,如果 n 不是 5的倍数则抛弃剩余元素。 对每组进行排序,之后取出每组的中间项(第 3 个元素)。 递归调用 SELECT 算法,得到这些中间项序列中的中项元素 mm 根据 mm,将原数组 A 划分为三个子数组: A1={小于 mm 的元素}; A2={等于 mm 的元素}; A3={大于 mm 的元素}; 根据 k 的大小,判断第 k 小元素会出现在 A1,A2,A3 中的哪一个数组里,之后,或者返回第 k 小元素(mm,在 A2中),或者在 A1 或 A3 上递归。 1：k &lt;len(A 1) 第 k 小元素在 A1 中; 2：len(A 1) =k &lt;= A 1+ A 2 第 k 小元素在 A2 中; 3： A 1 + A 2 &lt; k &lt;= A 1 + A 2+  A 3第 k 小元素在 A3 中; 该算法的运行时间是senta(n)(T(n)&lt;=20cn,c是排序43个元素所需的时间)，具有一个很大的常数系数，所以就有了随机版的选择算法： 12345678910111213141516171819 /* * 输入：n个元素的数组A[1...n]和整数k * 输出：A中的第k小元素 * */R_Select(A,1,n,k);void R_Select(int *A, int low, int high, int k) &#123; int v = random(low, high); int x = A[v]; A1 = &#123;a | a &lt; x&#125;; A2 = &#123;a | a = x&#125;; A3 = &#123;a | a &gt; x&#125;; if (A1.len &gt;= k)return R_Select(A, 1, A1.len, k); else if (A.len + A2.len &gt;= k)return x; else if (A1.len + A2.len &lt; k)return R_Select(A, 1, A3.len, k - A1.len - A2.len);&#125; 该版本的随机算法与原版本的主要不用是原版本是将序列分为若干个5元素序列分别进行排序后找到那些5元素序列中值组成的新序列的中值作为主元对元素进行划分，而随机算法是产生一个序列中的随机数（就是在待找序列中随机找了一个数）作为主元，省去了那些排序5元素数组的步骤，对于大小为n的输入，算法RandomizedSekect执行的期望比较次数小于4n，他的期望运行时间是senta(n)。可以发现该随机算法最坏情况下的运行时间也是senta(n)，但是其发生最坏情况不依赖于输入，仅当产生的随机数序列很不凑巧时才会发生，而这种概率是非常小的。]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hack Hangzhou]]></title>
    <url>%2F2018%2F05%2F20%2FHack-Hangz%2F</url>
    <content type="text"><![CDATA[参加了由杭州电子科技大学主办的Hack{中国}——2018全国高校黑客马拉松比赛，开发了一款以医疗为主题的软件： 邀请函 比赛现场 our result our result]]></content>
  </entry>
  <entry>
    <title><![CDATA[Android解决The APK file app-debug.apk does not exist on disk.]]></title>
    <url>%2F2018%2F05%2F17%2FAndroid%E8%A7%A3%E5%86%B3The%20APK%20file%20app-debug.apk%20does%20not%20exist%20on%20disk.%2F</url>
    <content type="text"><![CDATA[问题描述Android studio run app的时候报错The APK file app-debug.apk does not exist on disk. 解决方案Edit Configurations如图，点击Edit Configurations，查看你app配置中的是否有如下选项：如果没有则点击+号：然后这里置为空直接ok：然后点击ok重新run，如果不出意外该错误已经解决。 Gradle build如果第一种方法还未解决你的问题，可以尝试：]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随机算法]]></title>
    <url>%2F2018%2F05%2F17%2F%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概述随机算法是一种在接受输入的同时，为了随机选择的目的，还接受一串随机比特流并且在运行过程中使用该比特流的算法(允许算法在执行过程中随机地选择下一个计算步骤)。 随机算法通常有两个 优点 ： 较之那些我们所知的解决同一问题最好的确定性算法，随机算法所需的运行时间或空间通常小一些。 随机算法比较易于理解和实现（呵，站着说话不腰疼）。 随机算法的 基本特征 ：对所求解问题的同一实例用同一随机算法求解两次可能得到完全不同的效果。这两次求解所需的时间、所得到的结果可能会有相当大的差别。 随机算法的类别随机（概率）算法大致分四类： 数值概率算法 常用于数值问题的求解。 这类算法所得到的往往是近似解且近似解的精度随计算时间的增加而不断提高。 在许多情况下,要计算出问题的精确解是不可能的,或者没有必要,此时,用数值概率算法可以得到相当满意的解。 蒙特卡洛(Monte Carlo)算法 用于求问题的准确解。 对于许多问题来说,近似解毫无意义。 例如,一个判定问题其解为“是”或“否” ,二者必居其一, 不存在任何近似解。 又如,我们要求一个整数的因子,这样问题的解答必须是准 确的,一个整数的近似因子没有任何意义。 用蒙特卡洛算法能求得问题的一个解,但这个解未必是正确的。 求得正确解的概率依赖于算法所用的时间,算法所用的时间越多,得到正确解的概率就越高。 蒙特卡洛算法的主要缺点也在于此,即无法有效地判定所得到的解是否肯定正确。 拉斯维加斯(Las Vegas)算法 拉斯维加斯算法不会得到不正确的解。 一旦用拉斯维加斯算法找到一个解,这个解就一定是正确 解。 但有时用拉斯维加斯算法会找不到解。 与蒙特卡洛算法类似,拉斯维加斯算法找到正确解的概率随着它所用的计算时间 的增加而提高。 对于所求解问题的任一实例,用拉斯维加斯算法反复对该实例求解足够多次,可使求解失效的概率任意小。 舍伍德(Sherwood)算法 舍伍德算法总能求得问题的一个解,且所求得的解总是正确的。 当一个确定性算法在最坏情况下的计算复杂性与其在平均情况下的计算复杂性有较大差别时,可在这个确定性算法中引入随机性,将它改造成一个舍伍德算法,消除或减少问题的好坏实例间的这种差别。 例子 Monte Carlo算法 总是给出解，但是偶尔可能会产生非正确的解。然而，可以通过多次运行原算法，并且满足每次运行时的随机选择都相互独立，使产生非正确解的概率可以减到任意小。 主主元素问题（多数元素问题）问题描述设T[1…n]是一个长度为n的数组，当某个元素在该数组中存在的数量多于int(s/2)时称该元素为数组T的主元素（多数元素）。 求解思路算法随机选择数组元素x,由于数组T的非主元素个数小于n/2，所以，x不为主元素的概率小于1/2。因此判定数组T的主元素存在性的算法是一个偏真1/2正确的算法。50%的错误概率是不可容忍的，利用重复调用技术将错误概率降低到任何可接受的范围内。对于任何给定的p&gt;0，算法majorityMC重复调用(向上取整)log(1/p)次算法majority。它是一个偏真蒙特卡罗算法，且其错误概率小于p。算法majorityMC所需的计算时间显然是O(nlog(1/p))。 代码实现​1234567891011121314//重复k次调用算法Majoritytemplate&lt;class Type&gt;bool MajorityMC(Type *T,int n,double e)&#123; int k = ceil(log(1/e)/log((float)2)); for(int i=1; i&lt;=k; i++) &#123; if(Majority(T,n)) &#123; return true; &#125; &#125; return false;&#125; ​123456789101112131415161718bool Majority(Type *T,int n)&#123; RandomNumber rnd; int i = rnd.Random(n); Type x = T[i]; //随机选择数组元素 int k = 0; for(int j=0; j&lt;n; j++) &#123; if(T[j] == x) &#123; k++; &#125; &#125; return (k&gt;n/2); //k&gt;n/2时，T含有主元素&#125; 随机化快速排序（可能是最为流行的一种随机算法？）首先要明确传统快速排序的流程：从待排序序列中拿出最后一个（或者第一个）作为主元，将小于它的放在它的前面，大于它的放在它的后面，这时对该主元的前一部分和后一部分再分别递归进行“划分”，最后达到有序。这种方法有一个很大的问题就是当待排序数组是一个几乎有序的序列时其复杂度会很容易达到senta(n^2)，因为如果每次都选择第一个元素或者最后一个元素作为主元进行划分，对一个几乎有序的序列，划分后的递归对象（子序列）将会一个很长一个很短，这样可能经过好多次划分后还是有一个待划分的子部分很长。解决方法是每次不选择第一个或者最后一个作为主元，而是随机产生一个从第一个到最后一个之间的随机数作为主元进行划分，这样即保留了快速排序的优越性又避免了排序几乎有序序列时的痛点。 核心代码​12345678910111213void RandomQuickSort(int low,int high)&#123; if(low&lt;high)&#123; int v=random(low,high); int t=A[low]; A[low]=A[v]; A[v]=t; Split(A[low...high],low); RandomQuickSort(low,v-1); RandomQuickSort(v+1,high); &#125;&#125; 该算法在最坏情况下仍然是senta(n^2)，但这与输入形式无关。如果最坏情况发生，那是因为用随机数选取的主元不凑巧，这个事件发生的概率是非常小的。事实上，没有一种输入的排列可以引起它的最坏情况，算法的期望运行时间是senta(nlogn). 随机化的选择算法什么是选择算法： SELECT 算法描述 如果数组元素个数小于 44,则直接将数组排序并返回第 k小元素(采用直接的方法来解决问题,因为当总元素个数小于44*5=220的时候用直接的方法解决问题更快)。 把 n 个元素以每组 5 个元素划分为 int( n/5) 组,如果 n 不是 5的倍数则抛弃剩余元素。 对每组进行排序,之后取出每组的中间项(第 3 个元素)。 递归调用 SELECT 算法,得到这些中间项序列中的中项元素 mm 根据 mm,将原数组 A 划分为三个子数组: A1={小于 mm 的元素}; A2={等于 mm 的元素}; A3={大于 mm 的元素}; 根据 k 的大小,判断第 k 小元素会出现在 A1,A2,A3 中的哪一个数组里,之后,或者返回第 k 小元素(mm,在 A2中),或者在 A1 或 A3 上递归。 1：k &lt;len(A 1) 第 k 小元素在 A1 中; 2：len(A 1) =k &lt;= A 1+ A 2 第 k 小元素在 A2 中; 3： A 1 + A 2 &lt; k &lt;= A 1 + A 2+  A 3第 k 小元素在 A3 中; 该算法的运行时间是senta(n)(T(n)&lt;=20cn,c是排序43个元素所需的时间)，具有一个很大的常数系数，所以就有了随机版的选择算法： 12345678910111213141516171819 /* * 输入：n个元素的数组A[1...n]和整数k * 输出：A中的第k小元素 * */R_Select(A,1,n,k);void R_Select(int *A, int low, int high, int k) &#123; int v = random(low, high); int x = A[v]; A1 = &#123;a | a &lt; x&#125;; A2 = &#123;a | a = x&#125;; A3 = &#123;a | a &gt; x&#125;; if (A1.len &gt;= k)return R_Select(A, 1, A1.len, k); else if (A.len + A2.len &gt;= k)return x; else if (A1.len + A2.len &lt; k)return R_Select(A, 1, A3.len, k - A1.len - A2.len);&#125; 该版本的随机算法与原版本的主要不用是原版本是将序列分为若干个5元素序列分别进行排序后找到那些5元素序列中值组成的新序列的中值作为主元对元素进行划分，而随机算法是产生一个序列中的随机数（就是在待找序列中随机找了一个数）作为主元，省去了那些排序5元素数组的步骤，对于大小为n的输入，算法RandomizedSekect执行的期望比较次数小于4n，他的期望运行时间是senta(n)。可以发现该随机算法最坏情况下的运行时间也是senta(n)，但是其发生最坏情况不依赖于输入，仅当产生的随机数序列很不凑巧时才会发生，而这种概率是非常小的。]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>随机算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NP完全问题]]></title>
    <url>%2F2018%2F05%2F14%2FNP%E5%AE%8C%E5%85%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[如果一个算法的最差时间效率属于 O(p(n)) ,其中 p (n ) 是问题输入规模 n 的一个多项式函数,我们说该算法能够在多项式的时间内对问题求解 。我们把可以在多项式时间内求解的问题称为 易解的 ,而不能在多项式时间内求解的问题则称为 难解的 。 非正式地说，我们可以把那些 能够在多项式时间内求解 的问题当作计算机科学家所说的 P集合 。正式点,只有那些 能够回答是或否 的问题（又称判定问题）才属于 P。 P 类问题是一类能够用 确定性算法在多项式时间内求解 的 判定问题 。这种问题类型也称为 多项式类型 。 绝大多数判定问题的一个公共特性是: 虽然在计算上对问题求解可能是困难的,但在计算上 判定一个待定解是否解决了该问题 却是简单的,并且,这种判定可以在多项式时间内完成。 一个不确定算法是一个两阶段的过程,它把一个判定问题的实例 l 作为它的输入,并进行下面的操作: 猜测(非确定)阶段: 生成一个任意串 S,把它当作给定实例 l 的一个候选解,但 S也可能是完全不着边际的。 验证(确定)阶段:确定算法把 l 和 S 都作为它的输入,如果 S 的确是 l 的一个解的话,就输出“是”;如果 S 不是 l 的一个解,该算法要么返回“否”,要么就根本停不下来。 如果一个不确定算法在验证阶段的时间效率是多项式级的,我们说它是 不确定多项式类型 的算法。 NP 类问题(Non-deterministic Polynomial)是一类可以用不确定多项式算法求解的判定问题。我们把这种问题类型称为不确定多项式类。 我们说一个判定问题 D1可以多项式地化简为一个判定问题 D2 ,条件是存在一个函数 t 能够把 D1 的实例转化为D2 的实例,使得: t 把 D 1 的所有真实例映射为 D 2 的真实例,把 D 1 的所有假实例映射为 D 2 的假实例。 t 可以用一个多项式算法计算。 我们说一个判定问题 D 是 NP 完全问题,条件是: 它属于 NP 类型。 NP 中的任何问题都能够在多项式时间内化简为 D。 NP 完全问题: 合取范式的可满足性问题 哈密顿回路问题 旅行商问题 NP 完全问题的定义意味着,如果我们得到了一个 NP 完全问题的多项式确定算法,就说明所有的 NP 问题都能够用一个确定算法在多项式的时间内解出,因此,P= NP.换句话说,得到了一个 NP完全问题的多项式确定性算法可以表明,对于所有类型的判定问题来说,检验待定解和在多项式时间内求解在复杂性上没有本质的差别。这种推论使得大多数计算机科学家相信 P ≠ NP但是,到目前为止,还没有人能从数学上证明这一猜想。]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>NP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法分析基本概念]]></title>
    <url>%2F2018%2F05%2F14%2F%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[二分搜索Linearsearch​1234567891011121314/* * 输入：n个元素的数组A[1...n]、x * 输出：如果x=A[j]&amp;&amp;1&lt;=j&lt;=n，则输出j，否则输出0 */int Linearsearch(int *A,int x, int n)&#123; int j=0; while (j&lt;n&amp;&amp;x!=A[j])&#123; j++; &#125; if(x==A[j])return j; return 0;&#125; Binarysearch​12345678910111213141516/* * 输入：n个元素的升序数组A[1...n]、x * 输出：如果x=A[j]&amp;&amp;1&lt;=j&lt;=n，则输出j，否则输出0 */int Binarysearch(int *A, int x, int n) &#123; int low = 1, high = n, j = 0; while (low &lt;= high &amp;&amp; j == 0) &#123; int mid = (int) ((low + high) / 2); if (x == A[mid])j = mid; else if (x &lt; A[mid])high = mid - 1; else low = mid + 1; &#125; return j;&#125; 要注意二分搜索的输入一定是一个 升序的数组，实质就是一个二叉搜索树（所以也把二分搜索的执行描述为决策树），对于一个大小为n的排序数组，算法Binarysearch执行比较的最大次数为int（logn）+1（如果输入数组不是递增排好序的，则可在nlogn内对其进行排序后再进行二分搜索）。 合并两个已排序的表​1234567891011121314151617181920212223242526272829303132333435/* * 输入：数组A[1...m]和它的三个索引p，q，r，1&lt;=p&lt;=q&lt;r&lt;=m，p、q、r满足A[p...q]、A[q+1...r]分别按照升序排列 * 输出：合并两个子数组A[p...q]和A[q+1...r]的数组A[p...r] */void Merge(int *A, int p, int q, int r) &#123; int B[r + 1];//B[p...r]是辅助数组 int s = p, t = q + 1, k = p;//s指向A[p...q]子数组，t指向A[q+1...r]子数组，k指向B数组 while (s &lt;= q &amp;&amp; t &lt;= r) &#123; if (A[s] &lt;= A[t]) &#123; B[k] = A[s]; s++; &#125; else &#123; B[k] = A[t]; t++; &#125; k++; &#125; if (s = q + 1) &#123;//说明s指向的数组已经遍历完了 for (int i = t; i &lt;= r; ++i) &#123; B[k++] = A[i]; &#125; &#125; else &#123; for (int i = s; i &lt;= r; ++i) &#123; B[k++] = A[i]; &#125; &#125; for (int j = p; j &lt;= r; ++j) &#123; A[j] = B[j]; &#125;&#125; 设Merge算法要合并两个大小分别为n1和n2的数组（n1 选择排序​12345678910111213141516171819/* * 输入：n个元素的数组A[1...n] * 输出：按非降序排列的数组A[1...n] */void SelectionSort(int *A, int n) &#123; for (int i = 0; i &lt; n; ++i) &#123; for (int j = i + 1; j &lt;= n; ++j) &#123; if (A[i] &gt; A[j]) &#123; int t = A[i]; A[i] = A[i]; A[i] = t; &#125; &#125; &#125;&#125; 算法SelectionSort所需的元素比较次数为n(n-1)/2（n-1+n-2+n-3+…+2+1=n(n-1)/2），因为每次交换需要3次赋值，所以元素的赋值次数介于0到3(n-1)之间。 插入排序思路首先将第二个数与第一个数进行对比，如果第二个数比第一个数小，则将第二个数插入到第一个数之前，这样保证前两个数是有序的；接下来将第三个数与前两个数对比，比较的思路是先将第三个数存下来（记为x），然后将第三个数与第二个数比较，如果第二个数比第三个数大，则直接将第二个数向后移动一位，如果第二个数不比第三个数大，则说明此时前三个数都是有序的，因为之前前两个数是有序的，比较到最后，将x放到第三个数比较的终止位置即可。以此类推，将后面的i个数分别其前面的i-1个数进行对比，并将其插入到第一个比其大的数前面，最后即可完成排序。 代码实现​12345678910111213141516/* * 输入：n个元素的数组A[1...n] * 输出：按非降序排列的数组A[1...n] */void InsertionSort(int *A, int n) &#123; for (int i = 2; i &lt;= n; ++i) &#123; int x = A[i]; int j = i - 1; while (j &gt; 0 &amp;&amp; A[j] &gt; x) &#123; A[j + 1] = A[j]; j--; &#125; A[j + 1] = x; &#125;&#125; 执行算法SelectionSort的元素比较次数在n-1到n(n-1)/2之间，元素赋值次数等于元素比较次数加上n-1. 自底向上合并排序​ ​12345678910111213141516171819/* * 输入：n个元素的数组A[1...n] * 输出：按非降序排列的数组A[1...n] */void Merge(int *A, int p, int q, int r);void BottomUpSort(int *A, int n) &#123; int t = 1; while (t &lt; n) &#123; int s = t, t = 2 * s, i = 0; while (i + t &lt;= n) &#123; Merge(A, i + 1, i + s, i + t); i = i + t; &#125; if (i + s &lt; n) &#123; Merge(A, i + 1, i + s, n); &#125; &#125;&#125; 用算法BottomUpSort对n个元素的数组进行排序，当n为2的幂时，元素比较次数在(nlogn)/2到nlogn-n+1之间。执行该算法的元素赋值次数为2nlogn。 时间复杂性O前文提到算法InsertionSort执行的运算次数至多为cn^2，其中c为某个适当选择的正常数。这时我们说算法InsertionSort的运行时间是O(n^2)，说明当排序元素的个数等于或超过某个阈值n0时，对于某个常亮c，运行时间是cn^2，O符号描述的是一个上界但不一定是算法的实际执行时间，比如当排序一个已经排序好的数组时InsertionSort的运行时间就不是O(n^2)而是O(n)了。 Ω相比于O，Ω描述的是算法执行的 下界，比如算法InsertionSort的运算时间至少是cn，则称算法InsertionSort的运行时间是Ω（n），即无论何时，当被排序的元素个数等于或超过某一个阈值n0时，对于某个常数c，算法的运行时间至少是cn。 SentaSenta描述的是一个确切界限，如果对于任意大小等于或超过某一阈值n0的输入，如果运行时间在c1g(n)和c2g(n)之间，则称算法的运行时间是Senta(g(n))。 复杂性类与 o 符号o符号O 符号给出的上界可以是“紧”的,也可以是非“紧”的。2 n^ 2 =O ( n^ 2 ) 是渐近性紧边界2 n = O ( n^ 2 ) 不是渐近性紧边界 o 符号就用来表示 不是渐近性紧边界 的上界举例: 2 n = o ( n ) , 2 ^n ！= o ( n ) 直观上来说,在小 o 符号中, f ( n ) =o ( g ( n )) ,当 n 趋向于无穷大时, f (n ) 函数相当于 g (n )就变得不再重要了即lim- &gt;+oof(n)/g(n)=0 w符号用类比法来讲,小 w符号相对于大 Ω符号的关系正如 o 符号相对于 O 符号的关系。我们用小 w 符号来表示一个 渐近性非紧密的下界 。比如： (n^2)/2=w(n ) (n^2)/2!=w(n^2) lim- &gt;+oof(n)/g(n)=oo 空间复杂性我们把算法使用的空间 定义 、为:为了求解问题的实例而执行的计算步骤所需要的内存空间,它不包括分配用来存储输入的空间（为了区分那些在整个计算过程中占用了少于输入空间的算法） 。 算法的 空间复杂性不可能超过运行时间的复杂性 ,因为每写入一个内存单元都至少需要一定的时间。所以,如果用 T (n ) 和 S (n )分别代表算法的时间复杂性和空间复杂性,有: S ( n ) = O ( T ( n )) 。 最优算法如果可以证明任何一个求解问题 T的算法必定是Ω ( f ( n )) ,那么我们把在 O ( f ( n )) 时间内求解问题T的任何算法都称为问题T的最优算法。 如何估计算法的运行时间 计算迭代次数 计算基本运算的频度 &gt;一般来说,在分析一个算法运行时间时,可以找出这样一个元运算,它的频率至少和任何其他运算的频度一样大,称这样的运算为基本运算。我们还可以放宽这个定义,把那些频度和运行时间成正比的运算包括进来。 使用递推关系 &gt;如果一个算法本身是递归算法,那么计算这个算法运行时间的函数通常也是递归的,即是指,这个函数的定义中引用了函数自身。即便一个算法本身是非递归的,我们有时也可以用递归式来计算它的运行时间。 lim- &gt;+oof(n)/g(n)!=oo f(n)=O(g(n))lim-&gt;+oof(n)/g(n)!=0 f(n)=Ω(g(n))lim-&gt;+oof(n)/g(n)==c f(n)=Senta(g(n))]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[软件系统介绍文档模板]]></title>
    <url>%2F2018%2F05%2F11%2F%E8%BD%AF%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[概述开发背景【比如为什么要开发这个系统】 开发目标【该系统需要完成的基本功能，对系统的大体描述】 参考资料【该系统涉及的开源项目等】 设计原则【设计该系统遵守的原则，比如支持多数据库，可移植行，可拓展性等】 需求分析需求陈述【用平常语言描述该系统的全部功能和细节】 操作用例【描述具体的操作例子，比如登录后进行何种操作】 功能分析划分【分析功能并划分功能块】 系统登录【比如，需要实现两种登录模块，普通登录，管理员登录，并且描述可能出现的各种情况以及问题处理】 用户管理【比如：实现用户显示，添加，删除，修改】 …… 运行环境总体设计系统建模层次方框图【从顶部开始，按照层次分类进行细化】 ER图（实体-联系图）【分析各个对象之间的联系，画图ER图】 接口设计类图设计【使用UML画出各个类的属性、继承和方法】 接口设计【各个子系统之间的接口和用户接口】 内部接口设计【各个部件是通过何种方式进行连接，比如通过远程数据库，http等】 登录界面设计用户管理界面设计…… 数据库结构设计【主要是描述】 数据库E-R图数据库逻辑设计出错处理【描述如果出错的处理方法】 安全保密设计【描述采用何种方法保证安全性】 详细设计程序流程图【具体来说就是把经过总体设计得到的各个模块详细的加以描述。】 伪代码编写【使用中文或者英文进行伪代码编写，以后这些伪代码将会成为代码的注释】 实现编码代码约定代码编写原则测试要点登录测试要点【描述该如何测试，数据的输入，类型】 主界面测试要点…… 测试结果和总结维护维护方法维护文档功能拓展方法]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2F2018%2F05%2F08%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说， 不从整体最优上加以考虑 ，他所做出的仅是在某种意义上的局部最优解。贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。 最短路径问题问题描述给定一个有向图G=(V,E),s为V中一点,以s为起点,要确定从s出发到V中每一个其他定点的距离(距离的定义是最短路径对应的长度). Dijkstra算法算法步骤 初始时，S只包含源点，即S＝{v}，v的距离为0。U包含除v外的其他顶点，即:U={其余顶点}，若v与U中顶点u有边，则 &lt; u,v &gt;正常有权值，若u不是v的出边邻接点，则 &lt; u,v &gt; 权值为∞ 从U中选取一个距离v最小的顶点k，把k，加入S中（该选定的距离就是v到k的最短路径长度） 以k为新考虑的中间点，修改U中各顶点的距离；若从源点v到顶点u的距离（经过顶点k）比原来距离（不经过顶点k）短，则修改顶点u的距离值，修改后的距离值的顶点k的距离加上边上的权 重复步骤b和c直到所有顶点都包含在S中 代码​1234567891011121314151617181920212223242526272829303132333435363738394041424344const int MAXINT = 32767;const int MAXNUM = 10;int dist[MAXNUM];//表示距离int prev[MAXNUM];//记录每个顶点的前驱顶点(因为最短路径的唯一性,所以每个点的前驱元素都是唯一的)int A[MAXUNM][MAXNUM];void Dijkstra(int v0)&#123; bool S[MAXNUM]; // 判断是否已存入该点到S集合中 int n=MAXNUM; for(int i=1; i&lt;=n; ++i) &#123; dist[i] = A[v0][i]; S[i] = false; // 初始都未用过该点 if(dist[i] == MAXINT) //如果该点与源点之间无边 prev[i] = -1; else prev[i] = v0; &#125; dist[v0] = 0; S[v0] = true; for(int i=2; i&lt;=n; i++) &#123; int mindist = MAXINT; int u = v0; // 找出当前未使用的点j的dist[j]最小值 for(int j=1; j&lt;=n; ++j) if((!S[j]) &amp;&amp; dist[j]&lt;mindist)//如果j点没有被用过而且dist[j]小于mindist &#123; u = j; // u保存当前邻接点中距离最小的点的号码 mindist = dist[j]; &#125; S[u] = true; //将u置为已用 for(int j=1; j&lt;=n; j++)//更新u加入已用集合后的未用顶点集合中点到已用集合中点的距离 if((!S[j]) &amp;&amp; A[u][j]&lt;MAXINT) &#123; if(dist[u] + A[u][j] &lt; dist[j]) //在通过新加入的u点路径找到离v0点更短的路径 &#123; dist[j] = dist[u] + A[u][j]; //更新dist prev[j] = u; //记录前驱顶点 &#125; &#125; &#125;&#125; 算法复杂度算法的时间复杂度是senta(n^2) 稠图的线性时间算法最小耗费生成树问题描述设G =(V,E)是无向连通带权图，即一个网络。E中的每一条边（v,w）的权为c[v][w]。如果G的子图G’是一棵包含G的所有顶点的树，则称G’为G的生成树。生成树上各边权的总和称为生成树的耗费。在G的所有生成树中，耗费最小的生成树称为G的最小生成树。最小生成树最常见的题就是求解n个城市之间的修路问题. Kruskal算法算法描述给定无向连同带权图G = (V,E),V = {1,2,…,n}。Kruskal算法构造G的最小生成树的基本思想是： 将G的n个顶点看成n个孤立的连通分支,将所有的边按权从小大排序。 从第一条边开始，依边权递增的顺序检查每一条边。并按照下述方法连接两个不同的连通分支：当查看到第k条边(v,w)时，如果端点v和w分别是当前两个不同的连通分支T1和T2的端点时，就用边(v,w)将T1和T2连接成一个连通分支，然后继续查看第k+1条边；如果端点v和w在当前的同一个连通分支中，就直接再查看k+1条边。这个过程一个进行到只剩下一个连通分支时为止。 此时，已构成G的一棵最小生成树。 代码实现​1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;#define maxn 110 //最多点个数int n, m; //点个数，边数int parent[maxn]; //父亲节点，当值为-1时表示根节点int ans; //存放最小生成树权值struct eage //边的结构体，u、v为两端点，w为边权值&#123; int u, v, w;&#125;EG[5010];bool cmp(eage a, eage b) //排序调用&#123; return a.w &lt; b.w;&#125;int Find(int x) //寻找根节点，判断是否在同一棵树中的依据&#123; if(parent[x] == -1) return x; return Find(parent[x]);&#125;void Kruskal() //Kruskal算法，parent能够还原一棵生成树，或者森林&#123; memset(parent, -1, sizeof(parent)); sort(EG+1, EG+m+1, cmp); //按权值将边从小到大排序 ans = 0; for(int i = 1; i &lt;= m; i++) //按权值从小到大选择边 &#123; int t1 = Find(EG[i].u), t2 = Find(EG[i].v); if(t1 != t2) //若不在同一棵树种则选择该边，合并两棵树 &#123; ans += EG[i].w; parent[t1] = t2; &#125; &#125;&#125; 复杂度分析当图的边数为e时，Kruskal算法所需的时间是O(eloge). Prim算法算法描述设G = (V,E)是连通带权图，V = {1,2,…,n}。构造G的最小生成树,Prim算法的基本思想是：首先置S ={1}，然后，只要S是V的真子集，就进行如下的贪心选择：选取满足条件i ∈S,j ∈V –S,且c[i][j]最小的边，将顶点j添加到S中。这个过程一直进行到S = V时为止。在这个过程中选取到的所有边恰好构成G的一棵最小生成树。 代码实现​12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* Prim算法生成最小生成树 */void MiniSpanTree_Prim(MGraph MG)&#123; int min, i, j, k; int adjvex[MAXVEX];/* 保存相关顶点的父亲节点 */ int lowcost[MAXVEX];/* 保存相关顶点间边的权值 */ lowcost[0] = 0;/* 初始化第一个权值为0，即v0加入生成树 */ /* lowcost的值为0，在这里就是此下标的顶点已经加入生成树 */ adjvex[0] = 0;/* 初始化第一个顶点下标为0 */ cout &lt;&lt; "最小生成树的边为：" &lt;&lt; endl; for (i = 1; i &lt; MG.numVertexes; i++) &#123; lowcost[i] = MG.arc[0][i];/* 将v0顶点与之有边的权值存入数组 */ adjvex[i] = 0;/* 初始化都为v0的下标 */ &#125; for (i = 1; i &lt; MG.numVertexes; i++) &#123; min = INFINITY; /* 初始化最小权值为∞， */ j = 1; k = 0; while (j &lt; MG.numVertexes)/* 循环全部顶点 */ &#123; if (lowcost[j] != 0 &amp;&amp; lowcost[j] &lt; min)/* 如果权值不为0且权值小于min */ &#123; min = lowcost[j];/* 则让当前权值成为最小值 */ k = j;/* 将当前最小值的下标存入k */ &#125; j++; &#125; cout &lt;&lt; "(" &lt;&lt; adjvex[k] &lt;&lt; ", " &lt;&lt; k &lt;&lt; ")" &lt;&lt; " "; /* 打印当前顶点边中权值最小的边 */ lowcost[k] = 0;/* 将当前顶点的权值设置为0,表示此顶点已经完成任务 */ for (j = 1; j &lt; MG.numVertexes; j++)/* 循环所有顶点 */ &#123; /* 如果下标为k顶点各边权值小于此前这些顶点未被加入生成树权值 */ if (lowcost[j] != 0 &amp;&amp; MG.arc[k][j] &lt; lowcost[j]) &#123; lowcost[j] = MG.arc[k][j];/* 将较小的权值存入lowcost相应位置 */ adjvex[j] = k;/* 将k设为下标j的父亲节点 */ &#125; &#125; &#125; cout &lt;&lt; endl;&#125; 复杂度分析此算法的时间复杂度为O(n^2) 总结当e = Ω(n^2)时，Kruskal算法比Prim算法差；但当e = o(n^2)时，Kruskal算法比Prim算法好得多。]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>贪心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划]]></title>
    <url>%2F2018%2F05%2F07%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[什么是动态规划基本概念动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。动态规划是一种被广泛用于求解组合最优化问题的算法。 算法思想算法思想与分治法类似，也是 将待求解的问题分解为若干个子问题 （阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 与分治法的差别适合于用动态规划法求解的问题，经分解后得到的子问题往往 不是互相独立 的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 适用的情况能采用动态规划求解的问题的一般要具有3个性质： 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（ 该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势 ） 最长公共子序列问题问题描述给定两个长度为n和m的字符串A和B，确定A和B中最长公共子序列的长度。 解决思路 传统算法 一种传统的方式是使用蛮力搜索的方法，列举A所有的2^n个子序列对于每一个子序列子在senta(m)时间内来确定它是否也是B的子序列。该算法的时间复杂性是senta(m2^n)，是指数复杂性的。 动态规划算法 寻找一个求最长公共子序列的递推公式，令A=a_1a_2a_3….a_n和B=b_1b_2b_3…b_m，令L[i,j]表示a_1a_2_3…a_i和b_1b_2b_3…b_j的最长公共子序列的长度，则就有当i和j都大于0的时候，如果a_i=b_j，则L[i,j]=L[i-1,j-1]+1，反之，如果a_i!=b_j，则L[i,j]=max(L[i-1,j],L[i,j-1])所以就有以下递推公式： L [i,j]=0 i==0||j==0 L[i,j]=L[i-1,j-1]+1 i,j&gt;0&amp;&amp;a_i==b_j L[i,j]=max(L[i-1,j],L[i,j-1]) i,j&gt;0&amp;&amp;a_i=b_j 代码实现输入A和B字符串，返回二者的最长子序列长度 ​123456789101112131415161718int Lcs(char *A, int n, char *B, int m) &#123;//A[0...n] B[0...m] int L[n + 1][m + 1]; for (int i = 0; i &lt;= n; ++i) &#123; L[i][0] = 0; &#125; for (int j = 0; j &lt;= m; ++j) &#123; L[0][j] = 0; &#125; for (int k = 1; k &lt;= n; ++k) &#123; for (int i = 1; i &lt;= m; ++i) &#123; if (A[k] == B[i])L[k][i] = L[k - 1][i - 1] + 1; else L[k][i] = L[k][i - 1] &gt; L[k - 1][i] ? L[k][i - 1] : L[k - 1][i]; &#125; &#125; return L[n][m];&#125; 注意，以上算法需要的空间复杂度是senta(mn)，但是因为计算表中每一项的计算仅仅需要其上一行和上一列的元素，所以对算法进行改进可以使得空间复杂度降为senta(min(m,n))（准确来说是需要2min(m,n)的空间，仅仅将前一行和当前行存储下来即可）。 结论最长公共子序列问题的最优解能够在senta(mn)时间和senta(min(m,n))空间内计算得到。 矩阵链相乘问题描述给定一个n个矩阵的序列⟨A1,A2,A3…An⟩,我们要计算他们的乘积：A1A2A3…AnA1A2A3…An，由于矩阵乘法满足结合律，加括号不会影响结果，但是不同的加括号方法，算法复杂度有很大的差别：考虑矩阵链⟨A1,A2,A3⟩，三个矩阵规模分别为10×100、100×5、5×50： 按((A1A2)A3)方式，需要做10∗100∗5=5000次，再与A3相乘，又需要10∗5∗50=2500，共需要7500次运算； 按(A1（A2A3）)方式计算，共需要100∗5∗50+10∗100∗50=75000次标量乘法 以上两种不同的加括号方式具有10倍的差别，可见一个好的加括号方式，对计算效率有很大影响。 解决思路使用一个长度为n+1的一维数组p来记录每个矩阵的规模，其中n为矩阵下标，i的范围1~n，例如对于矩阵Ai而言，它的规模应该是p[i-1]×p[i]。由于i是从1到n取值，所以数组p的下标是从0到n。 用于存储最少乘法执行次数和最佳分段方式的结构是两个二维数组m和s，都是从1~n取值。m[i][j]记录矩阵链&lt; Ai,Ai+1,…,Aj&gt;的最少乘法执行次数 ，而s[i][j]则记录 最优质m[i][j]的分割点k。 需要注意的一点是当i=j时，m[i][j]=m[i][i]=0，因为一个矩阵不需要任何乘法。 假设矩阵链从Ai到Aj，有j-i+1个矩阵，我们从k处分开，将矩阵链分为Ai~Ak和Ak+1到Aj两块，那么我们可以比较容易的给出m[i][j]从k处分隔的公式： ​1m[i][j]=m[i][k]+m[k+1][j]+p[i-1]*p[k]*p[j]； 在一组确定的i和j值的情况下，要使m[i][j]的值最小，我们只要在所有的k取值中（i &lt;=k&lt; j)，寻找一个让m[i][j]最小的值即可。 假设L为矩阵链的长度，那么L=j-i+1。当L=1时，只有一个矩阵，不需要计算。那么我们可以从L=2到n进行循环，对每个合理的i和j值的组合，遍历所有k值对应的m[i][j]值，将最小的一个记录下来，存储到m[i][j]中，并将对应的k存储到s[i][j]中，就得到了我们想要的结果。 代码​123456789101112131415161718192021222324/* * 输入：ms[1...n+1],ms[i]表示第i个矩阵的行数，ms[i+1]表示第i个矩阵的列数 * 输出：n个矩阵的数量乘法的最小次数 */int dp[1024][1024] = &#123; 0 &#125;;struct Matrix &#123; int row; int column;&#125;;int matrixChainCost(Matrix *ms, int n) &#123; for (int scale = 2; scale &lt;= n; scale++) &#123; for (int i = 0; i &lt;= n - scale; i++) &#123; int j = i + scale - 1; dp[i][j] = INT_MAX; for (int k = i; k &lt; j; k++) &#123; dp[i][j] = std::min(dp[i][j], dp[i][k] + dp[k+1][j] + (ms[i].row*ms[k].column*ms[j].column)); &#125; &#125; &#125; return dp[0][n - 1];&#125; 复杂度分析 时间复杂度：senta(n^3) 空间复杂度：senta(n^2) 所有点对的最短路径问题问题描述设G是一个有向图，其中每条边(i, j)都有一个非负的长度L[i, j]，若点i 到点j 没有边相连，则设L[i, j] = ∞.找出每个顶点到其他所有顶点的最短路径所对应的长度。例如： 则 L： 0 2 9 8 0 6 1 ∞ 0 解决思路（Floyd算法）Floyd算法（所有点对最短路径）就是每对可以联通的顶点之间总存在一个借助于其他顶点作为媒介而达到路径最短的最短路径值（这个值通过不断增添的媒介顶点而得到更新，也可能不更新——通过媒介的路径并不比其原路径更短），所有的值存储于邻接矩阵中，这是典型的动态规划思想。 值得注意的是，Floyd算法本次的状态的获取 只用到了上个阶段的状态 ，而没有用到其他阶段的状态，这就为 压缩空间 奠定了条件。 Floyd算法能够成功的关键之一就是D0(初始矩阵，即权重矩阵)的初始化，凡是不相连接的边必须其dij必须等于正无穷且dii=0(矩阵对角线上的元素！) 代码实现​ /* * 输入：n×n维矩阵l[1...n,1...n]，对于有向图G=({1,2,...n},E)中的边(i,j)的长度为l[i,j] * 输出：矩阵D，使得D[i,j]等于i到j的距离 * l矩阵需要满足：l[i,i]=0，对于m--&gt;n没有直接连接的有向边（因为是有向图，只考虑单边），应有l[m,n]=INT.MAX（即无穷） * */ void Floyd(int **l,int n){ int **d= reinterpret_cast&lt;int **&gt;(new int[n + 1][n + 1]); for (int i = 1; i &lt;=n ; ++i) { for (int j = 1; j &lt;=n ; ++j) { d[i][j]=l[i][j]; } } for (int k = 1; k &lt;=n ; ++k) { for (int i = 1; i &lt;=n ; ++i) { for (int j = 1; j &lt;=n ; ++j) { d[i][j]=min(d[i][j],d[i][k]+d[k][j]); } } } } 复杂度分析算法的运行时间是senta(n^3)算法的空间复杂性是senta(n^2) 背包问题问题描述设U={u1,u2,u3…un}是一个准备放入容量为C的背包中的n项物品的集合。我们要做的是从U中拿出若干物品装入背包C，要求这些物品的总体积不超过C，但是要求装入背包的物品总价值最大。 解决思路有 n 种物品，物品 i 的体积为 v[i], 价值为 p[i]. 假定所有物品的体积和价格都大于 0, 以及背包的体积为 V.mp[x][y] 表示体积不超过 y 且可选前 x 种物品的情况下的最大总价值那么原问题可表示为 mp[n][V]。递归关系： 递归式 解释 mp[0][y] = 0 表示体积不超过 y 且可选前 0 种物品的情况下的最大总价值，没有物品可选，所以总价值为 0 mp[x][0] = 0 表示体积不超过 0 且可选前 x 种物品的情况下的最大总价值，没有物品可选，所以总价值为 0 当 v[x] &gt; y 时，mp[x][y] = mp[x-1][y] 因为 x 这件物品的体积已经超过所能允许的最大体积了，所以肯定不能放这件物品， 那么只能在前 x-1 件物品里选了当 v[x] &lt;= y 时，mp[x][y] = max{ mp[x-1][y], p[x] + mp[x-1][y-v[x]] } | x这件物品可能放入背包也可能不放入背包，所以取前两者的最大值就好了， 这样就将前两种情况都包括进来了 代码​123456789101112131415161718192021222324/* * 输入：物品集合U=&#123;u1,u2,u3...un&#125;，体积为s1,s2,s3...sn，价值为v1,v2,v3...vn，容量为C的背包 * 输出：满足条件的最大价值 * */int Knapsack(int *s,int *v,int C,int n)&#123; int V[n+1][C+1];//V[i][j]表示从前i项找出的装入体积为j背包的最大值 for (int i = 0; i &lt;=n ; ++i) &#123; V[i][0]=0; &#125; for (int j = 0; j &lt;=C ; ++j) &#123; V[0][j]=0; &#125; for (int k = 1; k &lt;=n ; ++k) &#123; for (int i = 1; i &lt;=C ; ++i) &#123; if(s[k]&lt;=i)&#123; V[k][i]=max(V[k-1][i],V[k-1][i-s[k]]+v[k]); &#125; &#125; &#125; return V[n][C];&#125; 算法复杂度背包问题的最优解可以在senta(nC)时间内和senta(C)空间内解得。注意，上述算法的时间复杂性对输入不是多项式的，但是它的运行时间关于输入值是多项式的（时间复杂性+其他耗费时间），故认为它是伪多项式时间算法。]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回溯算法]]></title>
    <url>%2F2018%2F05%2F07%2F%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概述回溯算法是一种组织搜索的一般技术，它常常可以避免搜索所有的可能性，适用于求解那些有潜在的大量解但是有限个数的解已经检查过的问题。 3着色问题问题描述给出一个无向图G=(V,E)，需要用三种颜色之一为V中的每个顶点着色，要求没有两个相邻的顶点有相同的颜色。 算法思想我们称没有两个邻接顶点有同样颜色的着色方案为合法的，反之成为非法的。如果不考虑合法性的要求，给出n个顶点的无向图，将其用三种颜色着色，共有n^3种不同的方法，因为没一个顶点都有三种不同的着色方案，这就构成了一颗三叉树，如图：在该三叉树中，从根到叶子节点的每一条路径代表一种着色方法（合法的和不合法的），我们需要做的就是选出一条合法的从根到叶子的路径即可。所以我们从跟节点开始向叶子节点走，这时有两种情况： 从根到当前节点的路径对应一个合法的着色： 当前路径长度小于n：过程终止（除非希望找到不止一种着色方案） 当前路径长度等于n：生成当前节点的一个子节点，并将生成的当前节点的子节点标记为新的当前节点 从根到当前节点的路径对应一个非法的着色：回溯到当前节点的父节点即将当前节点的父节点标记为新的当前节点 代码使用数组c[1…n]代表图的顶点集合，判断合法性只需判断与当前有联系的点中是否存在与之涂色相同的点即可，此处为节省时间省略该部分代码的实现。 迭代法​123456789101112131415161718192021222324252627282930313233343536void ColorItre(int *c) &#123;//c[1...n] for (int i = 1; i &lt;= n; ++i) &#123; c[i] = 0; &#125; bool flag = false; int k = 1; while (k &gt;= 1) &#123; while (c[k] &lt;= 2) &#123; c[k] = c[k] + 1; if (c[k]为合法的)&#123; if (k == n) &#123; flag = true; break; &#125; else &#123; k++; &#125; &#125; &#125; if (flag) &#123; break; &#125; //如果第二个循环跳出执行到这里，则说明当前节点k试遍了三种颜色仍然没有找到合法的着色，则将k--进行回溯，注意要将c[k]置为初始值0 c[k] = 0; k--; &#125; if (flag) &#123; cout &lt;&lt; "success" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "no solution" &lt;&lt; endl; &#125;&#125; 递归法​12345678910111213141516171819202122232425262728void ColorRec(int *c) &#123;//c[1...n] for (int i = 1; i &lt;= n; ++i) &#123; c[i] = 0; &#125; bool flag = false; flag = graphcolor(c, 1); if (flag) &#123; cout &lt;&lt; "success" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "no solution" &lt;&lt; endl; &#125;&#125;bool graphcolor(int *c, int i) &#123; for (int color = 1; color &lt;= 3; ++color) &#123; c[i] = color; if (c[i]是合法的)&#123; if (i &lt; n) &#123; graphcolor(c, i + 1); &#125; else &#123; return true; &#125; &#125; &#125; //如果执行到这里说明当前节点不存在合法着色，需要回溯，返回false即可激活前一次递归（即让前一层for循环的color加一），以此达到回溯的目的 return false;&#125; 复杂度分析这两种实现方式在最坏情况下生成了O(3^n)个节点，对于每个生成的节点，判断当前节点的合法性（合法、部分、二者都不是）需要O(n)的工作来检查，因此，最坏情况下的运行时间是O(n3^n)。 回溯法的特点 节点是使用深度优先搜索算法生成的 不需要存储整棵搜索树，只需存储根到当前活动节点的路径 8皇后问题代码见 两种不同方式解决八皇后问题，此处主要介绍算法思路。 问题描述八皇后问题是一个以国际象棋为背景的问题：如何能够在 8×8的国际象棋棋盘上放置八个皇后，使得任何一个皇后都无法直接吃掉其他的皇后？为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。八皇后问题可以推广为更一般的n皇后摆放问题：这时棋盘的大小变为n×n，而皇后个数也变成n。当且仅当n = 1 或 n ≥ 4 时问题有解。 代码代码和着色问题代码几乎一样，这里不做过多介绍，给出参考代码： ​123456789101112131415161718192021222324252627282930313233void eight_Queens() &#123; int c[9]; for (int i = 1; i &lt;= 8; ++i) &#123; c[i] = 0; &#125; bool flag = false; int k = 1; while (k &gt;= 1) &#123; while (c[k] &lt;= 7) &#123; c[k]++; if (c[k]为合法着色)&#123; if (k == 8) &#123; flag = true; break; &#125; else &#123; k++; &#125; &#125; &#125; if (flag) &#123; break; &#125; c[k] = 0; k--; &#125; if (flag) &#123; cout &lt;&lt; "success" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "no solution" &lt;&lt; endl; &#125;&#125; 复杂度分析回溯法在最坏情况下需要O（n^2）的运行时间。但是需要注意，虽然蛮力搜索法的最坏情况也需要O（n^2）的时间，但是根据经验回溯法的有效性远远超过蛮力法。(鬼知道这是谁的经验，反正只要知道考试用蛮力法肯定会xx) 一般回溯方法什么是一般回溯法在回溯法中，解向量中每个xi都属于一个有限的线序集Xi，因此，算法最初从空向量开始，然后选择X1中最小的元素作为x1，如果（x1）是一个部分解，算法从X2中找出最小的元素作为x2继续，如果（x1，x2）是一个部分解，则从X3中找出最小元素作为x3，否则跳过x2寻找下一个。一般地，假如算法已经找到部分解（x1,x2,x3…,xj），在判断v=（x1,x2,x3…,xj,x_j+1）时有以下情况： v是最终解：记录下当前v作为一组解，如果只想求得一组解则算法结束，否则继续寻找其他解 v是一组部分解：从X_j+2中寻找新的最小元素继续向前走 v既不是最终解也不是部分解： X_j+1中还有其他元素可供选择：在X_j+1中寻找下一个元素 X_j+1中没有其他元素可供选择：将x_j置为X_j中的下一个元素回溯，如果X_j中仍然没有其他元素可供选择，则照此方法继续向前回溯。 分支限界法算法介绍分支限界法（branch and bound method）是求解 纯整数规划 或 混合整数规划 问题的经典方法，在上世纪六十年代由LandDoig和Dakin等人提出。这种方法灵活且便于用计算机求解，目前已经成功运用于求解生产进度问题、旅行推销员问题、工厂选址问题、背包问题及分配问题等。算法基本思想如下： 按宽度优先策略遍历解空间树； 在遍历过程中，对处理的每个结点vi，根据界限函数，估计沿该结点向下搜索所可能达到的完全解的目标函数的可能取值范围—界限bound(vi)=[downi, upi]； 从中选择使目标函数取的极值(最大、最小)的结点优先进行宽度优先搜索，从而不断调整搜索方向，尽快找到问题解。 各结点的界限函数bound(vi)=[downi,upi]是解决问题的关键，通常依据具体问题而定。常见的两种分支限界法是队列式分支限界法和优先队列式分支限界法，它们分别按照队列先进先出的原则和优先队列中规定的优先级选取下一个节点为扩展节点。 分支限界法与回溯法的区别求解目标不同 回溯法的求解目标是找出解空间树中满足约束条件的 所有解 分支限界法的求解目标则是尽快找出满足约束条件的 一个解 ，或是在满足约束条件的解中找出在某种意义下的 最优解 分支限界法通常用于解决 离散值的最优化问题 搜索方式不同 回溯法以 深度优先 的方式（遍历结点）搜索解空间树 分支限界法以 广度优先 或 最小耗费优先 的方式搜索解空间树 对扩展结点的扩展方式不同 分支限界法中，每一个活结点只有一次机会成为扩展结点，活结点一旦成为扩展结点，就一次性产生其所有儿子结点 重复上述结点扩展过程，直至到找到所需的解或活结点表为空时为止 Demo——旅行商问题求解参考： 这里 问题描述给出一个城市的集合和一个定义在 每一对城市之间 的耗费函数，找出耗费最小的旅行。 解决思路考虑下图所示的情况及其代价矩阵，假定起始城市为1号城市： 注意代价矩阵的特点，每条满足要求的回路在代价矩阵中的每一行每一列有且只有1个元素与之对应。据此，我们可以用贪心算法计算问题的上界：以起始城市作为出发城市，每次从当前出发城市发出的多条边中，选择没有遍历过的最短边连接的城市，作为下一步达到城市。在这个问题中，从城市1出发，途经1→3→5→4→2→1，路径长度1+2+3+7+3=16作为上界，即最短路径长度&lt;=16。对于下界，一个简单的办法是直接将矩阵中每一行的最小元素相加，在这个问题中，路径长度1+3+1+3+2=10作为下界，即最短路径长度&gt;=10。更优的计算方式是将矩阵中每一行最小的2个元素相加除以2并向上取整。因为在一条路径上，每个城市有2条邻接边：进入该城市、离开该城市。对每一步经过的城市j，从最近的上一个城市i来，再到下一个最近城市k去，即i→j→k。在这个问题中，路径长度{(1+3)+(3+6)+(1+2)+(3+4)+(2+3)}/2向上取整等于14作为下界，即最短路径长度 =14。因此，以最短路径长度dist作为TSP问题目标函数，则dist的界为[14,16]。在问题求解过程中，如果1个部分解的目标函数dist下界超出此界限，则该部分解对应了死结点，可剪枝。对于1条正在生成的路径/部分解，设已经确定的顶点(已经经过/遍历的城市)集合为U=(r1,r2, …,rk)，则该部分解的目标函数的下界为(已经经过的路径的总长的2倍+从起点到最近未遍历城市的距离+从终点到最近未遍历城市的距离+进入/离开未遍历城市时各未遍历城市带来的最小路径成本)除以2并向上取整。假设正在生成的路径/部分解为1→4,U={1,4},未遍历城市={2,3,5},该部分解下界为{2*5+1+3+(3+6)+(1+2)+(2+3)}/2向上取整等于16：]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分治算法]]></title>
    <url>%2F2018%2F04%2F30%2F%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[什么是分治一个分治算法把问题实例划分为若干个子问题（一般是两个），并分别使用递归解决每个子实例，然后把这些子实例的解组合起来，得到原问题的解。 举个栗子考虑这样一个问题：我们需要在序列Ａ[1….n]中找到该序列的最大值元素和最小值元素，一种直接的算法是扫描一遍Ａ序列，用两个标志位max和min分别表示最大值和最小值元素，然后扫描时根据每个元素与当前最大最小值的比较情况动态调整最大最小值直至最后找到最大最小值，代码如下： ​12345678910void MaxMin(int *A,int n)&#123; int max,min; min=max=A[0]; for (int i = 1; i &lt;n ; ++i) &#123; if(A[i]&gt;max)max=A[i]; if(A[i]&lt;min)min=A[i]; &#125; cout&lt;&lt;max&lt;&lt;min&lt;&lt;endl;&#125; 显然，此种方法的元素比较次数是２ｎ－２，但是利用分治策略就可以将元素比较次数减少到(３ｎ)/2-2，具体做法：将数组分割成凉拌，Ａ[1…n/2]和Ａ[n/2+1…n]，在每一半中分别找到最大值和最小值，并返回这两个最小值中的最小值、这两个最大值中的最大值作为最终的最小、最大值。对应伪代码如下： ​1234567891011121314(max min) MaxMin2(int *A,int low,int high)&#123; if (high-low==1)&#123; if (A[low]&lt;A[high])return (A[low],A[high]); else return (A[high],A[low]); &#125; else&#123; int mid=(high+low)/2; (x1,y1)=MaxMin2(A,low,mid); (x2,y2)=MaxMin2(A,mid+1,high); x=min(x1,x2); y=max(y1,y2); return (x,y); &#125;&#125; 按照上述算法，设Ａ[1…n]有ｎ个元素，ｎ为２的幂，则仅用３ｎ/2-2次元素比较就可以在数组Ａ中找出最大值和最小值。 二分搜索分治（递归）实现原理比较简单，给出代码： ​12345678int binarysearch(int *A, int low, int high, int x) &#123;//A是已经排序过的数组,A[1....n] if (low &gt; high)return 0; int mid = (high + low) / 2; if (x == A[mid])return mid; if (x &lt; A[mid])return binarysearch(A, low, mid, x - 1); else return binarysearch(A, mid + 1, high, x); &#125; 算法BINARYSEARCHREC在ｎ个元素组成的数组中搜索某个元素所执行的比较次数不超过((int)lohn)+1，时间复杂度是Ｏ(logn)。 迭代实现​1234567891011121314int binarysearch(int *A, int n, int x) &#123;//A是已经排序过的数组,A[1....n] int low, high, j; low =1; high = n; j = 0;//j表示ｘ的下标 while (low &lt;= high &amp;&amp; j == 0) &#123; int mid = (high + low) / 2; if (x == A[mid]) j = mid; else if (x &lt; A[mid])high = mid - 1; else low = mid + 1; &#125; return j;&#125; 总结递归和迭代实现二分搜索算法的元素比较次数都在int(logn)+１内，但是迭代算法只需要senta(１)的空间，而迭代算法由于迭代深度为Ｏ(logn)，每个递归层次需要senta(1)的空间，所以总的需要的空间总量是Ｏ(logn)。 归并（合并）排序这里需要区分迭代式合并排序和递归式合并排序的区别（自行查阅资料） 迭代式主要思路是将索要排序数列看做若干个有序的小数列，因为将两个有序数列合并之后所得数列还是有序数列，所以经过不断合并，最后可将数列排为有序。 时间空间复杂度及稳定性 T(n)=O(nlog2–&gt;n) S(n)=O(n) 稳定 代码​123456789101112131415161718192021222324252627282930313233343536373839void MSort(vector&lt;int&gt; v) &#123; vector&lt;int&gt; h; h = v; int start, seg; for (seg = 1; seg &lt; v.size(); seg *= 2) &#123; int k = 0; for (start = 0; start &lt; v.size(); start = start + seg * 2) &#123; int end; end = start + seg; int low = start; while (low &lt; start + seg &amp;&amp; end &lt; start + seg + seg &amp;&amp; low &lt; v.size() &amp;&amp; end &lt; v.size()) &#123; if (v[low] &lt;= v[end]) &#123; h[k++] = v[low]; low++; &#125; else &#123; h[k++] = v[end]; end++; &#125; &#125; while (low &lt; start + seg &amp;&amp; low &lt; v.size()) &#123; h[k++] = v[low++]; &#125; while (end &lt; start + seg + seg &amp;&amp; end &lt; v.size()) &#123; h[k++] = v[end++]; &#125; &#125; v = h; &#125; show(v);&#125; 递归式主要思路是将待排序序列分成两个小部分，然后再对两个小部分运行相同的排序方法进行递归排序，最后将两个小部分合并起来。 代码MergeSort（A,1,n）; ​123456789101112131415161718192021222324252627282930313233void MergeSort(int *A, int low, int high) &#123; if (low &lt; high) &#123; int mid = (high + low) / 2; MergeSort(A, low, mid); MergeSort(A, high, mid + 1); Merge(A, low, mid, high); &#125;&#125;void Merge(int *A, int low, int mid, int high) &#123; int n = high - low; int B[high - low]; int b = mid; int i; for (i = 0; i &lt; n &amp;&amp; low &lt; mid &amp;&amp; b &lt; high; ++i) &#123; if (A[low] &lt; A[b]) &#123; B[i] = A[low++]; &#125; else &#123; B[i] = A[b++]; &#125; &#125; for (int j = low; j &lt; mid; ++j) &#123; B[i] = A[j]; &#125; for (int k = b; k &lt; high; ++k) &#123; B[i] = A[k]; &#125; for (int l = low; l &lt;high ; ++l) &#123; A[l]=B[i]; &#125;&#125; 总结算法MergeSort对一个n个元素的数组排序所需的时间是senta(nlogn)，空间是senta(n). 寻找中项和第k小元素场景描述寻找序列A[1…n]中的第k小元素。 算法描述传统的方法是直接将A[1…n]进行排序，然后取排序后的序列的第k个即为第k小元素，但是这种方法需要oumiga(nlogn)的时间，因为任何基于比较的排序过程在最坏情况下必须花费这么多时间，所以我们选择一种新的算法：我们要在n个元素中找到第k小元素的实质是寻找第k小元素在A中的位置，所以我们可以将A划分成三个子序列A1 A2A3，其中A2为单个元素的序列，A1中的所有元素小于A2，A3中的所有元素大于A2，此时就有以下几种情况： 如果A1的长度大于k则A序列中第K小元素一定在A1中，我们只需寻找A1中的第k小元素即可 如果A1的长度等于k-1，则A2中的那个单元素就是我们要找的第k小元素 如果A1的长度小鱼k-1，则我们需要在A3序列中找到第k-len(A1)-1小元素 这样，我们就可以采用分治的思想将原来的n个元素中寻找第k小元素不断缩小范围最终找到目标元素，具体算法步骤描述如下： SELECT 算法描述 如果数组元素个数小于 44,则直接将数组排序并返回第 k小元素(采用直接的方法来解决问题,因为当总元素个数小于44*5=220的时候用直接的方法解决问题更快)。 把 n 个元素以每组 5 个元素划分为 int( n/5) 组,如果 n 不是 5的倍数则抛弃剩余元素。 对每组进行排序,之后取出每组的中间项(第 3 个元素)。 递归调用 SELECT 算法,得到这些中间项序列中的中项元素 mm 根据 mm,将原数组 A 划分为三个子数组: A1={小于 mm 的元素}; A2={等于 mm 的元素}; A3={大于 mm 的元素}; 根据 k 的大小,判断第 k 小元素会出现在 A1,A2,A3 中的哪一个数组里,之后,或者返回第 k 小元素(mm,在 A2中),或者在 A1 或 A3 上递归。 k 代码实现​12345678910111213141516171819202122232425262728293031323334353637383940void sort(int *A, int low, int high) &#123; for (int i = low; i &lt; high; ++i) &#123; for (int j = i + 1; j &lt; high; ++j) &#123; if (A[i] &gt; A[j]) &#123; int t = A[i]; A[i] = A[j]; A[j] = t; &#125; &#125; &#125;&#125;int Select(int *A, int low, int high, int k) &#123; int p = high - low + 1; if (p &lt; 44) &#123; sort(A, low, high); return A[k]; &#125; int q = p / 5; int M[q]; for (int i = 0; i &lt; q; ++i) &#123; sort(A, i * 5, (i + 1) * 5);//将A分成q组，每组5个元素，如果5不整除p，则排除剩余元素 M[i] = A[i * 5 + 3];//M为q个子序列中的中项（中项集合） &#125; int mm = M[q / 2];//mm为中项集合的中项 int *A1, a1 = 0; int *A2, a2 = 0; int *A3, a3 = 0; for (int j = low; j &lt; high; ++j) &#123; if (A[j] &lt; mm)A1[a1++] = A[j]; if (A[j] = mm)A2[a2++] = A[j]; if (A[j] &gt; mm)A3[a3++] = A[j]; &#125; if (a1 &gt;= k)return Select(A1, 1, a1, k); if (a1 + a2 == k)return mm; if (a1 + a2 &lt; k)return Select(A3, 1, a3, k - a1 - a2); &#125; ​ 复杂度分析在一个由n个元素组成的线序集合中提取第k小元素，所需的时间是senta(n)(T(n)&lt;=20cn,c是排序43个元素所需的时间)，特别地，n个元素元素的中值可以在senta(n)时间找出。需要注意的是，虽然此算法所需的时间是senta(n)但是其中的倍数常量（20c）还是太大，我们会在随讲机算法的时候提出一个具有较小倍数常量的算法。 快速排序（QuickSort）快速排序（QuickSort）是一种具有senta(nlogn)时间复杂度的排序算法，相比MergeSort，QuickSort不需要辅助的存储空间，这是它的优势。 划分算法（Split）在进行快速排序算法的实现之前我们需要先实现划分算法，它是快速排序算法的基础。 什么是划分算法设A[low…high]是一个包含n个数的序列，设x=a[low],我们希望对A中的元素进行位置调整后实现当i&lt; new index of x时A[i] 实现思路对一个指定序列A[low…high]，从A[low+1]开始向后扫描元素，如果当前元素a&lt;=A[low]，则将a与第A[i]的元素互换位置，其中i是从low开始的，每进行一次元素的互换之前i++，最后，当A中元素扫描完毕时所有小于等于A[low]的元素都在i之前的位置（包括A[i]），所以此时只需将A[low]和A[i]的元素互换位置即可满足划分的定义，此时的i对应的就是元素A[low]的新位置. 代码实现​123456789101112131415161718192021int Split(int *A, int low, int high) &#123;//输入一个序列，返回A[low]对应元素的新位置 int i = low; int x = A[low]; for (int j = low + 1; j &lt;= high; ++j) &#123; if (A[j] &lt;= x) &#123; i++; if (i != j) &#123; int t = A[i]; A[i] = A[j]; A[j] = t; &#125; &#125; &#125; int t; t = A[low]; A[low] = A[i]; A[i] = t; return i;&#125; 复杂度分析因为算法split的元素比较次数恰好是n-1，所以它的时间复杂性为senta(n). 排序算法算法思想算法QuickSort的主要思路是利用Split算法将A[low…high]中的A[low]排列到其正确的位置A[w]，然后对子数组A[low…w-1]和子数组A[w+1…high]递归地进行排序从而产生整个排序数组。 代码实现​1234567void QuickSort(int *A, int low, int high) &#123; if (low &lt; high) &#123; int w = Split(A, low, high);//w为A[low]的新位置 QuickSort(A, low, w - 1); QuickSort(A, w + 1, high); &#125;&#125; 复杂度分析算法QuickSort对n个元素的数组进行排序时执行的平均比较次数是senta(nlogn)]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>分治算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[致敬那些用键盘改变世界的劳动者！]]></title>
    <url>%2F2018%2F04%2F30%2F%E8%87%B4%E6%95%AC%E9%82%A3%E4%BA%9B%E7%94%A8%E9%94%AE%E7%9B%98%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C%E7%9A%84%E5%8A%B3%E5%8A%A8%E8%80%85%EF%BC%81%2F</url>
    <content type="text"><![CDATA[end]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归纳法]]></title>
    <url>%2F2018%2F04%2F29%2F%E5%BD%92%E7%BA%B3%E6%B3%95%2F</url>
    <content type="text"><![CDATA[只调用一次的递归叫做尾递归 基数排序算法思想基数排序需要经历d次，d为所要排序数列中位数最多的数的位数，其过程是首先根据数列中数的个位的数值将所有数入0~9这10个队列，然后从0~9将元素依次出队，然后再根据十位元素的数值再次入队，然后出队，以此类推重复d次，最终即可完成排序。 时间空间复杂度及稳定性 T(n)=O(d*n) d为排序数中最大数的位数 S(n)=O(n) 稳定 代码​123456789101112131415161718192021222324252627void radixSort(vector&lt;int&gt; v) &#123; int d = GetMaxBit(v); int *count = new int[10]; queue&lt;int&gt; q[10]; int radix = 1; for (int i = 0; i &lt; d; ++i) &#123; for (int j = 0; j &lt; v.size(); ++j) &#123; int t; t = (v[j] / radix) % 10; q[t].push(v[j]); &#125; int p = 0; for (int k = 0; k &lt; 10; ++k) &#123; while (!q[k].empty()) &#123; v[p++] = q[k].front(); q[k].pop(); &#125; &#125; radix *= 10; &#125; show(v);&#125; 注意对于任何的基数都可以归纳出算法，而不仅仅是以10做基数。比如可以把二进制的每四位作为一个数字，也就是用16作为基数，表的数目将和基数相等但是要保证从低位开始将数分配到表中。 整数幂场景介绍很多时候我们需要求实数x的n次方即x^n，按照常规做法一般会对x进行n次自乘以得到x^n，但是这是非常低效的，因为它需要senta（n）次乘法，按照输入的大小来说它是指数级的。 归纳法思路一个比较高效的归纳算法是令m=int(n/2)，假设已经知道如何计算x^m,那么根据x^m次方来计算x^n次方就有两种情况： n为偶数 则x^n=（x^m）^2 n为奇数 则x^n=x(x^m)^2 归纳法实现代码（Exprec）​123456789101112131415int power(int x,int n)&#123; if (n==0)&#123; return 1; &#125; int m=n/2; int y; y=power(x,n/2); y=y*y; if (n%2!=0)&#123;//如果n是奇数 y=y*x; &#125; return y;&#125; 迭代法实现思路上述归纳法实现求x^n的关键部分在于采用递归不断判断n/2的奇偶性，所以我们可以采用迭代的办法，因为一个数除以2的k次方后的奇偶性由其化为二进制数的第k低位决定的（因为除法除以2就相当于二进制的左移操作），所以我们可以将n化为二进制数字dk,d(k-1)……d_0，从y=1开始，从左到右扫描二进制数字，如果当前二进制数字为0，则对应递归情况下的偶数情况即应该y=y^2，否则即为y=y(y^m)^2 迭代法实现代码（Exp）​12345678910int Exp(int x,int n)&#123; int d[10];//假设n化为2进制数字后存在d数组里面 int y=1; for (int i = len(d); i &gt;=0 ; --i) &#123; y=y*y; if(d[i]==1)&#123; y=y*x; &#125; &#125;&#125; 总结假设每次乘法的时间是常数，那么这两种方法所需的运行时间都是 senta(lohn) ，他们对于输入大小来说都是 线性 的。 多项式求值（Horner规则）场景介绍假设有n+2个数a0,a_1,……,a_n和x序列，要对多项式 *P_n(x)=a_nx^n+a(n-1)x^(n-1)+…+a_1x**求值，传统的办法是分别对每一个子项求值，然后再对整个式子求值，但是这种方法很低效，因为它需要n+（n-1）+（n-2）+…..+1=n(n+1)/2次乘法。 归纳法解决思路首先我们发现原式可进行如下化简：化简之后我们可以发现如果我们假设已知P(n-1)(x)，那么P_n(x)=x*P(n-1)(x)+a_0,所以就有了算法HORNER。 HORNER算法代码实现​12345678int Horner(int *A,int n,int x)&#123;//数组A的长度为n+2，从A[0]到A[n+1]代表了a_0到a_(n+1) int p=A[n+1];//p=a_(n+1) for (int i = 1; i &lt;=n ; ++i) &#123; p=p*x+A[n+1-i];//p=p*x+a_(n-i) &#125;&#125; 寻找多数元素场景描述令A[1…n]是一个整数序列，如果该序列中的某一个数x在该序列中出现的次数多余int(n/2)，则称x为该序列的 多数元素 。 解决方法 蛮力法 将每个元素与其他因素进行比较，并且对每一个元素计数，如果某个元素的计数大于int(n/2)，就可以断言它是多数元素。但是这种方法的比较次数是n(n-1)/2=senta(n^2)，代价过于昂贵。 利用排序 先将原序列进行排序，在最坏情况下，排序这一步需要oumiga(nlogn)次比较。 寻找中间元素 因为多数元素排序后一定是中间元素，可以找到该序列的中间元素后扫描整个序列该中间元素的出现次数来验证该元素是否为多数元素，由于中间元素可以再senta(n)时间内找到，这个方法要花费ｓｅｎｔａ(n)时间。 MAJORITY算法 首先我们需要知道，去掉一个序列中的两个不同的数后该序列原来的多数元素现在依然是新序列的多数元素，所以我们……我们能怎么样呢，这不好描述啊，还是看代码吧…… 代码实现​123456789101112131415161718192021222324252627282930313233int majority(int *A, int n) &#123; int c = candidate(A, 1, n); int count = 0; for (int i = 1; i &lt;= n; ++i) &#123; if (A[i] == c) &#123; count++; &#125; &#125; if (count &gt; (int) n / 2) &#123; return c; &#125; else &#123; return NULL; &#125;&#125;int candidate(int *A, int m, int n) &#123; int j = m; int c = A[m]; int count = 1; while (j &lt; n &amp;&amp; count &gt; 0) &#123; j++; if (A[j] == c) &#123; count++; &#125; else &#123; count--; &#125; &#125; if (j == n) &#123; return c; &#125; else &#123; return candidate(A, j + 1, n); &#125;&#125;]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>归纳法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法复杂度分析中的符号（Θ、Ο、ο、Ω、ω）简介]]></title>
    <url>%2F2018%2F04%2F29%2F%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%AD%E7%9A%84%E7%AC%A6%E5%8F%B7%EF%BC%88%CE%98%E3%80%81%CE%9F%E3%80%81%CE%BF%E3%80%81%CE%A9%E3%80%81%CF%89%EF%BC%89%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Θ，读音：theta、西塔；既是上界也是下界(tight)，等于的意思。 Ο，读音：big-oh、欧米可荣（大写）；表示上界(tightness unknown)，小于等于的意思。 ο，读音：small-oh、欧米可荣（小写）；表示上界(not tight)，小于的意思。 Ω，读音：big omega、 欧米伽 （大写） ；表示下界 (tightness unknown)，大于等于的意思。 ω，读音：small omega、 欧米伽 （小写）；表示下界(not tight)，大于的意思。 Ο是渐进上界，Ω是渐进下界。Θ需同时满足大Ο和Ω，故称为确界（必须同时符合上界和下界）。Ο极其有用，因为它表示了最差性能。具体如图所示：]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>算法复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆和不相交集数据机构——堆]]></title>
    <url>%2F2018%2F04%2F29%2F%E5%A0%86%E5%92%8C%E4%B8%8D%E7%9B%B8%E4%BA%A4%E9%9B%86%E6%95%B0%E6%8D%AE%E6%9C%BA%E6%9E%84%E2%80%94%E2%80%94%E5%A0%86%2F</url>
    <content type="text"><![CDATA[堆在很多情况下我们需要使用一种具有 插入元素 和 查找最大值元素 的数据结构，这种数据结构叫做 优先队列，如果采用普通队列，那么寻找最大元素需要搜索整个队列，开销比较大；如果使用排序数组，插入运算就需要移动很多的元素，开销也会比较大。这时候 堆就是一种 有效的实现优先队列的数据结构 。 堆的特点： 父节点大于等于子节点（但是两个子节点之间的大小关系没有要求），这样可以做到 沿着每条从根节点到叶子节点的路径，元素的键值都是以非升序排列的 。 堆是一个 几乎完全的二叉树 ，所以具有和完全二叉树一样的特点，即一般是存储在一个数组A[n]中，A[i]的左子节点在A[2i]中，右子节点在A[2i+1]中（当他们存在的时候）,A[i]的父亲节点在A[i/2]中（如果存在，i/2向下取整）。 堆需要支持的几种运算： * delete-max[H] 从一个非空的堆H中删除最大元素并将数据项返回 * insert[H,x] 将x插入到对H中 * delete[H,i] 从堆中删除第i项（注意不是删除i） * makeheap[A] 将A转换成一个堆 堆上的运算两个辅助运算SIFT-DOWN功能当某个节点（H[i]）的值大于他的父亲节点的值时，需要通过SITF-UP将这个节点 沿着从H[i]到H[1]这条唯一的路径上移到合适的位置以形成一个合格的堆。 实现思路将H[i]与其父亲节点H[i/2]比较，如果H[i]大于H[i/2]，则将H[i]与H[i/2]互换，直到H[i]没有父节点或者H[i]不大于H[i/2]。 代码​123456789101112131415161718 int SiftUp(int *H, int i) &#123; while (true) &#123; if (i == 1) &#123; break;//说明当前i是根节点 &#125; if (H[i] &gt; H[(int) i / 2]) &#123;//如果当前节点比父亲节点大 int t; t = H[i]; H[i] = H[(int) i / 2]; H[(int) i / 2] = t; i = i / 2; &#125; else &#123; break; &#125; &#125; return 0;&#125; SIFT-DOWN功能当某个节点（H[i]，i&lt;=(int)n/2即 非叶子节点）的值小于它的两个子节点H[2i]和H[2i+1]（如果存在的话）的最大值时，需要将SIFT-DOWN将渗到合适的位置。 实现思路将H[i]与其两个子节点中值最大的元素比较，如果小于最大的那个节点，则将H[i]与其最大的那个子节点互换。 代码：​123456789101112131415161718192021 int SiftDown(int *H, int i, int n) &#123; while (true) &#123; i = 2 * i; if (i &gt; n) &#123; break; &#125; if (i + 1 &lt;= n) &#123; if (H[i + 1] &gt; H[i]) &#123;//比较两个子节点哪个最大 i++; &#125; &#125; if (H[i] &gt; H[(int) i / 2]) &#123; int t; t = H[i]; H[i] = H[(int) i / 2]; H[(int) i / 2] = t; &#125; &#125;&#125; 插入（insert）功能将元素x插入到已有的堆H中 实现思路首先将堆的大小增加1（n++），然后将x放在H[n]中，然后根据需要将H[n]中的元素x进行上移操作，直到最后形成一个合格的堆。 算法时间复杂度分析一个大小为n的二叉堆其高度应该为（int）logn，所以将一个元素插入大小为n的堆中所需的时间复杂度为 O（logn） 代码​123456 void insert(int *H,int x,int &amp;n)&#123; n++; //这里默认H开的空间够用 H[n]=x; SiftUp(H, n);//将x根据需要上移&#125; 删除（delete）功能将堆H中的元素x删除 实现思路用堆中的最后一个元素H[n]替换需要删除的元素H[i]，然后堆的大小减一（n–），然后根据需要对H[i]进行上移或者下渗直到最后形成一个合格的堆。 算法时间复杂度分析一个大小为n的二叉堆其高度应该为（int）logn，所以从一个大小为n的堆中将一个元素删除所需的时间复杂度为 O（logn） 代码​12345678910111213141516 void Delete(int *H, int i, int &amp;n) &#123; if (i == n) &#123;//如果需要删除的是最后一个元素 n--; return; &#125; H[i] = H[n]; n--; if (H[i] &gt; H[(int) i / 2]) &#123;//如果当前节点比父亲节点大则需要上移 SiftUp(H, i); &#125; else &#123;//否则进行下渗 SiftDown(H, i, n); &#125;&#125; 删除最大值（deletemax）功能将堆H中的最大元素x删除并返回最大值。 实现思路用堆中的最后一个元素H[n]替换需要删除的元素H[1]，然后堆的大小减一（n–），然后根据需要对H[1]进行上移或者下渗直到最后形成一个合格的堆。 算法时间复杂度分析一个大小为n的二叉堆其高度应该为（int）logn，所以从一个大小为n的堆中将一个元素删除所需的时间复杂度为 O（logn） 代码​12345 int DeleteMax(int *H,int &amp;n)&#123; int x=H[1]; Delete(H, 1, n); return x;&#125; 创建堆（makeheap）功能给出一个有n个元素的数组H[1….n]，创建一个包含这些元素的堆。 实现思路类似于分治，首先，H的叶子节点（即最下面的一层单个元素）可以认为是若干个小堆，然后我们从倒数第二层开始，将倒数第二层和倒数第一层的元素进行适当调整，使得调整之后整个二叉完全数的最后两层是若干个子堆，按照这个思路，依次向上走，最终走到第1层的时候就可以保证整个完全二叉树是一个符合要求的堆。 需要注意的是对于一个完全二叉树， 倒数第二层的最后一个元素的下标为int(n/2) ，（因为倒数第二层的最后一个节点的下标x应该满足x*2=n）. 算法时间复杂度分析senta(n) 代码​12345 void makeheap(int *H,int n)&#123; for (int i = n/2; i &gt;=1 ; --i) &#123;//从倒数第二层到第一层 SiftDown(H,i,n); &#125;&#125; 堆排序（heapsort）功能利用堆对数组H[n]进行排序。 实现思路首先将数组H[n]调整成为一个（大顶）堆，这时可以保证H[1]是数组中的最大元素，然后将H[1]与H[n]互换位置，然后再调整1——n-1为一个大顶堆，然后将H[1]与H[n-1]互换，以此类推，最后就可以保证H为一个非升序的数组。 算法复杂度分析空间复杂度：因为本算法是在数组H原有的空间基础上进行排序的，所以空间复杂度是Senta（1）。时间复杂度：+ 建堆 senta(n)+ 执行n-1次siftdown nlog(n)所以总的时间复杂度是nlog（n） 代码​12345678910void HeapSort(int *H,int n)&#123; makeheap(H,n); int t; for (int i = n; i &gt;=2 ; --i) &#123; t=H[i]; H[i]=H[1]; H[1]=t; SiftDown(H,1,i-1); &#125;&#125;]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>堆</tag>
        <tag>堆排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬取了3W+用户评价后发现用户眼中的坚果3是这样的]]></title>
    <url>%2F2018%2F04%2F27%2F%E7%88%AC%E5%8F%96%E4%BA%863W%2B%E7%94%A8%E6%88%B7%E8%AF%84%E4%BB%B7%E5%90%8E%E5%8F%91%E7%8E%B0%E7%94%A8%E6%88%B7%E7%9C%BC%E4%B8%AD%E7%9A%84%E5%9D%9A%E6%9E%9C3%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%2F</url>
    <content type="text"><![CDATA[实现过程介绍从网页爬取数据思路首先我们打开京东商城坚果3 的购买页面：然后按F12进入开发者控制台（审查元素）：发现什么都没有，不要紧，点开评论区，你就会发现控制台出现类似这些信息：控制台从刚才的没有信息到现在获取到当前信息，唯一的变化就是你打开了评论，所以网页返回的评论区内容一定在当前控制台的某个位置，从Name字段一个一个分析，就可以发现很明显的一行：很明显这里就是我们需要的评论区数据，然后仔细分析其对应的Headers，就会发现我们获取数据需要的基本信息：然后点开preview，就会发现返回数据转化为json格式后的内容：进一步打开Response，看到网页返回的原始数据： 可以看到，网页返回的原始数据是用一个fetchJSON_comment98vv1587包裹着的json字符串，到这里，我们的思路就很清晰了：首先用URL和对应的Query StringParameters模仿网页发送请求，收到的Response将会是一份由fetchJSON_comment98vv1587（）包裹着的包含json数据的String，我们用正则表达式将json数据提取出来，然后对json数据进行解析并获取想要字段的数据即可。 代码实现首先根据网页控制台的信息定义相关必要的变量： ​ url=’https://club.jd.com/comment/productPageComments.action‘ QueryStringParameters={ &#39;callback&#39;:&#39;fetchJSON_comment98vv1587&#39;, &#39;productId&#39;:&#39;7029545&#39;, &#39;score&#39;:0, &#39;sortType&#39;:5, &#39;page&#39;:0, &#39;pageSize&#39;:10, &#39;isShadowSku&#39;:0, &#39;fold&#39;:1 } 需要注意的是这里的url并不是直接将控制台显示的url全部拿过来，而是只要其前一部分，因为如果用控制台上的url，则只能获取到当前页面的评论，我们想要获取全部的评论，所以必须动态变化url，这里我们将url分为两部分写，这样方便后面调整page以获取不同页面的评论。然后实现爬取数据的逻辑代码： ​ hotcomments = [] while(True): t=s.get(url,params=data).text #模拟网页发送请求并接收返回数据 try: t=re.search(r&#39;(?&lt;=fetchJSON_comment98vv1587\().*(?=\);)&#39;,t).group(0)#使用正则表达式匹配‘fetchJSON_comment98vv1587’ except Exception as e: break j=json.loads(t) #解析json commentSummary=j[&#39;comments&#39;] flag=0 for comment in commentSummary: flag=1 num=num+1 item = { &#39;content&#39;: comment[&#39;content&#39;] , &#39;nickname&#39;: comment[&#39;nickname&#39;], &#39;score&#39;: comment[&#39;score&#39;], &#39;creationTime&#39;:comment[&#39;creationTime&#39;], &#39;productColor&#39;:comment[&#39;productColor&#39;] } hotcomments.append(item) if flag==0: break data[&#39;page&#39;]+=1 #改变page字段，下一次循环爬取下一页评论 当以上当以上代码执行完成之后就可以将所有评论信息放在 hotcomments中，然后就可以从中拿取数据进行分析了。 使用Bar进行各项指标柱状图可视化三种不同颜色评论数量所占百分比​123456789101112131415161718a= productColor.count(u'碳黑色')b=productColor.count(u'酒红色')c=productColor.count(u'浅金色')d=float(a+b+c)a=float(a/d)b=float(b/d)c=float(c/d)ds = tablib.Dataset()ds.headers = ['颜色', '评论数']ds.append(['碳黑色',a])ds.append(['酒红色', b])ds.append(['浅金色', c])bar = Bar('颜色')bar.add('评论数量(%)', ds.get_col(0), ds.get_col(1))bar.render('color_bar.html') 从9号到26号单天评价数量所占百分比​123456789101112ds2 = tablib.Dataset()ds2.headers = ['评价时间', '评论数']f=0.0for i in range(9,27): f=f+creationTime.count(i)for i in range(9,27): ds2.append([str(i), creationTime.count(i)/f])bar2 = Bar('评价时间（购买时间）')bar2.add('评论数量(%)', ds2.get_col(0), ds2.get_col(1))bar2.render('time_bar.html') 不同评分所占百分比​12345678910111213ds3 = tablib.Dataset()ds3.headers = ['评分', '评论数']e=0.0for i in range(0,6): j=5-i e+=score.count(j)for i in range(0,6): j=5-i ds3.append([str(j), score.count(j)/e])bar3 = Bar('评分')bar3.add('评论数量(%)', ds3.get_col(0), ds3.get_col(1))bar3.render('score_bar.html') ​ 使用WordCloud进行评论词云可视化​1234567content_text = " ".join(content_list)bg_pic = imread('../WoMen_EasonChen/eason2.png')wordcloud = WordCloud(mask=bg_pic,font_path='../Font/SourceHanSansSC-Heavy.otf',background_color='white',max_words=200).generate(content_text)plt.figure()plt.imshow(wordcloud,interpolation='bilinear')plt.axis('off')plt.show() 可视化结果从图中可以看出，大部分用户比较喜欢碳黑色（74.38%），购买浅金色的用户最少，约占5%可以看到95%的用户都给出了5分好评 最后看一下词云显示的内容在给一张： 后记坚果3刚发布的时候在网上可以看到很多人在黑他，罗老师也毫不客气地表示“拉黑”这些锤黑，本人不是锤粉也不是锤黑，只是觉得中国像罗老师这样天生骄傲的企业家不多了，就像罗振宇老师说的希望罗永浩成功那样，我也希望罗老师成功，因为中国需要这么一个天生骄傲的企业家，希望罗老师会是下一个乔布斯甚至超越乔布斯，期待锤子科技515可以创造传奇。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My first web crawler project]]></title>
    <url>%2F2018%2F04%2F27%2FMy-first-web-crawler-project%2F</url>
    <content type="text"><![CDATA[我的第一个爬虫项目，爬取了京东上的锤子手机的评论数据并做可视化分析：]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用python绘制混淆矩阵（confusion_matrix）]]></title>
    <url>%2F2018%2F04%2F22%2F%E4%BD%BF%E7%94%A8python%E7%BB%98%E5%88%B6%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%EF%BC%88confusion_matrix%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Summary涉及到分类问题，我们经常需要通过可视化混淆矩阵来分析实验结果进而得出调参思路，本文介绍如何利用python绘制混淆矩阵（confusion_matrix），本文只提供代码，给出必要注释。 Code​123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# -*-coding:utf-8-*-from sklearn.metrics import confusion_matriximport matplotlib.pyplot as pltimport numpy as np#labels表示你不同类别的代号，比如这里的demo中有13个类别labels = ['A', 'B', 'C', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O']#y_true代表真实的label值 y_pred代表预测得到的lavel值y_true = np.loadtxt('../Data/re_label.txt')y_pred = np.loadtxt('../Data/pr_label.txt')tick_marks = np.array(range(len(labels))) + 0.5def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.binary): plt.imshow(cm, interpolation='nearest', cmap=cmap) plt.title(title) plt.colorbar() xlocations = np.array(range(len(labels))) plt.xticks(xlocations, labels, rotation=90) plt.yticks(xlocations, labels) plt.ylabel('True label') plt.xlabel('Predicted label') cm = confusion_matrix(y_true, y_pred) np.set_printoptions(precision=2) cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] print cm_normalized plt.figure(figsize=(12, 8), dpi=120) ind_array = np.arange(len(labels)) x, y = np.meshgrid(ind_array, ind_array) for x_val, y_val in zip(x.flatten(), y.flatten()): c = cm_normalized[y_val][x_val] if c &gt; 0.01: plt.text(x_val, y_val, "%0.2f" % (c,), color='red', fontsize=7, va='center', ha='center') # offset the tick plt.gca().set_xticks(tick_marks, minor=True) plt.gca().set_yticks(tick_marks, minor=True) plt.gca().xaxis.set_ticks_position('none') plt.gca().yaxis.set_ticks_position('none') plt.grid(True, which='minor', linestyle='-') plt.gcf().subplots_adjust(bottom=0.15) plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix') # show confusion matrix plt.savefig('../Data/confusion_matrix.png', format='png') plt.show() Result Instructions按照代码中的注释将labels、y_true 、y_pred替换为你自己的数据即可。 Reference 如何用python画好confusion matrix]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[白话设计模式]]></title>
    <url>%2F2018%2F04%2F17%2F%E7%99%BD%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[创建型设计模式对象怎么来 提供一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 工厂方法重点在于Factory类，当一个类的实例化依赖于不同场景时需要使用的，比如根据形状不同实例化不同形状类并返回的demo，根据不同的形状，实例化的Shape对象内部的实现逻辑不一样，这时候就可以使用工厂方法模式，将类内部的实现细节隐藏起来，用户只需要告诉工厂类自己需要什么情况下的产品，工厂就可以自动调用自己内部对应场景的代码从而返回一个用户需要的“产品”。 抽象工厂抽象工厂可以理解为工厂的工厂，比如demo中，首先有两个工厂Factory，分别用来实例化不同场景下的shape和color，然后再有过一个工厂的工厂即FactoryProducer，其根据用户的需求（shape或者color）返回shape工厂或者color工厂，然后用户再用返回的工厂去实例化自己需要的shape或者color。对比工厂方法模式，因为一个工厂只能生产一个产品，比如一个ShapeFactory只能根据不同情况实例化一个不同的Shape，那么当我们需要一整套的产品（比如形状和颜色形成了一套产品）时使用工厂方法显然就不能解决了，所以就需要抽象工厂模式，抽象工厂模式实际上是工厂的工厂，即其作用的目的是为了实例化不同的工厂，用户再通过不同的工厂实例化不同场景下成套的产品。 单例模式通俗来讲就是替用户实现对象的实例化，用户需要使用类的时候不需要实例化，直接通过getInstance就可以拿到需要使用的对象，进而调用对象的方法即可，这个设计模式平时用到的比较多，也比较容易理解。 生成器（建造者）模式生成器模式的目的是使用多个简单的对象一步一步构建成一个复杂的对象，比如在一个快餐店的商业案例中，一个典型的套餐可以是一个汉堡（Burger）和一杯冷饮（Colddrink）。汉堡（Burger）可以是素食汉堡（Veg Burger）或鸡肉汉堡（Chicken Burger），它们是包在纸盒中。冷饮（Colddrink）可以是可口可乐（coke）或百事可乐（pepsi），它们是装在瓶子中。那么，生成器（MealBuilder）的作用就是实现不同类型汉堡（Burger）与不同类型冷饮（Colddrink）的搭配，即通过MealBuilder这个生成器可以通过组合不同汉堡和冷饮这样简单的类从而狗仔出一个复杂的套餐（Meal）类，这就体现了生成器模式“使用多个简单的对象一步一步构建成一个复杂的对象”的要点，需要注意的是建造者模式与工厂方法模式有类似的地方，但是建造者模式更加关注零件装配的顺序而且生成的对象内部属性本身具有相互依赖性，比如Demo中的食物和对应的容器具有很强的相互依赖性。 原型模式原型模式实现的功能就是对象的拷贝，只不过这种拷贝的功能是在类中定义好的，即在定义类的时候就定义好了一个clone的接口，当这个类对应的对象在某一时刻需要拷贝出另一个对象时，只需调用这个对象的clone方法即可返回一个本对象的克隆体，那么为什么不直接实例化一个新的对象而要采用这种克隆的机制呢？想象一下如果一个类的某些属性的值需要从数据库中查询，这样每实例化一个新类就需要做查询的耗时操作，这时候如果直接用一个已有的对象去clone出一个新的对象就可以避免诸如数据库查询之类的耗时操作，提高了软件的执行效率。 结构型设计模式对象和谁有关 关注类和对象的组合，继承的概念被用来组合接口和定义组合对象获得新功能的方式。 组合模式组合模式的要点在于组合和结构，通俗来讲就是通过不同的组合来形成一个体系结构，实现要点是list的使用，以上述demo为例，CEO的下属包含headSales和headMarketing，即CEO这个对象的下属list里面只要添加headSales和headMarketing即可，所以如果把CEO理解为一个东西的话它是由headSales和headMarketing组合而成的（如果没有这两者真不知道CEO存在的意义是什么，一自己当自己的CEO？），而headSales又有若干个salesExecutive下属，所以headSales对象的下属list里面应该添加若干个salesExecutive对象，以此类推（headMarketing由若干个clerk组成）。至此，通过不断的组合，我们就可以由salesExecutive和clerk一路不断组合直到CEO，这就是“组合”的含义，同时也体现了很强的层级关系。 装饰者模式装饰者模式（DecoratorPattern）的目的是向一个现有的对象添加新的功能，同时又不改变其结构，这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供额外的功能。 装饰者模式的主要思路是通过一个新类（Decorator ）将原来的类包装起来，在Decorator 中给原来的类添加新的功能。 装饰者模式顾名思义就是起到一个装饰的作用，即在不改变原来类结构的前提下增加一些新的功能，这种模式一般会产生一个专门的装饰类，联想结构型设计模式的定义（描述不同类之间的关系），装饰者模式实际上描述的就是一个装饰与被装饰的关系，结合上面的demo，被装饰类是实现了shape接口的Rectangle类和Circle类，而装饰类ShapeDecorator是一个抽象装饰类，在其内部定义了装饰shape的方法draw，事实上是一种方法重写（准确来说是增加方法功能），然后在ShapeDecorator的子类RedShapeDecorator中的draw调用了起装饰作用的setRedBorder方法最终达到装饰实现shape子类的目的，从最终的输出也可以看出，装饰类的作用实际上就是在原有类的基础上新增加新的东西，还有一个比较接近现实的例子是玩游戏时开局一个英雄，玩着玩着英雄的装备越来越多、英雄的技能越来越多、英雄的皮肤越来越多，这些效果实际上都是在原来开局裸体（额实在不知道用什么形容词，懂我意思就好～）英雄的基础上装饰进去的，很好地体现了装饰的精髓。 代理模式现实生活中代理的例子其实很多，比如大家搭建服务器从而实现访问某些xx的网址的访问，其原理其实就是在云端搭建一台云主机，这台主机的地址一般是在可以访问你当前计算机不能访问的xx网址的地域（比如东亚的计算机可以访问很多nj访问不到的xx网址），所以当你想要从xx网址获取信息的时候就可以先把请求发给你搭建的云主机，让它去访问xx，然后再把信息返回给你，这样就像你直接访问了xx一样，这就是代理的意思。回到设计模式，代理模式实际上讲的就是一种“代理访问”的概念，当A类不能暴露给B类而B类又想调用A类的方法的时候必须通过一种折中的方法，即B类通过向可以调用A类的C类发送请求从而让C类调用A类干同样的事情，就是这个意思……具先实现其实也很简单，就是一个代理类将被代理类包裹起来，只对外界暴露调用被代理类方法的方法，从而实现代理模式，需要特别注意的是代理模式和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口 ，和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制 。 享元模式顾名思义，享元模式体现的就是一种“分享”的实质，即当很多地方都需要用到一个类的对象而实例化这个类又需要耗费很多资源的时候我们就可以把这个类的对象抽取出来，仅仅实例化一次，当以后需要实例化这个类的对象的时候直接把之前实例化的对象返回即可，比如demo中需要实例化不同颜色不同形状的shape对象，而这些对象的存在状态就那么几种，所以使用一个Factory类，当第一次接收到实例化shape类的请求时进行一次实例化并将实例化得到的结果存下来，以后再接收到实例化的请求时直接把之前实例化的同类型的对象返回即可，这样可以大大提高程序执行的效率。 桥接模式当一个抽象类有多个实现时，通常用集成来协调他们。抽象类定义对该抽象的接口，而具体子类则用不同方式加以实现。但是此方法的缺点是将子类的抽象部分和实现部分固定在了一起，使得难以对抽象部分和实现部分进行修改、扩充和重用。实现抽象化和实现化之间的解耦，具体到上述demo，抽象化指的是 draw redCircle和drawgreenCircle，如果不使用桥接模式，一般的实现方法是根据用户指令的不同（以参数的形式体现），实现不同的draw方法，而使用桥接模式，Circle类不用关心具体如何根据用户传入参数的不同实现不同的draw方法（即实现化部分），Circle类只需要根据用户传入接口的不同调用draw方法即可，具体的实现全都交给了DrawAPI（GreenCircle、ReadCircle）来做，即将draw这个功能的抽象化放在Circle类，实现化放在DrawAPI（GreenCircle、ReadCircle），从而实现了抽象化和实例化的分离。 适配器模式（这个模式描述的不是很好，感觉还是demo更容易理解一点）作为两个不兼容的接口之间的桥梁，它结合了两个独立接口的功能。这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。注意，要点是要在原来类的基础上使原本不兼容的功能变得兼容。Adapter类一般是用来实现与原有类不兼容的功能，比如demo中的MediaAdapter实现了MediaPlayer没有的特殊功能，用户只要调用AudioPlayer中的play方法，AudioPlayer会自动根据音频的类型选择不同的play方式，当音频类型不符合传统player的能力时AudioPlayer会使用adapter去调用之前不兼容的方法（功能），这样就实现了所谓的适配。 类适配器和对象适配器的区别：类适配器的重点在于类，是通过构造一个继承Adaptee类来实现适配器的功能；对象适配器的重点在于对象，是通过在直接包含Adaptee类来实现的，当需要调用特殊功能的时候直接使用Adapter中包含的那个Adaptee对象来调用特殊功能的方法即可。 行为型设计模式对象与对象在干嘛这些设计模式特别关注对象之间的通信 模板模式模板方法模式顾名思义就是定义了一个特殊的方法，这个方法的大体框架是写死的，比如demo中抽象类Game的play方法，它规定了所有实现类的play方法有且仅能有模板方法中定义中的行为，但是这些行为具体如何实现则不是模板方法所关心的，说白了就是模板方法规定了如果调用这个方法会干嘛，但是怎么去干就不是它所关心的重点了。 观察者模式观察者模式用一句话描述就是当一个类的对象（被观察者）的状态发生改变时同时其他依赖于它的对象（观察者）的状态也做相应的改变（做相应的动作）。 迭代器模式迭代器模式本质上就是一种遍历聚合对象的方式，这里的聚合对象一般具有较多的实例，比如java中的list等，也就是说对于有些对象，我们更加偏向于它的属性而不是行为，而迭代器模式提供了一种较为隐蔽的遍历这些对象属性的方法，通过经典的hasnext方法和next方法的配合使用，从而实现顺序访问聚合对象中各个元素,而又无须暴露该对象的内部表示。 责任链模式责任链模式的本质就是一条链，通过demo可以发现其实现方式和数据结构中的链表有很相似的地方，思想就是形成一条链，如果当前节点处理不了某些行为，则把这个行为请求转移到其下一级，以此类推，比较常见的实例就是java或者python中经常用到的trycatch机制，当某个方法有可能抛出异常而当前方法无法处理的时候我们就会可能将这个异常throw到外层，即责任链中的下一级。 备忘录模式备忘录模式的本质就是一种备份机制，其思路是将对象的状态在用户需要的时候备份下来，当需要状态回滚的时候直接将将对象的状态恢复到之前备份的状态，我们经常用的git版本控制管理系统其实就是一个特殊的备忘录模式，其在你需要的时候将你的仓库备份下来，这样你就可以在后期的开发中随时找到你之前备份的仓库状态，但是需要注意的是备忘录模式的重点是对象，其真正的目的是将单个对象的状态保存下来，至于其他的状态备份则不是它所侧重的。 命令模式命令模式实质上就是将命令抽象到一个具体的类中，即这个类是专门去执行某个命令的，比如demo中，SellStock就是专门执行sell这个命令的，当用户需要sell的时候只要实例化SellStock然后excute就可以完成sell，还有一个比较常用的例子是GUI开发中按钮（button）的作用，每一个按钮都是一个对象，当用户点击某个按钮后就会触发一个相应的命令，用户看到的是点击按钮产生效果，而代码层面上是实例化的按钮对象执行类似于demo中的excute方法完成自己的“命令”。 状态模式状态模式将各个状态所对应的操作分离开来,即对于不同的状态,由不同的子类实现具体操作,不同状态的切换由子类实现，比如上面的demo，同样是实现doAction根据不同的状态执行不同的逻辑，按照传统的方法需要使用ifelse进行判断，但是使用状态模式则可以将不同的状态实例化为不同的子类，然后在不同的子类（实际上是不同的状态）中实现不同的逻辑，客户端使用的时候只需要实例化不同的状态的子类就可以调用不同状态下的同名方法。 访问者模式访问者模式解决的是根据访问者的不同而执行不同的行为，即同样一个方法（方法名相同），但是当A调用这个方法时执行的是逻辑A，B调用这个方法时执行逻辑B，这种情况下就需要使用访问者模式来实现。具体到demo，我们想要实现不同的ComputerPart调用accept的时候执行不同的逻辑，只需要构造一个访问者类ComputerPartDisplayVisitor，它根据accept的调用者的不用执行不同的逻辑，而调用者只需要将this传入accept方法即可，accept方法会根据传入的参数类型的不同调用不同的逻辑（visit）。 策略模式当一个类的行为需要根据不同的状态改变时就需要使用策略模式，比如demo中Context类的executeStrategy方法执行的逻辑需要根据Context的Strategy成员的状态的变化而变化，传统地可以通过ifelse语句来实现对Strategy状态的判断进而实现不同的算法，但是如果采用策略模式，Context类就不必关心当前Strategy的状态，而将这种执行不同算法的控制权交给了客户端。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[适配器模式之类适配器与对象适配器的区别及代码实现]]></title>
    <url>%2F2018%2F04%2F16%2F%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%B1%BB%E9%80%82%E9%85%8D%E5%99%A8%E4%B8%8E%E5%AF%B9%E8%B1%A1%E9%80%82%E9%85%8D%E5%99%A8%E7%9A%84%E5%8C%BA%E5%88%AB%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[什么是适配器模式？适配器模式（Adapter）：直观理解就是使原来不能一起相互工作（接口不兼容）的两个功能通过Adapter兼容在一起。 类适配器和对象适配器类适配器Adapter 类继承Adaptee （被适配类），同时实现Target 接口（因为 Java 不支持多继承，所以只能通过接口的方法来实现多继承），在Client 类中我们可以根据需要选择并创建任一种符合需求的子类，来实现具体功能。 对象适配器不使用多继承或继承的方式，而是使用直接关联，或者称为委托的方式。 区别类适配器的重点在于类，是通过构造一个继承Adaptee类来实现适配器的功能；对象适配器的重点在于对象，是通过在直接包含Adaptee类来实现的，当需要调用特殊功能的时候直接使用Adapter中包含的那个Adaptee对象来调用特殊功能的方法即可。 Demo类适配器​1234567891011121314151617181920212223242526272829303132333435363738// 已存在的、具有特殊功能、但不符合我们既有的标准接口的类class Adaptee &#123; public void specificRequest() &#123; System.out.println("被适配类 具有特殊功能..."); &#125;&#125;// 目标接口，或称为标准接口interface Target &#123; public void request();&#125;// 具体目标类，只提供普通功能class ConcreteTarget implements Target &#123; public void request() &#123; System.out.println("普通类 具有普通功能..."); &#125;&#125;// 适配器类，继承了被适配类，同时实现标准接口class Adapter extends Adaptee implements Target&#123; public void request() &#123; super.specificRequest(); &#125;&#125;// 测试类public class Client &#123; public static void main(String[] args) &#123; // 使用普通功能类 Target concreteTarget = new ConcreteTarget();//实例化一个普通类 concreteTarget.request(); // 使用特殊功能类，即适配类 Target adapter = new Adapter(); adapter.request(); &#125;&#125; 测试结果：普通类 具有普通功能…被适配类 具有特殊功能… 对象适配器​1234567891011121314151617181920212223242526272829// 适配器类，直接关联被适配类，同时实现标准接口class Adapter implements Target&#123; // 直接关联被适配类 private Adaptee adaptee; // 可以通过构造函数传入具体需要适配的被适配类对象 public Adapter (Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; public void request() &#123; // 这里是使用委托的方式完成特殊功能 this.adaptee.specificRequest(); &#125;&#125;// 测试类public class Client &#123; public static void main(String[] args) &#123; // 使用普通功能类 Target concreteTarget = new ConcreteTarget(); concreteTarget.request(); // 使用特殊功能类，即适配类， // 需要先创建一个被适配类的对象作为参数 Target adapter = new Adapter(new Adaptee()); adapter.request(); &#125;&#125; 测试结果：普通类 具有普通功能…被适配类 具有特殊功能…]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[那些活在浪里的创业者最终被拍成了电影]]></title>
    <url>%2F2018%2F04%2F13%2F%E9%82%A3%E4%BA%9B%E6%B4%BB%E5%9C%A8%E6%B5%AA%E9%87%8C%E7%9A%84%E5%88%9B%E4%B8%9A%E8%80%85%E6%9C%80%E7%BB%88%E8%A2%AB%E6%8B%8D%E6%88%90%E4%BA%86%E7%94%B5%E5%BD%B1%2F</url>
    <content type="text"><![CDATA[“我又融了一个亿。” 在创业圈，这句话是奖章，也是把创业者逼至悬崖的剑。 中国互联网创业刚经历了最初的十年，创业者活在浪里。 这些浪里的人，包括罗永浩、戴威、张颖、Papi、傅盛、安传东，也包括了金星、马薇薇、唐岩、许单单、孙海涛、孟雷和潘飞。 2008年，摇滚乐队R.E.M.把西南偏南带到了中国。 那年，《断背山》男主角希斯·莱杰去世，R.E.M.乐队在西南偏南演出时将新歌献给了他。中国媒体刊发了这篇报道，人们第一次认识到了这个大洋彼岸的音乐节。 其实，在那年的西南偏南上，最火爆的是扎克伯格的采访。因为话题过于陈旧，一位与会者直接大声打断，引来一片欢呼。人们将这件事发到了Twitter上，西南偏南的知名度也因此大幅提升。 就在西南偏南举办的同时，苹果相继发布了iPhone软件开发包和预装AppStore的3G版iPhone。智慧的迅速变现让不少人蜂拥而至，掀起了一股开发热潮，移动互联网浪潮的序幕正式拉开。 1对大多数中国人来说，2008年最不可磨灭的记忆是北京奥运会，很多人为此开始苦练英语。 那年，36岁的罗永浩开始了人生的第一次创业，成立“老罗英语”。 消息公布后，他遭到了很多粉丝的谩骂，“你不是一个理想主义者吗？你怎么做生意去了？”罗永浩觉得这种指责十分滑稽，后来干脆把自己的演讲主题改成了《一个理想主义者的创业故事》。 在与这场演讲一同发售的自传《我的奋斗》里，罗永浩写道，“每一个生命来到世间，都注定要改变这个世界，你别无选择”。那年，罗永浩的另一个身份是网易的评委，四处开炮。这个活动的发起人是唐岩。当时，唐岩还是网易奥运频道的主编。 后来，罗永浩想做手机，但始终筹不到钱，中途萌生过先做个网站赚钱的念头。唐岩问他，你到底想做什么？老罗老实说：手机。唐岩一口应下，“我帮你找钱”。 2013年，智能机的出货量首次超越功能机。两个传统巨头诺基亚和摩托罗拉先后被收购，功能机的时代画上了句号，智能机全面进入了人们的生活。 这其中流露出的机会，被一个叫张颖的人抓住了。2008年，他创立了经纬中国，投资团队只有8个人，也没有定下豪赌移动互联网的战略，并不被人看好。 那年，一个刚满30岁的产品经理跟所在的公司决裂离职，举目无亲。这个年轻人就是傅盛。 张颖看到这个消息，要来电话打了过去，俩人下午就碰了头。张颖建议傅盛去虎跳峡散散心，并邀请他到经纬做EIR（入驻企业家）作为创业前的过渡。这段经历，也为经纬之后大举从互联网公司招募年轻人埋下了伏笔。张颖 那年秋天，美国第四大投行雷曼兄弟宣告破产。这只曾被纽约大学金融教授罗伊·史密斯形容为“有19条命的猫”，耗尽了自己的最后一条命。随后，美国次贷危机迅速演变成全球金融危机。 金星的第一次创业也在这时宣告失败。那是一个叫“美丽家族”的购物分享社区，模式与后来的蘑菇街很像。金融危机袭来后，已经谈妥的风投无法落实。他问家里借了一笔钱，强撑了一段时间，弹尽粮绝后不得不解散了公司。 他对仅剩的几名员工说，公司账上没钱了，就剩下这些电脑，大家分一分吧。吃完散伙饭后，金星一个人躲在办公室里哭了一下午。之后的很长一段时间，他都陷入在悲伤中不可自拔。 这些创始人只想躲起来乃至干脆去死的时刻其实是通往成功的必经之路。创业就像搏击，艰辛而孤独，你必须时刻准备着迎接击打，一次又一次。被击中后，可能痛苦不堪，但也只能等肾上腺素消失后，再去打下一个回合。 2008年，姜逸磊还在中戏导演系念大三，刚以“papi酱”为名注册了自己的豆瓣账号。 这一年，全球第一家共享经济公司Airbnb迎着金融危机诞生。为了推广，布莱恩·切斯基决定去西南偏南碰碰运气，但最终一共才定出去了两间房，其中一间还是他们自己定的。总之，这门生意当时完全没有任何火起来的迹象。 这时，后来成为中国共享经济引领者的戴威还在读高二，他的志向是考北大。 在移动互联网开端的这一年，未来还是面目模糊的样子，人人都在摸索着前行。 22011年，乔布斯的辞世引发了海啸般的悼念。 人们感叹苹果失去了一位有远见的天才，世界失去了一位出色的人类，一个传奇就此落幕。 很多人陷入到“成为下一个乔布斯”的期待中，江湖风起云涌。尽管罗永浩已经从英语培训里挣到了钱，但他感到自己真正热爱的事业终于来了，“手机行业唯一的聪明人死后，不是我选择了这个行业，是命运选中了我。” 他遭遇了很多人的嘲笑和质疑，甚至有600多人在网上诅咒他死全家。罗永浩一度觉得，自己好像没有那么爱这个世界了。但他坚持下来了，因为“不被嘲笑的愿望是不值得去实现的。” 罗永浩的手机梦想埋下种子时，他日后的投资人唐岩刚刚开始创业。上司方三文辞职创立雪球网后，唐岩意识到宴席终究要散场，他开始琢磨着自己出来单干。 唐岩判断，将来在移动端一定会有一个社交帝国，于是他做了陌陌。但这个想法投资人并不买账。有人问腾讯做陌陌这个事怎么办？唐岩心想，该怎么办就怎么办呗，不能因为这个可能性就不干了。 唐岩 移动互联网创业之风兴起时，张颖敏锐地注意到，人们黏在手机上的时间成倍增加，决定“豪赌移动互联网”，因为“一个能让手机变得像人体器官一样的行业，可以构成对任何传统行业的颠覆”。 他制定了人海战术，从互联网招了一批没有投资经验的产品经理来做投资。刚刚加入经纬的王华东，在微博上刷到了陌陌的内测版。陌陌正式上线4周后，就冲到了AppStore社交类免费榜第三，王华东立刻安排了和唐岩的再次见面。一拍即合的张颖和唐岩，当场签下了投资意向书。 这一年，傅盛创立的可牛影像与雷军的金山合并后，一直没有在市场上找到自己的位置——PC上有360，只能做到第二；手机上有360和腾讯，只能做老三——这是“注定的结果”。为此，傅盛特别痛苦，天天琢磨着怎么突破。 毕业后的papi酱也处于迷茫期，她说自己每天都站在人生的“米字路口”，凡是和专业沾边的工作都尝试了一圈。 她甚至去剧组试过几次戏，但总是被嫌弃，别人比她年轻、比她高、还比她好看……后来，她又尝试过导演，也写过剧本，但最后都不了了之。 最穷的时候，面条青菜就能应付一顿。她说，那时候做得最有追求的事情是定期买彩票。 失意之人又何止于她。 这一年，许单单开了国内首家众筹创业咖啡馆，邀请了一大批企业界、投资界的重要人士加盟，光股东就有100多位。但咖啡馆很难盈利，3W咖啡亏得一塌糊涂。 孟雷正处在人生的第一次创业中。他的创业方向是服务高端人群的国际头等舱、公务舱机票预订等服务。虽然公司年利润超两千万，但基于对旅游产业的洞察，孟雷意识到，传统方式在未来会遇到极大的瓶颈。 孙海涛在杭州进行自己第三次创业。那时，他隐约觉得这个项目模式走不通了，“作为CEO，我感觉是带着一帮人在巷子里跟人打架，但是打赢了你也出不去，因为你是在巷子里面。那时候很迷茫，想转型。” 地球的另一边，Airbnb这次在西南偏南迎来了曙光。暴增的音乐节参与人数让房东看到了商机，订不到酒店的人也找到了住处。这一次，Airbnb终于火了。 这一年，机敏的创业者们嗅到了移动互联网未来的方向，但他们并不被理解，依然在通往成功的路上孤独前行。当然，也不是每一个人都有好运降临。更多的人，仍然在焦虑和无助中试着拨开迷雾。就像丘吉尔所言：既然必须穿越地狱，那就走下去吧。 32014年，乌镇举办了首届世界互联网大会，中国成为了世界互联网的一极。 此时，中国智能手机正处于井喷期，每个季度销售量达到9000万台，是美国市场的三倍，80后90后平均每人每天在手机上花去3个小时。 草蛇灰线，伏脉千里。移动互联网的全面爆发，让那些眼光长远的人迎来了收获期。 陌陌就是其中的代表。上线三年的陌陌，在纳斯达克挂牌。两岁的儿子替唐岩敲响了开市钟，成为史上最小的敲钟人。唐岩也成为了《财富》杂志“全球40位40岁以下的商界精英”中的唯一中国上榜者。 但他说，“不是说钱不好，但钱有点平凡。” 傅盛也迎来了他的高光时刻。上市的猎豹，成为中国移动互联网公司出海的样本。 上市时，傅盛把五岁的女儿带去了美国的迪士尼。看着玩耍的女儿，他掉下了眼泪——梦想带领傅盛和猎豹走向了从未抵达的世界。 此时的经纬，累计投资了190家公司。张颖的办公室里有一块黑板，上面密密麻麻地记录着经纬系每家公司融资、并购行进的阶段。他常关上办公室的门，在黑板前审视河山。 “投资圈是个江湖，本该有门有派，可并不是谁都能被称为系。我的理解是没投资过100家，没有系统的布局，没有固执的行业关注，不能称之为系。”张颖说，“我们是哪一派我不好说，但你得承认，经纬有称‘系’的资格了。” 这一年，张颖日后投资的戴威刚刚开始创业。那时，戴威刚从青海支教回来，创业圈的风起云涌让戴威也有些心动。他在宿舍里完成了域名ofo的注册，这个创业项目很快获得了100万的天使投资。 没过多久，钱烧光了，工资发不出来的戴威开始失眠。他跑遍了市面上几十家基金，没有人看好这个项目。在整个资本市场最火热的时候，他一分钱也没融到。 烧完100万，戴威非常内疚也不甘心。他开始思考用户的痛点，最终决定转型做共享自行车。 2015年5月，ofo在微信公号上发布文章《这2000名北大人要干一票大的》，宣布将为北大校园提供超过一万辆自行车，同时呼吁北大师生贡献出自己的单车。文章末尾写道，“100多年来，有很多北大人改变北大，也改变了世界，这次轮到你了！” 戴威 戴威在北大四处推广共享单车时，曾与草根创业者安传东打过一次照面。一年之后，两人境遇大相径庭。 安传东出生于河南安阳的农村。他曾跟随做泥瓦匠的父亲到北京，顶着烈日在天坛搬砖。干完之后，老板企图赖账。大家手拉手上天台要跳楼，这才维权成功。 他第一次认识到现实的残酷，心里想着，我以后一定要留在北京，在这个城市出人头地。 2014年，安传东如愿留在了北京。但他觉得，在这个时代只有创业才能实现人生的翻盘。那时候，他没有经验也没有人脉，在一个孵化器睡了九个月的会议桌，才拉到了第一笔钱。 “每天都不挣钱，每天都往外支出，电费怎么那么贵啊？也是蛮让人心慌的。”安传东每天都生活在恐惧之中，靠写文案挣钱给同事发工资，最苦的时候自己连4毛钱公交车费都拿不出来。 最终，安传东没能成为厮杀的胜者。团队解散，只剩下了他一个人，但他还是不想放弃。“合伙人走了可以再找，高管走了可以再招，没钱了可以再融，但我要是放弃了，公司就真没了。”安传东 孟雷开始了他的共享经济创业。他卖掉了之前的公司，创立了一个专门连接境外华人司导和出境游用户的包车游品牌——皇包车旅行。后来，他还挖来了在旅行行业深耕十年的潘飞作为公司的CEO。 孟雷（左）潘飞（右） 许单单创办了拉勾网，他希望做一个薪资透明、每一封简历都有回馈的招聘网站。“尊严在当下社会是最值钱的。”许单单觉得，只要有效击中“尊严”这个社会痛点，网站做起来，是毫无悬念的。 这一年，珠海姑娘马薇薇和丈夫离了婚，父亲又查出了癌症。为了逃离阴霾，她坐上了北上的飞机，参加了《奇葩说》，并获得了冠军。马薇薇在节目中金句频出。比如，“这是一个什么都缺，唯独不缺梦想的年代。”她的这番话被视为金玉良言，在网上热传。 这一年，棱镜门主角斯诺登以远程的方式登陆西南偏南。他的发言掀起了公众对数据隐私、数据开放的思考，也促进了科技公司加强隐私保护的意识。 这一年，移动互联网全面爆发，人们看到了前所未有的创业速度——一家公司在三四年里实现了从有收入到有利润再到上市，创业者正以前所未有的速度完成造梦。这种速度，令围观者，甚至创业者本人惊叹，也吸引了越来越多的人加入创业大潮。 42016年，全球智能机销量近15亿部，庞大数字下是仅2%的增长率，市场迎来停滞。 这年的世界互联网大会上，王兴提出了互联网下半场的概念。“之前中国互联网的发展，在很大程度上靠的是人口红利，因为用户在快速增长，每年卖几亿部智能手机，大家的业务跟着水涨船高。但是现在，这个时代已经过去了，智能手机的年销量已经不增长了，总体网民的增长也大幅趋缓。” 与此同时，中国出现了25461支私募股权投资基金，可投资规模达4.29万亿元。数万亿资金像饿狼一样四处觅食，任何能带来用户流量和现金流的项目都遭到了疯狂的追捧。 这一年，这样的赛道有三个：共享单车、网络直播、内容创业。 2016年，ofo走出校园，日订单量从200迅速攀升至50万单。9月底，滴滴宣布战略投资ofo。戴威和共享单车从无人问津到炙手可热，似乎就是一夜之间。 有投资人说，“如果你人不在北京，基本上就投不进去了”。截至当年底，ofo完成了五轮融资，身后站着几乎所有重量级的投资机构。这样的情况，戴威从来没有遇过，他甚至失眠了两晚。 《胡润百富榜2017》显示，戴威成为首位上榜的90后。他创办的ofo获得了互联网史上最快最炫目的“融资加速度”。共享单车席卷全球，成为了“新四大发明”之一。 另一个赛道里，直播行业凶猛崛起，唐岩加入了直播大军之中。 上市后，陌陌股价始终被低估。那段时间，深夜不眠的唐岩经常看《我是歌手》，琢磨着做个有逼格的版本出来。高管全体反对，但他还是强制执行了。只不过，陌陌最终推出的是全民直播。唐岩抓住了大潮，局势一举扭转。2016年直播营收猛涨，陌陌开始迈向高点。 “你要非说理想败给了现实也可以。但理想和现实，肯定不是一个黑白分明的东西。”唐岩说，“人成熟的过程，本来就是一个不断妥协的过程”。 资本受益于时代浪潮，同时也在助推时代浪潮的前行。内容创业的风口里，papi酱和马薇薇是最大的获益者和代表者。 这一年，papi酱成了“第一网红”，拿到了1200万的投资，站上了网红界的金字塔塔尖。同时，她的首支贴片视频广告拍出了2200万的天价。由此，她达到了个人流量的最高点。 谈及自己的成功时，papi酱一脸庆幸地说，“感谢互联网的诞生，互联网是谁发明的啊！” papi酱 马薇薇也凭借奇葩说中积攒的粉丝和流量，创立了米果文化，踩上了风口。好友评价说，“马薇薇是一个最能够闻到钱的味道的人”。 孙海涛看到了投资的高回报，从创业者转向投资者，带领着51信用卡开始进行产业投资布局。 孙海涛 这一年，锤子亏损4亿元，一度徘徊在破产的边缘。罗永浩说，自从他做手机以来，他的头发掉了一半，胆结石大了一倍，体重增加了20%，但这些跟他获得的无穷无尽的快乐、满足、成就感和难以置信的温暖支持和鼓励相比，根本不值一提。 为了和科技走得更近一些，奥巴马成了首位参加西南偏南的美国总统。他翘掉了里根总统遗孀的葬礼，被不少政治界人士批评，回馈他的是巨星演唱会般的开场。至此，西南偏南真正走向了大众。 这一年，踏着时代的浪尖，很多人赶上了移动互联网的末班车，怀抱着希望，也在甘苦中煎熬。随着互联网下半场的开启，所有人都不得不承认竞争更残酷了。上半场的时候，错了也许还有机会。但现在，如果错了，想要翻身就更为艰难了。 52017年，移动互联网正在经历十字路口，它可能在等着创造新的辉煌也可能在等着低谷降临。创业者和投资人都意识到，当有了超级应用以后，流量的获取变得越来越难，谁懂得高效获取和利用流量，谁就有权力主宰新城邦。 这一年，我们拍摄了一部纪录片《燃点》，试图记录正在发生的创业史。 这一年，为了筹钱，罗永浩和直播平台签订合作，甚至以个人名义借款，以此维持公司的运转。因为他知道，公司活着就意味着一切。 罗永浩将2017年形容为“起死回生”。经历了大半年的生死煎熬，锤子科技终于扭转了颓势——坚果Pro 和坚果 Pro 2接连赢得了好评，销量上也收获了前所未有的佳绩。 “通往牛逼的路上，风景差得让人只想说脏话，但创业者在意的是远方。”罗永浩对创业这件事充满了热爱和任性，不管别人认为这条路适不适合他，他都要走下去。 陌陌收购探探，成为2018年农历新年后的第一场互联网公司收购。但唐岩依然有他新的焦虑。 这一年，经纬迎来了十周年纪念日。经纬系450多家公司，占据了中国移动互联网的半壁江山。即便如此，张颖还是在焦虑：“我们做得那么好了，我们怎么能再错过呢？” 狂飙猛进的共享单车市场进入胶着期，摩拜被王兴的美团收购了，ofo一度被传账上现金仅能支持一个月。唱衰的声浪都压在了戴威的肩上，直到新一轮融资完成，他才松了一口气。 但戴威仍然没有忘记他的初心，“我一直认为应该去做改变世界的事情。这是一个中国原创的，并且为全世界人去提供便捷服务的公司。”这也是ofo的愿景——让世界没有陌生的角落。戴威从不把情怀挂在嘴上，但你能从他的脸上看到，他还是那个愿意相信“美好终将发生”的人。 对傅盛来说，这也是艰难的一年。他问埃隆•马斯克：你做SpaceX、特斯拉，是不是觉得这件事情能赢？马斯克说，“我真的不知道我是不是一定能赢，这件事非常难，但我做这件事并不是因为它容易，就是因为它难。难，才有我做的价值；难，才有机会取得不一样的成就。”傅盛觉得，猎豹今天也处在这样的阶段。 傅盛 安传东经历了第三次失败，又一个项目草草结束。过年的时候，他跟父亲说起了在北京的创业经历，说着说着就掉下了眼泪。最近，在投资人的鼓舞下，安传东又开始了新一轮创业。 安传东屡战屡败的模样像极了年轻时跌跌撞撞的我们——我们都有过他那样非常努力的时刻，年轻、充满激情，但没有经验、没有资源、一无所有……一次又一次被命运击打。每个创业者都可以在安传东身上找到自己的第一次：成功了，就是一道风景；失败了，也是痛苦但舍不下的回忆。 金星的第三次创业四平八稳，他抓住了“男性创业，女性整形”的潮流，创立了医美平台新氧。2017年的第一个工作日，成立三年的新氧开始盈利。金星越来越成熟、稳当、有条不紊，他的现在，就像长大了的我们。 金星（左） 医美整形的每一步都面临着伦理的质疑，在对立中探索的金星也面临着一部分创业者的终极命题：如何领航一个不成熟的行业，又能在前行的同时避开暗礁？ 行业虽不同，困惑却如出一辙。papi酱和马薇薇作为大众娱乐明星已经成功，但作为创业者，她们还在各自寻找着更清晰的方向。 罗辑思维撤资后，面临质疑的papi酱开始探索从个人IP进化到MCN平台，她做了papitube。 马薇薇经历着同样的瓶颈，严重的失眠症长期困扰着她。 马薇薇 焦虑也许正是这个时代的候群症。对抗焦虑的最好手段，就是不甘现状和剑及履及的进步。 6十年如弹指般流逝，移动互联网浪潮全面席卷中国，以更高的效率和新的消费者互动关系，重构了商业的基本逻辑——信息获取、社交、购物、日常服务以及金融支付等方式都发生了翻天覆地的改变。 《燃点》的主角们也都完成了自己的逆袭，他们身上都有着鲜明的时代烙印，他们的故事，就是一部正在发生的创业史。 在这十年里，中国的经济总量增长了2.5倍，一跃超过日本，居于世界第二；人民币的规模总量增长了3倍，外汇储备增加了1.5倍；网民数量增长了2.5倍，电子商务在社会零售总额中的占比增长了13倍；中产阶层人口数量达到2.2亿，每年出境旅游人口增加了2.7倍；中国的消费者每年买走全球70%的奢侈品，而他们的平均年龄只有39岁。 今年是改革开放的第40个年头。40年前，高考实现了市场经济下最早的人才选拔。40年后，在一个愈加成熟的商业中国，创业者如走上搏击台，实现了以弱胜强的创富神话。 曾经，人们常用Copy to China来形容中国的发展模式，即将美国的创新抄袭到中国，国人大多也有这样的文化不自信。这十年来，人们一次次看到了Copyto Global，Made in China正在变成Created in China，中国的创业者也从跟随者变成了引领者。 我们试图记录下这个时代。我们不负责臧否成败，我们选取的也不是“成功者”或“失败者”，而是那些“强烈的人格”。这些人格包括了罗永浩、唐岩、戴威、金星、张颖、傅盛、papi酱、安传东、马薇薇、孟雷、潘飞、许单单、孙海涛。 他们纵身跃出舒适区，打破旧有常规，推动社会前进，并先于所有人迎接未来。这些创业者改造着一个个产业，也改变着中国。他们站在一起，就是当下中国创业史的最好记录。 原文地址： 这里]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ncnn使用详解(2)——Android端]]></title>
    <url>%2F2018%2F04%2F13%2FNcnn%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3(2)%E2%80%94%E2%80%94Android%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[摘要本片文章基于你已经完成了 这篇文章——PC端/)的学习，主要介绍如何将写好的c代码应用到Android项目中。 环境说明系统：Ubuntu16.04软件：Android Studio 前期准备之ndk安装在正式开始前我们需要先下载安装ndk，这里介绍一种简单高效的方式，打开Android Studio，然后依次点击File-&gt;Settings-&gt;Appearance&amp;Behavior-&gt;System Settings-&gt;Android SDK，然后在SDK Tools下找到ndk，然后选中，点击apply就可以自动下载安装了，如图：完成之后在你的sdk目录下会多出一个ndk-bundle的包，这就是你ndk的路径，类似下图：至此，ndk已经安装完毕了，下一步是配置ndk的环境变量：首先打开profile： sudo vim /etc/profile 打开后在profile文件的末尾加上： export NDK_HOME=sdkroot/ndk-bundle PATH=$NDK_HOME:$PATH sdkroot是你的sdk目录，每个人的不一样，视情况而定，下面是我的配置截图： 添加完成后保存退出，使用以下命令使配置的环境变量生效： source /etc/profile 验证ndk是否配置成功： ndk-build -v 出现类似以下输出即说明ndk配置成功： 编译ncnn sdk我们需要将ncnn打包，这样我们才能在android ndk的代码中使用include ​ mkdir build-android cd build-android cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \ -DANDROID_ABI=”armeabi-v7a” -DANDROID_ARM_NEON=ON \ -DANDROID_PLATFORM=android-14 .. make make install 参数说明： ​ ANDROID_ABI 是架构名字，”armeabi-v7a” 支持绝大部分手机硬件 ANDROID_ARM_NEON 是否使用 NEON 指令集，设为 ON 支持绝大部分手机硬件 ANDROID_PLATFORM 指定最低系统版本，&quot;android-14&quot; 就是 android-4.0 你可以根据自己的需要设置自己的参数，详见 这里 完成后你就可以在ncnn/build-android下找到install了，大概如图： install下有include和lib两个文件夹，这两个文件夹下的东西后面会用到。 进行ndk开发Android可以通过ndk-build和cmake两种方式来编译c，而且官方比较推荐的是cmake的方式，但是我用cmake试了好长时间一直报各种诡异的错误，应该是我还没有学到ncnn in ndk with cmake的正确打开方式，所以这里介绍一下使用ndk-build这种方式编译c，步骤如下：我这里新建了一个android 的demo项目，项目结构如下：主要是assets文件夹下放置你的bin和param文件，jni文件夹下放置你的cpp和两个mk文件，具体内容下面会介绍（可以直接在对应位置新建这两个文件夹），然后要修改你的appgradle文件：对应的内容你可以根据自己的情况修改，然后配置两个mk文件： Android.mk 12345678910111213141516171819202122232425262728293031LOCAL_PATH := $(call my-dir)#把这个路径改成你自己刚才编译的install路径，用全路径！NCNN_INSTALL_PATH := ncnn-master/build-android/installinclude $(CLEAR_VARS)LOCAL_MODULE := ncnnLOCAL_SRC_FILES := $(NCNN_INSTALL_PATH)/lib/libncnn.ainclude $(PREBUILT_STATIC_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := demo#这个是你的cpp文件LOCAL_SRC_FILES := demo.cppLOCAL_C_INCLUDES := $(NCNN_INSTALL_PATH)/includeLOCAL_STATIC_LIBRARIES := ncnnLOCAL_CFLAGS := -O2 -fvisibility=hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-mathLOCAL_CPPFLAGS := -O2 -fvisibility=hidden -fvisibility-inlines-hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-mathLOCAL_LDFLAGS += -Wl,--gc-sectionsLOCAL_CFLAGS += -fopenmpLOCAL_CPPFLAGS += -fopenmpLOCAL_LDFLAGS += -fopenmpLOCAL_LDLIBS := -lz -llog -ljnigraphicsinclude $(BUILD_SHARED_LIBRARY) Application.mk 123456789# APP_STL := stlport_staticAPP_STL := gnustl_static# APP_ABI := armeabi armeabi-v7aAPP_ABI := armeabi-v7aAPP_PLATFORM := android-9#NDK_TOOLCHAIN_VERSION := 4.9 这两个.mk文件我的建议是复制粘贴到你的项目里，只改动必要的文件路径，其余的参数别动，除非你知道你改的意思是什么～因为ndk的原理是使用java接口调用c代码，所以我们需要进行java接口的编写，给出一个示例代码： 1234567891011public class Ncnn&#123; public native boolean InitNcnn(String gestureDetectionModelPath); public native void Detect(float[] i,float[] q,float []scores,int[] a); static &#123; System.loadLibrary("demo"); &#125; 一共两个方法，一个是初始化，一个是执行预测，需要注意的是初始化方法调用的时候需要传入一个二进制文件路径的参数，大概思路是把bin和param文件拷贝到手机上然后让c代码读取，这里给出模板代码： ​ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private void IniteNcnn() throws IOException &#123; ncnn = new Ncnn();//实例化上面的java接口类 try &#123; copyBigDataToSD("demo.bin"); copyBigDataToSD("demo.param"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //模型初始化 File sdDir = Environment.getExternalStorageDirectory();//获取跟目录 String sdPath = sdDir.toString() + "/gesturencnn/"; boolean b = ncnn.InitNcnn(sdPath); &#125; private void copyBigDataToSD(String strOutFileName) throws IOException &#123; File sdDir = Environment.getExternalStorageDirectory(); File file = new File(sdDir.toString() + "/demo/"); if (!file.exists()) &#123; file.mkdir(); &#125; String tmpFile = sdDir.toString() + "/demo/" + strOutFileName; File f = new File(tmpFile); if (f.exists()) &#123; return; &#125; InputStream myInput; java.io.OutputStream myOutput = new FileOutputStream(sdDir.toString() + "/demo/" + strOutFileName); myInput = context.getAssets().open(strOutFileName); byte[] buffer = new byte[1024]; int length = myInput.read(buffer); while (length &gt; 0) &#123; myOutput.write(buffer, 0, length); length = myInput.read(buffer); &#125; myOutput.flush(); myInput.close(); myOutput.close(); &#125; ​ 直接在你需要的地方调用IniteNcnn（）就可以了，需要注意的是要 进行内存卡读取权限的申请 哦 然后将你上一篇教程写的demo.cpp放在jni目录下，对里面的代码进行必要的修改，主要需要实现模型的初始化和执行预测两个函数，初始化这里给出一个模板，至于执行预测的函数直接写一个对应函数然后调用你之前写好的c代码就可以了： 初始化这个函数是通用的，建议全部复制粘贴，具体对应的java接口代码后面会介绍 12345678910111213141516171819202122232425262728293031323334353637383940extern "C"&#123;#注意把这里的函数名改成你自己对应的，一定不能错！JNIEXPORT jboolean JNICALLJava_com_example_dmrf_JniClass_Ncnn_InitNcnn(JNIEnv *env, jobject instance, jstring DetectionModelPath_) &#123; const char *DetectionModelPath = env-&gt;GetStringUTFChars(DetectionModelPath_, 0); if (NULL == DetectionModelPath) &#123; return false; &#125; string tModelDir = DetectionModelPath; string tLastChar = tModelDir.substr(tModelDir.length() - 1, 1); if ("\\" == tLastChar) &#123; tModelDir = tModelDir.substr(0, tModelDir.length() - 1) + "/"; &#125; else if (tLastChar != "/") &#123; tModelDir += "/"; &#125; std::vector&lt;std::string&gt; param_files; param_files.resize(1); param_files[0] = tModelDir + "/demo.param"; std::vector&lt;std::string&gt; bin_files; bin_files.resize(1); bin_files[0] = tModelDir + "/demo.bin"; squeezenet.load_param(param_files[0].data()); squeezenet.load_model(bin_files[0].data()); env-&gt;ReleaseStringUTFChars(DetectionModelPath_, DetectionModelPath); return true;&#125; 至此所有代码已经编写完毕，然后就可以build了，步骤如下： cd到src/main/jni目录下，执行ndk-build，然后就会生成.so文件，然后你就可以干你的后序工作了。]]></content>
      <categories>
        <category>Ncnn</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>Deep Learning</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ncnn使用详解(1)——PC端]]></title>
    <url>%2F2018%2F04%2F13%2FNcnn%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3(1)%E2%80%94%E2%80%94PC%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[写在前面本系列文章的内容关于ncnn会有两篇文章（一篇介绍pc端使用，一篇介绍android端使用），主要是因为之前在使用ncnn的时候网上的资料比较少，可能是大佬们的主要精力都放在了算法优化上，所以相关的基础实践资料就感觉比较少，本系列文章将详细介绍ncnn从源码编译到最终在Android端的应用流程，希望可以帮到有需要的同仁。 相关链接（主要参考）ncnn主页： https://github.com/Tencent/ncnn 环境说明系统：Ubuntu16.04 编译源码从github下载源码git clone https://github.com/Tencent/ncnn 下载完后的目录结构应该是这样：然后对ncnn源码进行编译(在ncnn根目录下执行)： mkdir build cd build cmake .. make -j4 然后就可以编译成功了，相关截图： 在电脑上实现ncnn加载caffe模型对目标进行分类参考 这里 准备caffe网络和模型caffe 的网络和模型通常是搞深度学习的研究者训练出来的，一般来说训练完会有 train.prototxt deploy.prototxt snapshot_10000.caffemodel 部署的时候只需要 TEST 过程，所以有 deploy.prototxt 和 caffemodel 就足够了 alexnet 的 deploy.prototxt 可以在 这里下载 alexnet 的 caffemodel 可以在 这里下载 转换ncnn网络和模型caffe 自带了工具可以把老版本的 caffe 网络和模型转换为新版（ncnn的工具只认识新版），这里介绍一种比较笨但是比较快捷的方法：首先将你需要转换的prototxt和caffemodel放在你电脑的caffe/build/tools目录下，然后终端进入caffe/build/tools，执行命令： ./upgrade_net_proto_text old_deploy.prototxt new_deploy.prototxt ./upgrade_net_proto_binary old.caffemodel new.caffemodel 执行完成之后你就可以在caffe/build/tools下找到你的new_deploy.prototxt和new.caffemodel文件了。注意完成之后打开你的new_deploy.prototxt文件看一下，因为一般每次只需要做一个数据样本的识别，所以如果第一个 dim 不为1，要将其设为1，类似于这样： layer { name: &quot;data&quot; type: &quot;Input&quot; top: &quot;data&quot; input_param { shape: { dim: 1 dim: 3 dim: 227 dim: 227 } } } 使用 caffe2ncnn 工具转换为 ncnn 的网络描述和模型终端进入ncnn/build/toos/caffe（需要提前把上面转化的new_deploy.prototxt和new.caffemodel放到ncnn/build/tools/caffe下），执行如下命令： caffe2ncnn new_deploy.prototxt new.caffemodel demo.param demo.bin 执行完成之后在ncnn/build/tools下就可以看到生成的param和bin文件了，文件名你可以根据你的需要设置。 去除可见字符串（可选）用nihui大神的原文介绍：有 param 和 bin 文件其实已经可以用了，但是 param 描述文件是明文的，如果放在 APP分发出去容易被窥探到网络结构（说得好像不明文就看不到一样) 使用 ncnn2mem 工具转换为二进制描述文件和内存模型，生成alexnet.param.bin 和两个静态数组的代码文件： ncnn2mem demo.param demo.bin demo.id.h demo.mem.h 我下面的所有使用为了方便都使用的是没有去除可见字符串的param和bin，如果你有去除可见字符串的需求，可以在ncnn的examples中找到相应去除了可见字符串文件的使用方法。 实现在电脑上使用ncnn编写代码使用你喜欢的编辑器编写c语言代码，我这里不做过多语言介绍，直接给一个demo代码，我会在代码中给出关键代码的注释（保证你认真看完代码和注释就会懂ncnn的大概原理），请大家从main函数入口开始阅读，相信更多的读者喜欢这种直接showcode的方式： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;#include"gesture.id.h"#include "net.h"//使用ncnn，传入的参数第一个是你需要预测的数据，第二个参数是各个类别的得分vector，注意传入的是地址，这样才能在这个函数中改变其值static int detect_squeezenet( float *data, std::vector&lt;float&gt;&amp; cls_scores)&#123; //实例化ncnn：Net，注意include "net.h"，不要在意这时候因为找不到net.h文件而include&lt;net.h&gt;报错，后文会介绍正确的打开方式 ncnn::Net squeezenet; //加载二进制文件，也是照写，后面会介绍对应文件应该放的正确位置 int a=squeezenet.load_param("demo.param"); int b=squeezenet.load_param_bin("demo.bin"); //实例化Mat，前三个参数是维度，第四个参数是传入的data，维度的设置根据你自己的数据进行设置，顺序是w、h、c ncnn::Mat in = ncnn::Mat(550, 8, 2, data); //实例化Extractor ncnn::Extractor ex = squeezenet.create_extractor(); ex.set_light_mode(true); //注意把"data"换成你deploy中的数据层名字 int d= ex.input("data", in); ncnn::Mat out; //这里是真正的终点，不多说了，只能仰天膜拜nihui大牛，重点是将prob换成你deploy中最后一层的名字 int c=ex.extract("prob", out); //将out中的值转化为我们的cls_scores，这样就可以返回不同类别的得分了 cls_scores.resize(out.w); for (int j=0; j&lt;out.w; j++) &#123; cls_scores[j] = out[j]; &#125; return 0;&#125;int main(int argc, char** argv)&#123; //注意，这里的argv是之后从终端输入的参数，我这里是数据源的路径,因为我是从两个文件中生成一个总的数据，所以用了argv[1]和argv[2]，你也可以自己根据需求改变 const char* imagepath1 = argv[1]; const char* imagepath2=argv[2]; FILE *fopeni=NULL; FILE *fopenq=NULL; fopeni=fopen(imagepath1,"r"); fopenq=fopen(imagepath2,"r"); //这是我的数据，i和q相当于图片的两个通道 float i[4400]; float q[4400]; float data[8800]; int count=4400; for (int j = 0; j &lt; count; ++j) &#123; fscanf(fopeni,"%f",&amp;i[j]); fscanf(fopenq,"%f",&amp;q[j]); &#125; //这是将iq（相当于图片的两个通道的数据）转化为一个一维向量，需要特别注意的是数据维度的顺序 for (int j = 0; j &lt; 8800; ++j) &#123; if (j&lt;4400) &#123; data[j]=i[j]; &#125;else&#123; data[j]=q[j-4400]; &#125; &#125; char a[13]=&#123;'A','B','C','F','G','H','I','J','K','L','M','N','O'&#125;; //注意，这里是调用ncnn的代码 std::vector&lt;float&gt; cls_scores;//用来存储最终各类别的得分 //这个函数的实现在上面，快去看 detect_squeezenet(data, cls_scores); for (int i = 0; i &lt; cls_scores.size(); ++i) &#123; printf("%c : %f\n", a[i],cls_scores[i]); &#125; return 0;&#125; 代码中我展示了最简单的ncnn使用场景，你可以根据自己的需要加入不同的其他代码 编译并运行我们写的代码首先将你刚才写好的代码文件（假设命名为demo.cpp）放在ncnn/examples目录下，然后打开ncnn/examples目录下的CMakeLists.txt文件，增加这两行： add_executable(demo demo.cpp) target_link_libraries(demo ncnn) 最终的CMakeLists.txt文件类似这样： find_package(OpenCV QUIET COMPONENTS core highgui imgproc imgcodecs) if(NOT OpenCV_FOUND) find_package(OpenCV REQUIRED COMPONENTS core highgui imgproc) endif() include_directories(${CMAKE_CURRENT_SOURCE_DIR}/../src) include_directories(${CMAKE_CURRENT_BINARY_DIR}/../src) add_executable(squeezenet squeezenet.cpp) target_link_libraries(squeezenet ncnn ${OpenCV_LIBS}) add_executable(fasterrcnn fasterrcnn.cpp) target_link_libraries(fasterrcnn ncnn ${OpenCV_LIBS}) add_executable(demo demo.cpp) target_link_libraries(demo ncnn) add_subdirectory(ssd) 然后打开ncnn根目录下的CMakeLists.txt文件，将编译examples语句的注释打开（默认是被注释掉的），如图：更改后保存退出，现在就可以终端进入ncnn/build后执行： make 执行完毕后你就可以在ncnn/build/examples下找到你的可执行文件了（demo） 执行可执行文件首先将你之前生成的.param和.bin文件复制到ncnn/build/examples目录下，然后终端cd到ncnn/build/examples，执行： ./demo data_path1 data_path2 然后你就可以看到奇迹了～]]></content>
      <categories>
        <category>Ncnn</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>Deep Learning</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android NDK常见错误解决方案]]></title>
    <url>%2F2018%2F04%2F03%2FAndroid%20NDK%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[clang++: error: linker command failed with exit code 1 (use -v to see invocation)这种错误最常见的出现形式是sync的时候没错，但是build的时候就报这个错误，解决方案：在app的defaultConfig中的ndk节点中添加： 1stl "gnustl_static" 即可 Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp.hxx .in .txx这种错误大多数情况下是因为编译器找不到对应的c文件，解决方案是在cmakelist中用全路径代替简略路径，比如： 1file(GLOB SignalNative_SRC $&#123;CMAKE_SOURCE_DIR&#125;/src/main/cpp/Signal/*.cpp) 而不是 1file(GLOB SignalNative_SRC $&#123;src/main/cpp/Signal/*.cpp)]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>NDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分别使用C语言和Python实现矩阵归一化]]></title>
    <url>%2F2018%2F03%2F29%2F%E5%88%86%E5%88%AB%E4%BD%BF%E7%94%A8C%E8%AF%AD%E8%A8%80%E5%92%8CPython%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E5%BD%92%E4%B8%80%E5%8C%96%2F</url>
    <content type="text"><![CDATA[直接上代码：C语言： ​123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;algorithm&gt;void mean(float *data,int len,float &amp;mean,float &amp;max,float &amp;min)&#123; float sum=data[0]; max=data[0]; min=data[0]; for (int i = 1; i &lt; len; ++i) &#123; sum+=data[i]; if(data[i]&gt;max)max=data[i]; if(data[i]&lt;min)min=data[i]; &#125; mean=sum/len;&#125;void normalize(float *data,int len)&#123; float m=0.0; float mx=0.0; float mn=0.0; mean(data,len,m,mx,mn); printf("mean:%f\nmax:%f\nmin:%f\n",m,mx,mn ); for (int i = 0; i &lt; len; ++i) &#123; data[i]=(data[i]-m)/(mx-mn); &#125;&#125; Python： ​12345def Normalize(data): m = np.mean(data) mx = max(data) mn = min(data) return [(float(i) - m) / (mx - mn) for i in data]]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>归一化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——访问者模式]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变 。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。 介绍意图主要将数据结构与数据操作分离。 主要解决稳定的数据结构和易变的操作耦合问题。 何时使用需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。 如何解决在被访问的类里面加一个对外提供接待访问者的接口。 关键代码在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。 应用实例您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。 优点 符合单一职责原则 优秀的扩展性 灵活性。 缺点 具体元素对访问者公布细节，违反了迪米特原则 具体元素变更比较困难 违反了依赖倒置原则，依赖了具体类，没有依赖抽象 使用场景 对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作 需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。 注意事项访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。 Demo我们将创建一个定义接受操作的 ComputerPart 接口。Keyboard、Mouse、Monitor 和 Computer 是实现了ComputerPart 接口的实体类。我们将定义另一个接口 ComputerPartVisitor，它定义了访问者类的操作。Computer使用实体访问者来执行相应的动作。VisitorPatternDemo，我们的演示类使用 Computer、ComputerPartVisitor 类来演示访问者模式的用法。 定义一个表示元素的接口 ComputerPart.java 123public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125; 创建扩展了上述类的实体类 Keyboard.java 1234567public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Monitor.java 1234567public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Mouse.java 1234567public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Computer.java 12345678910111213141516public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer()&#123; parts = new ComputerPart[] &#123;new Mouse(), new Keyboard(), new Monitor()&#125;; &#125; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; computerPartVisitor.visit(this); &#125;&#125; 定义一个表示访问者的接口 ComputerPartVisitor.java 123456public interface ComputerPartVisitor &#123; public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);&#125; 创建实现了上述类的实体访问者 ComputerPartDisplayVisitor.java 12345678910111213141516171819202122public class ComputerPartDisplayVisitor implements ComputerPartVisitor &#123; @Override public void visit(Computer computer) &#123; System.out.println("Displaying Computer."); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println("Displaying Mouse."); &#125; @Override public void visit(Keyboard keyboard) &#123; System.out.println("Displaying Keyboard."); &#125; @Override public void visit(Monitor monitor) &#123; System.out.println("Displaying Monitor."); &#125;&#125; 使用 ComputerPartDisplayVisitor 来显示 Computer 的组成部分 VisitorPatternDemo.java 12345678910public class VisitorPatternDemo &#123; public static void main(String[] args) &#123;``` ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor());``` &#125;&#125; 验证输出​ Displaying Mouse. Displaying Keyboard. Displaying Monitor. Displaying Computer. 总结访问者模式解决的是根据访问者的不同而执行不同的行为，即同样一个方法（方法名相同），但是当A调用这个方法时执行的是逻辑A，B调用这个方法时执行逻辑B，这种情况下就需要使用访问者模式来实现。具体到demo，我们想要实现不同的ComputerPart调用accept的时候执行不同的逻辑，只需要构造一个访问者类ComputerPartDisplayVisitor，它根据accept的调用者的不用执行不同的逻辑，而调用者只需要将this传入accept方法即可，accept方法会根据传入的参数类型的不同调用不同的逻辑（visit）。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——模板模式]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述在模板模式（TemplatePattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 介绍意图定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 主要解决一些方法通用，却在每一个子类都重新写了这一方法。 何时使用有一些通用的方法。 如何解决将这些通用算法抽象出来。 关键代码在抽象类实现，其他步骤在子类实现。 应用实例 在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异 西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架 spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存 优点 封装不变部分，扩展可变部分 提取公共代码，便于维护 行为由父类控制，子类实现 缺点每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 使用场景 有多个子类共有的方法，且逻辑相同 重要的、复杂的方法，可以考虑作为模板方法 注意事项为防止恶意操作，一般 模板方法都加上 final 关键词 。 Demo我们将创建一个定义操作的 Game 抽象类，其中，模板方法设置为 final，这样它就不会被重写。Cricket 和 Football 是扩展了 Game的实体类，它们重写了抽象类的方法。TemplatePatternDemo，我们的演示类使用 Game 来演示模板模式的用法。 创建一个抽象类，它的模板方法被设置为 final Game.java 1234567891011121314151617181920212223 public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125; ## 创建扩展了上述类的实体类 Cricket.java 1234567891011121314151617public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println("Cricket Game Finished!"); &#125; @Override void initialize() &#123; System.out.println("Cricket Game Initialized! Start playing."); &#125; @Override void startPlay() &#123; System.out.println("Cricket Game Started. Enjoy the game!"); &#125;&#125; Football.java 1234567891011121314151617public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println("Football Game Finished!"); &#125; @Override void initialize() &#123; System.out.println("Football Game Initialized! Start playing."); &#125; @Override void startPlay() &#123; System.out.println("Football Game Started. Enjoy the game!"); &#125;&#125; 使用 Game 的模板方法 play() 来演示游戏的定义方式 TemplatePatternDemo.java 12345678910111213public class TemplatePatternDemo &#123; public static void main(String[] args) &#123;``` Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); ``` &#125;&#125; 验证输出​1234567Cricket Game Initialized! Start playing.Cricket Game Started. Enjoy the game!Cricket Game Finished!Football Game Initialized! Start playing.Football Game Started. Enjoy the game!Football Game Finished! 总结模板方法模式顾名思义就是定义了一个特殊的方法，这个方法的大体框架是写死的，比如demo中抽象类Game的play方法，它规定了所有实现类的play方法有且仅能有模板方法中定义中的行为，但是这些行为具体如何实现则不是模板方法所关心的，说白了就是模板方法规定了如果调用这个方法会干嘛，但是怎么去干就不是它所关心的重点了。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——策略模式]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述在策略模式（Strategy Pattern）中，一个类的 行为或其算法可以在运行时更改 。这种类型的设计模式属于行为型模式。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 介绍意图定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 主要解决在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 何时使用一个系统有许多许多类，而区分它们的只是他们直接的行为。 如何解决将这些算法封装成一个一个的类，任意地替换。 关键代码实现同一个接口 应用实例 诸葛亮的锦囊妙计，每一个锦囊就是一个策略 旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略 JAVA AWT 中的 LayoutManager 优点 算法可以自由切换 避免使用多重条件判断 扩展性良好。 缺点 策略类会增多 所有策略类都需要对外暴露 使用场景 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为 一个系统需要动态地在几种算法中选择一种 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 注意事项如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 Demo我们将创建一个定义活动的 Strategy 接口和实现了 Strategy 接口的实体策略类。Context 是一个使用了某种策略的类。StrategyPatternDemo，我们的演示类使用 Context 和策略对象来演示 Context 在它所配置或使用的策略改变时的行为变化。 创建一个接口 Strategy.java 123public interface Strategy &#123; public int doOperation(int num1, int num2);&#125; 创建实现接口的实体类 OperationAdd.java 123456public class OperationAdd implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125; OperationSubstract.java 123456public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125; OperationMultiply.java 123456public class OperationMultiply implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125; 创建 Context 类 Context.java 1234567891011- public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125; &#125; ## 使用 Context 来查看当它改变策略 Strategy 时的行为变化 StrategyPatternDemo.java 123456789101112131415public class StrategyPatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(new OperationAdd()); System.out.println("10 + 5 = " + context.executeStrategy(10, 5));``` context = new Context(new OperationSubstract()); System.out.println("10 - 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println("10 * 5 = " + context.executeStrategy(10, 5));``` &#125;&#125; 验证输出​ 10 + 5 = 15 10 - 5 = 5 10 * 5 = 5 总结当一个类的行为需要根据不同的状态改变时就需要使用策略模式，比如demo中Context类的executeStrategy方法执行的逻辑需要根据Context的Strategy成员的状态的变化而变化，传统地可以通过if else语句来实现对Strategy状态的判断进而实现不同的算法，但是如果采用策略模式，Context类就不必关心当前Strategy的状态，而将这种执行不同算法的控制权交给了客户端。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——状态模式]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。在状态模式中，我们创建表示各种状态的对象和一个 行为随着状态对象改变而改变 的 context 对象。 介绍意图允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。 主要解决对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。 何时使用代码中包含大量 与对象状态有关的条件语句 。 如何解决将各种具体的状态类抽象出来。 关键代码通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除if…else 等条件选择语句。 应用实例 打篮球的时候运动员可以有正常状态、不正常状态和超常状态 优点 封装了转换规则 枚举可能的状态，在枚举状态之前需要确定状态种类 将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为 允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块 可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数 缺点 状态模式的使用必然会增加系统类和对象的个数 状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱 状态模式对”开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码 使用场景 行为随状态改变而改变的场景 条件、分支语句的代替者 注意事项在行为受状态约束的时候使用状态模式，而且 状态不超过 5 个 。 Demo我们将创建一个 State 接口和实现了 State 接口的实体状态类。Context 是一个带有某个状态的类。StatePatternDemo，我们的演示类使用 Context 和状态对象来演示 Context 在状态改变时的行为变化。 创建一个接口 State.java 123public interface State &#123; public void doAction(Context context);&#125; 创建实现接口的实体类 StartState.java 1234567891011public class StartState implements State &#123; public void doAction(Context context) &#123; System.out.println("Player is in start state"); context.setState(this); &#125; public String toString()&#123; return "Start State"; &#125;&#125; StopState.java 1234567891011public class StopState implements State &#123; public void doAction(Context context) &#123; System.out.println("Player is in stop state"); context.setState(this); &#125; public String toString()&#123; return "Stop State"; &#125;&#125; 创建 Context 类 Context.java 123456789101112131415public class Context &#123; private State state; public Context()&#123; state = null; &#125; public void setState(State state)&#123; this.state = state; &#125; public State getState()&#123; return state; &#125;&#125; 使用 Context 来查看当状态 State 改变时的行为变化 StatePatternDemo.java 1234567891011121314 public class StatePatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(); StartState startState = new StartState(); startState.doAction(context); System.out.println(context.getState().toString()); StopState stopState = new StopState(); stopState.doAction(context); System.out.println(context.getState().toString()); &#125;&#125; 验证输出​1234Player is in start stateStart StatePlayer is in stop stateStop State 总结状态模式将各个状态所对应的操作分离开来,即对于不同的状态,由不同的子类实现具体操作,不同状态的切换由子类实现，比如上面的demo，同样是实现doAction根据不同的状态执行不同的逻辑，按照传统的方法需要使用ifelse进行判断，但是使用状态模式则可以将不同的状态实例化为不同的子类，然后在不同的子类（实际上是不同的状态）中实现不同的逻辑，客户端使用的时候只需要实例化不同的状态的子类就可以调用不同状态下的同名方法。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——观察者模式]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如， 当一个对象被修改时，则会自动通知依赖它的对象。观察者模式属于行为型模式。 介绍意图定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决使用面向对象技术，可以将这种依赖关系弱化。 关键代码在抽象类里有一个 ArrayList 存放观察者们。 应用实例 拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价 西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。 优点 观察者和被观察者是抽象耦合的 建立一套触发机制 缺点 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化 使用场景一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。一个对象必须通知其他对象，而并不知道这些对象是谁。需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种 链式触发机制 。 注意事项 JAVA 中已经有了对观察者模式的支持类 避免循环引用 如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式 Demo观察者模式使用三个类 Subject、Observer 和 Client。Subject 对象带有绑定观察者到 Client 对象和从 Client对象解绑观察者的方法。我们创建 Subject 类、Observer 抽象类和扩展了抽象类 Observer 的实体类。ObserverPatternDemo，我们的演示类使用 Subject 和实体类对象来演示观察者模式。 创建 Subject 类 Subject.java 12345678910111213141516171819202122232425262728import java.util.ArrayList;import java.util.List;public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; notifyAllObservers(); &#125; public void attach(Observer observer)&#123; observers.add(observer); &#125; public void notifyAllObservers()&#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125; &#125; 创建 Observer 类 Observer.java 1234public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125; 创建实体观察者类 BinaryObserver.java 12345678910111213public class BinaryObserver extends Observer&#123; public BinaryObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( "Binary String: " + Integer.toBinaryString( subject.getState() ) ); &#125;&#125; OctalObserver.java 12345678910111213public class OctalObserver extends Observer&#123; public OctalObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( "Octal String: " + Integer.toOctalString( subject.getState() ) ); &#125;&#125; HexaObserver.java 12345678910111213public class HexaObserver extends Observer&#123; public HexaObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( "Hex String: " + Integer.toHexString( subject.getState() ).toUpperCase() ); &#125;&#125; 使用 Subject 和实体观察者对象 ObserverPatternDemo.java 1234567891011121314151617public class ObserverPatternDemo &#123; public static void main(String[] args) &#123;​ Subject subject = new Subject();``` new HexaObserver(subject); new OctalObserver(subject); new BinaryObserver(subject); System.out.println("First state change: 15"); subject.setState(15); System.out.println("Second state change: 10"); subject.setState(10);``` &#125;&#125; 验证输出​ First state change: 15 Hex String: F Octal String: 17 Binary String: 1111 Second state change: 10 Hex String: A Octal String: 12 Binary String: 1010 总结观察者模式用一句话描述就是当一个类的对象（被观察者）的状态发生改变时同时其他依赖于它的对象（观察者）的状态也做相应的改变（做相应的动作）。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——备忘录模式]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。 介绍意图在不破坏封装性的前提下，捕获一个对象的内部状态，并 在该对象之外保存这个状态 。 主要解决所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。 何时使用很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有”后悔药”可吃。 如何解决通过一个备忘录类专门存储对象状态。 关键代码客户不与备忘录类耦合，与备忘录管理类耦合。 应用实例 后悔药 打游戏时的存档 Windows 里的 ctri + z IE 中的后退 数据库的事务管理 优点 给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态 实现了信息的封装，使得用户不需要关心状态的保存细节 缺点消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。 使用场景 需要保存/恢复数据的相关状态场景 提供一个可回滚的操作 注意事项 为了符合迪米特原则，还要增加一个管理备忘录的类 为了节约内存，可使用原型模式+备忘录模式 Demo备忘录模式使用三个类 Memento、Originator 和 CareTaker。Memento 包含了要被恢复的对象的状态。Originator创建并在 Memento 对象中存储状态。Caretaker 对象负责从 Memento 中恢复对象的状态。MementoPatternDemo，我们的演示类使用 CareTaker 和 Originator 对象来显示对象的状态恢复。 创建 Memento 类 Memento.java 123456789101112public class Memento &#123; private String state; public Memento(String state)&#123; this.state = state; &#125; public String getState()&#123; return state; &#125; &#125; 创建 Originator 类 Originator.java 123456789101112131415161718192021public class Originator &#123; private String state; public void setState(String state)&#123; this.state = state; &#125; public String getState()&#123; return state; &#125; public Memento saveStateToMemento()&#123; return new Memento(state); &#125; public void getStateFromMemento(Memento Memento)&#123; state = Memento.getState(); &#125;&#125; 创建 CareTaker 类 CareTaker.java 1234567891011121314import java.util.ArrayList;import java.util.List;public class CareTaker &#123; private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;(); public void add(Memento state)&#123; mementoList.add(state); &#125; public Memento get(int index)&#123; return mementoList.get(index); &#125;&#125; 使用 CareTaker 和 Originator 对象 MementoPatternDemo.java 123456789101112131415161718192021public class MementoPatternDemo &#123; public static void main(String[] args) &#123;​ Originator originator = new Originator();​ CareTaker careTaker = new CareTaker();​ originator.setState("State #1");​ originator.setState("State #2");​ careTaker.add(originator.saveStateToMemento());​ originator.setState("State #3");​ careTaker.add(originator.saveStateToMemento());​ originator.setState("State #4");``` System.out.println("Current State: " + originator.getState()); originator.getStateFromMemento(careTaker.get(0)); System.out.println("First saved State: " + originator.getState()); originator.getStateFromMemento(careTaker.get(1)); System.out.println("Second saved State: " + originator.getState());``` &#125;&#125; 验证输出​ Current State: State #4 First saved State: State #2 Second saved State: State #3 总结备忘录模式的本质就是一种备份机制，其思路是将对象的状态在用户需要的时候备份下来，当需要状态回滚的时候直接将将对象的状态恢复到之前备份的状态，我们经常用的git版本控制管理系统其实就是一个特殊的备忘录模式，其在你需要的时候将你的仓库备份下来，这样你就可以在后期的开发中随时找到你之前备份的仓库状态，但是需要注意的是备忘录模式的终点是对象，其真正的目的是将单个对象的状态保存下来，至于其他的状态备份则不是它所侧重的。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——中介者模式]]></title>
    <url>%2F2018%2F03%2F25%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个 中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 介绍意图用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 主要解决对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。 何时使用多个类相互耦合，形成了网状结构。 如何解决将上述网状结构分离为星型结构。 关键代码对象 Colleague 之间的通信封装到一个类中单独处理。 应用实例 中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易 机场调度系统 MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者 优点 降低了类的复杂度，将一对多转化成了一对一 各个类之间的解耦 符合迪米特原则。 缺点中介者会庞大，变得复杂难以维护。 使用场景 系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象 想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。 注意事项不应当在职责混乱的时候使用。 Demo我们通过聊天室实例来演示中介者模式。实例中，多个用户可以向聊天室发送消息，聊天室向所有的用户显示消息。我们将创建两个类 ChatRoom 和User。User 对象使用 ChatRoom 方法来分享他们的消息。MediatorPatternDemo，我们的演示类使用 User 对象来显示他们之间的通信。 创建中介类 ChatRoom.java 12345678import java.util.Date; public class ChatRoom &#123; public static void showMessage(User user, String message)&#123; System.out.println(new Date().toString() + " [" + user.getName() +"] : " + message); &#125;&#125; 创建 user 类 User.java 12345678910111213141516171819public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(String name)&#123; this.name = name; &#125; public void sendMessage(String message)&#123; ChatRoom.showMessage(this,message); &#125;&#125; 使用 User 对象来显示他们之间的通信 MediatorPatternDemo.java 12345678 public class MediatorPatternDemo &#123; public static void main(String[] args) &#123; User robert = new User("Robert"); User john = new User("John"); robert.sendMessage("Hi! John!"); john.sendMessage("Hello! Robert!"); &#125;&#125; 验证输出​12Thu Jan 31 16:05:46 IST 2013 [Robert] : Hi! John!Thu Jan 31 16:05:46 IST 2013 [John] : Hello! Robert!]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——迭代器模式]]></title>
    <url>%2F2018%2F03%2F25%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示 。迭代器模式属于行为型模式。 介绍意图提供一种方法顺序访问一个聚合对象中各个元素, 而又 无须暴露该对象的内部表示 。 主要解决不同的方式来遍历整个整合对象。 何时使用遍历一个聚合对象。 如何解决把在元素之间游走的责任交给迭代器，而不是聚合对象。 关键代码定义接口：hasNext, next。 应用实例JAVA 中的 iterator。 优点 它支持以不同的方式遍历一个聚合对象 迭代器简化了聚合类 在同一个聚合上可以有多个遍历 在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码 缺点由于迭代器模式将存储数据和遍历数据的职责分离， 增加新的聚合类需要对应增加新的迭代器类 ，类的个数成对增加，这在一定程度上增加了系统的复杂性。 使用场景 访问一个聚合对象的内容而无须暴露它的内部表示 需要为聚合对象提供多种遍历方式 为遍历不同的聚合结构提供一个统一的接口 注意事项迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据。 Demo我们将创建一个叙述导航方法的 Iterator 接口和一个返回迭代器的 Container 接口。实现了 Container 接口的实体类将负责实现Iterator 接口。IteratorPatternDemo，我们的演示类使用实体类 NamesRepository 来打印 NamesRepository 中存储为集合的Names。 创建接口 Iterator.java 1234public interface Iterator &#123; public boolean hasNext(); public Object next();&#125; Container.java 123public interface Container &#123; public Iterator getIterator();&#125; 创建实现了 Container 接口的实体类，该类有实现了 Iterator 接口的内部类 NameIterator NameRepository.java 1234567891011121314151617181920212223242526272829303132public class NameRepository implements Container &#123; public String names[] = &#123;"Robert" , "John" ,"Julie" , "Lora"&#125;; @Override public Iterator getIterator() &#123; return new NameIterator(); &#125; private class NameIterator implements Iterator &#123;``` int index; @Override public boolean hasNext() &#123; if(index &lt; names.length)&#123; return true; &#125; return false; &#125; @Override public Object next() &#123; if(this.hasNext())&#123; return names[index++]; &#125; return null; &#125; ``` &#125;&#125; 使用 NameRepository 来获取迭代器，并打印名字 IteratorPatternDemo.java 1234567891011121314- public class IteratorPatternDemo &#123; public static void main(String[] args) &#123; NameRepository namesRepository = new NameRepository(); ``` for(Iterator iter = namesRepository.getIterator(); iter.hasNext();)&#123; String name = (String)iter.next(); System.out.println("Name : " + name); &#125; ``` &#125; &#125; ## 验证输出 ​ Name : Robert Name : John Name : Julie Name : Lora 总结迭代器模式本质上就是一种遍历聚合对象的方式，这里的聚合对象一般具有较多的实例，比如java中的list等，也就是说对于有些对象，我们更加偏向于它的属性而不是行为，而迭代器模式提供了一种较为隐蔽的遍历这些对象属性的方法，通过经典的hasnext方法和next方法的配合使用，从而实现顺序访问聚合对象中各个元素,而又无须暴露该对象的内部表示。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>行为型模式</tag>
        <tag>迭代器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——解释器模式]]></title>
    <url>%2F2018%2F03%2F25%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述解释器模式（Interpreter Pattern）提供了 评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 介绍意图给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决对于一些固定文法构建一个解释句子的解释器。 何时使用如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决构件语法树，定义终结符与非终结符。 关键代码构件环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例 编译器 运算表达式计算 优点 可扩展性比较好，灵活 增加了新的解释表达式的方式 易于实现简单文法。 缺点 可利用场景比较少 对于复杂的文法比较难维护 解释器模式会引起类膨胀 解释器模式采用递归调用方法 使用场景 可以将一个需要解释执行的语言中的句子表示为一个抽象语法树 一些重复出现的问题可以用一种简单的语言来进行表达 一个简单语法需要解释的场景。 注意事项可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 Demo我们将创建一个接口 Expression 和实现了 Expression 接口的实体类。定义作为上下文中主要解释器的 TerminalExpression类。其他的类 OrExpression、AndExpression 用于创建组合式表达式。InterpreterPatternDemo，我们的演示类使用 Expression 类创建规则和演示表达式的解析。 创建一个表达式接口 Expression.java 123public interface Expression &#123; public boolean interpret(String context);&#125; 创建实现了上述接口的实体类 TerminalExpression.java 12345678910111213141516public class TerminalExpression implements Expression &#123; private String data; public TerminalExpression(String data)&#123; this.data = data; &#125; @Override public boolean interpret(String context) &#123; if(context.contains(data))&#123; return true; &#125; return false; &#125;&#125; OrExpression.java 123456789101112131415public class OrExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public OrExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) || expr2.interpret(context); &#125;&#125; AndExpression.java 123456789101112131415public class AndExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public AndExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) &amp;&amp; expr2.interpret(context); &#125;&#125; InterpreterPatternDemo 使用 Expression 类来创建规则，并解析它们 InterpreterPatternDemo.java 12345678910111213141516171819202122232425262728public class InterpreterPatternDemo &#123; //规则：Robert 和 John 是男性 public static Expression getMaleExpression()&#123;​ Expression robert = new TerminalExpression("Robert");​ Expression john = new TerminalExpression("John");​ return new OrExpression(robert, john); &#125; //规则：Julie 是一个已婚的女性 public static Expression getMarriedWomanExpression()&#123;​ Expression julie = new TerminalExpression("Julie");​ Expression married = new TerminalExpression("Married");​ return new AndExpression(julie, married); &#125; public static void main(String[] args) &#123;​ Expression isMale = getMaleExpression();​ Expression isMarriedWoman = getMarriedWomanExpression();``` System.out.println("John is male? " + isMale.interpret("John")); System.out.println("Julie is a married women? " + isMarriedWoman.interpret("Married Julie"));``` &#125;&#125; 验证输出​ John is male? true Julie is a married women? true]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——命令模式]]></title>
    <url>%2F2018%2F03%2F25%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述命令模式（CommandPattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 介绍意图将一个请求封装成一个对象 ，从而使您可以用不同的请求对客户进行参数化。 主要解决在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决通过调用者调用接受者执行命令，顺序： 调用者→接受者→命令 。 关键代码定义三个角色： received: 真正的命令执行对象 Command invoker: 使用命令对象的入口 应用实例struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点 降低了系统耦合度。 新的命令可以很容易添加到系统中去。 缺点使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景认为是命令的地方都可以使用命令模式，比如： GUI 中每一个按钮(button)都是一条命令。 模拟 CMD。 注意事项系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 Demo我们首先创建作为命令的接口 Order，然后创建作为请求的 Stock 类。实体命令类 BuyStock 和 SellStock，实现了 Order接口，将执行实际的命令处理。创建作为调用对象的类 Broker，它接受订单并能下订单。Broker 对象使用命令模式，基于命令的类型确定哪个对象执行哪个命令。CommandPatternDemo，我们的演示类使用 Broker类来演示命令模式。 创建一个命令接口 Order.java 123public interface Order &#123; void execute();&#125; ## 创建一个请求类 Stock.java 1234567891011121314public class Stock &#123; private String name = "ABC"; private int quantity = 10; public void buy()&#123; System.out.println("Stock [ Name: "+name+", Quantity: " + quantity +" ] bought"); &#125; public void sell()&#123; System.out.println("Stock [ Name: "+name+", Quantity: " + quantity +" ] sold"); &#125;&#125; 创建实现了 Order 接口的实体类 BuyStock.java 1234567891011public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.buy(); &#125;&#125; SellStock.java 1234567891011public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.sell(); &#125;&#125; 创建命令调用类 Broker.java 1234567891011121314151617import java.util.ArrayList;import java.util.List; public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order)&#123; orderList.add(order); &#125; public void placeOrders()&#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125; 使用 Broker 类来接受并执行命令 CommandPatternDemo.java 1234567891011121314151617public class CommandPatternDemo &#123; public static void main(String[] args) &#123;​ Stock abcStock = new Stock();``` BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders();``` &#125;&#125; 验证输出​ Stock [ Name: ABC, Quantity: 10 ] bought Stock [ Name: ABC, Quantity: 10 ] sold 总结命令模式实质上就是将命令抽象到一个具体的类中，即这个类是专门去执行某个命令的，比如demo中，SellStock就是专门执行sell这个命令的，当用户需要sell的时候只要实例化SellStock然后excute就可以完成sell，还有一个比较常用的例子是GUI开发中按钮（button）的作用，每一个按钮都是一个对象，当用户点击某个按钮后就会触发一个相应的命令，用户看到的是点击按钮产生效果，而代码层面上是实例化的按钮对象执行类似于demo中的excute方法完成自己的“命令”。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下如何在pycharm中导入tensorflow]]></title>
    <url>%2F2018%2F03%2F18%2Fubuntu%E4%B8%8B%E5%A6%82%E4%BD%95%E5%9C%A8pycharm%E4%B8%AD%E5%AF%BC%E5%85%A5tensorflow%2F</url>
    <content type="text"><![CDATA[摘要按照tensorflow的官方文档安装完成tensorflow之后可以再终端（Terminal）下激活python环境并使用，但是当你在pycharm下import tensorflow 的时候却会发现报错no this module，以下是解决方案： 原因分析其实无法在pycharm下导入tensorflow的原因是你是将tensorflow安装在了你终端默认的python路径下，而当你使用pycharm创建一个项目时它会默认给你新建一个python虚拟环境，而不会去使用你本地默认的（这就是为什么在终端下可以import tensorflow 而在pycharm中却报错的原因），所以解决这个问题的方法就是在你pycharm的项目中将python环境和你终端默认的python环境设置为同一个： 查看终端python环境所在目录直接在终端输入： $ which python 即可打印出来终端默认的python环境： 设置pycharm中的Project Interpreter步骤如下：File–&gt;setting–&gt;Project:**–&gt;Project Interpreter然后在选择框中选中你终端下查询出来的那一个python路径即可。 可能遇到的问题在Project Interpreter中选中正确的Python环境后可能会报如下错误： ​ pycharm please specify a different SDK name 这个的原因是你当前列表存在与你选中的python环境重名的python环境（一般是你pycharm之前项目建立的python环境），解决方法是删除列表里现有的python环境，直接show all,，然后点击删除就好，删除后再添加你的本地python环境即可import成功。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>tensorflow</tag>
        <tag>pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行为型模式——责任链模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个 接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。在这种模式中，通常 每个接收者都包含对另一个接收者的引用 。 如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推(感觉有点像链表？)。 介绍意图避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。何时使用：在处理消息的时候以过滤很多道。 如何解决拦截的类都实现统一接口。 关键代码Handler 里面聚合它自己，在 HandleRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例 红楼梦中的”击鼓传花” 烽火台？ 优点 降低耦合度：它将请求的发送者和接收者解耦 简化了对象：使得对象不需要知道链的结构 增强给对象指派职责的灵活性，通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任 增加新的请求处理类很方便 缺点 不能保证请求一定被接收 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用 可能不容易观察运行时的特征，有碍于除错 使用场景 有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定 在不明确指定接收者的情况下，向多个对象中的一个提交一个请求 可动态指定一组对象处理请求 实现我们创建抽象类 AbstractLogger，带有详细的日志记录级别。然后我们创建三种类型的记录器，都扩展了AbstractLogger。每个记录器消息的级别是否属于自己的级别，如果是则相应地打印出来，否则将不打印并把消息传给下一个记录器。 创建抽象的记录器类 AbstractLogger.java 12345678910111213141516171819202122232425public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; //责任链中的下一个元素 protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger)&#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message)&#123; if(this.level &lt;= level)&#123; write(message); &#125; if(nextLogger !=null)&#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message);&#125; 创建扩展了该记录器类的实体类 ConsoleLogger.java 1234567891011public class ConsoleLogger extends AbstractLogger &#123; public ConsoleLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Standard Console::Logger: " + message); &#125;&#125; ErrorLogger.java 1234567891011public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Error Console::Logger: " + message); &#125;&#125; FileLogger.java 1234567891011public class FileLogger extends AbstractLogger &#123; public FileLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("File::Logger: " + message); &#125;&#125; 创建不同类型的记录器，赋予它们不同的错误级别，并在每个记录器中设置下一个记录器，每个记录器中的下一个记录器代表的是链的一部分 ChainPatternDemo.java public class ChainPatternDemo { private static AbstractLogger getChainOfLoggers(){ AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger fileLogger = new FileLogger(AbstractLogger.DEBUG); AbstractLogger consoleLogger = new ConsoleLogger(AbstractLogger.INFO); errorLogger.setNextLogger(fileLogger); fileLogger.setNextLogger(consoleLogger); return errorLogger; } public static void main(String[] args) { AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, &quot;This is an information.&quot;); loggerChain.logMessage(AbstractLogger.DEBUG, &quot;This is an debug level information.&quot;); loggerChain.logMessage(AbstractLogger.ERROR, &quot;This is an error information.&quot;); } } 验证输出​ Standard Console::Logger: This is an information. File::Logger: This is an debug level information. Standard Console::Logger: This is an debug level information. Error Console::Logger: This is an error information. File::Logger: This is an error information. Standard Console::Logger: This is an error information. 总结责任链模式的本质就是一条链，通过demo可以发现其实现方式和数据结构中的链表有很相似的地方，思想就是形成一条链，如果当前节点处理不了某些行为，则把这个行为请求转移到其下一级，以此类推，比较常见的实例就是java或者python中经常用到的trycatch机制，当某个方法有可能抛出异常而当前方法无法处理的时候我们就会可能抛出的这个异常throw到外层，即责任链中的下一级。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型设计模式——代理模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 介绍意图为其他对象提供一种代理以控制对这个对象的访问。 主要解决在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用想在访问一个类时做一些控制。 如何解决增加中间层。 关键代码实现与被代理类组合。 应用实例 Windows 里面的快捷方式。 猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 买火车票不一定在火车站买，也可以去代售点。 一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 优点 职责清晰 高扩展性 智能化。 缺点 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 使用场景按职责来划分，通常有以下使用场景： 远程代理 虚拟代理 Copy-on-Write 代理 保护（Protect or Access）代理 Cache代理 防火墙（Firewall）代理 同步化（Synchronization）代理 智能引用（Smart Reference）代理 实现我们将创建一个 Image 接口和实现了 Image 接口的实体类。ProxyImage 是一个代理类，减少 RealImage 对象加载的内存占用。ProxyPatternDemo，我们的演示类使用 ProxyImage 来获取要加载的 Image 对象，并按照需求进行显示。 创建一个接口 Image.java public interface Image { void display(); } 创建实现接口的实体类 RealImage.java public class RealImage implements Image { private String fileName; public RealImage(String fileName){ this.fileName = fileName; loadFromDisk(fileName); } @Override public void display() { System.out.println(&quot;Displaying &quot; + fileName); } private void loadFromDisk(String fileName){ System.out.println(&quot;Loading &quot; + fileName); } } ProxyImage.java public class ProxyImage implements Image{ private RealImage realImage; private String fileName; public ProxyImage(String fileName){ this.fileName = fileName; } @Override public void display() { if(realImage == null){ realImage = new RealImage(fileName); } realImage.display(); } } 当被请求时，使用 ProxyImage 来获取 RealImage 类的对象 ProxyPatternDemo.java public class ProxyPatternDemo { public static void main(String[] args) { Image image = new ProxyImage(&quot;test_10mb.jpg&quot;); //图像将从磁盘加载 image.display(); System.out.println(&quot;&quot;); //图像将无法从磁盘加载 image.display(); } } 验证输出Loading test_10mb.jpg Displaying test_10mb.jpg Displaying test_10mb.jpg 总结现实生活中代理的例子其实很多，比如大家搭建服务器从而实现访问某些xx的网址的访问，其原理其实就是在云端搭建一台云主机，这台主机的地址一般是在可以访问你当前计算机不能访问的xx网址的地域（比如东亚的计算机可以访问很多nj访问不到的xx网址），所以当你想要从xx网址获取信息的时候就可以先把请求发给你搭建的云主机，让它去访问xx，然后再把信息返回给你，这样就像你直接访问了xx一样，这就是代理的意思。回到设计模式，代理模式实际上讲的就是一种“代理访问”的概念，当A类不能暴露给B类而B类又想调用A类的方法的时候必须通过一种折中的方法，即B类通过向可以调用A类的C类发送请求从而让C类调用A类干同样的事情，就是这个意思……具先实现其实也很简单，就是一个代理类将别代理类包裹起来，只对外界暴露调用被代理类方法的方法，从而实现代理模式，需要特别注意的是代理模式和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口 ，和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制 。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>代理模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构型设计模式——享元模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式 。享元模式 尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象 。 介绍意图运用共享技术有效地支持大量细粒度的对象。 主要解决在有大量对象时，有可能会造成内存溢出，我们把其中共同的部分抽象出来，如果有相同的业务请求，直接返回在内存中已有的对象，避免重新创建。 何时使用 系统中有大量对象 这些对象消耗大量内存 这些对象的状态大部分可以外部化 这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替 系统不依赖于这些对象身份，这些对象是不可分辨的 如何解决用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。 关键代码用 HashMap 存储这些对象。 应用实例 JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面。 数据库的数据池。 优点大大减少对象的创建，降低系统的内存，使效率提高。 缺点提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。 使用场景 系统有大量相似对象。 需要缓冲池的场景。 注意事项 注意划分外部状态和内部状态，否则可能会引起线程安全问题。 这些类必须有一个工厂对象加以控制。 实现我们将创建一个 Shape 接口和实现了 Shape 接口的实体类 Circle。下一步是定义工厂类 ShapeFactory。ShapeFactory 有一个 Circle 的 HashMap，其中键名为 Circle对象的颜色。无论何时接收到请求，都会创建一个特定颜色的圆。ShapeFactory 检查它的 HashMap 中的 circle 对象，如果找到Circle 对象，则返回该对象，否则将创建一个存储在 hashmap 中以备后续使用的新对象，并把该对象返回到客户端。FlyWeightPatternDemo，我们的演示类使用 ShapeFactory 来获取 Shape 对象。它将向 ShapeFactory传递信息（red / green / blue/ black / white），以便获取它所需对象的颜色。 创建一个接口 Shape.java public interface Shape { void draw(); } 创建实现接口的实体类 Circle.java public class Circle implements Shape { private String color; private int x; private int y; private int radius; public Circle(String color){ this.color = color; } public void setX(int x) { this.x = x; } public void setY(int y) { this.y = y; } public void setRadius(int radius) { this.radius = radius; } @Override public void draw() { System.out.println(&quot;Circle: Draw() [Color : &quot; + color +&quot;, x : &quot; + x +&quot;, y :&quot; + y +&quot;, radius :&quot; + radius); } } 创建一个工厂，生成基于给定信息的实体类的对象 ShapeFactory.java import java.util.HashMap; public class ShapeFactory { private static final HashMap&lt;String, Shape&gt; circleMap = new HashMap&lt;&gt;(); public static Shape getCircle(String color) { Circle circle = (Circle)circleMap.get(color); if(circle == null) { circle = new Circle(color); circleMap.put(color, circle); System.out.println(&quot;Creating circle of color : &quot; + color); } return circle; } } 使用该工厂，通过传递颜色信息来获取实体类的对象 FlyweightPatternDemo.java public class FlyweightPatternDemo { private static final String colors[] = { &quot;Red&quot;, &quot;Green&quot;, &quot;Blue&quot;, &quot;White&quot;, &quot;Black&quot; }; public static void main(String[] args) { for(int i=0; i &lt; 20; ++i) { Circle circle = (Circle)ShapeFactory.getCircle(getRandomColor()); circle.setX(getRandomX()); circle.setY(getRandomY()); circle.setRadius(100); circle.draw(); } } private static String getRandomColor() { return colors[(int)(Math.random()*colors.length)]; } private static int getRandomX() { return (int)(Math.random()*100 ); } private static int getRandomY() { return (int)(Math.random()*100); } } 验证输出Creating circle of color : Black Circle: Draw() [Color : Black, x : 36, y :71, radius :100 Creating circle of color : Green Circle: Draw() [Color : Green, x : 27, y :27, radius :100 Creating circle of color : White Circle: Draw() [Color : White, x : 64, y :10, radius :100 Creating circle of color : Red Circle: Draw() [Color : Red, x : 15, y :44, radius :100 Circle: Draw() [Color : Green, x : 19, y :10, radius :100 Circle: Draw() [Color : Green, x : 94, y :32, radius :100 Circle: Draw() [Color : White, x : 69, y :98, radius :100 Creating circle of color : Blue Circle: Draw() [Color : Blue, x : 13, y :4, radius :100 Circle: Draw() [Color : Green, x : 21, y :21, radius :100 Circle: Draw() [Color : Blue, x : 55, y :86, radius :100 Circle: Draw() [Color : White, x : 90, y :70, radius :100 Circle: Draw() [Color : Green, x : 78, y :3, radius :100 Circle: Draw() [Color : Green, x : 64, y :89, radius :100 Circle: Draw() [Color : Blue, x : 3, y :91, radius :100 Circle: Draw() [Color : Blue, x : 62, y :82, radius :100 Circle: Draw() [Color : Green, x : 97, y :61, radius :100 Circle: Draw() [Color : Green, x : 86, y :12, radius :100 Circle: Draw() [Color : Green, x : 38, y :93, radius :100 Circle: Draw() [Color : Red, x : 76, y :82, radius :100 Circle: Draw() [Color : Blue, x : 95, y :82, radius :100 总结顾名思义，享元模式体现的就是一种“分享”的实质，即当很多地方都需要用到一个类的对象而实例化这个类又需要耗费很多资源的时候我们就可以把这个类的对象抽取出来，仅仅实例化一次，当以后需要实例化这个类的对象的时候直接把之前实例化的对象返回即可，比如demo中需要实例化不同颜色不同形状的shape对象，而这些对象的存在状态就那么几种，所以使用一个Factory类，当第一次接收到实例化shape类的请求时进行一次实例化并将实例化得到的结果存下来，以后再接收到实例化的请求时直接把之前实例化的同类型的对象返回即可，这样可以大大提高程序执行的效率。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型设计模式——外观模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述外观模式（FacadePattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。 介绍意图为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 主要解决降低访问复杂系统的内部子系统时的复杂度，简化客户端与之的接口。 何时使用 客户端不需要知道系统内部的复杂联系，整个系统只需提供一个”接待员”即可。 定义系统的入口。 如何解决客户端不与系统耦合，外观类与系统耦合。 关键代码在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 应用实例 去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便。 JAVA 的三层开发模式。 优点 减少系统相互依赖。 提高灵活性。 提高了安全性。 缺点不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。 使用场景 为复杂的模块或子系统提供外界访问的模块。 子系统相对独立。 预防低水平人员带来的风险。 注意事项在层次化结构中，可以使用外观模式定义系统中每一层的入口。 实现我们将创建一个 Shape 接口和实现了 Shape 接口的实体类。下一步是定义一个外观类 ShapeMaker。ShapeMaker 类使用实体类来代表用户对这些类的调用。FacadePatternDemo，我们的演示类使用 ShapeMaker 类来显示结果。 创建一个接口。 Shape.java public interface Shape { void draw(); } 创建实现接口的实体类 Rectangle.java public class Rectangle implements Shape { @Override public void draw() { System.out.println(&quot;Rectangle::draw()&quot;); } } Square.java public class Square implements Shape { @Override public void draw() { System.out.println(&quot;Square::draw()&quot;); } } Circle.java public class Circle implements Shape { @Override public void draw() { System.out.println(&quot;Circle::draw()&quot;); } } 创建一个外观类 ShapeMaker.java public class ShapeMaker { private Shape circle; private Shape rectangle; private Shape square; public ShapeMaker() { circle = new Circle(); rectangle = new Rectangle(); square = new Square(); } public void drawCircle(){ circle.draw(); } public void drawRectangle(){ rectangle.draw(); } public void drawSquare(){ square.draw(); } } 使用该外观类画出各种类型的形状 FacadePatternDemo.java public class FacadePatternDemo { public static void main(String[] args) { ShapeMaker shapeMaker = new ShapeMaker(); shapeMaker.drawCircle(); shapeMaker.drawRectangle(); shapeMaker.drawSquare(); } } 验证输出Circle::draw() Rectangle::draw() Square::draw()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型模式——装饰器模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述装饰器模式（DecoratorPattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。我们通过下面的实例来演示装饰器模式的用法。其中，我们将把一个形状装饰上不同的颜色，同时又不改变形状类。 介绍意图动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 主要解决一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用在不想增加很多子类的情况下扩展类。 如何解决将具体功能职责划分，同时继承装饰者模式。 关键代码 Component 类充当抽象角色，不应该具体实现。 修饰类引用和继承 Component 类，具体扩展类重写父类方法。 应用实例 孙悟空有 72 变，当他变成”庙宇”后，他的根本还是一只猴子，但是他又有了庙宇的功能。 不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。 优点装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点多层装饰比较复杂。 使用场景 扩展一个类的功能。 动态增加功能，动态撤销。 注意事项可代替继承。 Demo创建一个接口 Shape.java public interface Shape { void draw(); } 创建实现接口的实体类 Rectangle.java public class Rectangle implements Shape { @Override public void draw() { System.out.println(&quot;Shape: Rectangle&quot;); } } Circle.java public class Circle implements Shape { @Override public void draw() { System.out.println(&quot;Shape: Circle&quot;); } } 创建实现了 Shape 接口的抽象装饰类 ShapeDecorator.java public abstract class ShapeDecorator implements Shape { protected Shape decoratedShape; public ShapeDecorator(Shape decoratedShape){ this.decoratedShape = decoratedShape; } public void draw(){ decoratedShape.draw(); } } 创建扩展了 ShapeDecorator 类的实体装饰类 RedShapeDecorator.java public class RedShapeDecorator extends ShapeDecorator { public RedShapeDecorator(Shape decoratedShape) { super(decoratedShape); } @Override public void draw() { decoratedShape.draw(); setRedBorder(decoratedShape); } private void setRedBorder(Shape decoratedShape){ System.out.println(&quot;Border Color: Red&quot;); } } 使用 RedShapeDecorator 来装饰 Shape 对象 DecoratorPatternDemo.java public class DecoratorPatternDemo { public static void main(String[] args) { Shape circle = new Circle(); Shape redCircle = new RedShapeDecorator(new Circle()); Shape redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println(&quot;Circle with normal border&quot;); circle.draw(); System.out.println(&quot;\nCircle of red border&quot;); redCircle.draw(); System.out.println(&quot;\nRectangle of red border&quot;); redRectangle.draw(); } } 验证输出Circle with normal border Shape: Circle Circle of red border Shape: Circle Border Color: Red Rectangle of red border Shape: Rectangle Border Color: Red 总结装饰者模式顾名思义就是起到一个装饰的作用，即在不改变原来类结构的前提下增加一些新的功能，这种模式一般会产生一个专门的装饰类，联想结构型设计模式的定义（描述不同类之间的关系），装饰者模式实际上描述的就是一个装饰与被装饰的关系，结合上面的demo，被装饰类是实现了shape接口的Rectangle类和Circle类，而装饰类ShapeDecorator是一个抽象装饰类，在其内部定义了装饰shape的方法draw，事实上是一种方法重写（准确来说是增加方法功能），然后在ShapeDecorator的子类RedShapeDecorator中的draw调用了起装饰作用的setRedBorder方法最终达到装饰实现shape子类的目的，从最终的输出也可以看出，装饰类的作用实际上就是在原有类的基础上新增加新的东西，还有一个比较接近现实的例子是玩游戏时开局一个英雄，玩着玩着英雄的装备越来越多、英雄的技能越来越多、英雄的皮肤越来越多，这些效果实际上都是在原来开局裸体（额实在不知道用什么形容词，懂我意思就好～）英雄的基础上装饰进去的，很好地体现了装饰的精髓。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型模式——组合模式]]></title>
    <url>%2F2018%2F03%2F12%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述组合模式（CompositePattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。我们通过下面的实例来演示组合模式的用法。实例演示了一个组织中员工的层次结构。 介绍意图将对象组合成树形结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 主要解决它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以向处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。 何时使用 您想表示对象的部分-整体层次结构（树形结构）。 您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。 如何解决树枝和叶子实现统一接口，树枝内部组合该接口。 关键代码树枝内部组合该接口，并且含有内部属性 List，里面放 Component。 应用实例 算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作符也可以是操作树、操作符和另一个操作数。 在 JAVA AWT 和 SWING 中，对于 Button 和 Checkbox 是树叶，Container 是树枝。 优点 高层模块调用简单。 节点自由增加。 缺点在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。 使用场景部分、整体场景，如树形菜单，文件、文件夹的管理。 注意事项定义时为具体类。 Demo我们有一个类 Employee，该类被当作组合模型类。CompositePatternDemo，我们的演示类使用 Employee类来添加部门层次结构，并打印所有员工。 创建 Employee 类，该类带有 Employee 对象的列表Employee.java import java.util.ArrayList; import java.util.List; public class Employee { private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; //构造函数 public Employee(String name,String dept, int sal) { this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); } public void add(Employee e) { subordinates.add(e); } public void remove(Employee e) { subordinates.remove(e); } public List&lt;Employee&gt; getSubordinates(){ return subordinates; } public String toString(){ return (&quot;Employee :[ Name : &quot;+ name +&quot;, dept : &quot;+ dept + &quot;, salary :&quot; + salary+&quot; ]&quot;); } } 使用 Employee 类来创建和打印员工的层次结构CompositePatternDemo.java public class CompositePatternDemo { public static void main(String[] args) { Employee CEO = new Employee(&quot;John&quot;,&quot;CEO&quot;, 30000); Employee headSales = new Employee(&quot;Robert&quot;,&quot;Head Sales&quot;, 20000); Employee headMarketing = new Employee(&quot;Michel&quot;,&quot;Head Marketing&quot;, 20000); Employee clerk1 = new Employee(&quot;Laura&quot;,&quot;Marketing&quot;, 10000); Employee clerk2 = new Employee(&quot;Bob&quot;,&quot;Marketing&quot;, 10000); Employee salesExecutive1 = new Employee(&quot;Richard&quot;,&quot;Sales&quot;, 10000); Employee salesExecutive2 = new Employee(&quot;Rob&quot;,&quot;Sales&quot;, 10000); CEO.add(headSales); CEO.add(headMarketing); headSales.add(salesExecutive1); headSales.add(salesExecutive2); headMarketing.add(clerk1); headMarketing.add(clerk2); //打印该组织的所有员工 System.out.println(CEO); for (Employee headEmployee : CEO.getSubordinates()) { System.out.println(headEmployee); for (Employee employee : headEmployee.getSubordinates()) { System.out.println(employee); } } } } 验证输出Employee :[ Name : John, dept : CEO, salary :30000 ] Employee :[ Name : Robert, dept : Head Sales, salary :20000 ] Employee :[ Name : Richard, dept : Sales, salary :10000 ] Employee :[ Name : Rob, dept : Sales, salary :10000 ] Employee :[ Name : Michel, dept : Head Marketing, salary :20000 ] Employee :[ Name : Laura, dept : Marketing, salary :10000 ] Employee :[ Name : Bob, dept : Marketing, salary :10000 ] 总结组合模式的要点在于组合和结构，通俗来讲就是通过不同的组合来形成一个体系结构，实现要点是list的使用，以上述demo为例，CEO的下属包含headSales和headMarketing，即CEO这个对象的下属list里面只要添加headSales和headMarketing即可，所以如果把CEO理解为一个东西的话它是由headSales和headMarketing组合而成的（如果没有这两者真不知道CEO存在的意义是什么，一自己当自己的CEO？），而headSales又有若干个salesExecutive下属，所以headSales对象的下属list里面应该添加若干个salesExecutive对象，以此类推（headMarketing由若干个clerk组成）。至此，通过不断的组合，我们就可以由salesExecutive和clerk一路不断组合直到CEO，这就是“组合”的含义，同时也体现了很强的层级关系。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型模式——过滤器模式]]></title>
    <url>%2F2018%2F03%2F12%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%BF%87%E6%BB%A4%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述过滤器模式（Filter Pattern）或标准模式（CriteriaPattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。 Demo我们将创建一个 Person 对象、Criteria 接口和实现了该接口的实体类，来过滤 Person对象的列表。CriteriaPatternDemo，我们的演示类使用 Criteria 对象，基于各种标准和它们的结合来过滤 Person 对象的列表。 实现创建一个类，在该类上应用标准Person.java public class Person { private String name; private String gender; private String maritalStatus; public Person(String name,String gender,String maritalStatus){ this.name = name; this.gender = gender; this.maritalStatus = maritalStatus; } public String getName() { return name; } public String getGender() { return gender; } public String getMaritalStatus() { return maritalStatus; } } 为标准（Criteria）创建一个接口Criteria.java import java.util.List; public interface Criteria { public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons); } 创建实现了 Criteria 接口的实体类CriteriaMale.java import java.util.ArrayList; import java.util.List; public class CriteriaMale implements Criteria { @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) { List&lt;Person&gt; malePersons = new ArrayList&lt;Person&gt;(); for (Person person : persons) { if(person.getGender().equalsIgnoreCase(&quot;MALE&quot;)){ malePersons.add(person); } } return malePersons; } } CriteriaFemale.java import java.util.ArrayList; import java.util.List; public class CriteriaFemale implements Criteria { @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) { List&lt;Person&gt; femalePersons = new ArrayList&lt;Person&gt;(); for (Person person : persons) { if(person.getGender().equalsIgnoreCase(&quot;FEMALE&quot;)){ femalePersons.add(person); } } return femalePersons; } } CriteriaSingle.java import java.util.ArrayList; import java.util.List; public class CriteriaSingle implements Criteria { @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) { List&lt;Person&gt; singlePersons = new ArrayList&lt;Person&gt;(); for (Person person : persons) { if(person.getMaritalStatus().equalsIgnoreCase(&quot;SINGLE&quot;)){ singlePersons.add(person); } } return singlePersons; } } AndCriteria.java import java.util.List; public class AndCriteria implements Criteria { private Criteria criteria; private Criteria otherCriteria; public AndCriteria(Criteria criteria, Criteria otherCriteria) { this.criteria = criteria; this.otherCriteria = otherCriteria; } @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) { List&lt;Person&gt; firstCriteriaPersons = criteria.meetCriteria(persons); return otherCriteria.meetCriteria(firstCriteriaPersons); } } OrCriteria.java import java.util.List; public class OrCriteria implements Criteria { private Criteria criteria; private Criteria otherCriteria; public OrCriteria(Criteria criteria, Criteria otherCriteria) { this.criteria = criteria; this.otherCriteria = otherCriteria; } @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) { List&lt;Person&gt; firstCriteriaItems = criteria.meetCriteria(persons); List&lt;Person&gt; otherCriteriaItems = otherCriteria.meetCriteria(persons); for (Person person : otherCriteriaItems) { if(!firstCriteriaItems.contains(person)){ firstCriteriaItems.add(person); } } return firstCriteriaItems; } } 使用不同的标准（Criteria）和它们的结合来过滤 Person 对象的列表CriteriaPatternDemo.java import java.util.ArrayList; import java.util.List; public class CriteriaPatternDemo { public static void main(String[] args) { List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); persons.add(new Person(&quot;Robert&quot;,&quot;Male&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;John&quot;,&quot;Male&quot;, &quot;Married&quot;)); persons.add(new Person(&quot;Laura&quot;,&quot;Female&quot;, &quot;Married&quot;)); persons.add(new Person(&quot;Diana&quot;,&quot;Female&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;Mike&quot;,&quot;Male&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;Bobby&quot;,&quot;Male&quot;, &quot;Single&quot;)); Criteria male = new CriteriaMale(); Criteria female = new CriteriaFemale(); Criteria single = new CriteriaSingle(); Criteria singleMale = new AndCriteria(single, male); Criteria singleOrFemale = new OrCriteria(single, female); System.out.println(&quot;Males: &quot;); printPersons(male.meetCriteria(persons)); System.out.println(&quot;\nFemales: &quot;); printPersons(female.meetCriteria(persons)); System.out.println(&quot;\nSingle Males: &quot;); printPersons(singleMale.meetCriteria(persons)); System.out.println(&quot;\nSingle Or Females: &quot;); printPersons(singleOrFemale.meetCriteria(persons)); } public static void printPersons(List&lt;Person&gt; persons){ for (Person person : persons) { System.out.println(&quot;Person : [ Name : &quot; + person.getName() +&quot;, Gender : &quot; + person.getGender() +&quot;, Marital Status : &quot; + person.getMaritalStatus() +&quot; ]&quot;); } } } 输出Males: Person : [ Name : Robert, Gender : Male, Marital Status : Single ] Person : [ Name : John, Gender : Male, Marital Status : Married ] Person : [ Name : Mike, Gender : Male, Marital Status : Single ] Person : [ Name : Bobby, Gender : Male, Marital Status : Single ] Females: Person : [ Name : Laura, Gender : Female, Marital Status : Married ] Person : [ Name : Diana, Gender : Female, Marital Status : Single ] Single Males: Person : [ Name : Robert, Gender : Male, Marital Status : Single ] Person : [ Name : Mike, Gender : Male, Marital Status : Single ] Person : [ Name : Bobby, Gender : Male, Marital Status : Single ] Single Or Females: Person : [ Name : Robert, Gender : Male, Marital Status : Single ] Person : [ Name : Diana, Gender : Female, Marital Status : Single ] Person : [ Name : Mike, Gender : Male, Marital Status : Single ] Person : [ Name : Bobby, Gender : Male, Marital Status : Single ] Person : [ Name : Laura, Gender : Female, Marital Status : Married ] 总结过滤器模式就是起一个筛选作用。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型模式——桥接模式]]></title>
    <url>%2F2018%2F03%2F12%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。 介绍意图将抽象部分与实现部分分离，使它们都可以独立的变化。 主要解决在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活。 何时使用实现系统可能有多个角度分类，每一种角度都可能变化。 如何解决把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合。 关键代码抽象类依赖实现类 应用实例 猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化。生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择。 墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的。 优点 抽象和实现的分离 优秀的扩展能力 实现细节对客户透明 缺点桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程 使用场景 如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展 注意事项对于两个独立变化的维度，使用桥接模式再适合不过了 Demo我们有一个作为桥接实现的 DrawAPI 接口和实现了 DrawAPI 接口的实体类 RedCircle、GreenCircle。Shape是一个抽象类，将使用 DrawAPI 的对象，我们的演示类使用 Shape 类来画出不同颜色的圆: 创建桥接实现接口DrawAPI.java public interface DrawAPI { public void drawCircle(int radius, int x, int y); } 创建实现了 DrawAPI 接口的实体桥接实现类RedCircle.java public class RedCircle implements DrawAPI { @Override public void drawCircle(int radius, int x, int y) { System.out.println(&quot;Drawing Circle[ color: red, radius: &quot; + radius +&quot;, x: &quot; +x+&quot;, &quot;+ y +&quot;]&quot;); } } GreenCircle.java public class GreenCircle implements DrawAPI { @Override public void drawCircle(int radius, int x, int y) { System.out.println(&quot;Drawing Circle[ color: green, radius: &quot; + radius +&quot;, x: &quot; +x+&quot;, &quot;+ y +&quot;]&quot;); } } 使用 DrawAPI 接口创建抽象类 ShapeShape.java public abstract class Shape { protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI){ this.drawAPI = drawAPI; } public abstract void draw(); } 创建实现了 Shape 接口的实体类Circle.java public class Circle extends Shape { private int x, y, radius; public Circle(int x, int y, int radius, DrawAPI drawAPI) { super(drawAPI); this.x = x; this.y = y; this.radius = radius; } public void draw() { drawAPI.drawCircle(radius,x,y); } } 使用 Shape 和 DrawAPI 类画出不同颜色的圆BridgePatternDemo.java public class BridgePatternDemo { public static void main(String[] args) { Shape redCircle = new Circle(100,100, 10, new RedCircle()); Shape greenCircle = new Circle(100,100, 10, new GreenCircle()); redCircle.draw(); greenCircle.draw(); } } 输出Drawing Circle[ color: red, radius: 10, x: 100, 100] Drawing Circle[ color: green, radius: 10, x: 100, 100] 总结当一个抽象类有多个实现时，通常用集成来协调他们。抽象类定义对该抽象的接口，而具体子类则用不同方式加以实现。但是此方法的缺点是将子类的抽象部分和实现部分固定在了一起，使得难以对抽象部分和实现部分进行修改、扩充和重用。实现抽象化和实现化之间的解耦，具体到上述demo，抽象化指的是 draw redCircle和drawgreenCircle，如果不使用桥接模式，一般的实现方法是根据用户指令的不同（以参数的形式体现），实现不同的draw方法，而使用桥接模式，Circle类不用关心具体如何根据用户传入参数的不同实现不同的draw方法（即实现化部分），Circle类只需要根据用户传入接口的不同调用draw方法即可，具体的实现全都交给了DrawAPI（GreenCircle、ReadCircle）来做，即将draw这个功能的抽象化放在Circle类，实现化放在DrawAPI（GreenCircle、ReadCircle），从而实现了抽象化和实例化的分离。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[结构型模式——适配器模式]]></title>
    <url>%2F2018%2F03%2F12%2F%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。你将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。 介绍意图将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 主要解决主要解决在软件系统中，常常要将一些”现存的对象”放到新的环境中，而新环境要求的接口是现对象不能满足的。 何时使用 系统需要使用现有的类，而此类的接口不符合系统的需要 想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口 通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。） 如何解决继承或依赖（推荐） 关键代码适配器继承或依赖已有的对象，实现想要的目标接口。 应用实例 美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V 在 LINUX 上运行 WINDOWS 程序 优点 可以让任何两个没有关联的类一起运行 提高了类的复用 增加了类的透明度 灵活性好。 缺点 过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构 .由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。 使用场景有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项适配器不是在详细设计时添加的，而是解决正在服役的项目的问题(即在改装现存代码时可能会用到)。 实现我们有一个 MediaPlayer 接口和一个实现了 MediaPlayer 接口的实体类 AudioPlayer。默认情况下，AudioPlayer可以播放 mp3 格式的音频文件。我们还有另一个接口 AdvancedMediaPlayer 和实现了 AdvancedMediaPlayer 接口的实体类。该类可以播放 vlc 和 mp4格式的文件。我们想要让 AudioPlayer 播放其他格式的音频文件。为了实现这个功能，我们需要创建一个实现了 MediaPlayer 接口的适配器类MediaAdapter，并使用 AdvancedMediaPlayer 对象来播放所需的格式。AudioPlayer 使用适配器类 MediaAdapter 传递所需的音频类型，不需要知道能播放所需格式音频的实际类: Demo为媒体播放器和更高级的媒体播放器创建接口MediaPlayer.java public interface MediaPlayer { public void play(String audioType, String fileName); } AdvancedMediaPlayer.java public interface AdvancedMediaPlayer { public void playVlc(String fileName); public void playMp4(String fileName); } 创建实现了 AdvancedMediaPlayer 接口的实体类VlcPlayer.java public class VlcPlayer implements AdvancedMediaPlayer{ @Override public void playVlc(String fileName) { System.out.println(&quot;Playing vlc file. Name: &quot;+ fileName); } @Override public void playMp4(String fileName) { //什么也不做 } } Mp4Player.java public class Mp4Player implements AdvancedMediaPlayer{ @Override public void playVlc(String fileName) { //什么也不做 } @Override public void playMp4(String fileName) { System.out.println(&quot;Playing mp4 file. Name: &quot;+ fileName); } } 创建实现了 MediaPlayer 接口的适配器类MediaAdapter.java public class MediaAdapter implements MediaPlayer { AdvancedMediaPlayer advancedMusicPlayer; public MediaAdapter(String audioType){ if(audioType.equalsIgnoreCase(&quot;vlc&quot;) ){ advancedMusicPlayer = new VlcPlayer(); } else if (audioType.equalsIgnoreCase(&quot;mp4&quot;)){ advancedMusicPlayer = new Mp4Player(); } } @Override public void play(String audioType, String fileName) { if(audioType.equalsIgnoreCase(&quot;vlc&quot;)){ advancedMusicPlayer.playVlc(fileName); }else if(audioType.equalsIgnoreCase(&quot;mp4&quot;)){ advancedMusicPlayer.playMp4(fileName); } } } 创建实现了 MediaPlayer 接口的实体类AudioPlayer.java public class AudioPlayer implements MediaPlayer { MediaAdapter mediaAdapter; @Override public void play(String audioType, String fileName) { //播放 mp3 音乐文件的内置支持 if(audioType.equalsIgnoreCase(&quot;mp3&quot;)){ System.out.println(&quot;Playing mp3 file. Name: &quot;+ fileName); } //mediaAdapter 提供了播放其他文件格式的支持 else if(audioType.equalsIgnoreCase(&quot;vlc&quot;) || audioType.equalsIgnoreCase(&quot;mp4&quot;)){ mediaAdapter = new MediaAdapter(audioType); mediaAdapter.play(audioType, fileName); } else{ System.out.println(&quot;Invalid media. &quot;+ audioType + &quot; format not supported&quot;); } } } 使用 AudioPlayer 来播放不同类型的音频格式AdapterPatternDemo.java public class AdapterPatternDemo { public static void main(String[] args) { AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play(&quot;mp3&quot;, &quot;beyond the horizon.mp3&quot;); audioPlayer.play(&quot;mp4&quot;, &quot;alone.mp4&quot;); audioPlayer.play(&quot;vlc&quot;, &quot;far far away.vlc&quot;); audioPlayer.play(&quot;avi&quot;, &quot;mind me.avi&quot;); } } 输出Playing mp3 file. Name: beyond the horizon.mp3 Playing mp4 file. Name: alone.mp4 Playing vlc file. Name: far far away.vlc Invalid media. avi format not supported 总结作为两个不兼容的接口之间的桥梁，它结合了两个独立接口的功能。这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。注意，要点是要在原来类的基础上使原本不兼容的功能变得兼容。Adapter类一般是用来实现与原有类不兼容的功能，比如demo中的MediaAdapter实现了MediaPlayer没有的特殊功能，用户只要调用AudioPlayer中的play方法，AudioPlayer会自动根据音频的类型选择不同的play方式，当音频类型不符合传统player的能力时AudioPlayer会使用adapter去调用之前不兼容的方法（功能），这样就实现了所谓的适配。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>适配器模式</tag>
        <tag>结构型模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建型模式——原型模式]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述原型模式（Prototype Pattern）是用于 创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式是实现了一个原型接口， 该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 介绍意图用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 主要解决在运行期建立和删除原型。 何时使用 当一个系统应该独立于它的产品创建，构成和表示时 当要实例化的类是在运行时刻指定时，例如，通过动态装载 为了避免创建一个与产品类层次平行的工厂类层次时 当一个类的实例只能有几个不同状态组合中的一种时 建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些 如何解决利用已有的一个原型对象，快速地生成和原型对象一样的实例。 关键代码 实现克隆操作，在 JAVA 继承 Cloneable，重写 clone()。 原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，它同样要求这些”易变类”拥有稳定的接口。 应用实例 细胞分裂 JAVA 中的 Object clone() 方法。 优点 性能提高 逃避构造函数的约束。 缺点 配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候 必须实现 Cloneable 接口。 使用场景 资源优化场景 类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等 性能和安全要求的场景 通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式 一个对象多个修改者的场景 一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用 在实际项目中，原型模式很少单独出现， 一般是和工厂方法模式一起出现 ，通过 clone 的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用。 注意事项与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写，深拷贝是通过实现Serializable 读取二进制流。 Demo我们将创建一个抽象类 Shape 和扩展了 Shape 类的实体类。下一步是定义类 ShapeCache，该类把 shape 对象存储在一个Hashtable 中，并在请求的时候返回它们的克隆。 创建一个实现了 Clonable 接口的抽象类。Shape.java public abstract class Shape implements Cloneable { private String id; protected String type; abstract void draw(); public String getType(){ return type; } public String getId() { return id; } public void setId(String id) { this.id = id; } public Object clone() { Object clone = null; try { clone = super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return clone; } } 创建扩展了上面抽象类的实体类。Rectangle.java public class Rectangle extends Shape { public Rectangle(){ type = &quot;Rectangle&quot;; } @Override public void draw() { System.out.println(&quot;Inside Rectangle-&gt;draw() method.&quot;); } } Square.java public class Square extends Shape { public Square(){ type = &quot;Square&quot;; } @Override public void draw() { System.out.println(&quot;Inside Square-&gt;draw() method.&quot;); } } Circle.java public class Circle extends Shape { public Circle(){ type = &quot;Circle&quot;; } @Override public void draw() { System.out.println(&quot;Inside Circle-&gt;draw() method.&quot;); } } 创建一个类，从数据库获取实体类，并把它们存储在一个 Hashtable 中ShapeCache.java import java.util.Hashtable; public class ShapeCache { private static Hashtable&lt;String, Shape&gt; shapeMap = new Hashtable&lt;String, Shape&gt;(); public static Shape getShape(String shapeId) { Shape cachedShape = shapeMap.get(shapeId); return (Shape) cachedShape.clone(); } // 对每种形状都运行数据库查询，并创建该形状 // shapeMap.put(shapeKey, shape); // 例如，我们要添加三种形状 public static void loadCache() { Circle circle = new Circle(); circle.setId(&quot;1&quot;); shapeMap.put(circle.getId(),circle); Square square = new Square(); square.setId(&quot;2&quot;); shapeMap.put(square.getId(),square); Rectangle rectangle = new Rectangle(); rectangle.setId(&quot;3&quot;); shapeMap.put(rectangle.getId(),rectangle); } } PrototypePatternDemo 使用 ShapeCache 类来获取存储在 Hashtable 中的形状的克隆PrototypePatternDemo.java public class PrototypePatternDemo { public static void main(String[] args) { ShapeCache.loadCache(); Shape clonedShape = (Shape) ShapeCache.getShape(&quot;1&quot;); System.out.println(&quot;Shape : &quot; + clonedShape.getType()); Shape clonedShape2 = (Shape) ShapeCache.getShape(&quot;2&quot;); System.out.println(&quot;Shape : &quot; + clonedShape2.getType()); Shape clonedShape3 = (Shape) ShapeCache.getShape(&quot;3&quot;); System.out.println(&quot;Shape : &quot; + clonedShape3.getType()); } } 输出Shape : Circle Shape : Square Shape : Rectangle 总结原型模式实现的功能就是对象的拷贝，只不过这种拷贝的功能是在类中定义好的，即在定义类的时候就定义好了一个clone的接口，当这个类对应的对象在某一时刻需要拷贝出另一个对象时，只需调用这个对象的clone方法即可返回一个本对象的克隆体，那么为什么不直接实例化一个新的对象而要采用这种克隆的机制呢？想象一下如果一个类的某些属性的值需要从数据库中查询，这样每实例化一个新类就需要做查询的耗时操作，这时候如果直接用一个已有的对象去clone出一个新的对象就可以避免诸如数据库查询之类的耗时操作，提高了软件的执行效率。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>原型模式</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建型模式——建造者模式]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述建造者模式（BuilderPattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。一个 Builder 类会一步一步构造最终的对象。该 Builder 类是独立于其他对象的。 介绍意图将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 主要解决主要解决在软件系统中，有时候面临着”一个复杂对象”的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。 何时使用一些基本部件不会变，而其组合经常变化的时候。 如何解决将变与不变分离开。 关键代码建造者：创建和提供实例导演：管理建造出来的实例的依赖关系。 应用实例 去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐”。 JAVA 中的 StringBuilder。 优点 建造者独立，易扩展 便于控制细节风险。 缺点 产品必须有共同点，范围有限制 如内部变化复杂，会有很多的建造类。 使用场景 需要生成的对象具有复杂的内部结构 需要生成的对象内部属性本身相互依赖。 Demo我们假设在一个快餐店的商业案例中，一个典型的套餐可以是一个汉堡（Burger）和一杯冷饮（Cold drink）。汉堡（Burger）可以是素食汉堡（VegBurger）或鸡肉汉堡（Chicken Burger），它们是包在纸盒中。冷饮（Colddrink）可以是可口可乐（coke）或百事可乐（pepsi），它们是装在瓶子中。我们将创建一个表示食物条目（比如汉堡和冷饮）的 Item 接口和实现 Item 接口的实体类，以及一个表示食物包装的 Packing 接口和实现Packing 接口的实体类，汉堡是包在纸盒中，冷饮是装在瓶子中。然后我们创建一个 Meal 类，带有 Item 的 ArrayList 和一个通过结合 Item 来创建不同类型的 Meal 对象的MealBuilder。BuilderPatternDemo，我们的演示类使用 MealBuilder 来创建一个 Meal: 创建一个表示食物条目和食物包装的接口Item.java public interface Item { //食物条目（比如汉堡和冷饮） public String name(); public Packing packing(); public float price(); } Packing.java public interface Packing { public String pack(); } 创建实现 Packing 接口的实体类。Wrapper.java public class Wrapper implements Packing { @Override public String pack() { return &quot;Wrapper&quot;; } } Bottle.java public class Bottle implements Packing { @Override public String pack() { return &quot;Bottle&quot;; } } 创建实现 Item 接口的抽象类，该类提供了默认的功能Burger.java public abstract class Burger implements Item { @Override public Packing packing() { return new Wrapper(); } @Override public abstract float price(); } ColdDrink.java public abstract class ColdDrink implements Item { @Override public Packing packing() { return new Bottle(); } @Override public abstract float price(); } 创建扩展了 Burger 和 ColdDrink 的实体类。VegBurger.java public class VegBurger extends Burger { @Override public float price() { return 25.0f; } @Override public String name() { return &quot;Veg Burger&quot;; } } ChickenBurger.java public class ChickenBurger extends Burger { @Override public float price() { return 50.5f; } @Override public String name() { return &quot;Chicken Burger&quot;; } } Coke.java public class Coke extends ColdDrink { @Override public float price() { return 30.0f; } @Override public String name() { return &quot;Coke&quot;; } } Pepsi.java public class Pepsi extends ColdDrink { @Override public float price() { return 35.0f; } @Override public String name() { return &quot;Pepsi&quot;; } } 创建一个 Meal 类，带有上面定义的 Item 对象Meal.java import java.util.ArrayList; import java.util.List; public class Meal { private List&lt;Item&gt; items = new ArrayList&lt;Item&gt;(); public void addItem(Item item){ items.add(item); } public float getCost(){ float cost = 0.0f; for (Item item : items) { cost += item.price(); } return cost; } public void showItems(){ for (Item item : items) { System.out.print(&quot;Item : &quot;+item.name()); System.out.print(&quot;, Packing : &quot;+item.packing().pack()); System.out.println(&quot;, Price : &quot;+item.price()); } } } 创建一个 MealBuilder 类，实际的 builder 类负责创建 Meal 对象MealBuilder.java public class MealBuilder { public Meal prepareVegMeal (){ Meal meal = new Meal(); meal.addItem(new VegBurger()); meal.addItem(new Coke()); return meal; } public Meal prepareNonVegMeal (){ Meal meal = new Meal(); meal.addItem(new ChickenBurger()); meal.addItem(new Pepsi()); return meal; } } BuiderPatternDemo 使用 MealBuider 来演示建造者模式（Builder Pattern）BuilderPatternDemo.java public class BuilderPatternDemo { public static void main(String[] args) { MealBuilder mealBuilder = new MealBuilder(); Meal vegMeal = mealBuilder.prepareVegMeal(); System.out.println(&quot;Veg Meal&quot;); vegMeal.showItems(); System.out.println(&quot;Total Cost: &quot; +vegMeal.getCost()); Meal nonVegMeal = mealBuilder.prepareNonVegMeal(); System.out.println(&quot;\n\nNon-Veg Meal&quot;); nonVegMeal.showItems(); System.out.println(&quot;Total Cost: &quot; +nonVegMeal.getCost()); } } 输出。Veg Meal Item : Veg Burger, Packing : Wrapper, Price : 25.0 Item : Coke, Packing : Bottle, Price : 30.0 Total Cost: 55.0 Non-Veg Meal Item : Chicken Burger, Packing : Wrapper, Price : 50.5 Item : Pepsi, Packing : Bottle, Price : 35.0 Total Cost: 85.5 总结建造者模式与工厂方法模式有类似的地方，但是建造者模式更加关注零件装配的顺序而且生成的对象内部属性本身具有相互依赖性，比如Demo中的食物和对应的容器具有很强的相互依赖性。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[创建型模式——单例模式]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述单例模式（Singleton Pattern）是最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 注意： 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 介绍意图保证一个类仅有一个实例，并提供一个访问它的全局访问点。 主要解决一个全局使用的类频繁地创建与销毁。 何时使用当您想控制实例数目，节省系统资源的时候。 如何解决判断系统是否已经有这个单例，如果有则返回，如果没有则创建。 关键代码构造函数是私有的。 应用实例 一个党只能有一个主席 Windows 是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行 优点 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存） 避免对资源的多重占用（比如写文件操作） 缺点没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 使用场景 要求生产唯一序列号 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 注意事项(这个注意事项放在这么显眼的位置就是为了说明它的重要性)getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance被多次实例化。 Demo我们将创建一个 SingleObject 类。SingleObject 类有它的私有构造函数和本身的一个静态实例。SingleObject 类提供了一个静态方法，供外界获取它的静态实例。 创建一个 Singleton 类SingleObject.java public class SingleObject { //创建 SingleObject 的一个对象 private static SingleObject instance = new SingleObject(); //让构造函数为 private，这样该类就不会被实例化 private SingleObject(){} //获取唯一可用的对象 public static SingleObject getInstance(){ return instance; } public void showMessage(){ System.out.println(&quot;Hello World!&quot;); } } 从 singleton 类获取唯一的对象SingletonPatternDemo.java public class SingletonPatternDemo { public static void main(String[] args) { //不合法的构造函数 //编译时错误：构造函数 SingleObject() 是不可见的 //SingleObject object = new SingleObject(); //获取唯一可用的对象 SingleObject object = SingleObject.getInstance(); //显示消息 object.showMessage(); } } 输出Hello World! 单例模式的几种实现方式单例模式的实现有多种方式，如下所示： 懒汉式，线程不安全是否 Lazy 初始化：是是否多线程安全：否实现难度：易描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。代码实例： public class Singleton { private static Singleton instance; private Singleton (){} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 接下来介绍的几种实现方式都支持多线程，但是在性能上有所差异。 懒汉式，线程安全是否 Lazy 初始化：是是否多线程安全：是实现难度：易描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。优点：第一次调用才初始化，避免内存浪费。缺点：必须加锁 synchronized 才能保证单例，但 加锁会影响效率 。getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。代码实例： public class Singleton { private static Singleton instance; private Singleton (){} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 饿汉式是否 Lazy 初始化：否是否多线程安全：是实现难度：易描述：这种方式比较常用，但容易产生垃圾对象。优点：没有加锁，执行效率会提高。缺点：类加载时就初始化，浪费内存。它基于 classloder 机制避免了多线程的同步问题，不过，instance在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法，但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。代码实例： public class Singleton { private static Singleton instance = new Singleton(); private Singleton (){} public static Singleton getInstance() { return instance; } } 双检锁/双重校验锁（DCL，即 double-checked locking）JDK 版本：JDK1.5 起是否 Lazy 初始化：是是否多线程安全：是实现难度：较复杂描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。getInstance() 的性能对应用程序很关键。代码实例： public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } volatile和synchronized关键字的区别 Java中volatile和synchronized关键字的区别 登记式/静态内部类是否 Lazy 初始化：是是否多线程安全：是实现难度：一般描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。这种方式同样利用了 classloder 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有通过显式调用 getInstance方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。代码实例： public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton (){} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } 枚举JDK 版本：JDK1.5 起是否 Lazy 初始化：否是否多线程安全：是实现难度：易描述：这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。这种方式是 Effective Java 作者 Josh Bloch提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。不过，由于 JDK1.5 之后才加入enum 特性，用这种方式写不免让人感觉生疏，在实际工作中，也很少用。不能通过 reflection attack 来调用私有构造方法。代码实例： public enum Singleton { INSTANCE; public void whateverMethod() { } } 关于java中的enum，详见 这里 经验之谈一般情况下，不建议使用第 1 种和第 2 种懒汉方式，建议使用第 3 种饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用第 5种登记方式。如果涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。如果有其他特殊的需求，可以考虑使用第 4 种双检锁方式。 总结其实单例模式通俗来讲就是让一个类在整个程序中只有一个对象。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java中volatile和synchronized的区别]]></title>
    <url>%2F2018%2F03%2F10%2Fjava%E4%B8%ADvolatile%E5%92%8Csynchronized%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[概述java中volatile和synchronized关键字都是伴随着多线程经常使用的关键字，很多然搞不清楚二者的区别，这篇文章记录下来笔者的一点认识，若有不正确的地方欢迎大家在评论区指出。 区别 volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别 volatile仅能实现变量的修改可见性，不能保证原子性 ；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化 加粗字体部分的原因如下：线程A修改了变量还没结束时,另外的线程B可以看到已修改的值,而且可以修改这个变量,而不用等待A释放锁,因为Volatile 变量没上锁。 举例用在多线程，同步变量。线程为了提高效率，将某成员变量(如A)拷贝了一份（如B），线程中对A的访问其实访问的是B。只在某些动作时才进行A和B的同步。因此存在A和B不一致的情况。volatile就是用来避免这种情况的。volatile告诉jvm，它所修饰的变量不保留拷贝，直接访问主内存中的（也就是上面说的A) 总结synchronized关键字很好理解，就是保证所修饰的变量、方法、和类同时只能被一个xx调用（这里没想好修饰词），而volatile是为了保证变量可以同时被多个线程调用，而且没有上锁，即上面提到的线程A修改了变量还没结束时,另外的线程B可以看到已修改的值，这种机制有利有弊，希望大家使用的时候一定要慎重。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建型模式——抽象工厂模式]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述抽象工厂模式（Abstract FactoryPattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。 介绍意图提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 主要解决主要解决接口选择的问题。 何时使用系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。 如何解决在一个产品族里面，定义多个产品。 关键代码在一个工厂里聚合多个同类产品。 应用实例工作了，为了参加一些聚会，肯定有两套或多套衣服吧，比如说有商务装（成套，一系列具体产品）、时尚装（成套，一系列具体产品），甚至对于一个家庭来说，可能有商务女装、商务男装、时尚女装、时尚男装，这些也都是成套的，即一系列具体产品。假设一种情况（现实中是不存在的，要不然，没法进入共产主义了，但有利于说明抽象工厂模式），在您的家中，某一个衣柜（具体工厂）只能存放某一种这样的衣服（成套，一系列具体产品），每次拿这种成套的衣服时也自然要从这个衣柜中取出了。用OO的思想去理解，所有的衣柜（具体工厂）都是衣柜类的（抽象工厂）某一个，而每一件成套的衣服又包括具体的上衣（某一具体产品），裤子（某一具体产品），这些具体的上衣其实也都是上衣（抽象产品），具体的裤子也都是裤子（另一个抽象产品）。 优点当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。 使用场景 QQ 换皮肤，一整套一起换 生成不同操作系统的程序。 注意事项产品族难扩展，产品等级易扩展。 Demo思路我们将创建 Shape 和 Color 接口和实现这些接口的实体类。下一步是创建抽象工厂类 AbstractFactory。接着定义工厂类ShapeFactory 和 ColorFactory，这两个工厂类都是扩展了 AbstractFactory。然后创建一个工厂创造器/生成器类 : 实现我们的演示类使用 FactoryProducer 来获取 AbstractFactory 对象。它将向 AbstractFactory 传递形状信息Shape（CIRCLE / RECTANGLE / SQUARE），以便获取它所需对象的类型。同时它还向 AbstractFactory 传递颜色信息Color（RED / GREEN / BLUE），以便获取它所需对象的类型。 为形状创建一个接口Shape.java public interface Shape { void draw(); } 创建实现形状接口的实体类Rectangle.java public class Rectangle implements Shape { @Override public void draw() { System.out.println(&quot;Inside Rectangle-&gt;draw() method.&quot;); } } Square.java public class Square implements Shape { @Override public void draw() { System.out.println(&quot;Inside Square-&gt;draw() method.&quot;); } } Circle.java public class Circle implements Shape { @Override public void draw() { System.out.println(&quot;Inside Circle-&gt;draw() method.&quot;); } } 为颜色创建一个接口。Color.java public interface Color { void fill(); } 创建实现颜色接口的实体类Red.java public class Red implements Color { @Override public void fill() { System.out.println(&quot;Inside Red-&gt;fill() method.&quot;); } } Green.java public class Green implements Color { @Override public void fill() { System.out.println(&quot;Inside Green-&gt;fill() method.&quot;); } } Blue.java public class Blue implements Color { @Override public void fill() { System.out.println(&quot;Inside Blue-&gt;fill() method.&quot;); } } 为 Color 和 Shape 对象创建抽象类来获取工厂AbstractFactory.java public abstract class AbstractFactory { abstract Color getColor(String color); abstract Shape getShape(String shape) ; } abstract复习abstract修饰类，会使这个类成为一个抽象类，这个类将不能生成对象实例，但可以做为对象变量声明的类型（见下面代码），也就是编译时类型。抽象类就相当于一类的半成品，需要子类继承并覆盖其中的抽象方法。 创建扩展了 AbstractFactory 的工厂类，基于给定的信息生成实体类的对象ShapeFactory.java public class ShapeFactory extends AbstractFactory { @Override public Shape getShape(String shapeType){ if(shapeType == null){ return null; } if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;)){ return new Circle(); } else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;)){ return new Rectangle(); } else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;)){ return new Square(); } return null; } @Override Color getColor(String color) { return null; } } ColorFactory.java public class ColorFactory extends AbstractFactory { @Override public Shape getShape(String shapeType){ return null; } @Override Color getColor(String color) { if(color == null){ return null; } if(color.equalsIgnoreCase(&quot;RED&quot;)){ return new Red(); } else if(color.equalsIgnoreCase(&quot;GREEN&quot;)){ return new Green(); } else if(color.equalsIgnoreCase(&quot;BLUE&quot;)){ return new Blue(); } return null; } } 创建一个工厂创造器/生成器类，通过传递形状或颜色信息来获取工厂FactoryProducer.java public class FactoryProducer { public static AbstractFactory getFactory(String choice){ if(choice.equalsIgnoreCase(&quot;SHAPE&quot;)){ return new ShapeFactory(); } else if(choice.equalsIgnoreCase(&quot;COLOR&quot;)){ return new ColorFactory(); } return null; } } 使用 FactoryProducer 来获取 AbstractFactory，通过传递类型信息来获取实体类的对象AbstractFactoryPatternDemo.java public class AbstractFactoryPatternDemo { public static void main(String[] args) { //获取形状工厂 AbstractFactory shapeFactory = FactoryProducer.getFactory(&quot;SHAPE&quot;); //获取形状为 Circle 的对象 Shape shape1 = shapeFactory.getShape(&quot;CIRCLE&quot;); //调用 Circle 的 draw 方法 shape1.draw(); //获取形状为 Rectangle 的对象 Shape shape2 = shapeFactory.getShape(&quot;RECTANGLE&quot;); //调用 Rectangle 的 draw 方法 shape2.draw(); //获取形状为 Square 的对象 Shape shape3 = shapeFactory.getShape(&quot;SQUARE&quot;); //调用 Square 的 draw 方法 shape3.draw(); //获取颜色工厂 AbstractFactory colorFactory = FactoryProducer.getFactory(&quot;COLOR&quot;); //获取颜色为 Red 的对象 Color color1 = colorFactory.getColor(&quot;RED&quot;); //调用 Red 的 fill 方法 color1.fill(); //获取颜色为 Green 的对象 Color color2 = colorFactory.getColor(&quot;Green&quot;); //调用 Green 的 fill 方法 color2.fill(); //获取颜色为 Blue 的对象 Color color3 = colorFactory.getColor(&quot;BLUE&quot;); //调用 Blue 的 fill 方法 color3.fill(); } } 输出Inside Circle-&gt;draw() method. Inside Rectangle-&gt;draw() method. Inside Square-&gt;draw() method. Inside Red-&gt;fill() method. Inside Green-&gt;fill() method. Inside Blue-&gt;fill() method. 总结对比工厂方法模式，因为一个工厂只能生产一个产品，比如 博客 中一个ShapeFactory只能根据不同情况实例化不同的Shape，那么当我们需要一整套的产品（比如形状和颜色形成了一套产品）时使用工厂方法显然就不能解决了，所以就需要抽象工厂模式，抽象工厂模式实际上是工厂的工厂，即其作用的目的是为了实例化不同的工厂，用户再通过不同的工厂实例化不同场景下成套的产品。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>抽象工厂</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建型模式——工厂方法(虚构造器)模式]]></title>
    <url>%2F2018%2F03%2F10%2F%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95(%E8%99%9A%E6%9E%84%E9%80%A0%E5%99%A8)%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述工厂模式（Factory Pattern）是 面向对象语言最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 介绍意图定义一个创建对象的接口， 让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行 。 主要解决主要解决接口选择的问题。 何时使用我们明确地计划不同条件下创建不同实例时。 如何解决让其子类实现工厂接口，返回的也是一个抽象的产品。 关键代码创建过程在其子类执行。 应用实例你需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 优点 一个调用者想创建一个对象，只要知道其名称就可以了 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以 屏蔽产品的具体实现，调用者只关心产品的接口。 缺点每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 使用场景日志记录器记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 数据库访问当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 注意事项作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。 Demo我们的demo使用 ShapeFactory 来获取 Shape 对象。它将向 ShapeFactory 传递信息（CIRCLE / RECTANGLE /SQUARE），以便获取它所需对象的类型: 创建一个接口Shape.java public interface Shape { void draw(); } 创建实现接口的实体类Rectangle.java public class Rectangle implements Shape { @Override public void draw() { System.out.println(&quot;Inside Rectangle-&gt;draw() method.&quot;); } } Square.java public class Square implements Shape { @Override public void draw() { System.out.println(&quot;Inside Square-&gt;draw() method.&quot;); } } Circle.java public class Circle implements Shape { @Override public void draw() { System.out.println(&quot;Inside Circle-&gt;draw() method.&quot;); } } 创建一个工厂，生成基于给定信息的实体类的对象ShapeFactory.java public class ShapeFactory { //使用 getShape 方法获取形状类型的对象 public Shape getShape(String shapeType){ if(shapeType == null){ return null; } if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;)){ return new Circle(); } else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;)){ return new Rectangle(); } else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;)){ return new Square(); } return null; } } 使用该工厂，通过传递类型信息来获取实体类的对象FactoryPatternDemo.java public class FactoryPatternDemo { public static void main(String[] args) { ShapeFactory shapeFactory = new ShapeFactory(); //获取 Circle 的对象，并调用它的 draw 方法 Shape shape1 = shapeFactory.getShape(&quot;CIRCLE&quot;); //调用 Circle 的 draw 方法 shape1.draw(); //获取 Rectangle 的对象，并调用它的 draw 方法 Shape shape2 = shapeFactory.getShape(&quot;RECTANGLE&quot;); //调用 Rectangle 的 draw 方法 shape2.draw(); //获取 Square 的对象，并调用它的 draw 方法 Shape shape3 = shapeFactory.getShape(&quot;SQUARE&quot;); //调用 Square 的 draw 方法 shape3.draw(); } } 输出Inside Circle-&gt;draw() method. Inside Rectangle-&gt;draw() method. Inside Square-&gt;draw() method. 总结工厂方法模式其实就是当一个类的实例化依赖于不同场景时需要使用的，比如上面demo，根据不同的形状，实例化的Shape对象内部的实现逻辑不一样，这时候就可以使用工厂方法模式，将类内部的实现细节隐藏起来，用户只需要告诉工厂类自己需要什么情况下的产品，工厂就可以自动调用自己内部对应场景的代码从而返回一个用户需要的“产品”。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列文章概述]]></title>
    <url>%2F2018%2F03%2F10%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是设计模式设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。 都有哪些设计模式创建型模式:对象怎么来这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 具体模式 工厂模式（Factory Pattern） 抽象工厂模式（Abstract Factory Pattern） 单例模式（Singleton Pattern） 建造者模式（Builder Pattern） 原型模式（Prototype Pattern） 结构型模式:对象和谁有关这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 具体模式 适配器模式（Adapter Pattern） 桥接模式（Bridge Pattern） 过滤器模式（Filter、Criteria Pattern） 组合模式（Composite Pattern） 装饰器模式（Decorator Pattern） 外观模式（Facade Pattern） 享元模式（Flyweight Pattern） 代理模式（Proxy Pattern） 行为型模式:对象与对象在干嘛这些设计模式特别关注对象之间的通信。 具体模式 责任链模式（Chain of Responsibility Pattern） 命令模式（Command Pattern） 解释器模式（Interpreter Pattern） 迭代器模式（Iterator Pattern） 中介者模式（Mediator Pattern） 备忘录模式（Memento Pattern） 观察者模式（Observer Pattern） 状态模式（State Pattern） 空对象模式（Null Object Pattern） 策略模式（Strategy Pattern） 模板模式（Template Pattern） 访问者模式（Visitor Pattern） 设计模式的六大原则开闭原则（Open Close Principle）：实现热插拔，提高扩展性对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 里氏代换原则（Liskov Substitution Principle）：实现抽象的规范，实现子父类互相替换里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 依赖倒转原则（Dependence Inversion Principle）：针对接口编程，实现开闭原则的基础这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）：降低耦合度，接口单独设计，互相隔离使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。 迪米特法则，又称最少知道原则（Demeter Principle）：功能模块尽量独立一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle）：尽量使用聚合，组合，而不是继承尽量使用合成/聚合的方式，而不是使用继承。 tip软件体系机构是指一个系统的有目的的设计和规划，这个设计规划既不描述活动，也不描述系统怎样开发，它只描述系统的组成元素及相互的交互协作。一个UML模型只描述了一个系统要做什么，他并没有告诉我们系统怎么做。 参考本系列文章将主要参考：《设计模式——可复用面向对象软件的基础》&amp; http://www.runoob.com/design-pattern/design-pattern-tutorial.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python文件读写的基本操作]]></title>
    <url>%2F2018%2F03%2F06%2Fpython%E4%B8%AD%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[获取某一文件夹下的所有文件： 1files1 = os.listdir(path1)#获取path1下的所有文件（夹） 复制文件： 12import shutilshutil.copyfile(path1, path2)#将path1下的文件复制到path2 从txt文件中获取数据到矩阵中： 12import numpy as npdatai = np.loadtxt(path1) 新建文件夹： 1os.mkdir(path3 ）#新建一个path3文件夹 将numpy矩阵保存到txt文件中： 1np.savetxt(path, result)#将result（矩阵）保存到path路径 重命名文件 1os.rename(path2, path2)#将path1重命名为path2]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用numpy对矩阵进行归一化处理的方法]]></title>
    <url>%2F2018%2F03%2F06%2F%E5%88%A9%E7%94%A8numpy%E5%AF%B9%E7%9F%A9%E9%98%B5%E8%BF%9B%E8%A1%8C%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本文不讲归一化原理，只介绍实现（事实上看了代码就会懂原理），代码如下： ​12345def Normalize(data): m = np.mean(data) mx = max(data) mn = min(data) return [(float(i) - m) / (mx - mn) for i in data] 代码只有5行并不复杂，但是需要注意的一点是一定要将计算的均值以及矩阵的最大、最小值存为变量放到循环里，如果直接在循环里计算对应的值会造成归一化特别慢，笔者之前有过深切的酸爽体验….]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>归一化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python报错 unindent does not match any outer indentation level解决方案]]></title>
    <url>%2F2018%2F03%2F04%2Fpython%E6%8A%A5%E9%94%99%20unindent%20does%20not%20match%20any%20outer%20indentation%20level%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[这种情况一般是因为在写代码的时候混用了TAB和空格进行缩进，所以仔细检查代码缩进，所有缩进对其后错误就会排除。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android中AudioRecord使用详解]]></title>
    <url>%2F2018%2F02%2F26%2FAndroid%E4%B8%ADAudioRecord%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[摘要本文介绍了android中AudioRecord的一些基本使用，主要参考官方文档，本文不讲过多理论知识，主要介绍在实际开发中的使用方法。 类概述AudioRecord类在Java应用程序中管理音频资源，用来记录从平台音频输入设备产生的数据。通过AudioRecord对象来完成”pulling”（读取）数据。 应用通过以下几个方法负责立即从AudioRecord对象读取： 123read(byte[], int, int)read(short[], int, int)read(ByteBuffer, int). 无论使用哪种音频格式，使用AudioRecord是最方便的。 在创建AudioRecord对象时，AudioRecord会初始化，并和音频缓冲区连接，用来缓冲新的音频数据。根据构造时指定的缓冲区大小，来决定AudioRecord能够记录多长的数据。 从硬件设备读取的数据，应小于整个记录缓冲区。 构造函数public AudioRecord (int audioSource, int sampleRateInHz, int channelConfig,int audioFormat, int bufferSizeInBytes) 参数解释audioSource：音频源：指的是从哪里采集音频。这里我们当然是从麦克风采集音频，所以此参数的值为MICsampleRateInHz：采样率：音频的采样频率，每秒钟能够采样的次数，采样率越高，音质越高。给出的实例是44100、22050、11025但不限于这几个参数。例如要采集低质量的音频就可以使用4000、8000等低采样率。channelConfig：声道设置：android支持双声道立体声和单声道。MONO单声道，STEREO立体声audioFormat：编码制式和采样大小：采集来的数据当然使用PCM编码(脉冲代码调制编码，即PCM编码。PCM通过抽样、量化、编码三个步骤将连续变化的模拟信号转换为数字编码。)android支持的采样大小16bit或者8bit。当然采样大小越大，那么信息量越多，音质也越高，现在主流的采样大小都是16bit，在低质量的语音传输的时候8bit足够了。bufferSizeInBytes：采集数据需要的缓冲区的大小，如果不知道最小需要的大小可以在getMinBufferSize()查看。 公共方法public int getAudioFormat ()返回设置的音频数据格式。 public int getAudioSource ()返回音频录制源。 public int getChannelConfiguration ()返回设置的频道设置。 public int getChannelCount ()返回设置的频道数目。 public static int getMinBufferSize (int sampleRateInHz, int channelConfig,int audioFormat) 返回成功创建AudioRecord对象所需要的最小缓冲区大小。注意：这个大小并不保证在负荷下的流畅录制，应根据预期的频率来选择更高的值，AudioRecord实例在推送新数据时使用此值。 参数解释：​12345sampleRateInHz 默认采样率，单位Hz。channelConfig 描述音频通道设置。audioFormat 音频数据保证支持此格式 返回值：如果硬件不支持录制参数，或输入了一个无效的参数，则返回ERROR_BAD_VALUE，如果硬件查询到输出属性没有实现，或最小缓冲区用byte表示，则返回ERROR。 public int getNotificationMarkerPosition ()返回通知，标记框架中的位置。 public int getPositionNotificationPeriod ()返回通知，更新框架中的时间位置。 public int getRecordingState ()返回AudioRecord实例的录制状态。 public int getSampleRate ()返回设置的音频数据样本采样率，单位Hz。 public int getState ()返回AudioRecord实例的状态。 这点非常有用，用在AudioRecord 实例创建成功后，检查初始化属性。 它能肯定请求到了合适的硬件资源。 public int read (short[] audioData, int offsetInShorts, int sizeInShorts)从音频硬件录制缓冲区读取数据。 参数解释：​12345audioData 写入的音频录制数据。offsetInShorts 目标数组 audioData 的起始偏移量。sizeInShorts 请求读取的数据大小。 返回值：返回short型数据，表示读取到的数据，如果对象属性没有初始化，则返回ERROR_INVALID_OPERATION，如果参数不能解析成有效的数据或索引，则返回ERROR_BAD_VALUE。返回数值不会超过sizeInShorts。 public int read (byte[] audioData, int offsetInBytes, int sizeInBytes)从音频硬件录制缓冲区读取数据。 参数解释：​ audioData 写入的音频录制数据。 offsetInBytes audioData的起始偏移值，单位byte。 sizeInBytes 读取的最大字节数。 返回值：读入缓冲区的总byte数，如果对象属性没有初始化，则返回ERROR_INVALID_OPERATION，如果参数不能解析成有效的数据或索引，则返回ERROR_BAD_VALUE。读取的总byte数不会超过sizeInBytes。 public int read (ByteBuffer audioBuffer, int sizeInBytes)从音频硬件录制缓冲区读取数据，直接复制到指定缓冲区。 如果audioBuffer不是直接的缓冲区，此方法总是返回0。 参数解释：​ audioBuffer 存储写入音频录制数据的缓冲区。 sizeInBytes 请求的最大字节数。 返回值：读入缓冲区的总byte数，如果对象属性没有初始化，则返回ERROR_INVALID_OPERATION，如果参数不能解析成有效的数据或索引，则返回ERROR_BAD_VALUE。读取的总byte数不会超过sizeInBytes。public void release ()：释放本地AudioRecord资源。对象不能经常使用此方法，而且在调用release()后，必须设置引用为null。 public int setNotificationMarkerPosition (int markerInFrames)如果设置了setRecordPositionUpdateListener(OnRecordPositionUpdateListener)或setRecordPositionUpdateListener(OnRecordPositionUpdateListener,Handler)，则通知监听者设置位置标记。 参数解释： markerInFrames 在框架中快速标记位置。 返回值：返回错误或成功代码，请见SUCCESS、ERROR_BAD_VALUE、ERROR_INVALID_OPERATION。 public int setPositionNotificationPeriod (int periodInFrames)如果设置了setRecordPositionUpdateListener(OnRecordPositionUpdateListener)或setRecordPositionUpdateListener(OnRecordPositionUpdateListener,Handler)，则通知监听者设置时间标记。 参数解释：​ markerInFrames 在框架中快速更新时间标记。 返回值返回错误或成功代码 public void setRecordPositionUpdateListener(AudioRecord.OnRecordPositionUpdateListener listener, Handler handler) 当之前设置的标志已经成立，或者周期录制位置更新时，设置处理监听者。 使用此方法来将Handler 和别的线程联系起来，来接收AudioRecord事件，比创建AudioTrack 实例更好一些。 参数解释：​ handler 用来接收事件通知消息。 public void setRecordPositionUpdateListener(AudioRecord.OnRecordPositionUpdateListener listener) 当之前设置的标志已经成立，或者周期录制位置更新时，设置处理监听者。 public void startRecording ()AudioRecord实例开始进行录制。 受保护方法protected void finalize ()通知VM回收此对象内存。 此方法只能用在运行的应用程序没有任何线程再使用此对象，来告诉垃圾回收器回收此对象。 此方法用于释放系统资源，由垃圾回收器清除此对象。 默认没有实现，由VM来决定，但子类根据需要可重写finalize()。在执行期间，调用此方法可能会立即抛出未定义异常，但是可以忽略。 注意：VM保证对象可以一次或多次调用finalize()，但并不保证finalize()会马上执行。例如，对象B的finalize()可能延迟执行，等待对象A的finalize()延迟回收A的内存。为了安全起见，请看ReferenceQueue，它提供了更多地控制VM的垃圾回收。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>AudioRecord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《颠覆者》]]></title>
    <url>%2F2018%2F02%2F25%2F%E3%80%8A%E9%A2%A0%E8%A6%86%E8%80%85%E3%80%8B%2F</url>
    <content type="text"><![CDATA[摘要本博客主要记载国内第一民间网络安全公司360创始人兼CEO周鸿祎的自传《颠覆者》中较为经典的语录。 正文实现自我颠覆的人都有一点共性。通过我的观察，最终能够实现这种颠覆的人，都有着强烈的“内在驱动力”和“使命感”，如同万维钢在《智识分子》这本书里写到的那样：“内在动力才真正体现了一个人的自由意志，我之所以这么干不是谁刺激我，而纯粹是因为我就想这么干。对于这些人来说，工作已经不是简单的上下班的事了，而是一项事业。他们做这件事不需要外界的监督和激励，是自己要求自己非要把这件事情做成不可。所以真正了不起的事业应该是由使命感驱动” 所谓英雄，就是超越了阶层出身、超越了周边环境、超越了性格局限，拒绝按照任何设定好的程序行事，不能被大数据预测，能给世界带来惊喜，最不像机器的人。（万维钢《智识分子》） 英雄，不是那些被大数据预测的俗人，他们，让这个世界变得有意思。 从零到一，每个创业者在从无到有创立一家公司后，都要经受非人的考验，每一天都有形式不同的突发情况，大家都要经历那种面对突发情况的紧、九死一生的惊险、迅速做出决定的逼仄、死而复生的恍惚。这所有的一切都如同本.霍洛维茨 在《创业维艰》中描述的那样——解决这些难题，没有任何公式套路可用。 但让人无奈的是，每一次美国做空机构都是在他们的白天发布报告，而我不得不在中国的半夜把员工叫起来开会应对。这样的剧情如此反复循环重复，实在让人睡眠不足。 在我从事软件行业的时候，很少有人直到软件是什么，电脑只是一个行业，电脑工程师只是一个职业。但是今天，无论是手机APP，还是智慧城市、电子政务、物联网（IOT），以及将来的无人驾驶汽车，很多东西都和软件息息相关。人们开始说，软件定义世界，一切皆可编程，万物均要互联。 我认为一个企业的存在不在于你的股价有多高，因为股价再高，随着历史的推进，有一天也终会跌到零；也不在于企业有多少利润，这些东西都会随着时间的流逝而消逝。有的公司消逝了大家可能感觉无所谓，或者很快就有替代产品出现，大家不觉得缺这样一家公司别人会为它感到难过。我希望我们能做一家让大家离不开的公司。 作为一个决策者，做决定很多时候都要面临艰难的处境，但是决策必须当机立断，正如 本.霍洛维茨在《创业维艰》里说的那样——那些看似微不足道的踌躇和犹豫，可能会造成致命的延误。我承担不起任何犹豫不决。 虽然有精忠报国的愿望，也对未来充满了希望。但是市场不相信口号，也不相信眼泪，投资人不会为你的理想买单， 如果对360的私有化做一个比喻，我觉得这个过程就像我们半夜在盘山公路狂奔，没有开灯。但是回头看，幸亏我们没有开灯。如果直到路途如此惊险，也许在路途中，我们早已吓得魂飞魄散。 真正的勇敢，并非骁勇善战，而是无论何时何地都不忘初心，坚守信仰，并秉持自己始终不会放弃的那种纯粹。 人类社会经历过的PC互联网时代、移动互联网时代，以及现在所处的物联网时代，技术发展和商业模式创新之间始终是相辅相成的关系，每当科技发展的红利被商业模式创新挖掘殆尽后，经济也随之步入寒冬，直到下一次技术革命的出现，商业模式创新才能重新迸发生机。 现阶段移动互联网的商业模式创新已经挖光了Web2.0时代的技术红利，所有人都在寻找新技术，以期获得新的商业模式创新。人工智能技术无疑就是下一轮技术革命的焦点，假如未来的某一天，我们在这方面有了突破，那么新的商业模式也将涌现出来，带来一个甚至多个万亿级市场。 在我们的世界中，科技已经如自然一样成为一股强大的力量，而我们将借助这种力量，乘风破浪。对于人工智能时代的来临，我愿意引用 凯文.凯利在《必然》中描述的场景，对此我深信不疑： 千年之后，当历史学家回溯过往的时候，会认为第三个千禧之年的开端是一个古老的绝妙时代。在这个时代中，地球上的居民首次把自己与一种巨大的失误相连。未来，它的规模将会继续增加，但是如今，你我正生活在它刚刚苏醒的时刻。 未来的人们会羡慕我们，希望自己也能亲眼见证它的诞生。这些年里，人类开始用微小的智能让没有生气的事物变得活跃，把他们编织进云端机器智能这张大网中，并将数十亿心智作为一个超级心智相连。 这个聚拢的过程将被当做这个星球上迄今为止发生的最重要的、最负责任也是最令人惊叹的事件。 单纯的理工男经常缺乏基本的人文认知，就算技术再好也有软肋。 文字素养是一个人的基本素养。文字不好，你没有办法写出一个漂亮的商业计划书，前言不搭后语而经常错失投资人；文字不好，你没有办法成为一个好的产品经理，因为你没有办法精准地描述出产品的功能，打动不了用户；文字不好，你不能和竞争对手在公开领域沟通，做不出好的PR（公关），甚至连场口水仗都赢不了。 《史蒂夫.乔布斯传》、《富兰克林传》、《爱因斯坦传》的作者 沃尔特.艾萨克森在写了这些伟人的传记后从他们的身上得出了：一个具有强烈个性的人身上集合了人文和科学的天赋后所产生的那种创造力，我相信这种创造力也是在21世纪建立创新型经济的关键因素。 尽管破旧的城市、沉闷的生活，以及正统的世界让我没有方向，但是计算机那扇窗已经略微地打开了，若隐若现的光照射进来，变成了我每天生活的希望。 作为一个年轻人，真正幸运的并不是在很年轻的时候就得到了很多财富，而是在成年之前就感受到了自己来到这个世界的使命，有了目标之后努力才不会盲目。 丹尼尔.科伊尔在《一万小时天才理论》中说：“在未来某些时候，也许已经发生了——你会坠入爱河。不是和某个人，而是和某个你自己的想法——关于你想成为谁，关于你生来会成为谁。这种爱，这种激情，就是发展才能的原始燃料”。 “我的理想很明确，这辈子就要做一个电脑软件的开发者。做一款产品，改变世界”。 ——周鸿祎在高二班会上关于自己理想的描述 乔布斯说：“一个人开始热爱一件事的时候，就会达到一种非理性的状态”。 做一件事情总要不计回报，一旦投入了全部的感情，最后的回报总会出其不意地到来。 做产品不能总从程序员和产品经理的角度出发，还要化繁为简，达到使用的极简主义。 我的大学很充实，但似乎很难用开心和不开心来总结。开心来自简单的事情：吃了一顿好饭、听了一首好歌、疯狂地读了一晚上程序，或者暑假的时候邮购了音响零件，自己制成了一个噪声巨大的音响。而不开心的时候也是有的：走在西安交通大学的林荫大道上，没有姑娘的瞩目，没有浪漫的故事，有的只是一颗理工男的寂寞心，偶尔悲壮。 如果一个社会只以成败论英雄，或者只以金钱多少论英雄，是不可能激励年轻人创新的。 注册公司只是创业的形式，创业的关键在于推出什么样的产品。 周鸿祎描述当初创业做反病毒卡的自己：“一个希望以查杀计算机病毒起家的学生公司，需要每天在电脑上调试程序，寻找病毒特征，而此时，我们连一台属于自己的计算机都没有。” 王朔在《玩的就是心跳》中说：“我们受的教育一贯是把个人置于一种渺小的境界。这是我们的悲剧，也是我们的习惯，很明白却无能为力”。 现实世界让我认识到，客户使用产品的环境远远比试验中的环境复杂，你必须从客户的角度去考虑和解决问题。从那个时候开始，我作为技术专家的优越感和自负被砍掉，这就是做第一个产品让我悟出的道理。 做生意并不像想象中的那样充满浪漫，做生意是丑陋的、累心的、让人见识冷血和无情的。 当我们尝试一个新技能时，我们就像进入黑屋子的人，总是碰到家具，但是每次碰撞都会让我们明确往哪走。我们不应该忽视错误或者试图忘记它们，因为它们为我们指出了道路所在，同时为我们指出了一个事实，那些不敢冒险的人就无法施展它们的才华。——《一万小时天才理论》 固执是产品经理的大敌。 在任何一个领域想要出众，都是要经过至少一万小时的练习才可以。并且，这些练习并不是在你的舒适区进行，而是要在容易犯错的地方进行精深练习。 以我自身经验来说，大学生也好，研究生也好，我已经算是比一般的学生更接近社会三教九流的人了，但是当我真正走出去的时候，我还是感觉离真正的时长太远太远了。 创业是一种精深，但是不要为了创业而创业，不要把创业狭义地理解为开公司，当CEO。这种事情太容易了，但是它未必成功。 无论你做什么，所有的努力都不会白费。 今天的辛苦，就是明天的财富。 关于谈恋爱，我并不是很在行，我很少地会讨好地说一些甜言蜜语去“撩妹”，一般只是讲述自己的事儿。那个时候我还是个很落魄的小工程师，每个月的收入只有1000块，没单独的地方住，每天在北大食堂蹭饭吃，外表看上去毫不起眼。在胡欢（周鸿祎的妻子）面前，我喜欢讲述自己过去创业的经历，大谈特谈自己的梦想、未来自己想做的事，我讲到我会怎么样用一个软件或者程序去改变世界，一副“`天将降大任于斯人也”的样子。一般女孩看到我这样的人，会觉得我有点不切实际，或者是神经病，但是胡欢没有这样认为。她一直坚信我说的是真的，并且后来也一直用行动支持着我。 做产品的人往往都会把自己的主观感受无限放大，把自己的需求认为是所有人的需求。 高瞻远瞩不是天生的，每个人的见识都是一点一点积累出来的。 很多互联网的成功其实都不是技术的成功，而是商业模式和理念的成功。 周鸿祎关于“裸辞”的回忆：“我就是当年‘裸辞’的程序员一名。除了我以外，第一代互联网创业者都在当时纷纷‘裸辞’了，丁磊和马云辞得更彻底。《沸腾十五年》里记录：1995年，丁磊从宁波电信局辞职，按照规定，这个时候大学生辞职要补偿国家培养大学生的费用，要交1万元。但丁磊当时没有那么多钱，只能提着箱子离开了单位，结果按照除名处置。同一年，马云向杭州电子科技大学提出辞职，第二天就借了10万元注册公司。他们比‘裸辞’做得更进一步，一辞职就负债了，比‘裸辞’更绝”。 创业者的孤独，不仅仅是要忍受创业路上资金的捉襟见肘、寻找投资人的种种困难，还要承受大多数人可能根本听不懂你创意的现实，一瞬间，你变成了孤独的星球。 互联网公司开发布会其实是挺可笑的一件事，最牛的互联网产品应该是人们使用过之后觉得这个产品太好了，急不可待地介绍给周围的朋友。最后用户量通过口碑营销不知不觉地就涨起来了。产品做得不好，发布会开的再绚烂也没用，这都是在漫无目的地烧钱。 很多创业者长期沉浸在自己的世界里，相信自己的直觉和判断，有的时候甚至到了偏执的状态，听不进去有经验人的劝解，最终错过了发展黄金期。 创业，每天都是在走钢丝，每天都是在做选择题，每天都在对抗杂乱无章的信息。很多创业者的路，都是在一片从未有过脚印的土地上一路走过来的。谁痛苦谁知道。 竞争对手是你的磨刀石，竞争对手越强大，对你的磨炼和考验越大，很多坚强的性格，都是残酷的市场竞争的衍生品。狼性和血性都是伴随着对人性的观察和考验而来的。 市场竞争，绝不会留给竞争者闪烁一个悲伤眼神的时间。 你以为自己已经跌倒了谷底，其实还有更深的深渊在前方等待，这是创业者时常遇到的境遇。 互联网上的应用，多一步就是99%的损耗。 一个公司对用户不作恶是成功的基础。 韦尔奇在《商业的本质》中写到：这是一种很稀缺的优秀品质。我们谈论的不是对风险的普通容忍。要成为一个企业家，你需要极大的勇气、疯狂的激情和超出理性的决心，忍受反复出现的近乎死亡的体验。 品牌延伸让新的产品在人们心目中没有自己独立的位置，还会让原来的品牌地位模糊不清，结往往是灾难性的。 对于跟随者来说，跟风发起跟风产品，绝对不是好的策略，因为好的品牌已经在消费者的心中占据了统治地位，这种地位一时间很难挑战。新的公司只有在大公司的业务机构里寻找薄弱环节，跟随者才有厚积薄发的可能。 作为一家技术公司，别的都是虚的，用户体验才是最重要的。 富贵非吾志。但知临水登山啸咏，自引壶觞自醉。此生天命更何疑？且乘流，遇坎还止步。 成功都是熬出来的，成功都是被逼出来的，很多时候，是看你熬不熬得住。 互联网是不断变化的，经验往往是靠不住的，你必须随时处于归零状态，从用户角度出发，随时把握用户新的需求。 只要在江湖，就难以避免征战，难以避免经理一些黑暗的时光；只要在江湖，就经常面临利益与长远的选择。 真正的光明却不是没有黑暗的时间，只是永不被黑暗所掩蔽罢了。真正的英雄绝不是没有卑下的情操，只是永不被卑下的情操屈服罢了。 只要是人人都需要的，就应该是免费的。 任何企业都可以找最强的竞争对手打，但是有一个对手是你打不过的，那就是趋势，趋势一旦爆发，就不会是一种线性的发展。它会积蓄力量于无形，然后突然爆发出雪崩效应。任何不愿意改变的力量都会在雪崩面前被毁灭，被市场边缘化。 将来会有越来越多的管理者认识到，保守而谨慎，必将引向毁灭之路，而不可能逃避经济风暴的摧残或将此作为长治久安的生存方式。 互联网公司之间竞争的严酷程度大大超过了普通的商业战争，大家都无所不用其极。 中国做互联网的人，一定会遇到三个无法回避的问题：生、死、腾讯。 任何做客户端的都怕腾讯，主要是怕两方面：第一是被它抄袭，第二是它厉害的推广平台。 真正的难题不是拥有伟大的梦想，而是你在半夜一身冷汗地惊醒时，发现梦想变成了一场噩梦。 ——《创业维艰》 商场就是战场，我们同样是战场上的军人，商业竞争对手就是我们的敌人，他们像饥饿的狼群一样守候在我们的身旁，随时准备吞噬着我们的客户。如果我们畏惧、退让，那么他们张开的血盆大口就会连同我们一起吞噬。 任何中国的互联网创业公司发展到一定的阶段，必然会遭遇腾讯“抄袭+捆绑”的“水泥天花板”。 正如人体骨骼在负重和压力下反而会越发强壮，谣言和暴动在遏制和镇压下反而愈演愈烈一样，我们生活中的许许多多事物也会从压力、混乱、波动和动荡中受益。 创业就像是搏击，不仅是因为要不停痛击你的对手。创业艰辛而孤独，需要持续不断地集中注意力。无论你做的多好，你都必须时刻准备再一次出拳打击。在搏击中，你被打了，感到痛苦不堪，然后你坐在场边，等肾上腺素消逝后，你才真切感受到那疼痛，然后，你要再去打下一回合。 似乎每个创业者在外界看来都是气势汹汹，但是每个人的心里有很多不踏实的地方，没有安全感。也许正是这种特质，造就了这类人容易成就一番事业。一个容易骄傲自满的人，不可能走得长远。 人们总是问我：当一名CEO的秘诀是什么？遗憾的是，没有秘诀。如果说存在这样一种技巧，那就是看其专心致志的能力和在无路可走时选择最佳路线的能力。与普通人相比，那些令你想躲藏起来甚至直接死掉的时刻，就是你作为一名CEO要经历的不同于常人的地方。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2017年度总结]]></title>
    <url>%2F2018%2F02%2F15%2F2017%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[写在前面：讲道理我是不太擅长于写这类非技术性的博文，但是觉得一眨眼又走过了一年，是得停下脚步回头看看，写点东西记录一下这一年的得失、展望一下新的一年，为新的一年立一些flag，如果没有什么意外以后每一年的年末我都会写一篇这样的总结性文章作为自己成长路上的标记，希望若干年后的自己可以通过这些东西看到当年的自己。 学习其实今年前期还是很在意学习方面的，也花费了很多时间在平时的课程上，可是好像out和in有点不对应，而且挤掉了很多本该用来做自己喜欢的事情上的时间，到后来就干脆顺其自然，没有太在意这方面，事实证明好像也没太大负面影响，而且可以有很多时间去研究自己感兴趣的东西，觉得这样挺好。但是回过头来客观来说还是学渣一枚（哭），看看身边大佬的绩点再看看自己的真的被虐到了，希望在新的一年里在学业上可以有进步，起码绩点不要太低，最好英语过六级哈哈 技术今年前期重点主要放在了开发类上面，利用时间做了几个hobbyproject，基本上都是android项目，接了几个朋友介绍的外包都是做一些边缘开发没有做到很核心的大项目，这和自己的技术不过关有很大的关系，后来在老哥的指导下基本弃了开发类的学习转到DL方面，帮着别人做了两个DL的基础识别应用觉得很受鼓舞，还有就是参加了创新工场的场景分类比赛拿到了名次，但是想一下这些东西都只是套别人的模型做了一下复现，很多核心的理论知识都不懂，所以希望新的一年可以静下心来研究一下DL的相关原理，打好理论基础。 work今年暑假本来有机会去网易做实习，但是由于提前被国防企业面对面的活动埋进坑里再加上对自己的技术不是很自信所以就阴差阳错丢掉了机会，寒假又不想离家太远想回家陪爸妈所以更没时间，希望2018的自己可以去参加一两场实习跟着老哥混混职场，也为了给简历上加两行字哈哈。 比赛今年好像大大小小也参加了十几场比赛，拿了一点奖（大多都是参与奖哈哈），但是也搞了很多和专业不想关的比赛（比如环保知识竞赛……我也不知道当时怎么就脑抽参加这种比赛），在比赛中认识了很多大牛，增长了自己的见识，希望明年的自己可以少参加一些没必要的比赛，把主要精力放在对自己重要的比赛上，这样可能产值会高一点。 科创科创刚开题的那段时间好像什么都想做，觉得好像一个月就能肝完一个项目，后来阴差阳错接到超哥的题目，才发现都是自己太单纯，各种问题源源不断，到现在也没一个理想的成果，说到底还是自己太浮躁太心急，希望新年可以静下心来耐心搞完这个题目，至于明年还要不要再接科创就要看明年科创开题时的心情了说不定到时候一抽风又给自己背个锅，不管怎么样一定保佑今年的题目结题啊！！！ 感情今年前半年我还是有女朋友的，可是到这会早就成一个人撸键盘了，老铁们都说是我情商太低，我觉得也是哈哈，毕竟自己几乎把所有空闲时间都给了电脑键盘，谁也受不了啊，所以就顺其自然吧，相信缘分就好。 鸡汤之前一直觉得搞技术的就得老老实实学技术，直到后来老哥的话改变了我的想法，从吴军的专栏到逻辑思维的某些文章再到周鸿祎的自传，让我懂了互联网行业不光是有技术就行，还得有不可言说的境界与见识，希望18年的自己可以抽一些时间补一些行业的经典读物，提升一下自己的见识与境界。 总结这会觉得自己过去的一年好像一事无成，觉得自己过去的一年很浮躁，忙忙碌碌一年也没什么太大的收获，希望18年的自己可以静下心来做一些应该做的事情，希望明年这个时候可以有更多的收获，加油！]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>年终总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android动态权限申请]]></title>
    <url>%2F2018%2F01%2F25%2FAndroid%E5%8A%A8%E6%80%81%E6%9D%83%E9%99%90%E7%94%B3%E8%AF%B7%2F</url>
    <content type="text"><![CDATA[摘要本文介绍了如何用最短的代码解决Android 6.0以上的动态权限申请问题 说明：本文不讲原理不讲过程只讲如何用最简单的方法使用，如想了解具体原理可深入工具类的源码进行学习，或者去找其他资源。 添加相关依赖在你项目的app gradle的dependencies下添加下列语句： ​1implementation 'com.github.dfqin:grantor:2.1.0' 添加后Sync，即可将相关工具代码导入 代码实现动态权限申请首先要保证在manifests里面加上你需要的权限，然后在MainActivity中添加如下方法： ​12345678910111213141516171819private void RequestPermission() &#123; String[] permissions = &#123;Manifest.permission.RECORD_AUDIO, Manifest.permission.WRITE_EXTERNAL_STORAGE&#125;; if (PermissionsUtil.hasPermission(MainActivity.this, permissions)) &#123; //已经获取相关权限 &#125; else &#123; PermissionsUtil.requestPermission(MainActivity.this, new PermissionListener() &#123; @Override public void permissionGranted(@NonNull String[] permission) &#123;//用户授予了权限 &#125; @Override public void permissionDenied(@NonNull String[] permission) &#123;//用户拒绝了权限 Toast.makeText(MainActivity.this, "相关权限被拒绝，本应用将无法正常运行", Toast.LENGTH_SHORT).show(); &#125; &#125;, permissions); &#125; &#125; 然后在OnCreate中调用该方法即可，如果要申请其他的权限只需要把本文代码中permissions的内容改成你自己的即可。 参考 http://blog.csdn.net/dfqin/article/details/55190073 感谢博主提供的轮子。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>动态权限申请</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八大常见排序算法介绍]]></title>
    <url>%2F2018%2F01%2F13%2F%E5%85%AB%E5%A4%A7%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[直接插入排序算法思想首先将第二个数与第一个数进行对比，如果第二个数比第一个数小，则将第二个数插入到第一个数之前，这样保证前两个数是有序的；接下来将第三个数与前两个数对比，发现有比第三个数大的数即将第三个数插入到对应数的前面，这样一次插入可保证前三个数是有序的；以此类推，将后面的i个数分别其前面的i-1个数进行对比，并将其插入到第一个比其大的数前面，最后即可完成排序。 时间空间复杂度及稳定性 T(n)=O(n^2) S(n)=O(1) 稳定 代码​1234567891011121314void InsertSort(vector&lt;int&gt; v) &#123; for (int i = 1; i &lt; v.size(); ++i) &#123; for (int j = 0; j &lt; i; ++j) &#123; if (v[j] &gt; v[i]) &#123; int t = v[i]; for (int k = i; k &gt; j; --k) &#123; v[k] = v[k - 1]; &#125; v[j] = t; &#125; &#125; &#125;&#125; 希尔排序算法思想希尔排序又称缩小增量排序，也属于一种插入排序算法，其基本思想是将要被排序的数列分成若干个子序列然后分别进行插入排序，待这些子序列排序完成后大序列就会基本有序，这时再对整个大序列进行一次直接插入排序；其分散数列的原则一般是5-3-1，即先将大数列每隔5个取一个数，这样最终会形成5个子数列，将这5个子数列分别进行插入排序，然后将排序好的数列每隔3个取一个形成3个子数列，再对这三个子数列进行三次插入排序，最后，对整个基本有序的大数列进行一次插入排序达到排序整个数列的目的。 时间空间复杂度即稳定性 T(n)=O(n^1.5) S(n)=O(1) 不稳定 代码​1234567void ShellSort(vector&lt;int&gt; v) &#123; int d[3] = &#123;5, 3, 1&#125;; for (int i = 0; i &lt; 3; ++i) &#123; ShellInsert(v, d[i]); &#125; show(v);&#125; ​123456789101112131415void ShellInsert(vector&lt;int&gt; &amp;v, int d) &#123; for (int l = 0; l &lt; d; ++l) &#123; for (int i = l + 1; i &lt; v.size(); i += d) &#123; for (int j = l; j &lt; i; j += d) &#123; if (v[i] &lt; v[j]) &#123; int t=v[i]; for(int k=i;k&gt;j;i-=d)&#123; v[k]=v[k-d]; &#125; v[j]=t; &#125; &#125; &#125; &#125;&#125; 冒泡排序算法思想冒泡排序的主要思想是将大的数向下“沉”，将小的数向上“气泡”，具体过程：首先将第一个数与第二个数进行对比，若第二个数小于第一个数，则将第一个数与第二个数交换，然后比较第二个数和第三个数，如果第二个数大于第三个数，则将其对换，最后的结果是将数列中最大的一个数换到数列的最后一位。然后再对前n-1个数进行相同的过程，结果是将倒数第二大的数放在倒数第二位。以此类推，经历n-1次后所有数列将会有序。 时间空间复杂度及稳定性 T(n)=O(n^2) S(n)=O(1) 稳定 代码​12345678910111213141516171819void BubbleSort(vector&lt;int&gt; v) &#123; for (int i = 0; i &lt; v.size(); ++i) &#123; int flag = 1; for (int j = 0; j &lt; v.size() - i &amp;&amp; j &lt; v.size() - 1; ++j) &#123; if (v[j] &gt; v[j + 1]) &#123; int t; t = v[j]; v[j] = v[j + 1]; v[j + 1] = t; flag = 0; &#125; &#125; if (flag == 1) &#123;//说明已经有序了 break; &#125; show(v);&#125; ​ 快速排序算法思想快速排序是对冒泡排序的一种改进，其基本思路是通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 时间空间复杂度及稳定性 T(n)=O(nlog2-&gt;n) S(n)=O(log2-&gt;n) 不稳定 代码​1234567891011121314151617181920212223242526272829303132333435363738void QuickSort(vector&lt;int&gt; v) &#123; QSort(v, 0, v.size() - 1); show(v);&#125;void QSort(vector&lt;int&gt; &amp;v, int low, int high) &#123; if (low &gt;= high) &#123; return; &#125; int t = Partition(v, low, high); QSort(v, low, t - 1); QSort(v, t + 1, high);&#125;int Partition(vector&lt;int&gt; &amp;v, int low, int high) &#123; int pivotkey; pivotkey = v[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; v[high] &gt;= pivotkey) &#123; --high; &#125; int t; t = v[low]; v[low] = v[high]; v[high] = t; while (low &lt; high &amp;&amp; v[low] &lt;= pivotkey) &#123; ++low; &#125; t = v[low]; v[low] = v[high]; v[high] = t; &#125; return low;&#125; 选择排序算法思想选择排序的思路是首先找到序列中的最小数，将其放在第一位，然后找到第二小的数将其放在第二位，以此类推，最终将所有第i小的数放在第i位从而达到排序目的。 时间空间复杂度及稳定性 S(n)=O(1) T(n)=O(n^2) 不稳定 代码​12345678910111213141516void SelectSort(vector&lt;int&gt; v) &#123; for (int i = 0; i &lt; v.size(); ++i) &#123; int min; min = i; for (int j = i + 1; j &lt; v.size(); ++j) &#123; if (v[j] &lt; v[min]) &#123; min = j; &#125; &#125; int t; t = v[min]; v[min] = v[i]; v[i] = t; &#125; show(v);&#125; 堆排序算法思想堆排序的主要思路是先将所要排序的数列看做是一颗完全二叉树并建立大顶堆，然后将堆顶元素放在堆的最后一位，然后再调整该二叉树为大顶堆，然后再将堆顶放在二叉树的最后一位，调整二叉树为大顶堆，重复这一过程直至完成排序。 时间空间复杂度及稳定性 T(n)=O(nlog2–&gt;n) S(n)=O(1) 不稳定 代码​123456789101112131415161718192021222324252627282930313233343536373839404142434445void HeapSort(vector&lt;int&gt; v) &#123; int size = v.size(); v.push_back(0); for (int k = v.size(); k &gt; 0; --k) &#123; v[k] = v[k - 1]; &#125; //建堆 for (int i = size / 2; i &gt; 0; --i) &#123; HeapAdjust(v, i, size); &#125; for (int j = size; j &gt; 1; --j) &#123; int t; t = v[1]; v[1] = v[j]; v[j] = t; HeapAdjust(v, 1, j - 1); &#125; for (int i = 1; i &lt; v.size(); ++i) &#123; cout &lt;&lt; v[i] &lt;&lt; " "; &#125; cout &lt;&lt; endl;&#125;void HeapAdjust(vector&lt;int&gt; &amp;v, int s, int m) &#123; /* * 已知v[s..m]除v[s]之外均满足堆的定义，本函数调整v[s]，使得v[s..m]成为一个小顶堆 */ int rc; rc = v[s]; for (int i = 2 * s; i &lt;= m; i = 2 * i) &#123; if (i &lt; m &amp;&amp; v[i] &lt; v[i + 1]) &#123; i++;//i为较大数据的下标 &#125; if (rc &gt;= v[i]) &#123; break; &#125; v[s] = v[i]; s = i; &#125; v[s] = rc;&#125; 归并排序算法思想归并排序的主要思路是将索要排序数列看做若干个有序的小数列，因为将两个有序数列合并之后所得数列还是有序数列，所以经过不断合并，最后可将数列排为有序。 时间空间复杂度及稳定性 T(n)=O(nlog2–&gt;n) S(n)=O(n) 稳定 代码123456789101112131415161718192021222324252627282930313233343536 void MSort(vector&lt;int&gt; v) &#123; vector&lt;int&gt; h; h = v; int start, seg; for (seg = 1; seg &lt; v.size(); seg *= 2) &#123; int k = 0; for (start = 0; start &lt; v.size(); start = start + seg * 2) &#123; int end; end = start + seg; int low = start; while (low &lt; start + seg &amp;&amp; end &lt; start + seg + seg &amp;&amp; low &lt; v.size() &amp;&amp; end &lt; v.size()) &#123; if (v[low] &lt;= v[end]) &#123; h[k++] = v[low]; low++; &#125; else &#123; h[k++] = v[end]; end++; &#125; &#125; while (low &lt; start + seg &amp;&amp; low &lt; v.size()) &#123; h[k++] = v[low++]; &#125; while (end &lt; start + seg + seg &amp;&amp; end &lt; v.size()) &#123; h[k++] = v[end++]; &#125; &#125; v = h; &#125; show(v);&#125; 基数排序算法思想基数排序需要经历d次，d为所要排序数列中位数最多的数的位数，其过程是首先根据数列中数的个位的数值将所有数入0~9这10个队列，然后从0~9将元素依次出队，然后再根据十位元素的数值再次入队，然后出队，以此类推重复d次，最终即可完成排序。 时间空间复杂度及稳定性 T(n)=O(d*n) d为排序数中最大数的位数 S(n)=O(n) 稳定 代码​123456789101112131415161718192021222324252627void radixSort(vector&lt;int&gt; v) &#123; int d = GetMaxBit(v); int *count = new int[10]; queue&lt;int&gt; q[10]; int radix = 1; for (int i = 0; i &lt; d; ++i) &#123; for (int j = 0; j &lt; v.size(); ++j) &#123; int t; t = (v[j] / radix) % 10; q[t].push(v[j]); &#125; int p = 0; for (int k = 0; k &lt; 10; ++k) &#123; while (!q[k].empty()) &#123; v[p++] = q[k].front(); q[k].pop(); &#125; &#125; radix *= 10; &#125; show(v);&#125;]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hack NUAA]]></title>
    <url>%2F2017%2F12%2F24%2FHack-NUAA%2F</url>
    <content type="text"><![CDATA[参加了由南京航空航天大学主办的南京四校（南京大学、东南大学、南京航空航天大学、南京理工大学）联合创客马拉松（Hackathon）, 在本校参加比赛体验感不错，最终以总排名第二获得二等奖～ 大合照 logo 团队成员合照 获奖证书]]></content>
  </entry>
  <entry>
    <title><![CDATA[将非图片数据转化为caffe可用的LMDB的方法]]></title>
    <url>%2F2017%2F12%2F19%2F%E5%B0%86%E9%9D%9E%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E8%BD%AC%E5%8C%96%E4%B8%BAcaffe%E5%8F%AF%E7%94%A8%E7%9A%84LMDB%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[摘要：最近有需求要使用caffe训练一套文本文件的数据，数据格式是若干个txt文件，每个txt文件里面包含了880个浮点型数据，因为之前一直用caffe进行图片的相关训练，直接使用caffe自带的脚本将图片转化为LMDB即可作为数据源，但是没有遇到过将txt中的文本数字转化为LMDB的情况，查了很多资料终于解决，记录下来希望可以帮助到有需要的同学们。本文不讲原理，直接给大家一份转换的相关代码，请大家静下心来阅读一遍代码相信就可以搞懂，然后举一反三解决自己的问题。想要了解详细原理的同学可参考： http://blog.csdn.net/haluoluo211/article/details/54427421 ​1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# -*-coding:utf-8-*-import numpy as npimport randomimport lmdbimport caffeimport osdef load_data(fileI, fileQ): # dadai和dataq是（8,110）的二维数组，这是我的数据，可以理解为一张图片的两个通道 datai = np.loadtxt(fileI) dataq = np.loadtxt(fileQ) datai=datai.reshape(8,110) dataq=dataq.reshape(8,110) data = np.zeros((2, 8, 110)) # 初始化data，需要注意的是如果数据是1×n维的也需要np.zeros((2,1,110))初始化而不是np.zeros((2,110)) data[0] = datai data[1] = dataq datum = caffe.proto.caffe_pb2.Datum() datum.channels = 2 # 设置channels，因为我的数据是I和Q相当于一张图片的两个通道，即我的“图片”有两个通道，所以这里设置为2 datum.height = 8 # 设置height，表示数据矩阵的高 datum.width = 110 # 设置width，表示数据矩阵的宽 a=data.tostring() datum.data = a # data #因为我的label隐含在txt文件的文件名里，所以这里根据txt文件的名字来给数据设置label，你也可以根据你的情况导入label if fileI[4]=='B': datum.label = int(0) # label else: datum.label = int(1) # label str_id = fileI[:-4] #顺序+图片名字作为key，你可以根据你的想法设置key final_data = &#123;"datum": datum, "key": str_id&#125; return final_datadef get_lmdb(lmdb_name): num=0 env = lmdb.open(lmdb_name,map_size=int(1e9)) # 打开lmdb，这里可以不设置map_size，但是根据经验建议大家设置上，而且不要设置的太小 #path1和path2分别代表我的I.txt和Q.txt文件的来源（我的一份数据是一个I.txt和一个Q.txt，可以理解为一张图片的两个通道） path1 = "/home/dmrf/Data/I_TEST" path2 = "/home/dmrf/Data/Q_TEST" files1=os.listdir(path1) files2=os.listdir(path2) f1=[] f2=[] for a in files1: for b in files2: if a[8:]==b[8:]: f1.append(a) f2.append(b) files2.remove(b) else:continue random.shuffle(zip(f1,f2)) for (file1, file2) in zip(f1,f2): if file1[8:]==file2[8:]: dataget = load_data(path1+"/"+file1, path2+"/"+file2) if dataget!=0: datum = dataget["datum"] key = dataget["key"] with env.begin(write=True) as txn: txn.put(key, datum.SerializeToString()) num=num+1 print("转换中："+str(num)) print("success:"+str(num))#函数入口get_lmdb("test_lmdb") 以上就是大概原理，其实很简单，希望可以帮助到大家。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>LMDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌企业文化建设分析]]></title>
    <url>%2F2017%2F12%2F05%2F%E8%B0%B7%E6%AD%8C%E4%BC%81%E4%B8%9A%E6%96%87%E5%8C%96%E5%BB%BA%E8%AE%BE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[引言“一百英尺之内必有食物”这大概是谷歌最具特色的一句标语。在一个倡导着工作就是生活的自由环境下，谷歌公司的工作人员不断用他们的创造力研发出一个又一个优质的产品。而 Google强劲的发展势头与其独特的企业文化有着密不可分的关系。怎样的企业，怎样的文化特色，怎样用文化影响每一个公司员工，怎样利用这样的企业文化，这是一个不容忽视的话题。 企业文化概述美国学者伦斯·米勒在 《美国文化精神》 中说道：“企业唯有发展出一种文化，这种文化能够在激励中获得成功的一切行为，这样公司才能 在竞争中获得成功。”这就是企业文化。关于企业文化的概念, 国内外学者有许多不同的认识和表述。有人曾对企业文化的定义作过统计, 共有 180 多种,几乎每一个管理学家和企业文化学家都有自己的定义。中国社会科学院工业研究所研究员韩朗岚认为：“企业文化有广义和狭义两种理解。广义的企业文化是指企业所创造的具有自身特点的物质文化和精神文化;狭义的企业文化是企业所形成的具有自身个性、经营宗旨、价值观念和道德行为准则的综合”。从这里可以看出，企业文化是企业价值取向、经营理念、管理制度、行为准则、企业精神等方面的概括与升华。企业文化的结构有三个层次，实体的物质题。文化构成企业文化的硬件外壳，制度文化是观念 形态的转化，是企业硬外壳的支撑，而精神文化是企业文化的精髓，主导着企业的共性和特性及企业的发展范式。企业文化的重要性毋庸置疑，表现为以下几个方面： 企业文化本身就是一种企业竞争力优质的企业文化更能够促使企业提供满足消费者需求的产品与服务。马斯洛的需求层次理论告诉我们，人的需要可分为五个层次：生理需要、安全需要、社交需要、尊重需要、自我实现需要。当低的需要得到基本满足时，下一个更高层次的需要就将成为主导需要，而随着科技的进步、社会的发展，人们的生活越来越富裕，人们的需要逐渐从低层次的需要转变为高层次的需要，低层次的需求不再有激励作用，这时，消费者更强调一种文化（消费文化），更加追求个性，时尚，前卫，张扬，而带有这些特质的产品往往产生于优质的文化底蕴。所以说，优质的独具特色的企业文化更加能抓住顾客的心，从而在激烈的竞争中崭露头角。 企业文化能有效的调节人与人之间的关系，规范和约束人的行为通过文化建设，发挥文化的功能，来推动和促进企业发展。近些年来日益受到管理界的重视、最终升华出的一种新的管理理论和方法——人本管理，就是坚持以人为本，重视员工的精神需求，满足其社交需要和自我实现需要，提高员工的凝聚力和适应力，对企业的发展与建设起到了重要的指导作用。可见，构建高层次的、具有深刻影响力的企业文化，能够提高企业管理的水平，满足人的多层次、多重性的需要，也有利于社会文化的发展。 企业文化具有难以被模仿和复制的独特性我们知道企业要在竞争中长期占有优势, 必须具有核心竞争力。核心竞争力是指企业在研发、 制造、 设计、 营销、服务等一个或几个环节上具有竞争对手难以模仿的明显的优势,并能够满足客户价值需求的独特能力。然而在信息，科学技术高速发展的今天，以上几点很难保证竞争对手难以模仿，甚至可能会被迎头赶上，优势往往很难持续下去。但企业文化不一样，每一个企业都有着自己的定位、独特环境，发展方向，优势劣势、经营模式、文化传统，很难保证这些因素全部吻合。并且，从克拉克洪-斯托克柏克提出的文化差异分析模型——K-S框架，我们可以知道，与环境的关系、时间取向、对人的本质的看法、活动取向、责任中心、空间取向的不同将会导致企业文化的差异。加之，企业文化既没有固定的模式，也没有定量的指标，导致企业文化很难模仿，可以说，企业文化是一个公司的独特标志，是支撑企业发展的重要力量。第四，企业文化有助于企业向学习型组织发展。现代企业正处在不断变化的社会环境中，市场竞争不断加强，规模扩大，市场不断扩展，一个企业只有通过不断的学习，并根据实际情况做出产品、技术、制度的变革，才能适应不断发展的时代潮流。美国原通用电器CEO韦尔奇说:“最终的竞争优势在于一个企业的学习能力以及将其迅速转化的能力。”没有学习，没有变革的企业将很快失去竞争优势。所以，一个学习氛围浓厚，员工积极进取，敢于不断改变自己的企业才能够不断发展。优秀的企业文化鼓励个人学习、 自我超越, 注重团队精神的培养和建立共同的愿望, 所以有助于企业向学习型组织发展。 谷歌的企业文化谷歌（英语：GoogleInc.，NASDAQ：GOOG、FWB：GGQ1，官方中文译名为谷歌），是一家美国的跨国科技企业，致力于互联网搜索、云计算、广告技术等领域，开发并提供大量基于互联网的产品与服务，其主要利润来自于AdWords等广告服务。李开复说，和Google“恋爱”，他感受到这家公司的文化是：一群穿着短裤的年轻人，对新技术创新有极大的热情；对诚信的追求近乎执著；员工之间关系平等、自由和透明；先让客户满意，暂时不赚钱也没关系。2014年5月21日，市场研究公司明略行（MillwardBrown）公布，谷歌取代苹果成为全球最具价值的商业品牌，这与谷歌优质的，富有个性的企业文化密不可分。下面从企业文化的三个层次来介绍谷歌的企业文化。 谷歌的物质文化谷歌为员工提供了便利的服务和人性化的工作环境。 “免费：”文化在谷歌，“免费”被当作公司文化的一部分。员工用餐、健身、按摩、洗衣、洗澡、看病都100%免费；每层楼都有一个咖啡厅，可以随时冲咖啡、吃点心，大冰箱里有各种饮料，免费任喝。 办公环境宽松便捷每位员工至少配备两台大屏幕显示器，平均每个办公室有4-6名员工，并且技术人员24小时待命，计算机或其他数码产品可以随时送修。办公大楼随处可见白色书写板，目的是方便员工随时记下各种新创意。一位Google产品经理对此表示：“你坐在办公室时，灵感并不一定会来；或许就在你走动时，灵感就会如期而至。” 娱乐设施完备公司内，到处都有排球场，游泳池，台球室，甚至还配备有专门的按摩师。谷歌就像是一个游乐园，帮助员工迅速消除疲劳，回归工作状态。 完善的福利谷歌的花钱速度在硅谷堪称奇迹，对于员工，谷歌有着完善的福利，谷歌总部餐厅、美容院、牙医院、加油站、甚至按摩店应有尽有，俨然一个自给自足的独立王国。免费美食、24小时健身房、瑜伽课、演讲课、医疗服务、营养师、干洗机、按摩服务、私人教练、温泉水疗，上下班接送，外语培训„„应有尽有。 谷歌的制度文化管理制度人员招聘制度“宁缺毋滥”是谷歌管理人才的一个重要理念。有资料显示，最终获得谷歌工作职位的应聘者平均需要通过6.2次面试，参与面试的面试官，除了人力资源部和岗位需求部门，也会邀请跨部门甚至跨区域的人参加面试，这是为了是进入谷歌的员工尽量契合谷歌的企业文化。谷歌非常鼓励内部员工推荐应聘者，因为他们对于公司文化更加了解，其推荐的人更加适应公司文化。 绩效管理谷歌有着一套十分精密严谨、完全数值化的内部目标绩效考核制度——OKR，所有员工的考核评分对内公开，这种目标考核也成为各部门任务协作的一个手段。OKR全称“目标与关键成果”，是一套定义与跟踪目标及其完成情况的管理工具和具体方法，适用于公司、团队与个人，是一种简便易行的绩效考评方式。谷歌通过在公司层面设立目标，并在团队、管理人、普通员工层面均设立明确的，具体可行的目标，这与目标管理法基本契合，在每个季度末期，谷歌将会对OKR考核实施评分，评分过低，高分并不一定受到表扬，如果本期目标制定野心不够，下期OKR制定则需要调整。低分也不会受到指责，而是通过分析工作数据，找到下一季度OKR的改进办法。企业的生死要么是方向的问题（战略和目标）要么是行动的问题，行动不能支撑目标的实现，这样的行动是在“杀害”这个公司，因为这样浪费人力、物力、财力，甚至有可能抵消、阻碍甚至破坏其他人的正确行动。OKR的特点是简单、直接、透明。OKR的优点主要有三点：第一，谷歌依赖于创新、创意、创造，没有可跟随的目标和方向，需要企业自己探索，自下而上的OKR则更能激发员工的创造力，通过设定目标并采取措施并最终达成目标的这个过程让员工感受到了创造性努力的激情和乐趣，满足了员工的自我实现需要。第二，OKR的实施对象是公司的每一个成员，每一个员工都能把握公司的动态和自己所处的位置，并通过与其他员工的对比，了解自己的优势劣势，并做出改变，提升自身素质。第三，让每一个员工都清楚的明白自己是公司的一个不可或缺的一部分，增加其对公司的归属感。 时间管理谷歌的员工从来不用在乎早上闹铃会不会准时响起，员工可以悠闲自得地去上班。谷歌提倡弹性的工作制度，充分相信员工，把工作时间的掌控权交给员工，由员工根据自己的喜好自由安排时间，给员工提供了宽松、自由的环境。从组织文化理论的角度来分析，由于谷歌公司的核心在于不断推出新的产品来获利，因此给员工一个不压抑、不拘束的环境就显得非常重要。 工作制度灵活高效的工作方式成为谷歌持续高速发展的秘诀之一。创新的意识还源自于灵活的小团 队工作方式。“将有智慧有激情的员工针对关键问题，分成3～5人的小团队，扁平化的组织，以海量的计算资源和数据作为支持，同时允许工程师抽出20%的时间，根据兴趣自己确定研究方向。”这是谷歌组织结构的基本原则。小团队的工作方式看起来平常，其实却蕴涵着深刻的道理：在庞大的组织中，总有很多聪明人，他们可以轻松地找到“混”下去的方法，即便是复杂的绩效考核也对这类人束手无策。但是在有3～5人组成的小团队中，却容不得“聪明人”再浑水摸鱼，必须全力以赴才能被大家认可。激发了全体成员创造力的同时，进行小3.薪酬制度薪酬制度是人力资源管理的主要职能之一，“激励是管理的核心”，而薪酬激励又是企业目前普遍采用的且行之有效的一种激励方式。谷歌推出以绩效为导向的富有竞争力的全面薪酬：谷歌的全面薪酬包括工资、津贴、奖金、福利、保险、股票期权等。在对员工的短期、期、和长期激励上，各自发挥着不同的作用。对外，谷歌整体薪酬保持着市场上的强大竞争力；对内充分考虑不同岗位，职级以及员工工作表现的差异性，建立了全方位的以业绩为导向的薪资理念。范围的绩效考核，所得的结论就会更加客观。谷歌为所有正式员工发放股票期权，并且每年都会根据员工上一年度的业绩表现再授予股票期权。业绩表现越好的员工，越得到更高的工资、奖金和股票期权，从而保障员工的收入与绩效充分接轨。 谷歌的精神文化按照索涅费尔德的分类，组织文化可被划分 为学院式文化、俱乐部式文化、棒球队式文化和堡垒式文化四个类别。学院式文化适合那些追求稳定性的人群。同时用人单位并不介意雇员是刚刚毕业的学生。而俱乐部式文化与其相对，这样的组织很重视经验年龄和资历，军队和政府机关多是俱乐部式文化的典型。堡垒式文化更多的是强调维持生存，因此这种组织文化尤其适合于经济不景气的大环境。棒球队式的文化也正如其名，它提倡冒险创新，组织往往给员工充分的自由。那么按照索涅费尔德的分类，谷歌公司就应属于棒球队式的文化。我认为，谷歌的精神文化主要分为以下四个方面： 创新作为一个要求不断推出新产品的公司，谷歌的创新精神可以说是企业精神的重中之重。 谷歌将创新列入员工的工作时间预算要求技术人员花80%的时间在核心的搜索和广告业务上，其余20%则用在他们自己选择的技术项目上，每位工程师都有 20%的自由支配时间，这些时间允许工程师不紧紧抓着核心项目不放。他们可以将这部分时间投入他们所感兴趣的课题上进行研究，正是这种鼓励创新的机制使得谷歌新产品的推出速度非常快。 善于利用失败谷歌快速地推出大量创新产品，这些产品可能并不完美，但谷歌会让市场来选择。谷歌创始人佩奇还曾表扬一名犯下大错、给公司造成数百万美元损失的高管：“我很高兴你犯了这个错误。因为我希望公司能够行动迅速、做很多很多的事情，而不是谨小慎微、什么也不敢做。” 用数据支持灵感人们普遍认为，创意的构思过程是混乱无序的，但谷歌却以一套非常严谨的以数据为驱动的创意评估流程，很好地平衡了这种无序性。谷歌对于分析和数据的重视远远超过其他绝大多数公司。它的搜索引擎一样快。 自由办公区沙发随处可见，员工可以随意喝咖啡聊天，甚至分不清哪里是办公区，哪里是休闲区。“我们的每间办公室都有独特的名字，比如‘立秋’‘秋分’，这都是我们员工自己的创意。谷歌的工作模式就是平等和倾听每一位员工的声音，我喜欢这样无为而治的文化。”李开复说。这就是谷歌独具特色的文化。并且，20%的自由分配时间并不是强制的，谷歌给了员工充分的自由来分配这段时间李开复说“其实，自由时间比例多少并不重要。谷歌20％自由时间制度的背后，有一个更重要的原则，我们信任员工。我们放权给员工，并不会真的去衡量这个20％，我们觉得员工会自行调整。打个比方，如果员工觉得自己正在做的某个程序非常重要，那么，这个月他可以只做这个程序；如果员工觉得公司交给他的任务更重要，那么，他可能花三个月来做，而根本不会去碰这个20％。你可以质疑，也许这个制度的回报只有10％，也有可能是20％，甚至是30％，这个我没有办法做出确切的回答。但是，我们不能用数字来进行衡量，这个制度所代表的，是公司的一种自由的风气，这种风气也是吸引人的一种途径。”自由来源于公司对员工的充分信任，这种信任在其他公司是极为少见的。 个人主义美国前总统肯尼迪曾经说道：“如果价值是文化的灵魂，那么英雄就是这些价值的化身和组织机构力量的集中体现。”信奉个人主义以及塑造英雄，是谷歌企业文化的“中流砥柱”。这一方面给企业内部员工提供学习的榜样，树立绩效的标准，刺激员工积极进取，相互竞争；另一方面，也可以对外作为公司的象征，成为公司的形象代表。美国企业文化注重个人英雄的巨大影响力，为了争夺本土化人才，往往不惜重金。李开复在2005年7月19日突然宣布跳槽谷歌，出任其中国区总裁，负责中国研发中心的运营。微软当日就向华盛顿州地方法院提起诉讼，指控谷歌和李开复违反了“同业禁止”协议。9月14日，位于西雅图市的华盛顿州金县法院做出初步裁决，允许李开复任职谷歌中国研发中心，但对其工作内容进行了限定。李开复对于中国的年轻学子有着巨大的号召力，为了能抢到中意的人才，谷歌不惜和IT巨头微软诉诸法律，其对个人英雄的重视可见一斑。 使命感谷歌的每个人都有强烈的使命感和目标感，他们相信自己的工作能以积极的方式影响着千百万人。 谷歌有两条口号：“完美的搜索引擎”和“不作恶”。第一条口号“完美的搜索引擎”更多侧重于增强其产品的可信性和专业性，而第二条口号则更多是在强调一种拒绝为了盈利而不择手段的企业风气。谷歌有着他的使命，谷歌的使命就是整合全球的信息，做一个最公正、最完美的搜索引擎。谷歌的这宏大的使命深深地烙在每个员工的心里，谷歌的使命就是他们的责任，并是他们与公司同气连枝，并促使他们自信满满，大刀阔斧的前进。 结语通过以谷歌公司为例，我们知道了企业文化是企业的核心竞争力，使企业经久不衰的动力来源。完善企业制度，建立以人为本的企业文化，并随着时代潮流不断完善和发展，互相借鉴与补充，是每个企业不可忽视的重要内容 参考文献：《浅谈谷歌的企业文化》金志峰]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[人工智能是否会超越人类？]]></title>
    <url>%2F2017%2F12%2F01%2F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%98%AF%E5%90%A6%E4%BC%9A%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[导语：随着人工智能的飞速发展，很多人都在担忧人工智能是否会超越人类、甚至毁灭人类，比如像特斯拉的CEO埃隆.马斯克认为也许只有人看到人工智能在街上杀人的时候，才会意识到这个问题的严重性。很多人对这个问题都有自己的答案，但是他们的答案也许只是因为他们的直觉，而真正的原因恐怕连他们自己也不清楚，比如有的人可能会说因为自己觉得未来人工智能会有自主学习的能力，所以人工智能会超越人类，而另一类人也许会说因为人工智能也是由人制造的，所以不会超越人类。一般人这么思考问题也许不能算错，但是作为一名IT人，必须学会用工程的思维来思考问题，而不是靠自己的直觉，本篇文章就带大家了解一下吴军老师是如何用工程的思维论证这个问题的： 图灵机是什么？图灵博士被认为是神一样的人。在20世纪，全世界智力水平可以和爱因斯坦平起平坐的人恐怕只有图灵和冯.诺依曼两个人了（而后者被认为的智力甚至超越了爱因斯坦）。在上个实际30年代中期，图灵在思考三个问题： 1.世界上是否所有的数学问题都有明确的答案？ 2.如果有明确答案，是否可以通过有限步骤的计算得到答案？ 3.对于那些有可能在有限步骤计算出来的数学问题，能否有一种假想的机械，让它不断运动，最后当机械停下来的时候，那个数学问题就解决了？ 图灵思考问题的这个方法后人称之为图灵机，是一个数学模型。今天所有的计算机，包括全世界正在设计的计算机，从解决问题的能力来讲，都没有超出图灵机的范畴。 人工智能的边界在哪里？解释完图灵机，我们可以回到最初的问题了，人工智能的边界在哪里？其实给出图灵思考问题的答案就可以得到结论了： 世界上有很多问题，其中只有一小部分是数学问题 在数学问题中，只有一小部分是有解的 在有解的问题中，只有一小部分是理想状态的图灵机可以解决的 在后一类问题中，又只有一部分是今天实际的计算机可以解决的 而人工智能可以解决的问题，又只是计算机可以解决问题的一部分 吴军老师把这个问题画成了一张图： 至此，我们应该可以得到问题的答案了：人工智能所能解决的问题只是世界上的很小一部分。对于人工智能来讲，个人觉得现在世界没有解决的问题太多，无论是人还是机器（其实是背后编写程序的人），都应该想办法解决各种问题，而不是杞人忧天，担心人工智能这个工具太强大。 版权所有：【得到】APP订阅专栏：吴军的谷歌方法论]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TC Hackathon]]></title>
    <url>%2F2017%2F11%2F27%2FTC%20Hackathon%2F</url>
    <content type="text"><![CDATA[参加了由TechCrunch中国主办的TechCrunch 2017 国际创新峰会-上海站-黑客马拉松，接触了很多区块链大佬： Invitation card 到达比赛场地 比赛场地 正在coding的我 大家正在coding our result 正在演讲展示demo的我]]></content>
  </entry>
  <entry>
    <title><![CDATA[判断一棵二叉树是否是完全二叉树的方法]]></title>
    <url>%2F2017%2F11%2F22%2F%E5%88%A4%E6%96%AD%E4%B8%80%E6%A3%B5%E4%BA%8C%E5%8F%89%E6%A0%91%E6%98%AF%E5%90%A6%E6%98%AF%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[主要思路利用二叉树层次遍历的原理开始对二叉树进行层次遍历，特殊点在于遍历的时候将NULL也入队作为标记，如果当遍历到NULL的时候队列中仍然后非NULL元素未被遍历，说明该二叉树中有非空点在空点的右边，即不是完全二叉树。 代码实现​12345678910111213141516171819202122232425bool is_complete(BiTree biTree) &#123; queue&lt;BiNode *&gt; q; BiNode *biNode; // 进行广度优先遍历（层次遍历），并把NULL节点也放入队列 q.push(biTree); while ((biNode = q.front()) != NULL) &#123; q.pop(); q.push(biNode-&gt;lchild); q.push(biNode-&gt;rchild); &#125; // 判断是否还有未被访问到的节点 while (!q.empty()) &#123; biNode = q.front(); q.pop(); // 有未访问到的的非NULL节点，则树存在空洞，为非完全二叉树 if (NULL != biNode) &#123; cout &lt;&lt; "不是完全二叉树～" &lt;&lt; endl; return false; &#125; &#125; cout &lt;&lt; "是完全二叉树～" &lt;&lt; endl; return true;&#125; ​]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>完全二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之二叉树的遍历算法合集]]></title>
    <url>%2F2017%2F11%2F22%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86%E7%AE%97%E6%B3%95%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[摘要：今天用C撸了一遍数据中二叉树常见操作的实现，将实现过程中感觉有意思的几个功能实现记录下来方便以后复习～ 先序遍历递归实现​1234567891011121314void PreOrderTraverse(BiTree biTree) &#123;//先序遍历 if (biTree == NULL) &#123; cout &lt;&lt; "该树为空，无法遍历！" &lt;&lt; endl; &#125; cout &lt;&lt; biTree-&gt;data &lt;&lt; " "; if (biTree-&gt;lchild != NULL) &#123; PreOrderTraverse(biTree-&gt;lchild); &#125; if (biTree-&gt;rchild != NULL) &#123; PreOrderTraverse(biTree-&gt;rchild); &#125;&#125; 非递归实现​123456789101112131415161718192021 void PreOrderTraverse2(BiTree biTree) &#123;//先序遍历 stack&lt;BiNode *&gt; stack1; BiNode *biNode = biTree; stack1.push(biNode); while (biNode != NULL &amp;&amp; !stack1.empty()) &#123; biNode = stack1.top(); stack1.pop(); cout &lt;&lt; biNode-&gt;data &lt;&lt; " "; if (biNode-&gt;rchild != NULL) &#123; stack1.push(biNode-&gt;rchild); &#125; if (biNode-&gt;lchild != NULL) &#123; stack1.push(biNode-&gt;lchild); &#125; &#125;&#125; 中序遍历递归实现​12345678910111213void InOrderTraverse(BiTree biTree) &#123; if (biTree == NULL) &#123; cout &lt;&lt; "该树为空，无法遍历！" &lt;&lt; endl; &#125; if (biTree-&gt;lchild != NULL) &#123; InOrderTraverse(biTree-&gt;lchild); &#125; cout &lt;&lt; biTree-&gt;data &lt;&lt; " "; if (biTree-&gt;rchild != NULL) &#123; InOrderTraverse(biTree-&gt;rchild); &#125;&#125; 非递归实现​1234567891011121314151617181920void InOrderTraverse2(BiTree biTree) &#123; if (biTree == NULL) &#123; cout &lt;&lt; "该树为空，无法遍历！" &lt;&lt; endl; &#125; stack&lt;BiNode *&gt; stack1; BiNode *biNode = biTree; while (biNode != NULL || !stack1.empty()) &#123; if (biNode != NULL) &#123; stack1.push(biNode); biNode = biNode-&gt;lchild; &#125; else &#123; biNode = stack1.top(); stack1.pop(); cout &lt;&lt; biNode-&gt;data &lt;&lt; " "; biNode = biNode-&gt;rchild; &#125; &#125;&#125; 层次遍历递归实现二叉树Depth（）的实现​1234567891011int Depth(BiTree biTree) &#123; if (biTree == NULL) &#123; return 0; &#125; int u = Depth(biTree-&gt;lchild); int v = Depth(biTree-&gt;rchild); return u &gt; v ? u + 1 : v + 1;&#125; 遍历实现​12345678910111213141516171819202122void LevelOrderTraverse(BiTree biTree) &#123; for (int i = 1; i &lt;= Depth(biTree); ++i) &#123; LevelOrderTraversePrint(biTree, i); &#125;&#125;void LevelOrderTraversePrint(BiTree biTree, int depth) &#123; if (biTree == NULL) &#123; cout &lt;&lt; "该树为空，无法遍历！" &lt;&lt; endl; &#125; if (depth == 1) &#123; cout &lt;&lt; biTree-&gt;data &lt;&lt; " "; return; &#125; else &#123; if (biTree-&gt;lchild != NULL) &#123; LevelOrderTraversePrint(biTree-&gt;lchild, depth - 1); &#125; if (biTree-&gt;rchild != NULL) &#123; LevelOrderTraversePrint(biTree-&gt;rchild, depth - 1); &#125; &#125;&#125; ​ 非递归实现​1234567891011121314151617181920void PreOrderTraverse2(BiTree biTree) &#123;//先序遍历 stack&lt;BiNode *&gt; stack1; BiNode *biNode = biTree; stack1.push(biNode); while (biNode != NULL &amp;&amp; !stack1.empty()) &#123; biNode = stack1.top(); stack1.pop(); cout &lt;&lt; biNode-&gt;data &lt;&lt; " "; if (biNode-&gt;rchild != NULL) &#123; stack1.push(biNode-&gt;rchild); &#125; if (biNode-&gt;lchild != NULL) &#123; stack1.push(biNode-&gt;lchild); &#125; &#125;&#125; 总结遍历的时候使用非递归算法比采用递归算法的效率高效，但是同时非递归的算法实现比递归算法更难（除了层次遍历，个人觉得层次遍历的非递归实现反而比递归实现更简单）。]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[南方某高校离散数学实验报告]]></title>
    <url>%2F2017%2F11%2F22%2F%E5%8D%97%E6%96%B9%E6%9F%90%E9%AB%98%E6%A0%A1%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[实验一：专业论文阅读论文的基本信息论文题目与来源论文的题目为“An Implementation of the Behavior Annex in the AADL-toolsetOsate2”，发表在2011年4月的Software Engineering Institute | Carnegie MellonUniversity期刊（或会议录），引用格式为：Lasnier G, Pautet L, Hugues J, et al. AnImplementation of the Behavior Annex in the AADL-Toolset Osate2[C]// IEEEInternational Conference on Engineering of Complex Computer Systems. IEEE,2011:332-337. 论文作者信息论文的主要作者：Gilles Lasnier, Laurent PautetInst. TELECOM - TELECOM ParisTech – LTCI Paris,F-75634 CEDEX 13, France Email: {firstname.lastname}@telecom-paristech.frJérôme Hugues ISAE - Toulouse University Toulouse, 31056, France Email:jerome.hugues@isae.frLutz Wrage SEI - Carnegie Mellon University Pittsburgh, PA, 15213, USA Email:lwrage@sei.cmu.edu 论文的主要内容论文摘要论文的研究背景：Abstract-AADL是一种用于设计和分析高分辨率分布式和实时系统的建模语言。 作为AADL的拓展分支，该建模语言扩展了AADL模型以加强其分析功能。其指定了AADL应用程序模型的行为。 因此，本附件的植入允许执行行为分析。 另外，由于有几个AADL的拓展，实施通用机制来支持其中的每一个都是具有挑战性的。 要解决的问题：1）解析和分析几个AADL的子语言。2）对不同的AST生产需要连接进行分析。3）完成分析，要求确保与核心语言的一致性。 主要采用的方法：开发了一个可扩展的开源平台AADL工具集OSATE2，它包括AADL前端，架构分析功能和扩展机制，将外部后端作为插件进行集成。 得到的研究结果：通过重用多个OSATE2模块来驱动AADL-BA元素进而完成了对AADL模型的分析，开发出了新的编译器插件。 论文主体内容论文对问题的描述：Abstract-AADL是一种用于设计和分析高分辨率分布式和实时系统的建模语言。作为AADL附件出版的嵌入式子语言扩展了AADL模型以加强分析。但是，由于有几个AADL附件，实施通用机制来支持其中的每一个都是具有挑战性的。 论文解决问题的步骤：1：将AADLBA编译器作为集成；2：实现OSATE2的ECLIPSE插件；3：将AADL-BA元模型作为构建编译器的几个模块的骨干分支。 论文结果的体现方式：通过展示了研究人员如何使用AADL-BA模型来开发编译器的几个模块来说明研究结果。具体产品为OSATE2，这是一个提供了AADL前端和附件的插件，驱动行为附件分析（解析器+分析器）。用于定义AADL和AADL-BA元模型的相同技术，可轻松跨两个元模型的导航，以及生成独特的持久XMI表示（AADL模型+行为元素），有助于将其用作外部后台的输入。论文的创新点：通过以一个可拓展的开源平台AADL工具集OSATE2为基础，将前后端结合起来对问题进行研究和实验，而不是局限于传统的分析方法。 相关工作和展望论文的相关工作：为了研究的需要开发了一个可扩展的开源平台AADL工具集OSATE2，它包括AADL前端，架构分析功能和扩展机制，将外部后端作为插件进行集成。 下一步工作：通过外部后端的集成来分析行为自动机属性，例如作为模型检查器来验证死锁和基于模型的工具，以通过改进WCET估计和阻止共享资源的时间来增强调度分析。 实验二：构造命题逻辑合式公式的真值表实验内容根据用户输入的命题公式以及指定的分量的真值得出对应命题公式的真假值。 实验环境电脑环境系统：Ubuntu16.04LTS（Linux 4.10.0-37-generic x86_64）处理器：Intel® Pentium(R) CPU N3700 @ 1.60GHz × 4内存：7.7 GiB操作系统类型：64位操作系统图形：GeForce 920M/PCIe/SSE2 编译运行环境CLion2017.2.3 编程语言C/C++语言 实验算法数据结构定义本实验中主要使用C++中的map和string数据结构对数据进行处理，具体使用示例如下： 对真值的存储考虑到合式公式的真值是和字符/字符串一一对应的，而真值为int（0或1），所以本实验使用map将合式公式和真值作为键值对存储到map中，事实证明这种数据处理方式取得了较为高效的数据存储效果。 对合式公式的存储考虑到合式公式的不规则性以及在计算过程中需要频繁移动“指针”的位置，所以本实验使用string数据类型来存储要处理的合式公式，主要应用string的const_iterator对合式公式进行高效率的操作。2）算法描述（包含输入输出说明）本实验的主要算法思路是将需要判断真值的合式公式分解为小的合式公式“分而治之”，以括号为划分界限，计算出括号内”小的“合式公式的真值后再对总的合式公式进行真值判断。 输入说明输入合式公式时考虑到电脑输入字符的限制性，规定用！表示 否定 ， 用&amp; 表示 合取 ， 用| 表示 析取 输出说明本实验将会输出用户输入的总合式公式的真值，0代表”假“，1代表”真“。 算法流程图 实验结果运行界面 运行结果 实验分析实验优点分析：1：在求解较为复杂的合式公式的真值时采用”分而治之“的思想，将复杂的合式公式分解为多个简单的合式公式今进而求解，事实证明这种解决问题的思想起到了较为理想的效果。2：在进行具体的计算时可以充分利用C++语言的特性，巧妙地使用了C++中的map和string数据结构，达到了事半功倍的效果。 实验不足分析：1：未能将完整合式公式的各个分部分的真值也列出来2：未能实现图形界面从而增强用户人机交互的体验感 实验不足的改进方案：1：在对总的合式公式尽情求解时另外再使用一张map存储括号内的合式公式及其真值，但是要注意的是在存储时要特别处理”！“2：可以通过C++实现底层算法、java实现图形界面的方法实现本实验的图形界面，即在本实验C++代码的基础上做一个套壳封装 实验源码部分核心代码如下 扫描括号并进行计算的方法（函数）：​123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int run_expr(string &amp;Expr) &#123; //扫描括号 int sum_kh = 0;//括号数 string::const_iterator iter; string::const_iterator addr_kh[50];//用于记录括号的位置 char kind_kh[50];//用于记录括号的类型 for (iter = Expr.begin(); iter != Expr.end(); iter++) &#123; if (*iter == '(' || *iter == ')') &#123; addr_kh[sum_kh] = iter; kind_kh[sum_kh] = *iter; sum_kh++; &#125; &#125; if (0 == sum_kh)//如果没有括号 &#123; value = run_unkh_expr(Expr); return value; &#125; else &#123; int i = 0; for (; i &lt;= sum_kh; i++) &#123; if (kind_kh[i] == ')')//找到最内级的括号并跳出循环 break; &#125; //取出最内层没有括号的字符串 string in_str = string(addr_kh[i - 1] + 1, addr_kh[i]); //算出最内层表达式的值 //((!p&amp;q)|(p|q))&amp;(p|v) value = run_unkh_expr(in_str); v_map[in_str] = value; static char var = '1'; value_map[var] = value;//将括号整体设为一个字符‘1’ string::const_iterator ite = addr_kh[i - 1];//"字符(的位置" //判断（是不是表达式的开头 string::const_iterator init_i; bool is_begin = false; if (ite == expr.begin()) &#123; is_begin = true; &#125; else &#123; init_i = addr_kh[i - 1] - 1; &#125; &#123; expr.erase(ite, addr_kh[i] + 1);//删除掉最内层表达式包括括号在内 &#125; //再在删除的地方插入新的字符‘1’作为标记 if (is_begin == true) &#123; expr = var + expr; &#125; else &#123; expr.insert(init_i + 1, var); &#125; var = var + 1; value = run_expr(expr); return value; &#125;&#125; //求主析取范式和主合取范式的函数 处理具体合式关系的方法（函数）：​123456789101112131415int deal_cal(int par1, char par2, int par3) &#123; switch (par2) &#123; case '&amp;'://合取 return par1 &amp;&amp; par3; case '|'://析取 return par1 || par3; default: cout &lt;&lt; "有某些命题的真值错误" &lt;&lt; endl; break; &#125;&#125; 具体项目见： https://github.com/DMRFWIN/-DiscreteMathematicsExperiment_TruthTable.git 实验三：TSP问题求解（图形界面版）实验内容TSP问题求解 实验环境电脑环境系统：Ubuntu16.04LTS（Linux 4.10.0-37-generic x86_64）处理器：Intel® Pentium(R) CPU N3700 @ 1.60GHz × 4内存：7.7 GiB操作系统类型：64位操作系统图形：GeForce 920M/PCIe/SSE2 编译运行环境Intellij IDEA Community 编程语言JAVA语言 实验算法数据结构定义本实验中用到了java中较为经典的MAP、LIST等数据结构。 算法1描述（包含输入输出说明）算法思想描述a.从某一个城市开始，每次选择一个城市，直到所有的城市被走完。b.每次在选择下一个城市的时候，只考虑当前情况，保证迄今为止经过的路径总距离最小。 输入描述输入数据可以选择手动输入，也可选择从软件运行的本机中选择数据文件导入计算。 输出描述输出为两张表，一张为输入数据组成的数据表，另一张为最短路径经过的城市的代号构成的输出表，在表的末尾会输出对应算法计算的最短路径值。 算法1流程图 算法2描述算法2使用的是回溯法（试探法）： 回溯法描述从一条路往前走，能进则进，不能进则退回来，换一条路再试。 用回溯算法解决问题的一般步骤为：1、定义一个解空间，它包含问题的解。2、利用适于搜索的方法组织解空间。3、利用深度优先法搜索解空间。4、利用限界函数避免移动到不可能产生解的子空间。 输入描述输入数据可以选择手动输入，也可选择从软件运行的本机中选择数据文件导入计算。 输出描述输出为两张表，一张为输入数据组成的数据表，另一张为最短路径经过的城市的代号构成的输出表，在表的末尾会输出对应算法计算的最短路径值。 算法2流程图 实验结果运行界面数据源选择界面： 手动输入数据界面：从本机选择数据文件界面： 运行结果截图手动输入界面测试运行结果：从本机选择文件测试结果： 项目代码核心算法代码回溯法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package Algorithm;import java.util.Arrays;import java.util.HashMap;import java.util.Map;public class Back &#123; private int distance[][]; private int x[]; private int b[]; private int cl = 0; private int k = 10000; private int cityNum; public Back() &#123; &#125; public Map&lt;String, String&gt; GetMinRoadByBack(Map&lt;String, Integer&gt; roadBeans, String str_num) &#123; InitData(roadBeans, str_num); int i; Traveling(2); b[cityNum] = b[0]; Map&lt;String, String&gt; result = new HashMap&lt;&gt;(); result.put("result_road", Arrays.toString(b)); result.put("result_value", String.valueOf(k)); return result; &#125; private void Traveling(int t) &#123; int j; if (t &gt; cityNum) &#123; if (distance[x[cityNum]][1] != -1 &amp;&amp; (cl + distance[x[cityNum]][1] &lt; k)) &#123; for (j = 1; j &lt;= cityNum; j++) b[j - 1] = x[j]; k = cl + distance[x[cityNum]][1]; &#125; &#125; else &#123; for (j = t; j &lt;= cityNum; j++) &#123; if (distance[x[t - 1]][x[j]] != -1 &amp;&amp; (cl + distance[x[t - 1]][x[j]] &lt; k)) &#123; int p = x[t]; x[t] = x[j]; x[j] = p; cl += distance[x[t - 1]][x[t]]; Traveling(t + 1); cl -= distance[x[t - 1]][x[t]]; p = x[t]; x[t] = x[j]; x[j] = p; &#125; &#125; &#125; &#125; private void InitData(Map&lt;String, Integer&gt; roadBeans, String str_num) &#123; cityNum = str_num.length(); distance = new int[cityNum + 1][cityNum + 1]; x = new int[cityNum + 1]; b = new int[cityNum + 1]; for (int i = 1; i &lt;= cityNum; i++) &#123; x[i] = i; b[i] = 0; &#125; for (Map.Entry&lt;String, Integer&gt; entry : roadBeans.entrySet()) &#123; String s = entry.getKey(); String[] split = s.split(","); int a = Integer.parseInt(split[0]); int b = Integer.parseInt(split[1]); int length = entry.getValue(); distance[a][b] = length; &#125; &#125;&#125; 贪心法：​123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244package Algorithm;import Bean.RoadBean;import java.util.Arrays;import java.util.HashMap;import java.util.Map;public class Greedy &#123; private Map&lt;RoadBean, Double&gt; roadBeanst; private int cityNum; // 城市数量 private int[][] distance; // 距离矩阵 private Double[][] distance2; private int[] colable;//代表列，也表示是否走过，走过置0 private int[] row;//代表行，选过置0 public Map&lt;String, String&gt; GetMinRoadByTx(Map&lt;String, Integer&gt; roadBeans, String str_num) &#123; Map&lt;String, String&gt; result = new HashMap&lt;&gt;(); InitData(roadBeans, str_num); int[] temp = new int[cityNum]; int[] path = new int[cityNum + 1]; int path_num = 0; path[path_num++] = 1; int s = 0;//计算距离 int i = 0;//当前节点 int j = 0;//下一个节点 //默认从0开始 while (row[i] == 1) &#123; //复制一行 for (int k = 0; k &lt; cityNum; k++) &#123; temp[k] = distance[i][k]; //System.out.print(temp[k]+" "); &#125; //System.out.println(); //选择下一个节点，要求不是已经走过，并且与i不同 j = selectmin(temp); //找出下一节点 row[i] = 0;//行置0，表示已经选过 colable[j] = 0;//列0，表示已经走过 path[path_num++] = j + 1; //System.out.println(i + "--&gt;" + j); //System.out.println(distance[i][j]); if (distance[i][j] == 0) &#123; s += distance[j][i]; &#125; else &#123; s += distance[i][j]; &#125; i = j;//当前节点指向下一节点 &#125; result.put("result_road", Arrays.toString(path)); result.put("result_value", String.valueOf(s)); return result; &#125; public int selectmin(int[] p) &#123; int j = 0, m = p[0], k = 0; //寻找第一个可用节点，注意最后一次寻找，没有可用节点 while (colable[j] == 0) &#123; j++; //System.out.print(j+" "); if (j &gt;= cityNum) &#123; //没有可用节点，说明已结束，最后一次为 *--&gt;0 m = p[0]; break; //或者直接return 0; &#125; else &#123; m = p[j]; &#125; &#125; //从可用节点J开始往后扫描，找出距离最小节点 for (; j &lt; cityNum; j++) &#123; if (colable[j] == 1) &#123; if (m &gt;= p[j]) &#123; m = p[j]; k = j; &#125; &#125; &#125; return k; &#125; private void InitData(Map&lt;String, Integer&gt; roadBeans, String str_num) &#123; cityNum = str_num.length(); distance = new int[cityNum][cityNum]; colable = new int[cityNum]; colable[0] = 0; for (int i = 1; i &lt; cityNum; i++) &#123; colable[i] = 1; &#125; row = new int[cityNum]; for (int i = 0; i &lt; cityNum; i++) &#123; row[i] = 1; &#125; for (Map.Entry&lt;String, Integer&gt; entry : roadBeans.entrySet()) &#123; String s = entry.getKey(); String[] split = s.split(","); int a = Integer.parseInt(split[0]); int b = Integer.parseInt(split[1]); int length = entry.getValue(); a--; b--; distance[a][b] = length; &#125; &#125; public Map&lt;String, String&gt; GetMinRoadByTx(Map&lt;String, Double&gt; stringDoubleMap, int citynum) &#123; Map&lt;String, String&gt; result = new HashMap&lt;&gt;(); this.cityNum = citynum; InitData(stringDoubleMap); Double[] temp = new Double[cityNum]; for (int i = 0; i &lt; cityNum; i++) &#123; temp[i] = 0.0; &#125; int[] path = new int[cityNum + 1]; int path_num = 0; path[path_num++] = 1; Double s = 0.0;//计算距离 int i = 0;//当前节点 int j = 0;//下一个节点 //默认从0开始 while (row[i] == 1) &#123; //复制一行 for (int k = 0; k &lt; cityNum; k++) &#123; temp[k] = distance2[i][k]; //System.out.print(temp[k]+" "); &#125; //System.out.println(); //选择下一个节点，要求不是已经走过，并且与i不同 j = selectmin(temp); //找出下一节点 row[i] = 0;//行置0，表示已经选过 colable[j] = 0;//列0，表示已经走过 path[path_num++] = j + 1; //System.out.println(i + "--&gt;" + j); //System.out.println(distance[i][j]); if (distance2[i][j] == 0) &#123; s += distance2[j][i]; &#125; else &#123; s += distance2[i][j]; &#125; i = j;//当前节点指向下一节点 &#125; result.put("result_road", Arrays.toString(path)); result.put("result_value", String.valueOf(s)); return result; &#125; private int selectmin(Double[] p) &#123; int j = 0, k = 0; Double m = p[0]; //寻找第一个可用节点，注意最后一次寻找，没有可用节点 while (colable[j] == 0) &#123; j++; //System.out.print(j+" "); if (j &gt;= cityNum) &#123; //没有可用节点，说明已结束，最后一次为 *--&gt;0 m = p[0]; break; //或者直接return 0; &#125; else &#123; m = p[j]; &#125; &#125; //从可用节点J开始往后扫描，找出距离最小节点 for (; j &lt; cityNum; j++) &#123; if (colable[j] == 1) &#123; if (m &gt;= p[j]) &#123; m = p[j]; k = j; &#125; &#125; &#125; return k; &#125; private void InitData(Map&lt;String, Double&gt; stringDoubleMap) &#123; distance2 = new Double[cityNum][cityNum]; colable = new int[cityNum]; colable[0] = 0; for (int i = 1; i &lt; cityNum; i++) &#123; colable[i] = 1; &#125; row = new int[cityNum]; for (int i = 0; i &lt; cityNum; i++) &#123; row[i] = 1; &#125; for (Map.Entry&lt;String, Double&gt; entry : stringDoubleMap.entrySet()) &#123; String s = entry.getKey(); String[] split = s.split(","); int a = Integer.parseInt(split[0]); int b = Integer.parseInt(split[1]); Double length = entry.getValue(); a--; b--; distance2[a][b] = length; &#125; &#125;&#125; 具体代码见： java图形界面版TSP问题求解源码 实验三：TSP问题求解（没有图形界面的黑框框版）实验内容TSP问题求解 实验环境电脑环境系统：Ubuntu16.04LTS（Linux 4.10.0-37-generic x86_64）处理器：Intel® Pentium(R) CPU N3700 @ 1.60GHz × 4内存：7.7 GiB操作系统类型：64位操作系统图形：GeForce 920M/PCIe/SSE2 编译运行环境CLion2017.2.3 编程语言C/C++语言 实验算法数据结构定义本实验考虑到所要处理的城市数量不会太多，所以使用比较简单易懂的矩阵（二维数组）来存储图，即S[a][b]=c表示城市a和城市b之间的距离为c。 算法1描述（包含输入输出说明）算法1采用的是贪心算法 算法思想描述a.从某一个城市开始，每次选择一个城市，直到所有的城市被走完。b.每次在选择下一个城市的时候，只考虑当前情况，保证迄今为止经过的路径总距离最小。 输入描述输入时根据提示前两行输入城市数量n和道路数量m，接下来m行，每行3个数，表示m条道路的起点终点以及权重。 输出描述输出为2行，第一行为该算法求解的经过路径，格式为“a–&gt;b–&gt;c–&gt;d–&gt;a”，第二行为使用此种走法的最短路径值。 算法1流程图 算法2描述算法2使用的是回溯法（试探法）： 回溯法描述从一条路往前走，能进则进，不能进则退回来，换一条路再试。 用回溯算法解决问题的一般步骤为：1、定义一个解空间，它包含问题的解。2、利用适于搜索的方法组织解空间。3、利用深度优先法搜索解空间。4、利用限界函数避免移动到不可能产生解的子空间。 输入描述：输入时根据提示前两行输入城市数量n和道路数量m，接下来m行，每行3个数，表示m条道路的起点终点以及权重。 输出描述输出为2行，第一行为该算法求解的经过路径，格式为“a–&gt;b–&gt;c–&gt;d–&gt;a”，第二行为使用此种走法的最短路径值。 算法2流程图 实验结果运行界面 运行结果截图 项目代码核心算法代码回溯法：​123456789101112131415161718192021222324252627282930313233343536void GetMinRoadByHs() &#123; int i; for (i = 1; i &lt;= n; i++) &#123; x[i] = i; b[i] = 0; &#125; Traveling(2); cout &lt;&lt; "城市路线：" &lt;&lt; endl; for (i = 1; i &lt;= n; i++) cout &lt;&lt; b[i] &lt;&lt; "--&gt;"; cout &lt;&lt; b[1]; cout &lt;&lt; endl; cout &lt;&lt; "最短路线长度：" &lt;&lt; endl; cout &lt;&lt; k &lt;&lt; endl;&#125;void Traveling(int t) &#123; int j; if (t &gt; n) &#123; if (g[x[n]][1] != -1 &amp;&amp; (cl + g[x[n]][1] &lt; k)) &#123; for (j = 1; j &lt;= n; j++) b[j] = x[j]; k = cl + g[x[n]][1]; &#125; &#125; else &#123; for (j = t; j &lt;= n; j++) &#123; if (g[x[t - 1]][x[j]] != -1 &amp;&amp; (cl + g[x[t - 1]][x[j]] &lt; k)) &#123; swap(x[t], x[j]); cl += g[x[t - 1]][x[t]]; Traveling(t + 1); cl -= g[x[t - 1]][x[t]]; swap(x[t], x[j]); &#125; &#125; &#125;&#125; 贪心法：​123456789101112131415161718192021222324252627282930313233343536373839404142434445void GetMinRoadByTx() &#123; /** * S[n]用于存储已经访问过的城市 * D[a][b]用于存储a和b之间的距离 * flag 访问过为1，没访问过为0 * i至今已经访问过的城市 */ int j, k, l; int i; i = 1; int beng = i; int sum = 0; int Dtemp; int flag; do &#123; k = 1; Dtemp = 10000; do &#123; l = 0; flag = 0; do &#123; if (S[l] == k) &#123;//判断该城市是否已被访问过，若被访问过， flag = 1;//则flag为1 break;//跳出循环，不参与距离的比较 &#125; else l++; &#125; while (l &lt; i); if (flag == 0 &amp;&amp; D[k][S[i - 1]] &lt; Dtemp) &#123;/*D[k][S[i - 1]]表示当前未被访问的城市k与上一个已访问过的城市i-1之间的距离*/ j = k;//j用于存储已访问过的城市k Dtemp = D[k][S[i - 1]];//Dtemp用于暂时存储当前最小路径的值 &#125; k++; &#125; while (k &lt; n); S[i] = j;//将已访问过的城市j存入到S[i]中 i++; sum += Dtemp;//求出各城市之间的最短距离，注意：在结束循环时，该旅行商尚未回到原出发的城市 &#125; while (i &lt; n); sum += D[0][j];//D[0][j]为旅行商所在的最后一个城市与原出发的城市之间的距离 for (j = 0; j &lt; n; j++) &#123; //输出经过的城市的路径 cout &lt;&lt; S[j] + 1 &lt;&lt; "--&gt;"; &#125; cout &lt;&lt; beng; cout &lt;&lt; "\n" &lt;&lt; sum;&#125; 具体代码见： https://github.com/DMRFWIN/DiscreteMathematicsExperiment_TSP 实验分析2个算法的对比从实验结果很明显可以看出由于贪心法的“只关心局部最小”原则，导致最终求得的结果并不一定是最小的，相比之下回溯法求得的结果明显是最小的，但是回溯法的算法思想和代码复杂度明显高于贪心法，所以得出结论，当并不需要准确的最小值时我们可以用贪心法当对结果的准确性要求较高时我们应该使用回溯法。 实验总结和体会通过本次实验我有以下收获和感受：如何把课堂上学到的离散数学的理论知识应用到实际的编程中，懂得了离散数学是如何提高变成效率的。懂得了如何高效地阅读英文论文、从中提取精华部分，对以后阅读英文文档/论文有很大的帮助。对TSP问题有更加清晰的认识，知道如何编程实现不同的算法解决TSP问题。对合式公式的概念认识更加清楚，巩固了合式公式的计算方法。 对实验的建议：实验可以采用多人（3人以下）组队的方式合作完成，方便提高同学们的团队协作能力。]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[两种不同方式解决八皇后问题]]></title>
    <url>%2F2017%2F11%2F20%2F%E4%B8%A4%E7%A7%8D%E4%B8%8D%E5%90%8C%E6%96%B9%E5%BC%8F%E8%A7%A3%E5%86%B3%E5%85%AB%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述八皇后问题是一个以国际象棋为背景的问题：如何能够在8×8的国际象棋棋盘上放置八个皇后，使得任何一个皇后都无法直接吃掉其他的皇后？为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。 解决思路这个问题可以有两种解决方法，一种是使用递归，比较简单易懂，另一种是使用栈，利用栈的特性避免了递归的使用，从而提高了效率（递归的虽然简单易写，但是其效率往往较低）。 具体实现首先将节点的坐标定义为结构体： ​1234typedef struct &#123; int x; int y;&#125; Coord; 定义好judge函数（用于判断对应点坐标是否可以放置皇后）： ​123456789101112bool judge(SqStack S, int x, int y) &#123; SqStack m = S; while (!StackEmpty(m)) &#123; Coord e; e = Pop(m); if ((e.x == x) || (abs(e.x - x) == abs(e.y - y))) &#123; return false;//如果不行返回false &#125; &#125; return true;//如果可以返回true&#125; 递归​12345678910111213141516171819202122232425262728void Recursive(SqStack &amp;S, int y) &#123; if (StackEmpty(S)) &#123; for (int i = 1; i &lt;= N; ++i) &#123; Coord e; e.x = i; e.y = 1; Push(S, e); Recursive(S, 2); Pop(S); &#125; &#125; else if (Full(S)) &#123; StackTraverse(S); n++; return; &#125; else &#123; for (int i = 1; i &lt;= N; ++i) &#123; if (judge(S, i, y)) &#123; Coord e; e.x = i; e.y = y; Push(S, e); Recursive(S, y + 1); Pop(S); &#125; &#125; &#125;&#125; 这里要注意递归调用Recurive之后要pop出递归之前push进去的，有进就要有出～ 非递归​12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849void Search(SqStack s) &#123; int i = 1; bool flag; Coord e; e.x = 0; e.y = 1; while (i &lt;= 8) &#123; if (flag) &#123; e.x = 0; &#125; if (Full(s)) &#123; e = Pop(s); &#125; flag = false; for (int j = e.x + 1; j &lt;= 8; j++) &#123; if (judge(s, j, i)) &#123; Coord e2; e2.x = j; e2.y = i; Push(s, e2); // cout &lt;&lt; "a" &lt;&lt; i &lt;&lt; "(" &lt;&lt; e.y &lt;&lt; "," &lt;&lt; e.x &lt;&lt; ") "; flag = true; break; &#125; &#125; if (flag) &#123; if (i == 8) &#123; StackTraverse(s); num++; &#125; else &#123; i++; &#125; &#125; else &#123; i--; e = Pop(s); if (i == 0) &#123; break; &#125; &#125; &#125;&#125; ​]]></content>
      <categories>
        <category>Algorithm and data structure</category>
      </categories>
      <tags>
        <tag>八皇后</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从LeNet中分析Caffe模型要素]]></title>
    <url>%2F2017%2F11%2F08%2F%E4%BB%8ELeNet%E4%B8%AD%E5%88%86%E6%9E%90Caffe%E6%A8%A1%E5%9E%8B%E8%A6%81%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[Caffe的模型需要两个重要的参数文件： 网络模型 和 参数配置 (分别是.prototxt文件和.solver.prototxt文件），本文通过经典的LeNet网络分析具体的参数意义。 网络模型Caffe的网络模型文件定义了网络的每一层行为，下图是用Caffe中的python/draw_net.py画出的LeNet的模型（如果图片太小看不清可以右击在选择在新窗口打开或者保存到本地用图片查看器放大查看）： 数据层LeNet网络模型的输入层为数据层，即 网络模型的数据输入定义 ，一般包括训练数据层和测试数据层两种类型。 LeNet训练数据层​1234567891011121314151617 layer &#123; name: "mnist" type: "Data" top: "data" top: "label" include &#123; phase: TRAIN &#125;0p transform_param &#123; scale: 0.00390625//数据缩放因子 &#125; data_param &#123; source: "examples/mnist/mnist_train_lmdb"//数据路径 batch_size: 64//批处理数据大小即一次性读取图片的数目 backend: LMDB &#125;&#125; LeNet测试数据层与训练数据层各字段含义相同。 LeNet训练卷积（Convoluation）层​1234567891011121314151617181920212223layer &#123; name: "conv1" type: "Convolution" bottom: "data" top: "conv1" param &#123; lr_mult: 1//表示weight（权重）更新时的学习率，1倍表示与全局参数一致 &#125; param &#123; lr_mult: 2/*表示bias（偏差）更新时的学习率，一般为权重学习率（weight）学习率的2倍，这样一般会取得很好的收敛速率*/ &#125; convolution_param &#123;//卷积计算参数 num_output: 20//滤波个数即输出特征图（feature map）的数目 kernel_size: 5//滤波大小即卷积核尺寸（在这里为5×5） stride: 1//步长即卷积输出跳跃间隔，1表示连续输出，无跳跃 weight_filler &#123; type: "xavier"/*滤波类型，在这里的意思就是权值使用xavier填充器*/ &#125; bias_filler &#123; type: "constant"//bias使用常数填充器，默认为0 &#125; &#125;&#125; LeNet训练池化（Pooling）层​1234567891011layer &#123;//又叫下采样层 name: "pool1" type: "Pooling" bottom: "conv1"//输入blob top: "pool1"//输出blob pooling_param &#123;//下采样参数 pool: MAX//采样方式，这里用的是最大采样 kernel_size: 2//下采样窗口尺寸 stride: 2//下采样跳跃间隔，这里为2×2 &#125;&#125; LeNet训练全连接层​123456789101112131415161718192021layer &#123; name: "ip1" type: "InnerProduct" bottom: "pool2"//输入blob top: "ip1"//输出blob param &#123; lr_mult: 1 &#125; param &#123; lr_mult: 2 &#125; inner_product_param &#123;//全连接层参数 num_output: 500//该层输出参数为500 weight_filler &#123; type: "xavier" &#125; bias_filler &#123; type: "constant" &#125; &#125;&#125; LeNet训练激活函数层ReLU层​123456layer &#123;//非线性层 name: "relu1" type: "ReLU" bottom: "ip1" top: "ip1"&#125; Softmax层​1234567layer &#123;//损失层 name: "loss" type: "SoftmaxWithLoss"//损失函数 bottom: "ip2" bottom: "label" top: "loss"&#125; 参数配置Caffe中的参数配置文件.solver.prototxt定义了网络模型训练过程中需要设置的参数，比如学习率、权重衰减系数、迭代次数、使用CPU还是GPU等。 LeNet的参数文件解析​1234567891011121314151617181920212223242526272829303132333435# The train/test net protocol buffer definitionnet: "examples/mnist/lenet_train_test.prototxt"# test_iter specifies how many forward passes the test should carry out.# In the case of MNIST, we have test batch size 100 and 100 test iterations,# covering the full 10,000 testing images.test_iter: 100//预测阶段迭代次数（要求与TEST层的batch_size相乘之后等于总的预测集的图片数）# Carry out testing every 500 training iterations.test_interval: 500//训练时每迭代500次进行一次预测# The base learning rate, momentum and the weight decay of the network.base_lr: 0.01//基础学习速率momentum: 0.9//冲量weight_decay: 0.0005//权衰量# The learning rate policylr_policy: "inv"//学习速率的衰减策略gamma: 0.0001power: 0.75# Display every 100 iterationsdisplay: 100//没经过100次迭代在屏幕上打印一次运行log# The maximum number of iterationsmax_iter: 10000//最大迭代次数# snapshot intermediate resultssnapshot: 5000snapshot_prefix: "examples/mnist/lenet"# solver mode: CPU or GPUsolver_mode: GPU//选择使用CPU还是GPU进行训练 训练出的输出文件格式为.caffemodel即所求的model，可以拷贝至目标机器进行分类、定位和识别。 参考资料：【1】：深度学习——Caffe之经典模型详解与实战 乐毅 王斌 编著【2】：深度学习——21天实战caffe 赵永科 编著]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>Lenet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习入门知识]]></title>
    <url>%2F2017%2F11%2F08%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[神经网络模型人脑视觉机理大致机理： 从原始信号，叫做低级抽象，逐渐到高级抽象迭代。人类的逻辑思维，经常使用高度抽象的概念，例如人类看到一个气球并识别出它是一个气球的大体流程（对应图2-2左）：瞳孔摄入像素Pixels—— &gt;大脑皮层某些细胞发现边缘和方向——&gt;大脑判断眼前物体的形状是圆形的——&gt;大脑进一步判定该物体是个气球这个流程对应的人脑抽象阶段就是：原始信号摄入—— &gt;做初步处理——&gt;抽象——&gt;进一步抽象 总的来说，人的视觉系统的信息处理是分级的，如图2-2右图，从低级的V1区提取边缘特征，再到V2区的形状或者目标的部分结构，再到最高层，形成整个目标和目标行为。也就是说高层的特征是底层特征的组合 ，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。而抽象层面越高，存在的可能猜测就越少，越有利于分类。 人工神经网络人工神经网络实在现代神经科学的基础上提出和发展起来的，旨在反映人脑结构及功能的一种抽象数学模型。 人工神经元模型如图2-4显示了作为人工神经网络（Artificial Neural Network）的基本单元的神经元模型，它有三个要素：（1）：一组连接（对应神经元上的突触（神经元之间的连接接口，由于突触的信息传递特性是可变的，形成了神经元间连接的柔性，称为结构的可塑性）），连接强度由各连接上的权值 表示， 权值为正表示激活，为负表示抑制 。（2）：一个求和单元，用于求取各输入信号的加权和（线性组合）。（3）：一个非线性激活函数，起 非线性映射作用 并 将神经元输出幅度限制在一定范围内 。（详解见蓝皮书P16） BP神经网络通过对神经网络模型的了解我们知道人脑对信息的传递和对外界刺激所产生的反应都是由神经元控制的，人脑平均由上百亿这样的神经元组成。刺激在神经网络的传播是遵循一定规则的，一个神经元并非每次接到其他神经元传来的刺激都产生反应，它首先会将其相邻神经元传来的刺激进行积累，到一定时候产生自己的刺激并传递给一些与它相邻的神经元。而人脑对外界刺激的学习机制就是通过调节这些神经元之间联系及其强度 。 BP（Back Propagation）网络是一种按误差逆传播算法训练的多层前馈网络，是目前应用的最广泛的神经网络模型之一。BP网络能学习和存储大量的输入-输出模式映射关系。它的学习规则是 使用梯度下降法，通过反向传播来不断调整网络的权值和阈值，使网络的误差平方和最小 。BP神经网络模型拓扑结构包括输入层（Input）、隐层（Hide layer）和输出层（Output layer） 。 BP神经网络构成示意图： 简单的描述： 输入层将刺激传递给隐藏层，隐藏层通过神经元之间连接的强度（权值）和传递规则（激活函数）将刺激传到输出层，输出层整理隐藏层处理后的刺激产生最终结果。若有正确的结果，那么将正确的结果和产生的结果进行比较，得到误差，再逆推对神经网中的链接权重进行反馈修正，从而来完后才能学习过程。这就是BP神经网络的反馈机制，也正是BP（Back Propagation）名字的来源，即运用向后反馈的学习机制，来修正神经网中的权重，最终达到输出正确结果的目的。 BP算法由数据流的 前向计算（正向传播） 和识别信号的 反向传播 两个过程构成。正向传播时，传播方向为输入层—— &gt;隐层——&gt;输出层，每层神经元的状态只影响下一层神经元。如果在输出层得不到期望的输出，则转向误差信号的反向传播流程。通过这两个过程的交替执行，使网络误差函数达到最小值，从而完成信息提取和记忆过程。（具体正反向传播算法见蓝皮书P21。） 卷积神经网络（ConvNet/CNNs）卷积神经网络是 人工神经网络的一种 。卷积网络是 为识别二维形状特殊设计的一个多层感知器 ，这种网络结构对 平移、比例缩放、倾斜或者其他形式的变形 具有 高度不变性 。ConvNet的四项基本原则： 局部互联（局部感知）、共享权值（参数共享）、下采样（池化）、多个卷积层 。权值共享意味着更少的参数量，使之更类似于生物神经网络，降低了网络模型的复杂度，使图像可以直接作为网格的输入，避免了传统识别算法中复杂的特征提取和数据重建过程。 卷积神经网络的网络结构卷积神经网络是一个多层的神经网络，每层由多个二维平面组成，而 每个平面由多个独立神经元组成，如图2-9所示：（纵向的Input、C1、S2、C3、S4就是所谓的层）原理：输入图形通过三个可训练的 滤波器 和 可加偏置 进行 卷积 ，卷积后在C1层产生三个 特征映射图（feature map），然后特征映射图中每组的 四个像素 再进行 求和、加权值、加偏置 ，通过一个 激活函数（Sigmoid） 得到三个S2层的特征映射图 。这些特征映射图再经过 滤波 得到C3层。这个层级结构再和S2一样产生S4。最终，这些像素被光栅化，并 裂解成一个向量输入到传统的神经网络，进而得到输出。一般地，C层为 特征提取层 ，每个神经元的输入与前一层的 局部感受野 相连，并提取该局部特征，一旦该局部特征被提取后，它与其他特征间的位置关系也随之确定下来 。S层是 特征映射层 ，网络的 每个计算层 由多个特征映射组成， 每个特征映射为一个平面，平面上所有神经元的权值相等。特征映射结构采用 影响函数核小 的sigmoid函数作为卷积网络的激活函数，使得特征映射具有 位移不变性 。此外，由于 一个映射面上的神经元共享权值 ，因而减少了网络自由参数的个数，降低了网络参数选择的复杂度。卷积神经网络中的每一个特征提取层（C层）都紧跟着一个用来求局部平均与二次提取的计算层（S层） ，这种特有的两次特征提取结构使网络在识别时对输入样本有较高的畸变容忍能力 。 卷积网络的基本原则局部感知卷积神经网络有两种技术可以降低参数数目，第一种技术叫做 局部感知野（局部连接） 。一般认为人对外界的认识是从局部到全局的，而图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。因此，每个神经元其实没有必要对全局图像进行感知（全局连接），只需对局部进行感知（局部连接） ，然后 在更高层将局部信息综合起来就得到了全局信息。如图：图2-10左图为全连接，右图为局部连接，在右图中，假如每个神经元只与10×10个像素值相连，因为该图有1000000个神经元，那么权值数据为1,000,000×100个参数，减少为原来的千分之一。而那10×10个像素值对应的10×10个参数，其实就相当于卷积操作。 权值共享如果采用局部连接处理后参数还是过多，那么就需要新的策略，即 权值共享 。在上面的局部连接中，每个神经元都对应100个参数，一共1000000个神经元，如果这1000000个神经元的100个参数都是相等的（即这1000000个神经元共享参数），那么参数数目就为100了。可以把这100个参数（也就是卷积操作）看做是提取特征的方式，该方式与位置无关。这其中隐含的原理是： 图像的一部分的统计特性与其他部分是一样的，这也意味着我们在这一部分学习到的特征也能用在另一部分上，所以对与这个图像上的所有位置，我们都能使用相同的学习特征。更直观一些，当从一个大尺寸图像中随机选取一小块，比如8×8作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这8×8样本中学习到的特征作为探测器 ，应用到这个图像的任意地方去。特别地，我们可以用从8×8的样本中学习到的特征跟原本的大尺寸图案做卷积，从而这个大尺寸图像的任一位置获得一个同的激活值。 多卷积核上述例子只有100个参数时，表明只有1个10×10的卷积核，显然，特征提取是不充分的，我们可以添加多个卷积核，比如32个卷积核，可以学习32种特征。在有多个卷积核时，如图2-11所示（在图上表现就是从左图的一个球变成了好多个球一堆……）：图2-11右图对图片的不同部分进行卷积，他们表明了不同的卷积核。每个卷积核都会将图像生成为另外一幅图像。比如两个卷积核就可以生成两幅图像，这两幅图像可以看做一张图像的不同通道，如下图所示：图中左半部分的四个矩形框就表示四个通道（有两个卷积核），右边部分的两个框表示两个生成通道。其中需要注意的是，四个通道上每个通道对应一个卷积核（这样的话按理说应该有四个卷积核，但是事实只有2个卷积核，所以理解为一个卷积核可以被多个通道对应？），现将w1忽略，只看w0，那么w0的某位置（i，j）处的值，是由四个通道上（i，j）处的卷积结果相加再取激活函数值 得到的。所以，由四个通道卷积得到两个通道的过程中，参数的数目为4× 2× 2 ×2 个，其中4表示4个通道，第一个2表示生成2个通道，后两个2表示卷积核大小为2×2. 池化（下采样）在通过卷积获得了特征（features）之后，下一步我们希望利用这些特征去做分类。理论上讲，人们可以用所有提取到的特征去训练分类器，但是这样做面临计算量的挑战，并且容易出现过拟合（因为得到的特征太多了）。过拟合：用白话来说就是老师给你的题你都会做了，考试给你换个花样你就懵逼了。好，老师给你的题就相当于我们的训练数据，考试的题相当于测试数据，“过拟合”就是深度网络把训练的数据拟合的特别好，但是有点好过头了，对训练数据当然是100%好用，但是一来测试数据就疯了，那这样的网络训练出来其实是没有用的，训练集已经是监督学习了，拟合的再好也没用。（网络设计的太好太完美了，导致模型“记住了”训练集，但是到测试的时候就会表现的很差）。为了解决这一问题，我们应该回到起点，我们之所以决定采用卷积后的特征，是因为图像具有一种“静态性”，这也就意味着在一个图像区域中有用的特征极有可能在另外一个区域同样适用 。因此，为了描述大的图像，一个很自然的想法就是 对不同位置的特征进行聚合统计。例如，人们可以计算图像的一个区域上的 某个特定特征的平均值（或最大值）。这些概要统计特征不仅具有低得多的维度（相比于使用所有提取到的特征），同时能改善结果（不容易出现过拟合）。这种聚合的方法就叫做池化（Pooling） ，有时也叫作平均池化或最大池化（取决于计算池化的方法）。 深度学习的反思深度学习看似万能，实则有很多调参技巧在里面，掌握得当可以快速获得模型，否则可能费力不讨好： 模型参数远大于数据量相当于求解一个欠定方程，存在多解的可能性大，容易产生过拟合问题。 模型参数远小于数据量相当于求解超定方程，可能无解，或者有解但准确率很低，这属于欠拟合问题。 模型参数与数据量匹配相当于求解恰定方程，既能避免过拟合，也能兼顾准确率，但模型参数量和数据量怎样做到匹配，是一个工程问题。 所以，如果你选择用某个模型处理数据，那么应该考虑这个因素，越大的模型越难训练，因为需要与之匹配的数据量，一系列避免过拟合的方法才能训练一个较为理想的模型。幸运的是，我们可以将大模型首先在较大的数据集（如ImageNet）上预训练，得到模型（model），再对特定数据集（如人脸数据）进行精调（fine-tuning），即可得到较为理想的结果。 参考资料：【1】：深度学习——Caffe之经典模型详解与实战 乐毅 王斌 编著【2】：深度学习——21天实战caffe 赵永科 编著]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下配置caffe时无法链接libcudart.so.8.0的解决方案]]></title>
    <url>%2F2017%2F11%2F02%2Fubuntu%E4%B8%8B%E9%85%8D%E7%BD%AEcafe%E6%97%B6%E6%97%A0%E6%B3%95%E9%93%BE%E6%8E%A5libcudart.so.8.0%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[报错信息如下： 12error while loading shared libraries: libcudart.so.8.0: cannot openshared object file: No such file or directory 解决方案： 1sudo ldconfig /usr/local/cuda/lib64]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>ubuntu</tag>
        <tag>caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下安装TeamViewer远程协助软件]]></title>
    <url>%2F2017%2F11%2F01%2Fubuntu16.04%E4%B8%8B%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B8%A6Remmina%E6%8E%A7%E5%88%B6%E5%88%AB%E7%9A%84ubuntu%E6%9C%BA%E5%99%A8%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言团队开发中经常会使用到远程协助软件，当团队成员遇到问题的时候其他成员可以远程帮助解决，在TeamViewer是一款优秀的跨平台协作软件，这里简要介绍一下Ubuntu16.04系统下的安装方法： 下载deb包首先打开 TeamViewer的官网 下载对应系统版本的deb包：下载到的是一个32位的deb包。Debian 6/Ubuntu 10等旧发行版本可以下载64位deb包，因为它们没有Multiarch多架构功能。对于Ubuntu 16.04，我们必须下载32位deb包，因为Ubuntu 16.04具备多架构功能，即使是64位的Ubuntu 16.04系统也能安装32位的deb包。 安装下载好deb包后打开终端并将目录切换到deb包的位置（推荐直接把deb包放在home目录下，安装完成后即可删除）64位Ubuntu 16.04系统首先需要添加32位架构支持，命令如下： sudo dpkg --add-architecture i386 sudo apt-get update 添加好后就还需要下载一些依赖包： sudo apt-get install libdbus-1-3:i386 libasound2:i386 libexpat1:i386 libfontconfig1:i386 libfreetype6:i386 libjpeg62:i386 libpng12-0:i386 libsm6:i386 libxdamage1:i386 libxext6:i386 libxfixes3:i386 libxinerama1:i386 libxrandr2:i386 libxrender1:i386 libxtst6:i386 zlib1g:i386 libc6:i386 现在就可以安装deb包了： sudo dpkg -i teamviewer*.deb 安装完成后输入： teamviewer 打开TeamViewer，然后点击Sign up按照提示操作就可以了。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>TeamViewer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu16.04下安装Matlab]]></title>
    <url>%2F2017%2F10%2F30%2Fubuntu16.04%E4%B8%8B%E5%AE%89%E8%A3%85Matlab%2F</url>
    <content type="text"><![CDATA[不想说太多废话直接开干吧，我看了好多教程写的挺好但是不给matlab的资源，所以先把我搞到的matlab资源给大家，下载链接: https://pan.baidu.com/s/1qYPvHSg 密码: zwfq下载完成之后打开应该有如下三个文件：现在开始安装： 挂载映像文件在安装前，建议把所需文件都拷贝到了home目录，进行安装。那么使用下列命令挂先挂载R2016b_glnxa64_dvd1.iso： cd ~ mkdir matlab sudo mount -t auto -o loop Linux/R2016b_glnxa64_dvd1.iso matlab/ 安装Matlab挂载iso之后，会发现文件系统多了一个盘，说明挂载成功，然后进行安装： cd matlab/ sudo ./matlab/install 依次按照下列状态执行：到这里点击下一步即可开始安装，安装进行到80%左右的时候，会弹出一个提示框，说请插入dvd2，这时候我们需要重新开一个终端，把dvd2挂载到matlab文件夹中： sudo mount -t auto -o loop Linux/R2016b_glnxa64_dvd2.iso matlab/ 然后在对话框中点击OK，继续安装。安装完成后就可以卸载之前挂载的镜像和matlab文件夹了。 激活Matlab安装完成后，打开matlab： cd /usr/local/MATLAB/R2016b/bin ./matlab 第一步，先载入激活文件license_standalone.lic（因为笔者已经激活了matlab所以无法截图，以下两张图片来源于网络）： 第二步，把Crack文件夹中R2016b/Linux/R2016b/bin/glnxa64四个文件，复制到/usr/local/MATLAB/R2016b/bin/glnxa64目录下（为了命令行简单先把Matlab2016b Linux64 Crack文件夹重命名为Crack，在linux目录下执行）： sudo cp Crack/R2016b/bin/glnxa64/libcufft.so.7.5.18 /usr/local/MATLAB/R2016b/bin/glnxa64 sudo cp Crack/R2016b/bin/glnxa64/libinstutil.so /usr/local/MATLAB/R2016b/bin/glnxa64 sudo cp Crack/R2016b/bin/glnxa64/libmwlmgrimpl.so /usr/local/MATLAB/R2016b/bin/glnxa64 sudo cp Crack/R2016b/bin/glnxa64/libmwservices.so /usr/local/MATLAB/R2016b/bin/glnxa64 至此，MatLab已经安装、激活。 创建快捷方式通过以上步骤安装的matlab并没有快捷方式，读者可以通过创建环境变量或者创建快捷方式的方法来快速启动，笔者使用的是创建快捷方式的方法： sudo gedit /usr/share/applications/Matlab.desktop 写入以下内容（先把下图放进/usr/local/MATLAB/）： ​ [Desktop Entry] Type=Application Name=Matlab GenericName=Matlab 2016b Comment=Matlab:The Language of Technical Computing Exec=sh /usr/local/MATLAB/R2016b/bin/matlab -desktop Icon=/usr/local/MATLAB/Matlab.png Terminal=false Categories=Development; Matlab; 好了，现在你就可以从快捷方式启动MatLab啦。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下运行caffe下的“Hello World”——mnist手写体数字识别例程]]></title>
    <url>%2F2017%2F10%2F30%2Fubuntu%E4%B8%8B%E8%BF%90%E8%A1%8Ccaffe%E4%B8%8B%E7%9A%84%E2%80%9CHello%20World%E2%80%9D%E2%80%94%E2%80%94mnist%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E4%BE%8B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言mnist例程几乎是所有深度学习入坑者首先要经历的，第一次跑是在windows下跑的，后来为了DL入坑Linux就没跑过了，因为几位小伙伴也有这方面需求，所以特意抽时间跑了一遍，将我的运行过程记录下来，希望可以帮到有希望的小伙伴。 环境说明：笔者的系统环境为Ubuntu16.04，且默认大家已经安装配置好了caffe环境，如果有同学没有配置好caffe可以移步笔者的 另外一篇文章 主要步骤1：下载mnist数据集2：生成LMDB3：网络配置4：训练网络5：测试网络6：利用训练好的模型预测单张数字图片 下载mnist数据集mnist数据集可以在caffe源码框架的data/mnist下用get_mnist.sh脚本下载，具体命令如下（在caffe根目录下执行）： ​1./data/mnist/get_mnist.sh 生成LMDB我们下载到的数据集为二进制文件，需要转化为LEVELDB或LMDB才能被caffe识别，转化命令如下（在caffe根目录下执行）： ​ ./examples/mnist/create_mnist.sh 执行完这条命令以后我们就会在examples/mnist下发现mnist_train_lmdb和mnist_test_lmdb两个文件夹，每个文件夹里都有data.lmdb和lock.lmdb两个文件。 网络配置mnist使用的是lenet网络模型，其定义在mnist的lenet_train_test.prototxt文件中，只需要注意source参数文件路径： ​ layer { name: “mnist” type: “Data” top: “data” top: “label” include { phase: TRAIN } transform_param { scale: 0.00390625 } data_param { source: “examples/mnist/mnist_train_lmdb” batch_size: 64 backend: LMDB } } layer { name: “mnist” type: “Data” top: “data” top: “label” include { phase: TEST } transform_param { scale: 0.00390625 } data_param { //主要注意这里的路径为mnist_test_lmdb的路径就好（一般默认的路径都是对的） source: “examples/mnist/mnist_test_lmdb” batch_size: 100 backend: LMDB } } 训练网络确保mnist的网络模型没有问题后我们在caffe根目录下输入以下命令开始训练网络： ​ ./examples/mnist/train_lenet.sh 然后就是等待，大概十分钟左右就可以训练完毕，毕竟数据量小。 测试网络利用训练好的lenet-5模型权值文件（examples/mnist/lenet_iter_10000.caffemodel）可以对测试数据集（或外部数据集）进行预测，在caffe根目录下运行如下命令： ​ ./build/tools/caffe.bin test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -iterations 100 命令行解释： ./build/tools/caffe.bin test ，表示只做预测（forward前向传播计算），不进行参数更新（backward后向传播计算） -model examples/mnist/lenet_train_test.prototxt ，指定模型描述文本文件 -weights examples/mnist/lenet_iter_10000.caffemodel ，指定模型预先训练好的权值文件 -iterations 100 ，指定测试迭代次数。参与测试的样例数目为（iterations*batch_size），batch_size在modelprototxt中设定，为100时刚好覆盖10000个测试样本。 读者可运行上述命令，分析输出日志，与训练阶段输出做对比。 利用训练好的模型预测单张数字图片参考: http://blog.csdn.net/xunan003/article/details/73126425可能大家觉得上面的那些工作都没什么意思，就是敲一堆命令行+看一堆终端输出，所以我特意为大家准备了这部分测试预测自己的数字图片： 思路梳理手写数字图片必须满足以下条件：（1）必须是256位黑白色（2）必须是黑底白字（3）像素大小必须是28x28（4）数字在中间，上下左右没有过多空白 利用模型lenet_iter_10000.caffemodel测试单张手写体数字所需要的文件：（1）待测试图片（自己画的也行，网络上下的也行）； 需要注意的是，不管是什么格式，都要转换为28*28大小的黑白灰度图像，具体转化方法请自行百度，不想转化的我这里提供给大家一组我转化好的图片资源供大家下载链接:https://pan.baidu.com/s/1boGHQzl 密码:qfd6（2）deploy.prototxt（模型描述型文件）；（3）network.caffemodel（模型权值文件），在本例中就是lenet_iter_10000.caffemodel（4）labels.txt（标签文件）；（5）mean.binaryproto（二进制图像均值文件）；（6）classification.bin（二进制程序名）。与二进制均值文件配合使用，只是均值文件不同的模型有不同的均值文件，而这个bin文件为通用的，就是任何模型都可以做分类使用。 所需文件生成生成deploy.prototxt文件deploy.prototxt文件和lenet_train_test.prototxt文件类似，或者说对后者改动可得到前者。在examples/mnist目录下复制一份lenet_train_test.prototxt修改并保存后得到deploy.prototxt如下： ​ name: “LeNet” layer { name: “data” type: “Input” top: “data” input_param{shape:{dim:1 dim:1 dim:28 dim:28}} } layer { name: &quot;conv1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; top: &quot;conv1&quot; convolution_param { num_output: 20 kernel_size: 5 stride: 1 weight_filler { type: &quot;xavier&quot; } } } layer { name: &quot;pool1&quot; type: &quot;Pooling&quot; bottom: &quot;conv1&quot; top: &quot;pool1&quot; pooling_param { pool: MAX kernel_size: 2 stride: 2 } } layer { name: &quot;conv2&quot; type: &quot;Convolution&quot; bottom: &quot;pool1&quot; top: &quot;conv2&quot; convolution_param { num_output: 50 kernel_size: 5 stride: 1 weight_filler { type: &quot;xavier&quot; } } } layer { name: &quot;pool2&quot; type: &quot;Pooling&quot; bottom: &quot;conv2&quot; top: &quot;pool2&quot; pooling_param { pool: MAX kernel_size: 2 stride: 2 } } layer { name: &quot;ip1&quot; type: &quot;InnerProduct&quot; bottom: &quot;pool2&quot; top: &quot;ip1&quot; inner_product_param { num_output: 500 weight_filler { type: &quot;xavier&quot; } } } layer { name: &quot;relu1&quot; type: &quot;ReLU&quot; bottom: &quot;ip1&quot; top: &quot;ip1&quot; } layer { name: &quot;ip2&quot; type: &quot;InnerProduct&quot; bottom: &quot;ip1&quot; top: &quot;ip2&quot; inner_product_param { num_output: 10 weight_filler { type: &quot;xavier&quot; } } } layer { name: &quot;prob&quot; type: &quot;Softmax&quot; bottom: &quot;ip2&quot; top: &quot;prob&quot; } 生成labels.txt标签文件在当前目录下新建一个txt文件，命名为synset_words.txt，里面内容为我们训练mnist的图片内容，共有0~9十个数，那么我们就建立如下内容的标签文件： 生成mean.binaryproto二进制均值文件caffe作者为我们提供了一个计算均值的文件compute_image_mean.cpp，放在caffe根目录下的tools文件夹里面，运行下面命令生成mean.binaryproto二进制均值文件: sudo build/tools/compute_image_mean examples/mnist/mnist_train_lmdb examples/mnist/mean.binaryproto 生成的mean.binaryproto均值文件保存在了examples/mnist目录下。 分类器classification.bin在example文件夹中有一个cpp_classification的文件夹，打开它，有一个名为classification的cpp文件，这就是caffe提供给我们的调用分类网络进行前向计算，得到分类结果的接口。 开始测试在caffe根目录下命令： ​ ./build/examples/cpp_classification/classification.bin examples/mnist/deploy.prototxt examples/mnist/lenet_iter_10000.caffemodel examples/mnist/mean.binaryproto examples/mnist/synset_words.txt examples/images/3.jpg 然后就可以看到预测结果：]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>caffe</tag>
        <tag>mnist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装ubuntu系统时卡在开机logo的解决方案]]></title>
    <url>%2F2017%2F10%2F30%2F%E5%AE%89%E8%A3%85ubuntu%E7%B3%BB%E7%BB%9F%E6%97%B6%E5%8D%A1%E5%9C%A8%E5%BC%80%E6%9C%BAlogo%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[一般出现这种情况大多数是显卡驱动有问题，解决方案如下：1：在开机选择从U盘启动后（我是用U盘装的）会有几个选项让选择，最重要的两个是让你选择使用而不安装还是安装，我们通过上下箭头或者TAB把光标移动到“安装”选项，然后按e，进入grub界面，将这个界面的最后部分的“quiet splash —”改为“nomodeset”。F10保存，就可以进入安装界面，进行安装。2：按照这种方法安装完成后有一个问题就是第二次启动ubuntu系统的时候会卡在启动界面进不去，解决方案：重启，开机时光标选中“Ubuntu”，按“e”，进入grub界面，在刚刚改过的那行(倒数第二行)的末尾加上 “ acpi_osi=Linuxnomodeset”（nvidia显卡 ），再F10保存重启，就可以进入。但是每次进入都需要这样修改，肯定很麻烦，所以进去之后到/boot/grub/grub.cfg(sudo gedit /boot/grab/grab.cfg)中，找到刚刚在修改界面所看到的那一串代码，在同样的位置加入刚刚所修改的代码，保存退出就好了，这样就可以完美解决开机卡死的问题。说明：本教程只对NVIDIA显卡的电脑有效，其他的没测试过。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>报错解决方案</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下配置Android NDK的方法]]></title>
    <url>%2F2017%2F10%2F30%2FUbuntu16.04%E4%B8%8B%E9%85%8D%E7%BD%AENDK%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言：前段时间因为要做百度的mobile-deep-learning，在build其github上的项目时提示要安装配置NDK，网上有很多教程，但是大多不完善（至少我是没找到一个能完整解决我的问题的），历经坎坷终于配置成功，所以将我的配置方法记录下来，希望可以帮到有需要的同学。 下载NDK这里提供一种比较好用的下载方法，就是我们可以使用androidstudio进行NDK的下载（如果没有as的同学也可以到网上手动下载，资源很多的），具体方法如下：打开android studio的settings，然后在搜索框输入NDK，这时会出现如下界面：点击SDK Tools会看到：在这个列表里你会找到NDK，勾选之后点击Apply即可下载，另外如果正在看此文的你也打算研究一下百度的mobile-deep-learning，你也可以通过相同的下载方式下载Cmake。 配置NDK通过android studio下载的NDK默认会放在你的SDK目录下，文件名应为ndk-bundle，接下来介绍如何通过终端配置ndk的环境变量： 首先打开profile：sudo vim /etc/profile 没有安装vim的同学也可以使用gedit打开： sudo gedit /etc/profile 打开后在profile文件的末尾加上： export NDK_HOME=sdkroot/ndk-bundle PATH=$NDK_HOME:$PATH sdkroot是你的sdk目录，每个人的不一样，视情况而定，下面是我的配置截图：添加完成后保存退出，使用以下命令使配置的环境变量生效： source /etc/profile 验证ndk是否配置成功：ndk-build -v 出现类似以下输出即说明ndk配置成功：]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>NDK</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下配置caffe（亲测成功）]]></title>
    <url>%2F2017%2F10%2F08%2FUbuntu16.04%E4%B8%8B%E9%85%8D%E7%BD%AEcaffe%EF%BC%88%E4%BA%B2%E6%B5%8B%E6%88%90%E5%8A%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言：历经一个国庆的折腾，终于成功在Ubuntu下搭建好了caffe，过程中遇到的坑真的是数不胜数，最大的一次坑是本来已经配置好了结果手残命令行一阵不知名命令之后电脑崩溃又得重装系统，结果装好系统再配置的时候出现了比第一次更多的坑，真是说多了都是泪，为了让大家避免我遇到的坑，特写此文章，希望能帮助到有的同学，同时说明本人目前是大二本科生，能力有限，文章中如有不正确的地方希望大家积极指出，本人不胜感谢，好了，废话不多说，进入正文！ 目录结构1：安装开发所需依赖包2：下载安装CUDA8.0并验证是否安装成功3: 下载安装cudnn并验证是否安装成功4：下载安装opencv并验证是否安装成功5：安装编译caffe 特别说明：1:本教程版本搭配为：Ubuntu16.04+CUDA8.0+Opencv3.1.0，建议初学者尽量按照本教程的搭配进行配置，防止出现版本不搭造成的错误，这一点笔者真是深有体会，当然鼓励大家尝试新版本，如果有成功的同仁麻烦告诉我你的搭配，笔者不胜感激。2:建议大家在输入所有命令之前加上sudo，防止出现“权限不够”这类情况，笔者为了节省时间在教程里面有的需要加sudo的地方没有加，大家可不要偷懒～～3：本文参考blog：http://blog.csdn.net/yhaolpz，感谢大神博主的教程 安装开发所需依赖包命令行直接复制粘贴进以下命令即可： 123456789sudo apt-get install --no-install-recommends libboost-all-devsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compilersudo apt-get install libopenblas-dev liblapack-dev libatlas-base-devsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-devsudo apt-get install git cmake build-essential 因为有一定的几率安装失败，而如果刚好某个依赖安装失败导致后期出现莫名的错误那你可就欲哭无泪了，安装完成之后建议大家验证一下是否安装成功，验证方法是再在终端输入一遍sudoapt-get install ..的命令，如图： 下载安装CUDA8.0并验证是否安装成功下载安装CUDA8.0NVIDIA官网提供两种方式来安装CUDA，即run安装和deb安装，这里不建议初学者使用run安装，因为run安装对Linix版本和Linix kernel版本以及GCC版本都有严格要求，稍有不符，可能就会导致失败，所以这里为大家介绍deb方式安装： 首先下载CUDA8.0的deb包（可去官网下，也可至笔者的网盘下载，网盘链接见文末），下载好之后依次键入以下命令： sudo dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb sudo apt-get update sudo apt-get install cuda 配置环境变量命令： sudo gedit /etc/profile 在文件最后加上 PATH=/usr/local/cuda/bin:$PATH export PATH LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64 export LD_ LIBRARY_PATH 使用以下命令使其生效： source /etc/profile 安装完成以后一定要 重启电脑 使其生效。 验证CUDA8.0是否安装成功重启电脑之后请读者可依次键入以下命令验证CUDA8.0是否安装成功： ​ cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery sudo make ./deviceQuery 如果看到类似以下信息就说明CUDA安装成功： 下载安装cudnn并验证是否安装成功下载安装cudnn读者可以登录官网： https://developer.nvidia.com/rdp/cudnn-download，注册后下载cudnn，笔者这里上传了我用的cudnn，下载链接见文末。 下载完成后解压，得到一个 cuda 文件夹，该文件夹下include 和 lib64 两个文件夹，命令行进入 cudn/include路径下，然后进行以下操作： sudo cp cudnn.h /usr/local/cuda/include/ #复制头文件 然后命令行进入 cudn/lib64路径下，运行以下命令（注意：下面命令的..so.5.1.10和..so.5视个人的情况而定，如果你没有使用CUDN8.0以及其对应的cudnn版本，..so.后面的数字不一定与下面相同，读者可直接到你的文件目录下模糊查找对应的so版本）： sudo cp lib* /usr/local/cuda/lib64/ #复制动态链接库 cd /usr/local/cuda/lib64/ sudo rm -rf libcudnn.so libcudnn.so.5 #删除原有动态文件 sudo ln -s libcudnn.so.5.1.10 libcudnn.so.5 #生成软衔接 sudo ln -s libcudnn.so.5 libcudnn.so #生成软链接 验证cudnn是否安装成功键入以下命令： nvcc -V 如果出现类似以下内容则说明安装成功： 下载安装opencv并验证是否安装成功下载安装opencv读者可进入官网 : [http://opencv.org/releases.html , 选择 3.1.0 版本的 source , 下载 opencv-3.1.0.zip，也可至笔者的网盘下载，下载链接见文末，下载后解压至你想安装的目录，命令行进入已解压的文件夹 opencv-3.1.0 目录下，执行以下命令： mkdir build # 创建编译的文件目录 cd build cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local .. make -j8 #编译 这里需要注意的是，在执行cmake…的时候会下载一个压缩包，下载的地址是被墙掉的，可能大家有的人给自己的chrome搭了梯子，但是因为是通过终端下载的，所以就算你的chrome可以上外网也不一定下的来（因为你的终端不一定可以翻过去），这就导致会报类似如下的错误： 解决方法是读者去网上自行找下好的包然后导入，但是网上大多都是要积分才能下载的，这里笔者上传我的包（其实我也是花积分下载的）免费给大家，也算是为人民服务哈哈，下载链接同样见文末，下载后直接把下载的压缩包放入你的opencv目录/opencv-3.1.0/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e下，然后再次执行cmake…就可以正常了。编译成功后进行安装： sudo make install PS：1:make 的时候可能会报错： CMake Error at cuda_compile_generated_matrix_operations.cu.o.cmake :206 (message): Error generating /home/yy/opencv-2.4.9/build/modules/core/CMakeFiles/cuda_compile.dir/__/dynamicuda/src/cuda/./cuda_compile_generated_matrix_operations.cu.o make[2]: *** [modules/core/CMakeFiles/cuda_compile.dir/__/dynamicuda/src/cuda/./cuda_compile_generated_matrix_operations.cu.o] 错误 1 make[1]: *** [modules/core/CMakeFiles/opencv_core.dir/all] 错误 2 make: *** [all] 错误 2 解决方案 12sudo cmake -D CMAKE_BUILD_TYPE=bulid -D CMAKE_INSTALL_PREFIX=/usr/local -DCUDA_GENERATION=Kepler .. 然后再make。 sudo make时，也可能出现 make[2]: *** [modules/cudalegacy/CMakeFiles/opencv_cudalegacy.dir/src/graphcuts.cpp.o] Error 1 make[1]: *** [modules/cudalegacy/CMakeFiles/opencv_cudalegacy.dir/all] Error 2 make: *** [all] Error 2 的错误。那是因为 cuda-8.0与OpenCV 3.1.0发生了冲突。解决方法：修改openCV 3.1.0源码，使其兼容cuda-8.0,可做如下操作： sudo gedit opencv-3.1.0/modules/cudalegacy/src/graphcuts.cpp 将第四十五行位置的 ​ #if !defined (HAVE_CUDA) || defined (CUDA_DISABLER) 改为 ​ #if !defined(HAVE_CUDA)||defined(CUDA_DISABLER)||(CUDART_VERSION&gt;=8000) 然后重新执行make. 验证opencv安装是否成功在终端输入以下命令： pkg-config --modversion opencv 如果正常输出opencv版本则说明opencv安装成功。 下载配置编译caffe下载caffe首先在你要安装的路径下 clone ： git clone https://github.com/BVLC/caffe.git 配置caffe（这部分引自大神的blog）进入 caffe ，将 Makefile.config.example 文件复制一份并更名为 Makefile.config ： sudo cp Makefile.config.example Makefile.config 然后修改 Makefile.config 文件，在 caffe 目录下打开该文件： sudo gedit Makefile.config 修改 Makefile.config 文件内容： 将 USE_CUDNN := 1修改成：USE_CUDNN := 1 将 OPENCV_VERSION := 3修改为：OPENCV_VERSION := 3 将 WITH_PYTHON_LAYER := 1修改为WITH_PYTHON_LAYER := 1 将 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib 修改为： INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial 然后修改 caffe 目录下的 Makefile 文件：将： NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS) 替换为： NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS) 将： LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5 改为： LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial 然后修改 /usr/local/cuda/include/host_config.h 文件 : 将 `#error-- unsupported GNU version! gcc versions later than 4.9 are not` supported! 改为 //#error-- unsupported GNU version! gcc versions later than 4.9 are not supported! 编译caffe键入以下命令： make all -j8 这里的-j后面的参数试你电脑的配置决定PS:后期有几位小伙伴按照上面的配置之后在make这里报错，贴出几个常见的报错信息及解决方案：1： error while loading shared libraries: libopencv_core.so.2.2: cannot open shared object file: No such file or directory 注：每个人的libopencv_core.so后面的数字不一样，但是大概是这个么个报错解决方案1：这个错误可能是因为你没有装ffmpeg，输入 sudo apt-get install ffmpeg 安装，安装成功之后再执行make即可。解决方案2：如果使用解决方案1无效，则：在/usr/local/lib下搜索报错信息中的.so文件（比如示例报错信息就是搜索libopencv_core.so.2.2），如果找到该共享库的话，那么在/etc/ld.so.conf.d/xxxx.conf注意（xxxx.conf）是你自己命名的。比如我缺少opencv库 那么我就写opencv.conf。接下来，就在xxxx.conf文件中写path路径，比如说共享库在/usr/local/opencv/libopencv_core.so.2.4中的话，你就写/usr/local/opencv/最后 sudo ldconfig -v 如果有共享库输出的话，就证明成功了。2：fatal error: hdf5.h解决方案：在Makefile.config文件中把下面第一行代码改为第二行代码： INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include 1 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/ 1 在Makefile文件中把下面第一行代码改为第二行代码。 LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5 1 LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial 1 测试caffe键入以下命令： make runtest -j8 PS:这里可能会出现如下错误： 12error while loading shared libraries: libcudart.so.8.0: cannot open sharedobject file: No such file or directory 解决方案： 1sudo ldconfig /usr/local/cuda/lib64 如果出现类似如下信息则说明caffe配置成功： 至此我们就完成caffe的配置工作了，希望大家可以积极指出本文的不足之处便于笔者改正，不胜感激，最后给出本文的所有资源大礼包，下载链接:https://pan.baidu.com/s/1pKU5hrX 密码: xk5x]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My first hackthon]]></title>
    <url>%2F2017%2F05%2F14%2FMy-first-hackthon%2F</url>
    <content type="text"><![CDATA[参加了由China League Hacking（中国创客联盟）、江苏省品牌学会主办的中国创客联赛南京站2017创客马拉松，在南京碧桂园凤凰城酒店与队友将用花费了24 小时来创作并完成项目，这是第一次参加hackathon比赛，认识了很多优秀的同行，收获满满👍👍👍 大合照 我们的成果 开幕式1 比赛中途小游戏 凌晨四点，持续coding中 凌晨四点，持续coding中 凌晨四点，持续coding中 路演展示]]></content>
  </entry>
  <entry>
    <title><![CDATA[Start university trip]]></title>
    <url>%2F2016%2F09%2F06%2FStart-university-trip%2F</url>
    <content type="text"><![CDATA[正式进入大学了～ 开学典礼 军训 河边美景]]></content>
  </entry>
</search>
